2023-05-28 05:30:58,455 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -                           cfg.name : transformer_c
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -                     cfg.data.train : ../mt-2023-ex05/data/train.de-nl
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -                       cfg.data.dev : ../mt-2023-ex05/data/dev.de-nl
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -                      cfg.data.test : ../mt-2023-ex05/data/test.de-nl
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -       cfg.data.sample_train_subset : 100000
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -             cfg.data.src.normalize : False
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : ../mt-2023-ex05/vocab/vocab-10000-joint.txt
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenizer : moses
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.num_merges : 10000
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : ../mt-2023-ex05/vocab/codes10000.bpe
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.dropout : 0.0
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.model_type : bpe
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : nl
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2023-05-28 05:30:58,455 - INFO - joeynmt.helpers -             cfg.data.trg.normalize : False
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : ../mt-2023-ex05/vocab/vocab-10000-joint.txt
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenizer : moses
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.num_merges : 2000
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : ../mt-2023-ex05/vocab/codes10000.bpe
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.dropout : 0.0
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.model_type : bpe
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/transformer_c
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -             cfg.training.overwrite : True
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2023-05-28 05:30:58,456 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2023-05-28 05:30:58,457 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2023-05-28 05:30:58,457 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2023-05-28 05:30:58,457 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2023-05-28 05:30:58,457 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2023-05-28 05:30:58,457 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2023-05-28 05:30:58,457 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2023-05-28 05:30:58,457 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2023-05-28 05:30:58,457 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2023-05-28 05:30:58,457 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2023-05-28 05:30:58,459 - INFO - joeynmt.data - Building tokenizer...
2023-05-28 05:30:58,502 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses, tokenizer=BPE, separator=@@, dropout=0.0)
2023-05-28 05:30:58,502 - INFO - joeynmt.tokenizers - nl tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses, tokenizer=BPE, separator=@@, dropout=0.0)
2023-05-28 05:30:58,502 - INFO - joeynmt.data - Loading train set...
2023-05-28 05:31:20,160 - INFO - joeynmt.data - Building vocabulary...
2023-05-28 05:31:21,168 - INFO - joeynmt.data - Loading dev set...
2023-05-28 05:31:21,271 - INFO - joeynmt.data - Loading test set...
2023-05-28 05:31:21,439 - INFO - joeynmt.data - Data loaded.
2023-05-28 05:31:21,439 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=216893, src_lang=de, trg_lang=nl, has_trg=True, random_subset=100000)
2023-05-28 05:31:21,440 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1001, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2023-05-28 05:31:21,440 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1779, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2023-05-28 05:31:21,440 - INFO - joeynmt.data - First training example:
	[SRC] Al G@@ ore : Die Ab@@ wen@@ dung der Klima@@ kat@@ astrop@@ he
	[TRG] Al G@@ ore over het af@@ wen@@ den van de klimaat@@ crisis
2023-05-28 05:31:21,440 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) die (5) und (6) der (7) in (8) zu (9) das
2023-05-28 05:31:21,440 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) die (5) und (6) der (7) in (8) zu (9) das
2023-05-28 05:31:21,440 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 9988
2023-05-28 05:31:21,440 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 9988
2023-05-28 05:31:21,442 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-28 05:31:21,508 - INFO - joeynmt.model - Enc-dec model built.
2023-05-28 05:31:21,509 - INFO - joeynmt.model - Total params: 5456128
2023-05-28 05:31:21,509 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2023-05-28 05:31:21,509 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=9988),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=9988),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2023-05-28 05:31:21,510 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2023-05-28 05:31:21,510 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2023-05-28 05:31:21,510 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2023-05-28 05:31:21,510 - INFO - joeynmt.training - EPOCH 1
2023-05-28 05:31:21,535 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=0
2023-05-28 05:31:58,385 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     4.341369, Batch Acc: 0.056111, Tokens per Sec:     1874, Lr: 0.000300
2023-05-28 05:32:33,833 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     4.223673, Batch Acc: 0.090703, Tokens per Sec:     1900, Lr: 0.000300
2023-05-28 05:33:09,341 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     4.177887, Batch Acc: 0.101563, Tokens per Sec:     1988, Lr: 0.000300
2023-05-28 05:33:44,984 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     4.078465, Batch Acc: 0.114100, Tokens per Sec:     1887, Lr: 0.000300
2023-05-28 05:34:20,600 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.957776, Batch Acc: 0.128504, Tokens per Sec:     1855, Lr: 0.000300
2023-05-28 05:34:20,601 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:34:20,601 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:36:12,436 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.04, ppl:  56.74, acc:   0.13, generation: 111.5636[sec], evaluation: 0.0000[sec]
2023-05-28 05:36:12,439 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 05:36:12,611 - INFO - joeynmt.training - Example #0
2023-05-28 05:36:12,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:36:12,611 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:36:12,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'is', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']
2023-05-28 05:36:12,611 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:36:12,611 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:36:12,611 - INFO - joeynmt.training - 	Hypothesis: Ik is de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de
2023-05-28 05:36:12,611 - INFO - joeynmt.training - Example #1
2023-05-28 05:36:12,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 05:36:12,611 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 05:36:12,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'is', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']
2023-05-28 05:36:12,612 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:36:12,612 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:36:12,612 - INFO - joeynmt.training - 	Hypothesis: Ik is de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de
2023-05-28 05:36:12,612 - INFO - joeynmt.training - Example #2
2023-05-28 05:36:12,612 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 05:36:12,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 05:36:12,612 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['We', 'is', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']
2023-05-28 05:36:12,612 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:36:12,612 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:36:12,612 - INFO - joeynmt.training - 	Hypothesis: We is de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de
2023-05-28 05:36:12,612 - INFO - joeynmt.training - Example #3
2023-05-28 05:36:12,612 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 05:36:12,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 05:36:12,612 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['We', 'is', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']
2023-05-28 05:36:12,612 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:36:12,612 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:36:12,612 - INFO - joeynmt.training - 	Hypothesis: We is de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de
2023-05-28 05:36:12,612 - INFO - joeynmt.training - Example #4
2023-05-28 05:36:12,612 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 05:36:12,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 05:36:12,612 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'is', 'het', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']
2023-05-28 05:36:12,613 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:36:12,613 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:36:12,613 - INFO - joeynmt.training - 	Hypothesis: Ik is het de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de
2023-05-28 05:36:47,701 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.865761, Batch Acc: 0.136198, Tokens per Sec:     1895, Lr: 0.000300
2023-05-28 05:37:24,233 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.832825, Batch Acc: 0.150713, Tokens per Sec:     1821, Lr: 0.000300
2023-05-28 05:37:59,316 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.831936, Batch Acc: 0.163117, Tokens per Sec:     1949, Lr: 0.000300
2023-05-28 05:38:34,234 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.785704, Batch Acc: 0.166012, Tokens per Sec:     1940, Lr: 0.000300
2023-05-28 05:39:10,701 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.683556, Batch Acc: 0.169675, Tokens per Sec:     1840, Lr: 0.000300
2023-05-28 05:39:10,702 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:39:10,702 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:41:03,211 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.71, ppl:  41.02, acc:   0.16, generation: 112.3771[sec], evaluation: 0.0000[sec]
2023-05-28 05:41:03,215 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 05:41:03,362 - INFO - joeynmt.training - Example #0
2023-05-28 05:41:03,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:41:03,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:41:03,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'ik', 'ik', 'ik', 'ik', 'ik', 'was', ',', 'en', 'de', 'wereld', ',', 'en', 'de', 'wereld', ',', 'en', 'de', 'wereld', ',', 'en', 'de', 'wereld', ',', 'en', 'de', 'wereld', ',', 'en', 'de', 'wereld', ',', 'en', 'de', 'wereld', ',', 'en', 'de', 'wereld', ',', 'en', 'de', 'wereld', ',', 'en', 'de', 'wereld', ',', 'en', 'de', 'wereld', ',', 'en', 'de', 'wereld', '.', '</s>']
2023-05-28 05:41:03,363 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:41:03,363 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:41:03,363 - INFO - joeynmt.training - 	Hypothesis: Ik heb ik ik ik ik ik was, en de wereld, en de wereld, en de wereld, en de wereld, en de wereld, en de wereld, en de wereld, en de wereld, en de wereld, en de wereld, en de wereld, en de wereld.
2023-05-28 05:41:03,363 - INFO - joeynmt.training - Example #1
2023-05-28 05:41:03,363 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 05:41:03,363 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 05:41:03,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'het', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet']
2023-05-28 05:41:03,363 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:41:03,363 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:41:03,363 - INFO - joeynmt.training - 	Hypothesis: Maar dat het niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet
2023-05-28 05:41:03,363 - INFO - joeynmt.training - Example #2
2023-05-28 05:41:03,363 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 05:41:03,363 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 05:41:03,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', 'een', 'andere', 'van', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']
2023-05-28 05:41:03,363 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:41:03,363 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:41:03,364 - INFO - joeynmt.training - 	Hypothesis: Het is een andere van de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de
2023-05-28 05:41:03,364 - INFO - joeynmt.training - Example #3
2023-05-28 05:41:03,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 05:41:03,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 05:41:03,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', 'de', 'andere', 'van', 'de', 'andere', 'andere', 'andere', 'andere', 'andere', 'van', 'de', 'andere', 'van', 'de', 'andere', 'andere', 'andere', 'andere', 'andere', 'andere', 'andere', 'andere', 'andere', 'andere', 'van', 'de', 'andere', 'van', 'de', 'andere', 'van', 'de', 'andere', 'andere', 'andere', 'andere', 'van', 'de', 'andere', 'van', 'de', 'andere', 'andere', 'andere', 'andere', 'andere', 'van', 'de', 'andere', 'van', 'de', 'andere', 'van', 'de', 'wereld', '.', '</s>']
2023-05-28 05:41:03,364 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:41:03,364 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:41:03,364 - INFO - joeynmt.training - 	Hypothesis: Het is de andere van de andere andere andere andere andere van de andere van de andere andere andere andere andere andere andere andere andere andere van de andere van de andere van de andere andere andere andere van de andere van de andere andere andere andere andere van de andere van de andere van de wereld.
2023-05-28 05:41:03,364 - INFO - joeynmt.training - Example #4
2023-05-28 05:41:03,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 05:41:03,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 05:41:03,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'ik', 'is', 'ik', 'was', ',', 'ik', 'was', ',', 'ik', 'is', ',', 'ik', 'is', ',', 'ik', 'was', ',', 'ik', 'is', '.', '</s>']
2023-05-28 05:41:03,364 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:41:03,364 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:41:03,364 - INFO - joeynmt.training - 	Hypothesis: Ik heb ik is ik was, ik was, ik is, ik is, ik was, ik is.
2023-05-28 05:41:39,935 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.557590, Batch Acc: 0.175172, Tokens per Sec:     1891, Lr: 0.000300
2023-05-28 05:42:17,025 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     3.628801, Batch Acc: 0.178164, Tokens per Sec:     1812, Lr: 0.000300
2023-05-28 05:42:53,517 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     3.540910, Batch Acc: 0.179976, Tokens per Sec:     1831, Lr: 0.000300
2023-05-28 05:43:28,946 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     3.679107, Batch Acc: 0.184334, Tokens per Sec:     1888, Lr: 0.000300
2023-05-28 05:44:04,782 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.465894, Batch Acc: 0.188638, Tokens per Sec:     1896, Lr: 0.000300
2023-05-28 05:44:04,784 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:44:04,784 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:45:56,073 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.58, ppl:  35.92, acc:   0.18, generation: 111.1730[sec], evaluation: 0.0000[sec]
2023-05-28 05:45:56,077 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 05:45:56,242 - INFO - joeynmt.training - Example #0
2023-05-28 05:45:56,243 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:45:56,243 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:45:56,243 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', '.', '</s>']
2023-05-28 05:45:56,243 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:45:56,243 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:45:56,243 - INFO - joeynmt.training - 	Hypothesis: In de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld.
2023-05-28 05:45:56,243 - INFO - joeynmt.training - Example #1
2023-05-28 05:45:56,243 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 05:45:56,243 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 05:45:56,243 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet']
2023-05-28 05:45:56,243 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:45:56,243 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:45:56,243 - INFO - joeynmt.training - 	Hypothesis: Maar niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet
2023-05-28 05:45:56,244 - INFO - joeynmt.training - Example #2
2023-05-28 05:45:56,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 05:45:56,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 05:45:56,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eerste', 'is', 'een', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', '.', '</s>']
2023-05-28 05:45:56,244 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:45:56,244 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:45:56,244 - INFO - joeynmt.training - 	Hypothesis: De eerste is een van de wereld van de wereld van de wereld van de wereld.
2023-05-28 05:45:56,244 - INFO - joeynmt.training - Example #3
2023-05-28 05:45:56,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 05:45:56,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 05:45:56,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'zijn', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']
2023-05-28 05:45:56,244 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:45:56,244 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:45:56,244 - INFO - joeynmt.training - 	Hypothesis: Ze zijn de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de
2023-05-28 05:45:56,244 - INFO - joeynmt.training - Example #4
2023-05-28 05:45:56,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 05:45:56,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 05:45:56,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'wereld', 'is', 'dat', 'ik', 'een', 'van', 'de', 'wereld', 'is', 'dat', 'ik', 'een', 'van', 'de', 'wereld', 'is', '.', '</s>']
2023-05-28 05:45:56,244 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:45:56,244 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:45:56,244 - INFO - joeynmt.training - 	Hypothesis: De wereld is dat ik een van de wereld is dat ik een van de wereld is.
2023-05-28 05:46:32,533 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     3.591821, Batch Acc: 0.200349, Tokens per Sec:     1841, Lr: 0.000300
2023-05-28 05:47:07,860 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     3.457323, Batch Acc: 0.200570, Tokens per Sec:     1899, Lr: 0.000300
2023-05-28 05:47:43,024 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     3.517309, Batch Acc: 0.206641, Tokens per Sec:     1883, Lr: 0.000300
2023-05-28 05:48:18,576 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     3.366902, Batch Acc: 0.207157, Tokens per Sec:     1960, Lr: 0.000300
2023-05-28 05:48:54,504 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     3.224674, Batch Acc: 0.219221, Tokens per Sec:     1823, Lr: 0.000300
2023-05-28 05:48:54,505 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:48:54,505 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:50:41,873 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.44, ppl:  31.11, acc:   0.20, generation: 107.2640[sec], evaluation: 0.0000[sec]
2023-05-28 05:50:41,878 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 05:50:42,059 - INFO - joeynmt.training - Example #0
2023-05-28 05:50:42,059 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:50:42,060 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:50:42,060 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eerste', 'jaar', 'geleden', ',', 'de', 'jaren', 'van', 'de', 'jaren', 'van', 'de', 'jaren', 'van', 'de', 'jaren', 'van', 'de', 'jaren', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'jaren', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'jaren', ',', 'de', 'jaren', ',', 'de', 'jaren', ',', 'de', 'jaren', ',', 'de', 'jaren', '.', '</s>']
2023-05-28 05:50:42,060 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:50:42,060 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:50:42,060 - INFO - joeynmt.training - 	Hypothesis: De eerste jaar geleden, de jaren van de jaren van de jaren van de jaren van de jaren van de wereld van de wereld van de jaren van de wereld van de wereld van de wereld van de wereld van de jaren, de jaren, de jaren, de jaren, de jaren.
2023-05-28 05:50:42,060 - INFO - joeynmt.training - Example #1
2023-05-28 05:50:42,060 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 05:50:42,060 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 05:50:42,060 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'in', 'de', 'wereld', ',', 'maar', 'het', 'niet', 'niet', 'niet', 'niet', '.', '</s>']
2023-05-28 05:50:42,060 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:50:42,060 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:50:42,060 - INFO - joeynmt.training - 	Hypothesis: Maar niet niet niet niet niet niet niet niet niet niet in de wereld, maar het niet niet niet niet.
2023-05-28 05:50:42,060 - INFO - joeynmt.training - Example #2
2023-05-28 05:50:42,060 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 05:50:42,060 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 05:50:42,060 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eerste', 'is', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', '.', '</s>']
2023-05-28 05:50:42,061 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:50:42,061 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:50:42,061 - INFO - joeynmt.training - 	Hypothesis: De eerste is de wereld van de wereld van de wereld van de wereld van de wereld van de wereld.
2023-05-28 05:50:42,061 - INFO - joeynmt.training - Example #3
2023-05-28 05:50:42,061 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 05:50:42,061 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 05:50:42,061 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'zijn', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']
2023-05-28 05:50:42,061 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:50:42,061 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:50:42,061 - INFO - joeynmt.training - 	Hypothesis: Ze zijn de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de de
2023-05-28 05:50:42,061 - INFO - joeynmt.training - Example #4
2023-05-28 05:50:42,061 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 05:50:42,061 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 05:50:42,061 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eerste', 'jaar', ',', 'ik', 'het', 'jaar', 'geleden', ',', 'is', 'een', 'paar', 'jaar', 'geleden', ',', 'een', 'paar', 'jaar', 'geleden', '.', '</s>']
2023-05-28 05:50:42,061 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:50:42,061 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:50:42,061 - INFO - joeynmt.training - 	Hypothesis: De eerste jaar, ik het jaar geleden, is een paar jaar geleden, een paar jaar geleden.
2023-05-28 05:51:19,013 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     3.278508, Batch Acc: 0.226573, Tokens per Sec:     1807, Lr: 0.000300
2023-05-28 05:51:54,879 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     3.455759, Batch Acc: 0.223556, Tokens per Sec:     1853, Lr: 0.000300
2023-05-28 05:52:30,787 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     3.374503, Batch Acc: 0.233063, Tokens per Sec:     1871, Lr: 0.000300
2023-05-28 05:53:08,847 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     3.199130, Batch Acc: 0.237537, Tokens per Sec:     1727, Lr: 0.000300
2023-05-28 05:53:45,484 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     3.212557, Batch Acc: 0.242396, Tokens per Sec:     1814, Lr: 0.000300
2023-05-28 05:53:45,486 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:53:45,486 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:55:18,314 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.28, ppl:  26.46, acc:   0.23, generation: 92.7311[sec], evaluation: 0.0000[sec]
2023-05-28 05:55:18,318 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 05:55:18,491 - INFO - joeynmt.training - Example #0
2023-05-28 05:55:18,491 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:55:18,491 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:55:18,491 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'eerste', 'jaar', 'geleden', ',', 'de', 'eerste', 'jaar', 'geleden', ',', 'de', 'eerste', 'jaar', 'geleden', ',', 'de', 'eerste', 'eerste', 'jaar', 'geleden', ',', 'de', 'eerste', 'jaar', 'geleden', ',', 'de', 'de', 'de', 'de', 'de', 'eerste', 'jaar', 'geleden', ',', 'de', 'de', 'de', 'de', 'eerste', 'jaar', '.', '</s>']
2023-05-28 05:55:18,491 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:55:18,491 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:55:18,491 - INFO - joeynmt.training - 	Hypothesis: In de eerste jaar geleden, de eerste jaar geleden, de eerste jaar geleden, de eerste eerste jaar geleden, de eerste jaar geleden, de de de de de eerste jaar geleden, de de de de eerste jaar.
2023-05-28 05:55:18,491 - INFO - joeynmt.training - Example #1
2023-05-28 05:55:18,491 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 05:55:18,491 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 05:55:18,491 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'is', 'niet', 'niet', 'niet', 'niet', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', ',', 'niet', 'meer', 'meer', 'meer', ',', 'niet', 'niet', '.', '</s>']
2023-05-28 05:55:18,492 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:55:18,492 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:55:18,492 - INFO - joeynmt.training - 	Hypothesis: Maar het is niet niet niet niet de wereld van de wereld van de wereld, niet meer meer meer, niet niet.
2023-05-28 05:55:18,492 - INFO - joeynmt.training - Example #2
2023-05-28 05:55:18,492 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 05:55:18,492 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 05:55:18,492 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'meeste', 'is', 'de', 'de', 'de', 'de', 'wereld', 'van', 'de', 'wereld', '.', '</s>']
2023-05-28 05:55:18,492 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:55:18,492 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:55:18,492 - INFO - joeynmt.training - 	Hypothesis: De meeste is de de de de wereld van de wereld.
2023-05-28 05:55:18,492 - INFO - joeynmt.training - Example #3
2023-05-28 05:55:18,492 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 05:55:18,492 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 05:55:18,492 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'komt', 'in', 'de', 'eerste', ',', 'en', 'de', 'eerste', 'is', 'het', '.', '</s>']
2023-05-28 05:55:18,492 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:55:18,492 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:55:18,492 - INFO - joeynmt.training - 	Hypothesis: Ze komt in de eerste, en de eerste is het.
2023-05-28 05:55:18,492 - INFO - joeynmt.training - Example #4
2023-05-28 05:55:18,492 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 05:55:18,492 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 05:55:18,492 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eerste', 'van', 'de', 'eerste', 'van', 'de', 'eerste', 'van', 'de', 'eerste', 'jaar', '.', '</s>']
2023-05-28 05:55:18,493 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:55:18,493 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:55:18,493 - INFO - joeynmt.training - 	Hypothesis: De eerste van de eerste van de eerste van de eerste jaar.
2023-05-28 05:55:54,360 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     3.111276, Batch Acc: 0.250972, Tokens per Sec:     1834, Lr: 0.000300
2023-05-28 05:56:30,765 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     3.046976, Batch Acc: 0.260175, Tokens per Sec:     1889, Lr: 0.000300
2023-05-28 05:57:06,445 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     3.053649, Batch Acc: 0.264727, Tokens per Sec:     1886, Lr: 0.000300
2023-05-28 05:57:41,742 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     3.086493, Batch Acc: 0.270554, Tokens per Sec:     1853, Lr: 0.000300
2023-05-28 05:58:18,324 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.800837, Batch Acc: 0.276971, Tokens per Sec:     1874, Lr: 0.000300
2023-05-28 05:58:18,325 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:58:18,325 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:59:19,375 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.12, ppl:  22.64, acc:   0.26, generation: 60.9564[sec], evaluation: 0.0000[sec]
2023-05-28 05:59:19,378 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 05:59:19,547 - INFO - joeynmt.helpers - delete models/transformer_c/500.ckpt
2023-05-28 05:59:19,559 - INFO - joeynmt.training - Example #0
2023-05-28 05:59:19,559 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:59:19,559 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:59:19,559 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'een', 'paar', 'jaar', 'geleden', 'om', 'deze', 'twee', 'jaar', 'te', 'zien', 'om', 'te', 'zien', 'dat', 'de', 'jaren', 'van', 'de', 'VS', ',', 'die', 'de', 'jaren', ',', 'die', 'de', 'jaren', 'jaren', ',', 'die', 'de', 'jaren', 'jaren', '.', '</s>']
2023-05-28 05:59:19,560 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:59:19,560 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:59:19,560 - INFO - joeynmt.training - 	Hypothesis: Ik heb een paar jaar geleden om deze twee jaar te zien om te zien dat de jaren van de VS, die de jaren, die de jaren jaren, die de jaren jaren.
2023-05-28 05:59:19,560 - INFO - joeynmt.training - Example #1
2023-05-28 05:59:19,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 05:59:19,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 05:59:19,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'is', 'niet', 'dat', 'de', 'de', 'voor@@', 'kant', 'van', 'de', 'voor@@', 'kant', 'van', 'de', 'voor@@', 'kant', 'van', 'de', 'aarde', 'niet', 'in', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', '.', '</s>']
2023-05-28 05:59:19,560 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:59:19,560 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:59:19,560 - INFO - joeynmt.training - 	Hypothesis: Maar het is niet dat de de voorkant van de voorkant van de voorkant van de aarde niet in de de de de de de de de de de de de de.
2023-05-28 05:59:19,560 - INFO - joeynmt.training - Example #2
2023-05-28 05:59:19,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 05:59:19,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 05:59:19,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'andere', 'kant', 'is', 'de', 'de', 'de', 'de', 'de', 'de', 'grootste', 'kant', 'van', 'de', 'economie', '.', '</s>']
2023-05-28 05:59:19,560 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:59:19,560 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:59:19,560 - INFO - joeynmt.training - 	Hypothesis: In de andere kant is de de de de de de grootste kant van de economie.
2023-05-28 05:59:19,560 - INFO - joeynmt.training - Example #3
2023-05-28 05:59:19,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 05:59:19,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 05:59:19,561 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'in', 'de', 'sp@@', 'oren', 'en', 'in', 'de', 'k@@', 'é', '.', '</s>']
2023-05-28 05:59:19,561 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:59:19,561 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:59:19,561 - INFO - joeynmt.training - 	Hypothesis: Ze in de sporen en in de ké.
2023-05-28 05:59:19,561 - INFO - joeynmt.training - Example #4
2023-05-28 05:59:19,561 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 05:59:19,561 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 05:59:19,561 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eerste', 'jaar', ',', 'de', 'eerste', 'keer', 'dat', 'ik', 'een', 'paar', 'jaar', 'geleden', 'is', ',', 'een', 'paar', 'jaar', '.', '</s>']
2023-05-28 05:59:19,561 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:59:19,561 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:59:19,561 - INFO - joeynmt.training - 	Hypothesis: De eerste jaar, de eerste keer dat ik een paar jaar geleden is, een paar jaar.
2023-05-28 05:59:56,594 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     3.046056, Batch Acc: 0.279376, Tokens per Sec:     1797, Lr: 0.000300
2023-05-28 06:00:33,357 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.937587, Batch Acc: 0.286377, Tokens per Sec:     1812, Lr: 0.000300
2023-05-28 06:01:11,022 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.744981, Batch Acc: 0.291482, Tokens per Sec:     1777, Lr: 0.000300
2023-05-28 06:01:45,614 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.901025, Batch Acc: 0.294305, Tokens per Sec:     1920, Lr: 0.000300
2023-05-28 06:02:21,958 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.874330, Batch Acc: 0.302220, Tokens per Sec:     1921, Lr: 0.000300
2023-05-28 06:02:21,960 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:02:21,960 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 06:04:11,654 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.99, ppl:  19.79, acc:   0.28, generation: 109.5859[sec], evaluation: 0.0000[sec]
2023-05-28 06:04:11,659 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 06:04:11,793 - INFO - joeynmt.helpers - delete models/transformer_c/1000.ckpt
2023-05-28 06:04:11,808 - INFO - joeynmt.training - Example #0
2023-05-28 06:04:11,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 06:04:11,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 06:04:11,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'jaren', 'geleden', 'werd', 'ik', 'deze', 'twee', 'jaar', 'geleden', 'om', 'de', 'twee', 'jaar', 'te', 'maken', ',', 'die', 'de', 'meeste', 'mensen', 'die', 'de', 'grootste', 'van', 'de', 'jaren', ',', 'die', 'de', 'jaren', 'jaren', 'jaren', ',', 'die', 'de', 'jaren', 'jaren', 'jaren', ',', 'die', 'de', 'jaren', 'had', ',', 'is', 'er', 'er', 'een', 'land', 'van', 'de', 'eerste', 'procent', 'van', 'de', 'VS', '.', '</s>']
2023-05-28 06:04:11,809 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 06:04:11,809 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 06:04:11,809 - INFO - joeynmt.training - 	Hypothesis: De jaren geleden werd ik deze twee jaar geleden om de twee jaar te maken, die de meeste mensen die de grootste van de jaren, die de jaren jaren jaren, die de jaren jaren jaren, die de jaren had, is er er een land van de eerste procent van de VS.
2023-05-28 06:04:11,809 - INFO - joeynmt.training - Example #1
2023-05-28 06:04:11,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 06:04:11,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 06:04:11,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'is', 'niet', 'niet', 'goed', 'goed', 'voor', 'deze', 'kleine', 'kleine', 'kleine', 'kleine', 'kleine', 'grote', 'grote', 'grote', 'grote', ',', 'het', 'niet', 'de', 'b@@', 'ellen', 'niet', 'de', 'de', 'rest', 'van', 'de', 'de', 'de', 'b@@', 'ellen', '.', '</s>']
2023-05-28 06:04:11,809 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 06:04:11,809 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 06:04:11,809 - INFO - joeynmt.training - 	Hypothesis: Maar het is niet niet goed goed voor deze kleine kleine kleine kleine kleine grote grote grote grote, het niet de bellen niet de de rest van de de de bellen.
2023-05-28 06:04:11,809 - INFO - joeynmt.training - Example #2
2023-05-28 06:04:11,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 06:04:11,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 06:04:11,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'hele', 'wereld', 'is', 'een', 'grote', 'grote', 'in@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', 'in@@', '-@@', 'in@@', '-@@', 'in@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@', '-@@']
2023-05-28 06:04:11,810 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 06:04:11,810 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 06:04:11,810 - INFO - joeynmt.training - 	Hypothesis: In de hele wereld is een grote grote in-------------------------------------------------in-in-in------------------------------
2023-05-28 06:04:11,810 - INFO - joeynmt.training - Example #3
2023-05-28 06:04:11,810 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 06:04:11,810 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 06:04:11,810 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gaan', 'in', 'de', 'b@@', 'ellen', 'en', 'p@@', '-@@', '-@@', 'b@@', 'ellen', 'in', 'de', 'b@@', 'ellen', '.', '</s>']
2023-05-28 06:04:11,810 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 06:04:11,810 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 06:04:11,810 - INFO - joeynmt.training - 	Hypothesis: Ze gaan in de bellen en p--bellen in de bellen.
2023-05-28 06:04:11,810 - INFO - joeynmt.training - Example #4
2023-05-28 06:04:11,810 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 06:04:11,810 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 06:04:11,810 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'volgende', 'keer', 'dat', 'ik', 'jullie', 'jullie', 'een', 'grote', 'grote', 'grote', 'grote', 'grote', ',', 'is', 'een', 'paar', 'jaar', 'geleden', 'is', '.', '</s>']
2023-05-28 06:04:11,810 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 06:04:11,810 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 06:04:11,810 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende keer dat ik jullie jullie een grote grote grote grote grote, is een paar jaar geleden is.
2023-05-28 06:04:27,175 - INFO - joeynmt.training - Epoch   1: total training loss 12356.60
2023-05-28 06:04:27,177 - INFO - joeynmt.training - EPOCH 2
2023-05-28 06:04:27,204 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=1
2023-05-28 06:04:46,997 - INFO - joeynmt.training - Epoch   2, Step:     3600, Batch Loss:     2.910518, Batch Acc: 0.306268, Tokens per Sec:     1856, Lr: 0.000300
2023-05-28 06:05:21,387 - INFO - joeynmt.training - Epoch   2, Step:     3700, Batch Loss:     2.851128, Batch Acc: 0.310996, Tokens per Sec:     1928, Lr: 0.000300
2023-05-28 06:05:57,315 - INFO - joeynmt.training - Epoch   2, Step:     3800, Batch Loss:     2.577290, Batch Acc: 0.321343, Tokens per Sec:     1890, Lr: 0.000300
2023-05-28 06:06:33,711 - INFO - joeynmt.training - Epoch   2, Step:     3900, Batch Loss:     2.608114, Batch Acc: 0.324537, Tokens per Sec:     1848, Lr: 0.000300
2023-05-28 06:07:10,574 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     2.834929, Batch Acc: 0.323671, Tokens per Sec:     1809, Lr: 0.000300
2023-05-28 06:07:10,575 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:07:10,575 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 06:08:18,854 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.87, ppl:  17.59, acc:   0.30, generation: 68.1814[sec], evaluation: 0.0000[sec]
2023-05-28 06:08:18,856 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 06:08:19,019 - INFO - joeynmt.helpers - delete models/transformer_c/1500.ckpt
2023-05-28 06:08:19,038 - INFO - joeynmt.training - Example #0
2023-05-28 06:08:19,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 06:08:19,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 06:08:19,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'feite', 'heb', 'ik', 'deze', 'twee', 'twee', 'dagen', ',', 'om', 'te', 'laten', 'zien', 'dat', 'de', 'in@@', 'stellingen', 'van', 'de', 'meest', 'ge@@', 'ge@@', 'stuur@@', 'd', 'voor', 'de', 'de', 'jaren', 'die', 'de', 'jaren', 'jaren', 'jaren', 'de', '3@@', '.000', 'jaar', 'geleden', ',', 'die', 'de', '3@@', '.000', 'jaar', 'geleden', ',', 'heeft', '.', '</s>']
2023-05-28 06:08:19,038 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 06:08:19,038 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 06:08:19,038 - INFO - joeynmt.training - 	Hypothesis: In feite heb ik deze twee twee dagen, om te laten zien dat de instellingen van de meest gegestuurd voor de de jaren die de jaren jaren jaren de 3.000 jaar geleden, die de 3.000 jaar geleden, heeft.
2023-05-28 06:08:19,038 - INFO - joeynmt.training - Example #1
2023-05-28 06:08:19,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 06:08:19,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 06:08:19,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'genoeg', 'de', 'meest', 'ge@@', 'ge@@', 'stuur@@', 'd', 'van', 'deze', 'problemen', 'van', 'dit', 'soort', 'soort', '.', '</s>']
2023-05-28 06:08:19,039 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 06:08:19,039 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 06:08:19,039 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet genoeg de meest gegestuurd van deze problemen van dit soort soort.
2023-05-28 06:08:19,039 - INFO - joeynmt.training - Example #2
2023-05-28 06:08:19,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 06:08:19,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 06:08:19,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'feite', 'de', 'enorme', 'in@@', 'stellingen', 'van', 'de', 'enorme', 'in@@', 'stellingen', 'van', 'ons', 'leven', '.', '</s>']
2023-05-28 06:08:19,039 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 06:08:19,039 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 06:08:19,039 - INFO - joeynmt.training - 	Hypothesis: In feite de enorme instellingen van de enorme instellingen van ons leven.
2023-05-28 06:08:19,039 - INFO - joeynmt.training - Example #3
2023-05-28 06:08:19,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 06:08:19,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 06:08:19,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gaan', 'in', 'de', 'lucht', 'en', 'de', 'lucht', 'in', 'de', 'lucht', '.', '</s>']
2023-05-28 06:08:19,039 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 06:08:19,039 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 06:08:19,039 - INFO - joeynmt.training - 	Hypothesis: Ze gaan in de lucht en de lucht in de lucht.
2023-05-28 06:08:19,039 - INFO - joeynmt.training - Example #4
2023-05-28 06:08:19,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 06:08:19,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 06:08:19,040 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'volgende', 'volgende', ':', 'de', 'jullie', 'zien', 'is', 'een', 'tijd@@', 'je', ',', 'wat', 'er', 'gebeurt', 'in', 'de', 'laatste', 'laatste', 'jaar', '.', '</s>']
2023-05-28 06:08:19,040 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 06:08:19,040 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 06:08:19,040 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende volgende: de jullie zien is een tijdje, wat er gebeurt in de laatste laatste jaar.
2023-05-28 06:08:54,712 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     2.642190, Batch Acc: 0.328325, Tokens per Sec:     1871, Lr: 0.000300
2023-05-28 06:09:32,066 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     2.747581, Batch Acc: 0.334185, Tokens per Sec:     1802, Lr: 0.000300
2023-05-28 06:10:08,503 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     2.713705, Batch Acc: 0.334242, Tokens per Sec:     1741, Lr: 0.000300
2023-05-28 06:10:44,570 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     2.529491, Batch Acc: 0.333423, Tokens per Sec:     1865, Lr: 0.000300
2023-05-28 06:11:22,006 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     2.420276, Batch Acc: 0.344615, Tokens per Sec:     1769, Lr: 0.000300
2023-05-28 06:11:22,007 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:11:22,007 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 06:12:54,008 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.78, ppl:  16.17, acc:   0.32, generation: 91.8982[sec], evaluation: 0.0000[sec]
2023-05-28 06:12:54,012 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 06:12:54,178 - INFO - joeynmt.helpers - delete models/transformer_c/2000.ckpt
2023-05-28 06:12:54,193 - INFO - joeynmt.training - Example #0
2023-05-28 06:12:54,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 06:12:54,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 06:12:54,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'feite', 'heb', 'ik', 'deze', 'twee', 'twee', 'twee', ',', 'om', 'te', 'kijken', 'naar', 'de', 'grond', 'te', 'kijken', ',', 'die', 'de', 'be@@', 'vat', ',', 'die', 'de', 'be@@', 'vat', ',', 'die', 'in', 'de', 'jaren', 'drie', 'miljoen', ',', 'drie', 'miljoen', ',', 'die', 'de', 'grootste', 'jaar', 'geleden', ',', 'en', 'de', 'grootste', 'grootste', 'grootste', 'grootste', 'grootste', 'jaar', 'geleden', ',', 'om', 'de', 'meest', 'ge@@', 'ge@@', 'ge@@', 'de@@', 'erd', 'te', 'gaan', '.', '</s>']
2023-05-28 06:12:54,193 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 06:12:54,194 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 06:12:54,194 - INFO - joeynmt.training - 	Hypothesis: In feite heb ik deze twee twee twee, om te kijken naar de grond te kijken, die de bevat, die de bevat, die in de jaren drie miljoen, drie miljoen, die de grootste jaar geleden, en de grootste grootste grootste grootste grootste jaar geleden, om de meest gegegedeerd te gaan.
2023-05-28 06:12:54,194 - INFO - joeynmt.training - Example #1
2023-05-28 06:12:54,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 06:12:54,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 06:12:54,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'genoeg', 'de', 'voor@@', 'kant', 'niet', 'genoeg', 'de', 'voor@@', 'zien@@', 'ste', 'technologie', ',', 'want', 'het', 'is', 'niet', 'de', 'p@@', 'ool', 'van', 'de', 'kant', '.', '</s>']
2023-05-28 06:12:54,194 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 06:12:54,194 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 06:12:54,194 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet genoeg de voorkant niet genoeg de voorzienste technologie, want het is niet de pool van de kant.
2023-05-28 06:12:54,194 - INFO - joeynmt.training - Example #2
2023-05-28 06:12:54,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 06:12:54,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 06:12:54,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'feite', 'is', 'de', 'vorm', 'van', 'de', 'grote', 'schaal', 'van', 'het', 'eigen', 'eigen', 'eigen', 'systeem', '.', '</s>']
2023-05-28 06:12:54,194 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 06:12:54,194 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 06:12:54,194 - INFO - joeynmt.training - 	Hypothesis: In feite is de vorm van de grote schaal van het eigen eigen eigen systeem.
2023-05-28 06:12:54,194 - INFO - joeynmt.training - Example #3
2023-05-28 06:12:54,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 06:12:54,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 06:12:54,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'is', 'in', 'de', 'lucht', 'en', 'de', 'b@@', 'b@@', 'r', '.', '</s>']
2023-05-28 06:12:54,195 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 06:12:54,195 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 06:12:54,195 - INFO - joeynmt.training - 	Hypothesis: Ze is in de lucht en de bbr.
2023-05-28 06:12:54,195 - INFO - joeynmt.training - Example #4
2023-05-28 06:12:54,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 06:12:54,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 06:12:54,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'volgende', 'jaar', 'geleden', ',', 'is', 'een', 'grote', 'jaren', 'geleden', ',', 'is', 'een', 'grote', 'jaren', '.', '</s>']
2023-05-28 06:12:54,195 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 06:12:54,195 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 06:12:54,195 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende jaar geleden, is een grote jaren geleden, is een grote jaren.
2023-05-28 06:13:29,968 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     2.755911, Batch Acc: 0.348383, Tokens per Sec:     1826, Lr: 0.000300
2023-05-28 06:14:06,802 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     2.476109, Batch Acc: 0.349045, Tokens per Sec:     1710, Lr: 0.000300
2023-05-28 06:14:43,512 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     2.519129, Batch Acc: 0.356783, Tokens per Sec:     1850, Lr: 0.000300
2023-05-28 06:15:19,897 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     2.633594, Batch Acc: 0.358095, Tokens per Sec:     1870, Lr: 0.000300
2023-05-28 06:15:57,849 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     2.692762, Batch Acc: 0.361690, Tokens per Sec:     1731, Lr: 0.000300
2023-05-28 06:15:57,850 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:15:57,850 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 06:17:29,468 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.70, ppl:  14.85, acc:   0.33, generation: 91.5204[sec], evaluation: 0.0000[sec]
2023-05-28 06:17:29,473 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 06:17:29,626 - INFO - joeynmt.helpers - delete models/transformer_c/2500.ckpt
2023-05-28 06:17:29,643 - INFO - joeynmt.training - Example #0
2023-05-28 06:17:29,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 06:17:29,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 06:17:29,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ten', 'eerste', 'jaar', 'heb', 'ik', 'deze', 'twee', 'twee', 'soorten', 'om', 'te', 'zien', 'dat', 'de', 'on@@', 'afhan@@', 'kelijk@@', 'heid', 'van', 'de', 'grote', 'grote', ',', 'die', 'de', 'grote', 'miljoen', 'jaar', 'geleden', ',', 'de', 'grote', 'miljoen', 'jaar', 'die', 'de', 'grote', 'miljoen', 'jaar', '.', '</s>']
2023-05-28 06:17:29,644 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 06:17:29,644 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 06:17:29,644 - INFO - joeynmt.training - 	Hypothesis: Ten eerste jaar heb ik deze twee twee soorten om te zien dat de onafhankelijkheid van de grote grote, die de grote miljoen jaar geleden, de grote miljoen jaar die de grote miljoen jaar.
2023-05-28 06:17:29,644 - INFO - joeynmt.training - Example #1
2023-05-28 06:17:29,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 06:17:29,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 06:17:29,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'het', 'goed', 'genoeg', 'genoeg', ',', 'omdat', 'het', 'on@@', 'gelijk@@', 'heid', 'van', 'de', 'grote', 'problemen', 'van', 'de', 'ruimte', '.', '</s>']
2023-05-28 06:17:29,644 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 06:17:29,644 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 06:17:29,644 - INFO - joeynmt.training - 	Hypothesis: Maar dat is het goed genoeg genoeg, omdat het ongelijkheid van de grote problemen van de ruimte.
2023-05-28 06:17:29,644 - INFO - joeynmt.training - Example #2
2023-05-28 06:17:29,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 06:17:29,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 06:17:29,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'feite', 'is', 'de', 'voor@@', 'malige', 'de', 'in@@', 'stellingen', 'van', 'onze', 'sociale', 'systemen', '.', '</s>']
2023-05-28 06:17:29,645 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 06:17:29,645 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 06:17:29,645 - INFO - joeynmt.training - 	Hypothesis: In feite is de voormalige de instellingen van onze sociale systemen.
2023-05-28 06:17:29,645 - INFO - joeynmt.training - Example #3
2023-05-28 06:17:29,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 06:17:29,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 06:17:29,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'zijn', 'in', 'de', 'lucht', 'en', 'de', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'b@@', 'and@@', 's@@', 'je', 'in', 'de', 'lucht', '.', '</s>']
2023-05-28 06:17:29,645 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 06:17:29,645 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 06:17:29,645 - INFO - joeynmt.training - 	Hypothesis: Ze zijn in de lucht en de bbbbbbbbandsje in de lucht.
2023-05-28 06:17:29,645 - INFO - joeynmt.training - Example #4
2023-05-28 06:17:29,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 06:17:29,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 06:17:29,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'stap', 'is', 'dat', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'ge@@', 'ge@@', 'de@@', 'erd', 'van', 'de', 'laatste', '20', 'jaar', '.', '</s>']
2023-05-28 06:17:29,645 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 06:17:29,645 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 06:17:29,645 - INFO - joeynmt.training - 	Hypothesis: De volgende stap is dat ik jullie laat zien, is een gegedeerd van de laatste 20 jaar.
2023-05-28 06:18:04,681 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     2.677149, Batch Acc: 0.365515, Tokens per Sec:     1862, Lr: 0.000300
2023-05-28 06:18:38,796 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     2.349155, Batch Acc: 0.375414, Tokens per Sec:     1980, Lr: 0.000300
2023-05-28 06:19:14,760 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     2.273705, Batch Acc: 0.377476, Tokens per Sec:     1912, Lr: 0.000300
2023-05-28 06:19:49,521 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     2.492622, Batch Acc: 0.376374, Tokens per Sec:     1943, Lr: 0.000300
2023-05-28 06:20:25,981 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     2.498738, Batch Acc: 0.380583, Tokens per Sec:     1906, Lr: 0.000300
2023-05-28 06:20:25,982 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:20:25,983 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 06:21:58,725 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.61, ppl:  13.59, acc:   0.35, generation: 92.6426[sec], evaluation: 0.0000[sec]
2023-05-28 06:21:58,729 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 06:21:58,905 - INFO - joeynmt.helpers - delete models/transformer_c/3000.ckpt
2023-05-28 06:21:58,924 - INFO - joeynmt.training - Example #0
2023-05-28 06:21:58,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 06:21:58,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 06:21:58,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'al', 'al', 'deze', 'twee', 'miljoen', 'jaar', 'geleden', 'om', 'te', 'kijken', 'om', 'te', 'kijken', 'naar', 'de', 'on@@', 'voor@@', 'voor@@', 'zien@@', 'ingen', 'van', 'de', '4@@', '8', 'miljoen', 'jaar', 'de', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'pa@@', 'kt', 'door', '40', '%', 'van', 'de', '4@@', '8', '%', 'van', 'de', '4@@', '8', '%', 'van', 'de', '.', '</s>']
2023-05-28 06:21:58,925 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 06:21:58,925 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 06:21:58,925 - INFO - joeynmt.training - 	Hypothesis: Ik heb al al deze twee miljoen jaar geleden om te kijken om te kijken naar de onvoorvoorzieningen van de 48 miljoen jaar de gegegegegegegegegegegegegegegegegegepakt door 40% van de 48% van de 48% van de.
2023-05-28 06:21:58,925 - INFO - joeynmt.training - Example #1
2023-05-28 06:21:58,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 06:21:58,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 06:21:58,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'de', 'voor@@', 'stel@@', 'stel@@', 'baar', 'van', 'dit', 'soort', 'problemen', 'uit', ',', 'omdat', 'het', 'niet', 'zo', 'genoeg', 'is', 'dat', 'het', 'niet', 'erg', 'genoeg', 'is', '.', '</s>']
2023-05-28 06:21:58,925 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 06:21:58,925 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 06:21:58,925 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg de voorstelstelbaar van dit soort problemen uit, omdat het niet zo genoeg is dat het niet erg genoeg is.
2023-05-28 06:21:58,925 - INFO - joeynmt.training - Example #2
2023-05-28 06:21:58,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 06:21:58,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 06:21:58,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'een', 'bepaalde', 'zin', 'is', 'de', 'on@@', 'gelijk@@', 'heid', 'van', 'de', 'in@@', 'struct@@', 'ie', 'van', 'ons', 'menselijke', 'menselijke', 'systemen', '.', '</s>']
2023-05-28 06:21:58,926 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 06:21:58,926 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 06:21:58,926 - INFO - joeynmt.training - 	Hypothesis: In een bepaalde zin is de ongelijkheid van de instructie van ons menselijke menselijke systemen.
2023-05-28 06:21:58,926 - INFO - joeynmt.training - Example #3
2023-05-28 06:21:58,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 06:21:58,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 06:21:58,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'onen', 'in', 'de', 'win@@', 'ter', 'en', 'de', 'b@@', 'ou@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'w@@', 'oud', '.', '</s>']
2023-05-28 06:21:58,926 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 06:21:58,926 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 06:21:58,926 - INFO - joeynmt.training - 	Hypothesis: Ze wonen in de winter en de boudddddwoud.
2023-05-28 06:21:58,926 - INFO - joeynmt.training - Example #4
2023-05-28 06:21:58,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 06:21:58,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 06:21:58,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', ':', 'de', 'volgende', ':', 'de', 'volgende', 'generatie', ',', 'is', 'een', 'ge@@', 'ge@@', 'pa@@', 'kt', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 06:21:58,926 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 06:21:58,926 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 06:21:58,926 - INFO - joeynmt.training - 	Hypothesis: De volgende: de volgende: de volgende generatie, is een gegepakt wat er in de afgelopen 25 jaar.
2023-05-28 06:22:33,649 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     2.442436, Batch Acc: 0.387466, Tokens per Sec:     1915, Lr: 0.000300
2023-05-28 06:23:08,492 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     2.422532, Batch Acc: 0.389366, Tokens per Sec:     1917, Lr: 0.000300
2023-05-28 06:23:43,630 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     2.433484, Batch Acc: 0.388392, Tokens per Sec:     1918, Lr: 0.000300
2023-05-28 06:24:20,128 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     2.382542, Batch Acc: 0.397820, Tokens per Sec:     1845, Lr: 0.000300
2023-05-28 06:24:55,314 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     2.398455, Batch Acc: 0.395502, Tokens per Sec:     1905, Lr: 0.000300
2023-05-28 06:24:55,315 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:24:55,315 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 06:26:15,666 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.53, ppl:  12.50, acc:   0.37, generation: 80.2501[sec], evaluation: 0.0000[sec]
2023-05-28 06:26:15,669 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 06:26:15,940 - INFO - joeynmt.helpers - delete models/transformer_c/3500.ckpt
2023-05-28 06:26:15,955 - INFO - joeynmt.training - Example #0
2023-05-28 06:26:15,955 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 06:26:15,955 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 06:26:15,956 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eerste', 'jaar', 'heb', 'ik', 'deze', 'twee', 'soorten', 'die', 'uit@@', 'zien', ',', 'om', 'de', 'meest', 'ge@@', 'ge@@', 'ge@@', 'de@@', 'erd', 'te', 'zijn', 'voor', 'de', 'uit@@', 'brei@@', 'den', 'van', 'de', '4@@', '8', 'jaar', ',', 'de', 'meest', 'meest', 'ge@@', 'ge@@', 've@@', 'chten', 'van', '4@@', '8', 'jaar', ',', 'om', '40', 'procent', 'van', 'de', 'VS', '.', '</s>']
2023-05-28 06:26:15,956 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 06:26:15,956 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 06:26:15,956 - INFO - joeynmt.training - 	Hypothesis: De eerste jaar heb ik deze twee soorten die uitzien, om de meest gegegedeerd te zijn voor de uitbreiden van de 48 jaar, de meest meest gegevechten van 48 jaar, om 40 procent van de VS.
2023-05-28 06:26:15,956 - INFO - joeynmt.training - Example #1
2023-05-28 06:26:15,956 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 06:26:15,956 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 06:26:15,956 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'de', 'voor@@', 'kant', 'niet', 'genoeg', 'genoeg', 'is', 'om', 'dit', 'soort', 'soort', 'problemen', 'uit', 'te', 'leggen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'raa@@', 'g', 'van', 'de', 'ruimte', 'van', 'de', 'ruimte', '.', '</s>']
2023-05-28 06:26:15,956 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 06:26:15,956 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 06:26:15,956 - INFO - joeynmt.training - 	Hypothesis: Maar dat de voorkant niet genoeg genoeg is om dit soort soort problemen uit te leggen, omdat het niet de dikraag van de ruimte van de ruimte.
2023-05-28 06:26:15,956 - INFO - joeynmt.training - Example #2
2023-05-28 06:26:15,956 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 06:26:15,956 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 06:26:15,956 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'c@@', 'c@@', 'us', 'het', 'hart', 'van', 'het', 'hart', 'van', 'klimaat@@', 'verandering', '.', '</s>']
2023-05-28 06:26:15,957 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 06:26:15,957 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 06:26:15,957 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arcccus het hart van het hart van klimaatverandering.
2023-05-28 06:26:15,957 - INFO - joeynmt.training - Example #3
2023-05-28 06:26:15,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 06:26:15,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 06:26:15,957 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'onen', 'in', 'de', 'wind', 'en', 'sch@@', 'ij@@', 'f', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 06:26:15,957 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 06:26:15,957 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 06:26:15,957 - INFO - joeynmt.training - 	Hypothesis: Ze wonen in de wind en schijf in de zomer.
2023-05-28 06:26:15,957 - INFO - joeynmt.training - Example #4
2023-05-28 06:26:15,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 06:26:15,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 06:26:15,957 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'van', 'de', 'volgende', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 06:26:15,957 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 06:26:15,957 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 06:26:15,957 - INFO - joeynmt.training - 	Hypothesis: De volgende van de volgende van de laatste 25 jaar.
2023-05-28 06:26:52,397 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     2.320875, Batch Acc: 0.400978, Tokens per Sec:     1838, Lr: 0.000300
2023-05-28 06:27:29,802 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     2.391465, Batch Acc: 0.400468, Tokens per Sec:     1850, Lr: 0.000300
2023-05-28 06:28:05,912 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     2.270789, Batch Acc: 0.408695, Tokens per Sec:     1898, Lr: 0.000300
2023-05-28 06:28:41,388 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     2.365548, Batch Acc: 0.407134, Tokens per Sec:     1857, Lr: 0.000300
2023-05-28 06:29:18,530 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     2.286912, Batch Acc: 0.411103, Tokens per Sec:     1780, Lr: 0.000300
2023-05-28 06:29:18,531 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:29:18,531 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 06:30:42,295 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.47, ppl:  11.83, acc:   0.39, generation: 83.6648[sec], evaluation: 0.0000[sec]
2023-05-28 06:30:42,297 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 06:30:42,459 - INFO - joeynmt.helpers - delete models/transformer_c/4000.ckpt
2023-05-28 06:30:42,477 - INFO - joeynmt.training - Example #0
2023-05-28 06:30:42,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 06:30:42,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 06:30:42,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'jaar', 'geleden', 'heb', 'ik', 'deze', 'twee', 'keer', 'ge@@', 'ge@@', 'p@@', 'eerd', 'om', 'te', 'ver@@', 'laten', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'iteit', 'van', 'de', 'b@@', 'ellen', 'die', 'voor', 'een', 'aantal', 'jaar', 'van', 'de', 'meest', 'meest', 'meest', 'meest', 'ge@@', 'ge@@', 'gaan', ',', 'die', 'de', 'meest', 'meest', 'meest', 'ge@@', 'ge@@', 'gaan', '.', '</s>']
2023-05-28 06:30:42,477 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 06:30:42,477 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 06:30:42,477 - INFO - joeynmt.training - 	Hypothesis: Het jaar geleden heb ik deze twee keer gegepeerd om te verlaten zien dat de arciteit van de bellen die voor een aantal jaar van de meest meest meest meest gegegaan, die de meest meest meest gegegaan.
2023-05-28 06:30:42,477 - INFO - joeynmt.training - Example #1
2023-05-28 06:30:42,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 06:30:42,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 06:30:42,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'dat', 'de', 'meest', 'meest', 'ge@@', 'ge@@', 'creë@@', 'erd', 'zijn', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'k@@', 'aal', 'is', '.', '</s>']
2023-05-28 06:30:42,478 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 06:30:42,478 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 06:30:42,478 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg dat de meest meest gegecreëerd zijn omdat het niet de dikkaal is.
2023-05-28 06:30:42,478 - INFO - joeynmt.training - Example #2
2023-05-28 06:30:42,478 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 06:30:42,478 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 06:30:42,478 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'feite', 'is', 'de', 'ar@@', 'c@@', 'ische', 'ij@@', 'k@@', 'k@@', 'k@@', 'k@@', 'raa@@', 'e', 'het', 'hart', 'van', 'ons', 'klimaat@@', 'klimaat@@', 'verandering', '.', '</s>']
2023-05-28 06:30:42,478 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 06:30:42,478 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 06:30:42,478 - INFO - joeynmt.training - 	Hypothesis: In feite is de arcische ijkkkkraae het hart van ons klimaatklimaatverandering.
2023-05-28 06:30:42,478 - INFO - joeynmt.training - Example #3
2023-05-28 06:30:42,478 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 06:30:42,478 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 06:30:42,478 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', 'de', 'wind', 'en', 'sch@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'ing', 'en', '.', '</s>']
2023-05-28 06:30:42,478 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 06:30:42,478 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 06:30:42,478 - INFO - joeynmt.training - 	Hypothesis: Het is de wind en scheleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleleling en.
2023-05-28 06:30:42,478 - INFO - joeynmt.training - Example #4
2023-05-28 06:30:42,478 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 06:30:42,478 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 06:30:42,478 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'se@@', 'ctor', 'die', 'ik', 'ga', 'tonen', ',', 'is', 'een', 'teken@@', 'ing', 'van', 'wat', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 06:30:42,479 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 06:30:42,479 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 06:30:42,479 - INFO - joeynmt.training - 	Hypothesis: De volgende sector die ik ga tonen, is een tekening van wat in de laatste 25 jaar.
2023-05-28 06:31:18,493 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     2.286201, Batch Acc: 0.413702, Tokens per Sec:     1859, Lr: 0.000300
2023-05-28 06:31:53,851 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     1.872627, Batch Acc: 0.414786, Tokens per Sec:     1920, Lr: 0.000300
2023-05-28 06:32:29,057 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     2.329939, Batch Acc: 0.417487, Tokens per Sec:     1957, Lr: 0.000300
2023-05-28 06:33:04,459 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     2.268488, Batch Acc: 0.421214, Tokens per Sec:     1885, Lr: 0.000300
2023-05-28 06:33:39,722 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     2.256708, Batch Acc: 0.421647, Tokens per Sec:     1899, Lr: 0.000300
2023-05-28 06:33:39,724 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:33:39,724 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 06:34:38,600 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.42, ppl:  11.26, acc:   0.40, generation: 58.7833[sec], evaluation: 0.0000[sec]
2023-05-28 06:34:38,603 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 06:34:38,753 - INFO - joeynmt.helpers - delete models/transformer_c/4500.ckpt
2023-05-28 06:34:38,770 - INFO - joeynmt.training - Example #0
2023-05-28 06:34:38,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 06:34:38,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 06:34:38,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'keer', 'dat', 'de', 'twee', 'keer', ',', 'dat', 'de', 'ar@@', 'c@@', 'c@@', 'us', 'ij@@', 'sk@@', 'appen', ',', 'die', 'voor', 'de', 'uit@@', 'voer@@', 'ing', 'van', 'de', 'meest', 'ver@@', 'jaar@@', 'lijk@@', 'heid', 'van', '4@@', '8', 'miljoen', 'jaar', ',', 'om', '40', 'procent', 'van', 'de', 'VS', 'te', 'ver@@', 'kennen', '.', '</s>']
2023-05-28 06:34:38,770 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 06:34:38,771 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 06:34:38,771 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee keer dat de twee keer, dat de arccus ijskappen, die voor de uitvoering van de meest verjaarlijkheid van 48 miljoen jaar, om 40 procent van de VS te verkennen.
2023-05-28 06:34:38,771 - INFO - joeynmt.training - Example #1
2023-05-28 06:34:38,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 06:34:38,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 06:34:38,771 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'genoeg', 'de', 'meest', 'ge@@', 'wen@@', 'd', 'van', 'dit', 'soort', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'cap@@', 't', '.', '</s>']
2023-05-28 06:34:38,771 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 06:34:38,771 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 06:34:38,771 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet genoeg de meest gewend van dit soort problemen, omdat het niet de dicapt.
2023-05-28 06:34:38,771 - INFO - joeynmt.training - Example #2
2023-05-28 06:34:38,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 06:34:38,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 06:34:38,771 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'c@@', 'us', 'het', 'sch@@', 'ep@@', 'pen', 'van', 'onze', 'klimaat@@', 'verandering', '.', '</s>']
2023-05-28 06:34:38,771 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 06:34:38,771 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 06:34:38,771 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arccus het scheppen van onze klimaatverandering.
2023-05-28 06:34:38,771 - INFO - joeynmt.training - Example #3
2023-05-28 06:34:38,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 06:34:38,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 06:34:38,771 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'zijn', 'in', 'de', 'wind', 'en', 'sch@@', 'aa@@', 'p', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 06:34:38,772 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 06:34:38,772 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 06:34:38,772 - INFO - joeynmt.training - 	Hypothesis: Ze zijn in de wind en schaap in de zomer.
2023-05-28 06:34:38,772 - INFO - joeynmt.training - Example #4
2023-05-28 06:34:38,772 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 06:34:38,772 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 06:34:38,772 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'keer', 'dat', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'foto', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 06:34:38,772 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 06:34:38,772 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 06:34:38,772 - INFO - joeynmt.training - 	Hypothesis: De volgende keer dat ik jullie laat zien, is een foto van de laatste 25 jaar.
2023-05-28 06:35:16,189 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     2.294962, Batch Acc: 0.421766, Tokens per Sec:     1811, Lr: 0.000300
2023-05-28 06:35:20,067 - INFO - joeynmt.training - Epoch   2: total training loss 9037.75
2023-05-28 06:35:20,067 - INFO - joeynmt.training - EPOCH 3
2023-05-28 06:35:20,098 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=2
2023-05-28 06:35:51,934 - INFO - joeynmt.training - Epoch   3, Step:     7200, Batch Loss:     2.273931, Batch Acc: 0.437478, Tokens per Sec:     1865, Lr: 0.000300
2023-05-28 06:36:26,745 - INFO - joeynmt.training - Epoch   3, Step:     7300, Batch Loss:     2.301749, Batch Acc: 0.441622, Tokens per Sec:     1965, Lr: 0.000300
2023-05-28 06:37:01,680 - INFO - joeynmt.training - Epoch   3, Step:     7400, Batch Loss:     2.268039, Batch Acc: 0.441018, Tokens per Sec:     1939, Lr: 0.000300
2023-05-28 06:37:38,617 - INFO - joeynmt.training - Epoch   3, Step:     7500, Batch Loss:     2.400629, Batch Acc: 0.441807, Tokens per Sec:     1782, Lr: 0.000300
2023-05-28 06:37:38,619 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:37:38,619 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 06:38:58,601 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.37, ppl:  10.74, acc:   0.41, generation: 79.8824[sec], evaluation: 0.0000[sec]
2023-05-28 06:38:58,605 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 06:38:58,730 - INFO - joeynmt.helpers - delete models/transformer_c/5000.ckpt
2023-05-28 06:38:58,746 - INFO - joeynmt.training - Example #0
2023-05-28 06:38:58,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 06:38:58,747 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 06:38:58,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'zien', 'om', 'te', 'ver@@', 'kennen', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'k@@', 'k@@', 'ij@@', 'k@@', 'k@@', 'k@@', 'k@@', 'ij@@', 's@@', 's@@', 'de', 'van', 'de', '4@@', '8', 'miljoen', 'jaar', 'die', 'de', 'hoog@@', 'ste', '4@@', '8', 'miljoen', 'jaar', 'die', 'de', 'hoog@@', 'ste', 'van', 'de', 'hoog@@', 'ste', '4@@', '8', '%', 'van', 'de', 'VS', '.', '</s>']
2023-05-28 06:38:58,747 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 06:38:58,747 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 06:38:58,747 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia zien om te verkennen dat de arctische ijkkkijkkkkijssde van de 48 miljoen jaar die de hoogste 48 miljoen jaar die de hoogste van de hoogste 48% van de VS.
2023-05-28 06:38:58,747 - INFO - joeynmt.training - Example #1
2023-05-28 06:38:58,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 06:38:58,747 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 06:38:58,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'in', 'genoeg', 'de', 'voor@@', 'stel@@', 'ijke', 'problemen', 'van', 'dit', 'soort', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'k@@', 'jes', 'van', 'de', 'ij@@', 's@@', 'je', '.', '</s>']
2023-05-28 06:38:58,747 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 06:38:58,747 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 06:38:58,747 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet in genoeg de voorstelijke problemen van dit soort problemen, omdat het niet de dikkjes van de ijsje.
2023-05-28 06:38:58,747 - INFO - joeynmt.training - Example #2
2023-05-28 06:38:58,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 06:38:58,747 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 06:38:58,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'ieke', 'ij@@', 'k@@', 'k@@', 'k@@', 'k@@', 'app@@', 'e', 'het', 'hart', 'van', 'ons', 'wereldwijde', 'klimaat@@', 'verandering', '.', '</s>']
2023-05-28 06:38:58,748 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 06:38:58,748 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 06:38:58,748 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arieke ijkkkkappe het hart van ons wereldwijde klimaatverandering.
2023-05-28 06:38:58,748 - INFO - joeynmt.training - Example #3
2023-05-28 06:38:58,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 06:38:58,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 06:38:58,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', 'in', 'de', 'wind', 'en', 'de', 'b@@', 'lan@@', 'ter', 'van', 'de', 'zom@@', 'er', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 06:38:58,748 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 06:38:58,748 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 06:38:58,748 - INFO - joeynmt.training - 	Hypothesis: Het is in de wind en de blanter van de zomer in de zomer.
2023-05-28 06:38:58,748 - INFO - joeynmt.training - Example #4
2023-05-28 06:38:58,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 06:38:58,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 06:38:58,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'tijden', 'van', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 06:38:58,748 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 06:38:58,748 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 06:38:58,748 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien, is een tijden van de afgelopen 25 jaar.
2023-05-28 06:39:35,163 - INFO - joeynmt.training - Epoch   3, Step:     7600, Batch Loss:     2.199871, Batch Acc: 0.441054, Tokens per Sec:     1856, Lr: 0.000300
2023-05-28 06:40:11,907 - INFO - joeynmt.training - Epoch   3, Step:     7700, Batch Loss:     2.193237, Batch Acc: 0.442165, Tokens per Sec:     1901, Lr: 0.000300
2023-05-28 06:40:47,171 - INFO - joeynmt.training - Epoch   3, Step:     7800, Batch Loss:     2.609880, Batch Acc: 0.446056, Tokens per Sec:     1900, Lr: 0.000300
2023-05-28 06:41:22,887 - INFO - joeynmt.training - Epoch   3, Step:     7900, Batch Loss:     2.292855, Batch Acc: 0.436887, Tokens per Sec:     1907, Lr: 0.000300
2023-05-28 06:41:57,886 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:     2.277475, Batch Acc: 0.444918, Tokens per Sec:     1899, Lr: 0.000300
2023-05-28 06:41:57,887 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:41:57,887 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 06:43:12,733 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.35, ppl:  10.47, acc:   0.41, generation: 74.7481[sec], evaluation: 0.0000[sec]
2023-05-28 06:43:12,735 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 06:43:12,898 - INFO - joeynmt.helpers - delete models/transformer_c/5500.ckpt
2023-05-28 06:43:12,914 - INFO - joeynmt.training - Example #0
2023-05-28 06:43:12,914 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 06:43:12,914 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 06:43:12,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ten', 'eerste', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'laten', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'c@@', 'eu@@', 'tische', 'ij@@', 's@@', 'ij@@', 's@@', 's@@', 's@@', 'ij@@', 's@@', 's@@', 's@@', 'ij@@', 's@@', 's@@', 's@@', 'ij@@', 's@@', 'den', ',', 'die', 'ik', '40', 'procent', 'ge@@', 'to@@', 'ond', 'had', ',', 'om', '40', 'procent', 'van', 'de', 'Verenigde', 'Staten', '.', '</s>']
2023-05-28 06:43:12,915 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 06:43:12,915 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 06:43:12,915 - INFO - joeynmt.training - 	Hypothesis: Ten eerste jaar heb ik deze twee dia getoond om te laten zien dat de arcceutische ijsijsssijsssijsssijsden, die ik 40 procent getoond had, om 40 procent van de Verenigde Staten.
2023-05-28 06:43:12,915 - INFO - joeynmt.training - Example #1
2023-05-28 06:43:12,915 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 06:43:12,915 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 06:43:12,915 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'genoeg', 'de', 'voor@@', 'oor@@', 'ste', 'van', 'dit', 'soort', 'soort', 'problemen', 'van', 'dit', 'soort', 'soort', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'jes', 'van', 'de', 'ij@@', 's@@', 'je', '.', '</s>']
2023-05-28 06:43:12,915 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 06:43:12,915 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 06:43:12,915 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de vooroorste van dit soort soort problemen van dit soort soort problemen, omdat het niet de dikjes van de ijsje.
2023-05-28 06:43:12,915 - INFO - joeynmt.training - Example #2
2023-05-28 06:43:12,915 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 06:43:12,915 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 06:43:12,915 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'c@@', 'op@@', 'e', 'van', 'de', 'wereld', '.', '</s>']
2023-05-28 06:43:12,915 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 06:43:12,916 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 06:43:12,916 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arccope van de wereld.
2023-05-28 06:43:12,916 - INFO - joeynmt.training - Example #3
2023-05-28 06:43:12,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 06:43:12,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 06:43:12,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'zijn', 'in', 'de', 'wind', 'en', 'sch@@', 'aa@@', 'p', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 06:43:12,916 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 06:43:12,916 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 06:43:12,916 - INFO - joeynmt.training - 	Hypothesis: Ze zijn in de wind en schaap in de zomer.
2023-05-28 06:43:12,916 - INFO - joeynmt.training - Example #4
2023-05-28 06:43:12,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 06:43:12,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 06:43:12,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'tijden', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 06:43:12,916 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 06:43:12,916 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 06:43:12,916 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien, is een tijden van de laatste 25 jaar.
2023-05-28 06:43:48,175 - INFO - joeynmt.training - Epoch   3, Step:     8100, Batch Loss:     2.239893, Batch Acc: 0.444234, Tokens per Sec:     1860, Lr: 0.000300
2023-05-28 06:44:28,058 - INFO - joeynmt.training - Epoch   3, Step:     8200, Batch Loss:     2.100796, Batch Acc: 0.443162, Tokens per Sec:     1755, Lr: 0.000300
2023-05-28 06:45:07,128 - INFO - joeynmt.training - Epoch   3, Step:     8300, Batch Loss:     2.125761, Batch Acc: 0.444664, Tokens per Sec:     1721, Lr: 0.000300
2023-05-28 06:45:44,284 - INFO - joeynmt.training - Epoch   3, Step:     8400, Batch Loss:     2.300251, Batch Acc: 0.450483, Tokens per Sec:     1763, Lr: 0.000300
2023-05-28 06:46:20,561 - INFO - joeynmt.training - Epoch   3, Step:     8500, Batch Loss:     2.260458, Batch Acc: 0.447061, Tokens per Sec:     1893, Lr: 0.000300
2023-05-28 06:46:20,562 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:46:20,562 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 06:47:30,588 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.31, ppl:  10.10, acc:   0.42, generation: 69.9288[sec], evaluation: 0.0000[sec]
2023-05-28 06:47:30,591 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 06:47:30,725 - INFO - joeynmt.helpers - delete models/transformer_c/6000.ckpt
2023-05-28 06:47:30,740 - INFO - joeynmt.training - Example #0
2023-05-28 06:47:30,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 06:47:30,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 06:47:30,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', 'een', 'jaar', 'geleden', ',', 'en', 'ik', 'heb', 'deze', 'twee', 'keer', 'ge@@', 'keken', 'om', 'te', 'ver@@', 'kennen', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 's@@', 'oe@@', 'p', 'drie', 'miljoen', 'jaar', ',', 'om', 'de', 'gro@@', 'ten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'miljoen', 'jaar', ',', 'om', 'de', 'hoog@@', 'ste', 'van', 'de', 'stad', 'te', 'ver@@', 'laten', '.', '</s>']
2023-05-28 06:47:30,740 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 06:47:30,740 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 06:47:30,740 - INFO - joeynmt.training - 	Hypothesis: Het is een jaar geleden, en ik heb deze twee keer gekeken om te verkennen dat de arctische ijsssssssssssssoep drie miljoen jaar, om de groten van de onderste 48 miljoen jaar, om de hoogste van de stad te verlaten.
2023-05-28 06:47:30,741 - INFO - joeynmt.training - Example #1
2023-05-28 06:47:30,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 06:47:30,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 06:47:30,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'soort', 'soort', 'soort', 'problemen', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'raa@@', 'i', '.', '</s>']
2023-05-28 06:47:30,741 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 06:47:30,741 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 06:47:30,741 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet erg genoeg de oogst van dit soort soort soort problemen, want het is niet de dikraai.
2023-05-28 06:47:30,741 - INFO - joeynmt.training - Example #2
2023-05-28 06:47:30,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 06:47:30,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 06:47:30,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'us', 'van', 'de', 'mondiale', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 06:47:30,741 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 06:47:30,741 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 06:47:30,741 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arcus van de mondiale klimaatsysteem.
2023-05-28 06:47:30,741 - INFO - joeynmt.training - Example #3
2023-05-28 06:47:30,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 06:47:30,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 06:47:30,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'onden', 'in', 'de', 'wind', 'en', 'sch@@', 'aa@@', 'p', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 06:47:30,741 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 06:47:30,741 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 06:47:30,742 - INFO - joeynmt.training - 	Hypothesis: Ze wonden in de wind en schaap in de zomer.
2023-05-28 06:47:30,742 - INFO - joeynmt.training - Example #4
2023-05-28 06:47:30,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 06:47:30,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 06:47:30,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'je', 'dat', 'de', 'laatste', '25', 'jaar', 'gebeurt', '.', '</s>']
2023-05-28 06:47:30,742 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 06:47:30,742 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 06:47:30,742 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien, is een tijdje dat de laatste 25 jaar gebeurt.
2023-05-28 06:48:09,666 - INFO - joeynmt.training - Epoch   3, Step:     8600, Batch Loss:     2.207977, Batch Acc: 0.447128, Tokens per Sec:     1717, Lr: 0.000300
2023-05-28 06:48:45,238 - INFO - joeynmt.training - Epoch   3, Step:     8700, Batch Loss:     2.209661, Batch Acc: 0.451445, Tokens per Sec:     1883, Lr: 0.000300
2023-05-28 06:49:20,615 - INFO - joeynmt.training - Epoch   3, Step:     8800, Batch Loss:     2.246750, Batch Acc: 0.457598, Tokens per Sec:     1966, Lr: 0.000300
2023-05-28 06:49:55,815 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     1.989456, Batch Acc: 0.450821, Tokens per Sec:     1920, Lr: 0.000300
2023-05-28 06:50:31,155 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     2.196079, Batch Acc: 0.452697, Tokens per Sec:     1958, Lr: 0.000300
2023-05-28 06:50:31,156 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:50:31,157 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 06:51:51,878 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.30, ppl:   9.98, acc:   0.42, generation: 80.6216[sec], evaluation: 0.0000[sec]
2023-05-28 06:51:51,880 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 06:51:51,999 - INFO - joeynmt.helpers - delete models/transformer_c/6500.ckpt
2023-05-28 06:51:52,013 - INFO - joeynmt.training - Example #0
2023-05-28 06:51:52,013 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 06:51:52,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 06:51:52,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', 'zien', 'zien', ',', 'om', 'te', 'ver@@', 'laten', ',', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 's@@', 's@@', 's@@', 'app@@', 'e', ',', 'die', 'voor', 'de', 'meest', 'onder@@', 'ste', 'drie', 'miljoen', 'jaar', 'de', 'gro@@', 'ten@@', 'deels', 'van', 'de', 'onder@@', 'ste', '4@@', '8', '%', 'van', 'de', 'zon', ',', 'om', '40', 'procent', 'van', 'de', 'zon', 'te', 'ver@@', 'kennen', '.', '</s>']
2023-05-28 06:51:52,013 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 06:51:52,013 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 06:51:52,013 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia zien zien, om te verlaten, dat de arctische ijsssappe, die voor de meest onderste drie miljoen jaar de grotendeels van de onderste 48% van de zon, om 40 procent van de zon te verkennen.
2023-05-28 06:51:52,013 - INFO - joeynmt.training - Example #1
2023-05-28 06:51:52,013 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 06:51:52,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 06:51:52,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'specifieke', 'problemen', 'van', 'dit', 'soort', 'problemen', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 'zer', 'laat', '.', '</s>']
2023-05-28 06:51:52,014 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 06:51:52,014 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 06:51:52,014 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo genoeg de oogst van deze specifieke problemen van dit soort problemen, want het is niet de dikke van de ijzer laat.
2023-05-28 06:51:52,014 - INFO - joeynmt.training - Example #2
2023-05-28 06:51:52,014 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 06:51:52,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 06:51:52,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'us', 'van', 'de', 'wereld', 'de', 'wereld', 'van', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 06:51:52,014 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 06:51:52,014 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 06:51:52,014 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arcus van de wereld de wereld van klimaatsysteem.
2023-05-28 06:51:52,014 - INFO - joeynmt.training - Example #3
2023-05-28 06:51:52,014 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 06:51:52,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 06:51:52,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'oon', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'oon', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 06:51:52,014 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 06:51:52,014 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 06:51:52,014 - INFO - joeynmt.training - 	Hypothesis: Ze woon in de winter en schoon in de zomer.
2023-05-28 06:51:52,014 - INFO - joeynmt.training - Example #4
2023-05-28 06:51:52,014 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 06:51:52,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 06:51:52,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'ën@@', 't', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'schrift', 'wat', 'in', 'de', 'afgelopen', '25', 'jaar', 'gebeurd', 'is', '.', '</s>']
2023-05-28 06:51:52,015 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 06:51:52,015 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 06:51:52,015 - INFO - joeynmt.training - 	Hypothesis: De volgende diënt die ik jullie laat zien, is een tijdschrift wat in de afgelopen 25 jaar gebeurd is.
2023-05-28 06:52:28,355 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     1.908354, Batch Acc: 0.455679, Tokens per Sec:     1874, Lr: 0.000300
2023-05-28 06:53:04,712 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     2.306451, Batch Acc: 0.454790, Tokens per Sec:     1854, Lr: 0.000300
2023-05-28 06:53:40,831 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     2.127700, Batch Acc: 0.454729, Tokens per Sec:     1809, Lr: 0.000300
2023-05-28 06:54:15,180 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     2.079724, Batch Acc: 0.457813, Tokens per Sec:     1915, Lr: 0.000300
2023-05-28 06:54:51,011 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     2.092743, Batch Acc: 0.456443, Tokens per Sec:     1941, Lr: 0.000300
2023-05-28 06:54:51,014 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:54:51,014 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 06:55:57,063 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.26, ppl:   9.57, acc:   0.43, generation: 65.9527[sec], evaluation: 0.0000[sec]
2023-05-28 06:55:57,066 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 06:55:57,192 - INFO - joeynmt.helpers - delete models/transformer_c/7000.ckpt
2023-05-28 06:55:57,205 - INFO - joeynmt.training - Example #0
2023-05-28 06:55:57,205 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 06:55:57,205 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 06:55:57,205 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'zien', ',', 'om', 'te', 'ver@@', 'kennen', 'dat', 'de', 'ar@@', 'c@@', 'c@@', 'c@@', 'op@@', 's', ',', 'die', 'voor', 'de', 'meest', 'ge@@', 'plaat@@', 'st', 'van', '4@@', '8', 'jaar', ',', 'de', 'grootste', 'grootste', 'ge@@', 'p@@', 'aard', 'van', 'de', 'grootste', 'st@@', 'aten', 'van', 'de', '4@@', '8', 'procent', '.', '</s>']
2023-05-28 06:55:57,206 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 06:55:57,206 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 06:55:57,206 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia zien, om te verkennen dat de arcccops, die voor de meest geplaatst van 48 jaar, de grootste grootste gepaard van de grootste staten van de 48 procent.
2023-05-28 06:55:57,206 - INFO - joeynmt.training - Example #1
2023-05-28 06:55:57,206 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 06:55:57,206 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 06:55:57,206 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'specifieke', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'de', 'ij@@', 's@@', 'de', 'ij@@', 's@@', 'de', '.', '</s>']
2023-05-28 06:55:57,206 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 06:55:57,206 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 06:55:57,206 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg de oogst van deze specifieke problemen, omdat het niet de dikke ijsde ijsde ijsde.
2023-05-28 06:55:57,206 - INFO - joeynmt.training - Example #2
2023-05-28 06:55:57,206 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 06:55:57,206 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 06:55:57,206 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'c@@', 'c@@', 'eu@@', 'w', 'het', 'is', 'het', 'een', 'grote', 'hart', 'van', 'de', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 06:55:57,207 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 06:55:57,207 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 06:55:57,207 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arccceuw het is het een grote hart van de klimaatsysteem.
2023-05-28 06:55:57,207 - INFO - joeynmt.training - Example #3
2023-05-28 06:55:57,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 06:55:57,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 06:55:57,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'wind', 'en', 'sch@@', 'oon', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 06:55:57,207 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 06:55:57,207 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 06:55:57,207 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de wind en schoon in de zomer.
2023-05-28 06:55:57,207 - INFO - joeynmt.training - Example #4
2023-05-28 06:55:57,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 06:55:57,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 06:55:57,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'schrift', 'wat', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 06:55:57,207 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 06:55:57,210 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 06:55:57,210 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien, is een tijdschrift wat in de afgelopen 25 jaar.
2023-05-28 06:56:34,536 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     2.008401, Batch Acc: 0.457309, Tokens per Sec:     1731, Lr: 0.000300
2023-05-28 06:57:10,739 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     2.217263, Batch Acc: 0.460324, Tokens per Sec:     1852, Lr: 0.000300
2023-05-28 06:57:46,268 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     2.278114, Batch Acc: 0.460453, Tokens per Sec:     1916, Lr: 0.000300
2023-05-28 06:58:22,996 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     1.919106, Batch Acc: 0.462529, Tokens per Sec:     1863, Lr: 0.000300
2023-05-28 06:58:58,482 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     2.321184, Batch Acc: 0.464109, Tokens per Sec:     1849, Lr: 0.000300
2023-05-28 06:58:58,483 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 06:58:58,483 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:00:10,086 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.45, acc:   0.43, generation: 71.5061[sec], evaluation: 0.0000[sec]
2023-05-28 07:00:10,088 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:00:10,230 - INFO - joeynmt.helpers - delete models/transformer_c/7500.ckpt
2023-05-28 07:00:10,246 - INFO - joeynmt.training - Example #0
2023-05-28 07:00:10,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:00:10,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:00:10,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'zien', 'om', 'te', 'ver@@', 'kennen', 'dat', 'de', 'de', 'ar@@', 'c@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'appen', 'die', 'voor', 'de', 'onder@@', 'kant', 'van', 'de', 'drie', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'jaar', ',', 'om', '40', 'procent', 'van', 'de', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', 'van', 'de', 'st@@', 'aten', 'te', 'van', 'de', 'aarde', '.', '</s>']
2023-05-28 07:00:10,246 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:00:10,246 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:00:10,246 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia zien om te verkennen dat de de arcctische ijskappen die voor de onderkant van de drie miljoen jaar de grootte van de onderste 48 jaar, om 40 procent van de staten van de onderste 48 staten, om 40 procent van de staten te van de aarde.
2023-05-28 07:00:10,246 - INFO - joeynmt.training - Example #1
2023-05-28 07:00:10,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:00:10,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:00:10,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st@@', 'st@@', 'icht@@', 'ing', 'van', 'deze', 'specifieke', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 'f', '.', '</s>']
2023-05-28 07:00:10,247 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:00:10,247 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:00:10,247 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg de oogststichting van deze specifieke problemen, omdat het niet de dikke van de ijf.
2023-05-28 07:00:10,247 - INFO - joeynmt.training - Example #2
2023-05-28 07:00:10,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:00:10,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:00:10,247 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'ep@@', 'pen', 'van', 'de', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 07:00:10,247 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:00:10,247 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:00:10,247 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijkappe het scheppen van de wereldwijde klimaatsysteem.
2023-05-28 07:00:10,247 - INFO - joeynmt.training - Example #3
2023-05-28 07:00:10,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:00:10,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:00:10,247 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'onen', 'in', 'de', 'wind', 'en', 'sch@@', 'ru@@', 'p', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:00:10,247 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:00:10,247 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:00:10,247 - INFO - joeynmt.training - 	Hypothesis: Ze wonen in de wind en schrup in de zomer.
2023-05-28 07:00:10,247 - INFO - joeynmt.training - Example #4
2023-05-28 07:00:10,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:00:10,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:00:10,247 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'je', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 07:00:10,247 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:00:10,248 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:00:10,248 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien, is een tijdje van wat er in de laatste 25 jaar.
2023-05-28 07:00:44,739 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     2.128378, Batch Acc: 0.457007, Tokens per Sec:     1842, Lr: 0.000300
2023-05-28 07:01:19,903 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     2.224368, Batch Acc: 0.464019, Tokens per Sec:     1948, Lr: 0.000300
2023-05-28 07:01:55,690 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     1.963759, Batch Acc: 0.456013, Tokens per Sec:     1802, Lr: 0.000300
2023-05-28 07:02:32,798 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     1.988152, Batch Acc: 0.468599, Tokens per Sec:     1828, Lr: 0.000300
2023-05-28 07:03:08,491 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     2.001379, Batch Acc: 0.461622, Tokens per Sec:     1886, Lr: 0.000300
2023-05-28 07:03:08,493 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:03:08,493 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:04:31,296 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.23, ppl:   9.27, acc:   0.44, generation: 82.7062[sec], evaluation: 0.0000[sec]
2023-05-28 07:04:31,300 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:04:31,433 - INFO - joeynmt.helpers - delete models/transformer_c/8000.ckpt
2023-05-28 07:04:31,448 - INFO - joeynmt.training - Example #0
2023-05-28 07:04:31,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:04:31,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:04:31,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'laten', ',', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 's@@', 's@@', 's@@', 's@@', 'oe@@', 'p@@', 'e', ',', 'die', 'drie', 'miljoen', 'jaar', 'de', 'gro@@', 'ten', 'van', 'de', 'gro@@', 'ten', 'van', 'de', 'drie', 'miljoen', 'jaar', ',', 'de', 'gro@@', 'ten', 'van', 'de', 'VS', ',', 'met', '40', 'procent', ',', 'om', '40', 'procent', ',', 'die', 'de', 'grootste', 'ge@@', 'kregen', '.', '</s>']
2023-05-28 07:04:31,449 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:04:31,449 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:04:31,449 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verlaten, dat de arctische ijssssoepe, die drie miljoen jaar de groten van de groten van de drie miljoen jaar, de groten van de VS, met 40 procent, om 40 procent, die de grootste gekregen.
2023-05-28 07:04:31,449 - INFO - joeynmt.training - Example #1
2023-05-28 07:04:31,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:04:31,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:04:31,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'soort', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'ij@@', 'f', 'ij@@', 'f', '.', '</s>']
2023-05-28 07:04:31,449 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:04:31,449 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:04:31,449 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet erg genoeg de oogst van dit soort problemen, omdat het niet de dikke van ijf ijf.
2023-05-28 07:04:31,449 - INFO - joeynmt.training - Example #2
2023-05-28 07:04:31,450 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:04:31,450 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:04:31,450 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 'k@@', 'app@@', 'e', ',', 'het', 'is', 'het', 'meest', 'meest', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 07:04:31,450 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:04:31,450 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:04:31,450 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijkappe, het is het meest meest klimaatsysteem.
2023-05-28 07:04:31,450 - INFO - joeynmt.training - Example #3
2023-05-28 07:04:31,450 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:04:31,450 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:04:31,450 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'mp@@', 'mp@@', 'el', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:04:31,450 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:04:31,450 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:04:31,450 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompmpel in de zomer.
2023-05-28 07:04:31,450 - INFO - joeynmt.training - Example #4
2023-05-28 07:04:31,450 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:04:31,450 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:04:31,450 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'schrift', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 07:04:31,450 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:04:31,450 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:04:31,450 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien, is een tijdschrift wat er in de laatste 25 jaar.
2023-05-28 07:05:08,504 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     1.998253, Batch Acc: 0.462853, Tokens per Sec:     1794, Lr: 0.000300
2023-05-28 07:05:30,098 - INFO - joeynmt.training - Epoch   3: total training loss 7692.38
2023-05-28 07:05:30,099 - INFO - joeynmt.training - EPOCH 4
2023-05-28 07:05:30,131 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=3
2023-05-28 07:05:42,655 - INFO - joeynmt.training - Epoch   4, Step:    10700, Batch Loss:     2.029608, Batch Acc: 0.475885, Tokens per Sec:     2026, Lr: 0.000300
2023-05-28 07:06:17,803 - INFO - joeynmt.training - Epoch   4, Step:    10800, Batch Loss:     1.768126, Batch Acc: 0.474039, Tokens per Sec:     1863, Lr: 0.000300
2023-05-28 07:06:52,256 - INFO - joeynmt.training - Epoch   4, Step:    10900, Batch Loss:     2.141495, Batch Acc: 0.471897, Tokens per Sec:     2000, Lr: 0.000300
2023-05-28 07:07:27,372 - INFO - joeynmt.training - Epoch   4, Step:    11000, Batch Loss:     1.736997, Batch Acc: 0.481269, Tokens per Sec:     1912, Lr: 0.000300
2023-05-28 07:07:27,374 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:07:27,374 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:08:44,654 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.22, ppl:   9.19, acc:   0.44, generation: 77.1852[sec], evaluation: 0.0000[sec]
2023-05-28 07:08:44,658 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:08:44,789 - INFO - joeynmt.helpers - delete models/transformer_c/8500.ckpt
2023-05-28 07:08:44,804 - INFO - joeynmt.training - Example #0
2023-05-28 07:08:44,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:08:44,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:08:44,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'ver@@', 'kennen', ',', 'dat', 'de', 'Arab@@', 'ische', 'ij@@', 'k@@', 'app@@', 'e', ',', 'die', 'voor', 'voor', 'de', 'meest', 'meest', 'onder@@', 'onder@@', 'grond@@', 'stoffen', 'van', '4@@', '8', 'landen', '.', '</s>']
2023-05-28 07:08:44,805 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:08:44,805 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:08:44,805 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te verkennen, dat de Arabische ijkappe, die voor voor de meest meest onderondergrondstoffen van 48 landen.
2023-05-28 07:08:44,805 - INFO - joeynmt.training - Example #1
2023-05-28 07:08:44,805 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:08:44,805 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:08:44,805 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'specifieke', 'problemen', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'f', '.', '</s>']
2023-05-28 07:08:44,805 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:08:44,805 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:08:44,805 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg de oogst van deze specifieke problemen, want het is niet de dikke van het ijf.
2023-05-28 07:08:44,805 - INFO - joeynmt.training - Example #2
2023-05-28 07:08:44,805 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:08:44,805 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:08:44,805 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'ep@@', 'pen', 'van', 'onze', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 07:08:44,805 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:08:44,805 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:08:44,805 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijkappe het scheppen van onze wereldwijde klimaatsysteem.
2023-05-28 07:08:44,805 - INFO - joeynmt.training - Example #3
2023-05-28 07:08:44,805 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:08:44,805 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:08:44,805 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'aa@@', 'p', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:08:44,806 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:08:44,806 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:08:44,806 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schaap in de zomer.
2023-05-28 07:08:44,806 - INFO - joeynmt.training - Example #4
2023-05-28 07:08:44,806 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:08:44,806 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:08:44,806 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'schrift', 'wat', 'in', 'de', 'afgelopen', '25', 'jaar', 'gebeurt', '.', '</s>']
2023-05-28 07:08:44,806 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:08:44,806 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:08:44,806 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien, is een tijdschrift wat in de afgelopen 25 jaar gebeurt.
2023-05-28 07:09:18,815 - INFO - joeynmt.training - Epoch   4, Step:    11100, Batch Loss:     2.088386, Batch Acc: 0.475190, Tokens per Sec:     1931, Lr: 0.000300
2023-05-28 07:09:56,166 - INFO - joeynmt.training - Epoch   4, Step:    11200, Batch Loss:     1.953729, Batch Acc: 0.482462, Tokens per Sec:     1812, Lr: 0.000300
2023-05-28 07:10:31,145 - INFO - joeynmt.training - Epoch   4, Step:    11300, Batch Loss:     2.027225, Batch Acc: 0.479099, Tokens per Sec:     1960, Lr: 0.000300
2023-05-28 07:11:05,762 - INFO - joeynmt.training - Epoch   4, Step:    11400, Batch Loss:     2.192983, Batch Acc: 0.475963, Tokens per Sec:     1900, Lr: 0.000300
2023-05-28 07:11:43,980 - INFO - joeynmt.training - Epoch   4, Step:    11500, Batch Loss:     2.133510, Batch Acc: 0.474019, Tokens per Sec:     1800, Lr: 0.000300
2023-05-28 07:11:43,981 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:11:43,981 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:13:11,075 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.20, ppl:   9.05, acc:   0.44, generation: 86.9949[sec], evaluation: 0.0000[sec]
2023-05-28 07:13:11,079 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:13:11,240 - INFO - joeynmt.helpers - delete models/transformer_c/9000.ckpt
2023-05-28 07:13:11,262 - INFO - joeynmt.training - Example #0
2023-05-28 07:13:11,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:13:11,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:13:11,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', '<unk>', 'ap@@', 'os@@', ';', 's', 'van', 'de', '<unk>', 'ap@@', 'os@@', ';', 'van', 'de', '<unk>', 'ap@@', 'os@@', ';', 'van', '4@@', '8', 'miljoen', 'jaar', 'de', 'gro@@', 'ten', 'van', 'de', 'onder@@', 'kant', 'van', '4@@', '8', 'landen', ',', 'om', '40', 'procent', 'ge@@', 'dood', 'te', 'zijn', '.', '</s>']
2023-05-28 07:13:11,263 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:13:11,263 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:13:11,263 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia <unk> apos; s van de <unk> apos; van de <unk> apos; van 48 miljoen jaar de groten van de onderkant van 48 landen, om 40 procent gedood te zijn.
2023-05-28 07:13:11,263 - INFO - joeynmt.training - Example #1
2023-05-28 07:13:11,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:13:11,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:13:11,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'genoeg', 'de', 'oog@@', 'st', 'dat', 'het', 'niet', 'zo', 'genoeg', 'is', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ijs', '.', '</s>']
2023-05-28 07:13:11,263 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:13:11,263 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:13:11,263 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de oogst dat het niet zo genoeg is, want het is niet de dikke van het ijs.
2023-05-28 07:13:11,263 - INFO - joeynmt.training - Example #2
2023-05-28 07:13:11,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:13:11,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:13:11,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'isch', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'hart', 'van', 'onze', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 07:13:11,264 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:13:11,264 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:13:11,264 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabisch ijkappe het hart van onze wereldwijde klimaatsysteem.
2023-05-28 07:13:11,264 - INFO - joeynmt.training - Example #3
2023-05-28 07:13:11,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:13:11,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:13:11,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'wind', 'en', 'sch@@', 'ru@@', 'p', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:13:11,264 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:13:11,264 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:13:11,264 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de wind en schrup in de zomer.
2023-05-28 07:13:11,264 - INFO - joeynmt.training - Example #4
2023-05-28 07:13:11,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:13:11,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:13:11,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'ent', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', 'tijd@@', 'je', 'dat', 'de', 'laatste', '25', 'jaar', 'gebeurt', '.', '</s>']
2023-05-28 07:13:11,264 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:13:11,264 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:13:11,264 - INFO - joeynmt.training - 	Hypothesis: De volgende dient die ik je laat zien is een tijdje dat de laatste 25 jaar gebeurt.
2023-05-28 07:13:48,887 - INFO - joeynmt.training - Epoch   4, Step:    11600, Batch Loss:     1.958419, Batch Acc: 0.481502, Tokens per Sec:     1762, Lr: 0.000300
2023-05-28 07:14:25,564 - INFO - joeynmt.training - Epoch   4, Step:    11700, Batch Loss:     2.009629, Batch Acc: 0.481709, Tokens per Sec:     1835, Lr: 0.000300
2023-05-28 07:15:00,622 - INFO - joeynmt.training - Epoch   4, Step:    11800, Batch Loss:     1.866918, Batch Acc: 0.480313, Tokens per Sec:     1883, Lr: 0.000300
2023-05-28 07:15:36,236 - INFO - joeynmt.training - Epoch   4, Step:    11900, Batch Loss:     1.848093, Batch Acc: 0.477677, Tokens per Sec:     1872, Lr: 0.000300
2023-05-28 07:16:11,706 - INFO - joeynmt.training - Epoch   4, Step:    12000, Batch Loss:     1.920177, Batch Acc: 0.483006, Tokens per Sec:     1871, Lr: 0.000300
2023-05-28 07:16:11,707 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:16:11,707 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:17:21,159 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.19, ppl:   8.95, acc:   0.45, generation: 69.3588[sec], evaluation: 0.0000[sec]
2023-05-28 07:17:21,163 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:17:21,294 - INFO - joeynmt.helpers - delete models/transformer_c/9500.ckpt
2023-05-28 07:17:21,305 - INFO - joeynmt.training - Example #0
2023-05-28 07:17:21,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:17:21,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:17:21,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 's@@', 's@@', 's@@', 's@@', 'ij@@', 'sk@@', 'sk@@', 'appen', ',', 'die', 'voor', 'een', 'paar', 'miljoen', 'jaar', 'de', 'gro@@', 'ten', 'van', 'de', 'onder@@', 'kant', 'van', 'de', '4@@', '8', 'st@@', 'aten', ',', '40', 'procent', '.', '</s>']
2023-05-28 07:17:21,305 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:17:21,305 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:17:21,306 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien dat de arctische ijssssijskskappen, die voor een paar miljoen jaar de groten van de onderkant van de 48 staten, 40 procent.
2023-05-28 07:17:21,306 - INFO - joeynmt.training - Example #1
2023-05-28 07:17:21,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:17:21,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:17:21,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'veel', 'meer', 'de', 'oog@@', 'st', 'van', 'dit', 'speciale', 'problemen', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 's@@', 's@@', 'je', '.', '</s>']
2023-05-28 07:17:21,306 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:17:21,306 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:17:21,306 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet veel meer de oogst van dit speciale problemen, want het is het niet de dikke van de ijsssje.
2023-05-28 07:17:21,306 - INFO - joeynmt.training - Example #2
2023-05-28 07:17:21,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:17:21,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:17:21,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'appen', 'het', 'sch@@', 'ep@@', 'pen', 'van', 'ons', 'leven', '.', '</s>']
2023-05-28 07:17:21,306 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:17:21,306 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:17:21,306 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappen het scheppen van ons leven.
2023-05-28 07:17:21,306 - INFO - joeynmt.training - Example #3
2023-05-28 07:17:21,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:17:21,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:17:21,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'wind', 'en', 'sch@@', 'aal@@', 'f', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:17:21,307 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:17:21,307 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:17:21,307 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de wind en schaalf in de zomer.
2023-05-28 07:17:21,307 - INFO - joeynmt.training - Example #4
2023-05-28 07:17:21,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:17:21,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:17:21,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tijd@@', 'st@@', 'ip', 'op', 'wat', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 07:17:21,307 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:17:21,307 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:17:21,307 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdstip op wat in de laatste 25 jaar.
2023-05-28 07:17:55,575 - INFO - joeynmt.training - Epoch   4, Step:    12100, Batch Loss:     1.891910, Batch Acc: 0.481964, Tokens per Sec:     1924, Lr: 0.000300
2023-05-28 07:18:31,027 - INFO - joeynmt.training - Epoch   4, Step:    12200, Batch Loss:     2.129907, Batch Acc: 0.473236, Tokens per Sec:     1829, Lr: 0.000300
2023-05-28 07:19:06,879 - INFO - joeynmt.training - Epoch   4, Step:    12300, Batch Loss:     2.047440, Batch Acc: 0.483502, Tokens per Sec:     1856, Lr: 0.000300
2023-05-28 07:19:41,102 - INFO - joeynmt.training - Epoch   4, Step:    12400, Batch Loss:     1.943591, Batch Acc: 0.477305, Tokens per Sec:     1968, Lr: 0.000300
2023-05-28 07:20:15,060 - INFO - joeynmt.training - Epoch   4, Step:    12500, Batch Loss:     2.185992, Batch Acc: 0.477805, Tokens per Sec:     1913, Lr: 0.000300
2023-05-28 07:20:15,061 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:20:15,061 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:21:27,832 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.18, ppl:   8.80, acc:   0.45, generation: 72.6733[sec], evaluation: 0.0000[sec]
2023-05-28 07:21:27,835 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:21:27,964 - INFO - joeynmt.helpers - delete models/transformer_c/10000.ckpt
2023-05-28 07:21:27,979 - INFO - joeynmt.training - Example #0
2023-05-28 07:21:27,979 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:21:27,979 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:21:27,979 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', '<unk>', 'ap@@', 'os@@', ';', 's', 'zien', 'dat', 'de', 'Arab@@', 'ische', 'ij@@', 's@@', 's@@', 's@@', 's@@', 'app@@', 'e', ',', 'die', 'voor', 'de', 'meest', 'drie', 'miljoen', 'jaar', ',', 'de', 'gro@@', 'ten', 'van', 'de', 'gro@@', 'ten', 'van', 'de', 'gro@@', 'ten', '4@@', '8', 'st@@', 'aten', ',', 'ongeveer', '40', 'procent', 'ge@@', 'kregen', '.', '</s>']
2023-05-28 07:21:27,979 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:21:27,979 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:21:27,979 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia <unk> apos; s zien dat de Arabische ijssssappe, die voor de meest drie miljoen jaar, de groten van de groten van de groten 48 staten, ongeveer 40 procent gekregen.
2023-05-28 07:21:27,979 - INFO - joeynmt.training - Example #1
2023-05-28 07:21:27,979 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:21:27,979 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:21:27,979 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'speciale', 'problemen', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'f', '.', '</s>']
2023-05-28 07:21:27,979 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:21:27,980 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:21:27,980 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo genoeg de oogst van dit speciale problemen, want het is niet de dikke van het ijf.
2023-05-28 07:21:27,980 - INFO - joeynmt.training - Example #2
2023-05-28 07:21:27,980 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:21:27,980 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:21:27,980 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 's@@', 's@@', 's@@', 'oe@@', 'p', 'het', 'hart', 'van', 'ons', 'mondiale', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 07:21:27,980 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:21:27,980 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:21:27,980 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijsssoep het hart van ons mondiale klimaatsysteem.
2023-05-28 07:21:27,980 - INFO - joeynmt.training - Example #3
2023-05-28 07:21:27,980 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:21:27,980 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:21:27,980 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'wind', 'en', 'sch@@', 'ru@@', 'p', '.', '</s>']
2023-05-28 07:21:27,980 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:21:27,980 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:21:27,980 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de wind en schrup.
2023-05-28 07:21:27,980 - INFO - joeynmt.training - Example #4
2023-05-28 07:21:27,980 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:21:27,980 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:21:27,980 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tijd@@', 'schrift', 'wat', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 07:21:27,980 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:21:27,981 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:21:27,981 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschrift wat in de laatste 25 jaar.
2023-05-28 07:22:05,754 - INFO - joeynmt.training - Epoch   4, Step:    12600, Batch Loss:     2.026284, Batch Acc: 0.476889, Tokens per Sec:     1772, Lr: 0.000300
2023-05-28 07:22:43,268 - INFO - joeynmt.training - Epoch   4, Step:    12700, Batch Loss:     2.046845, Batch Acc: 0.481284, Tokens per Sec:     1770, Lr: 0.000300
2023-05-28 07:23:20,072 - INFO - joeynmt.training - Epoch   4, Step:    12800, Batch Loss:     2.094307, Batch Acc: 0.477660, Tokens per Sec:     1792, Lr: 0.000300
2023-05-28 07:23:55,789 - INFO - joeynmt.training - Epoch   4, Step:    12900, Batch Loss:     2.019924, Batch Acc: 0.479626, Tokens per Sec:     1864, Lr: 0.000300
2023-05-28 07:24:32,206 - INFO - joeynmt.training - Epoch   4, Step:    13000, Batch Loss:     1.929978, Batch Acc: 0.480394, Tokens per Sec:     1886, Lr: 0.000300
2023-05-28 07:24:32,206 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:24:32,206 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:25:32,719 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.16, ppl:   8.69, acc:   0.45, generation: 60.4183[sec], evaluation: 0.0000[sec]
2023-05-28 07:25:32,721 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:25:32,854 - INFO - joeynmt.helpers - delete models/transformer_c/10500.ckpt
2023-05-28 07:25:32,868 - INFO - joeynmt.training - Example #0
2023-05-28 07:25:32,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:25:32,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:25:32,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'kijken', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 's@@', 's@@', 's@@', 'app@@', 'e', ',', 'die', 'voor', 'een', 'deel', 'van', '4@@', '8', ',', 'drie', 'miljoen', 'jaar', 'de', 'gro@@', 'en', '.', '</s>']
2023-05-28 07:25:32,869 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:25:32,869 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:25:32,869 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te kijken dat de arctische ijsssappe, die voor een deel van 48, drie miljoen jaar de groen.
2023-05-28 07:25:32,869 - INFO - joeynmt.training - Example #1
2023-05-28 07:25:32,869 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:25:32,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:25:32,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'speciale', 'probleem', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 'zer', 'laat', '.', '</s>']
2023-05-28 07:25:32,869 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:25:32,869 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:25:32,869 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet erg genoeg de oogst van dit speciale probleem, omdat het niet de dikke van de ijzer laat.
2023-05-28 07:25:32,869 - INFO - joeynmt.training - Example #2
2023-05-28 07:25:32,869 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:25:32,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:25:32,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'la@@', 'p', 'het', 'hart', 'van', 'ons', 'wereld@@', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 07:25:32,870 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:25:32,870 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:25:32,870 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het schlap het hart van ons wereldklimaatsysteem.
2023-05-28 07:25:32,870 - INFO - joeynmt.training - Example #3
2023-05-28 07:25:32,870 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:25:32,870 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:25:32,870 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'mm@@', 'el@@', 'de', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:25:32,870 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:25:32,870 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:25:32,870 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrommelde in de zomer.
2023-05-28 07:25:32,870 - INFO - joeynmt.training - Example #4
2023-05-28 07:25:32,870 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:25:32,870 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:25:32,870 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'teken@@', 'tr@@', 'ein', 'wat', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 07:25:32,870 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:25:32,870 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:25:32,870 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tekentrein wat in de laatste 25 jaar.
2023-05-28 07:26:10,121 - INFO - joeynmt.training - Epoch   4, Step:    13100, Batch Loss:     1.939288, Batch Acc: 0.486882, Tokens per Sec:     1858, Lr: 0.000300
2023-05-28 07:26:46,045 - INFO - joeynmt.training - Epoch   4, Step:    13200, Batch Loss:     2.005234, Batch Acc: 0.483467, Tokens per Sec:     1898, Lr: 0.000300
2023-05-28 07:27:23,184 - INFO - joeynmt.training - Epoch   4, Step:    13300, Batch Loss:     1.967790, Batch Acc: 0.485773, Tokens per Sec:     1755, Lr: 0.000300
2023-05-28 07:28:00,090 - INFO - joeynmt.training - Epoch   4, Step:    13400, Batch Loss:     1.831663, Batch Acc: 0.482148, Tokens per Sec:     1803, Lr: 0.000300
2023-05-28 07:28:38,801 - INFO - joeynmt.training - Epoch   4, Step:    13500, Batch Loss:     1.973957, Batch Acc: 0.484151, Tokens per Sec:     1745, Lr: 0.000300
2023-05-28 07:28:38,802 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:28:38,802 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:29:48,457 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.15, ppl:   8.55, acc:   0.45, generation: 69.5603[sec], evaluation: 0.0000[sec]
2023-05-28 07:29:48,459 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:29:48,595 - INFO - joeynmt.helpers - delete models/transformer_c/11000.ckpt
2023-05-28 07:29:48,608 - INFO - joeynmt.training - Example #0
2023-05-28 07:29:48,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:29:48,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:29:48,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'dit', 'jaar', 'geleden', ',', 'en', 'ik', 'laat', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', ',', 'die', 'voor', 'voor', 'een', 'deel', 'van', 'de', 'meest', 'meest', 'onder@@', 'ste', '4@@', '8', 'miljoen', 'jaar', 'de', 'gro@@', 'en', 'om', '40', 'procent', 'te', 'ver@@', 'gro@@', 'ten', 'van', 'de', 'gro@@', 'en', '.', '</s>']
2023-05-28 07:29:48,609 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:29:48,609 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:29:48,609 - INFO - joeynmt.training - 	Hypothesis: Ik heb dit jaar geleden, en ik laat zien dat de arctische ijkappe, die voor voor een deel van de meest meest onderste 48 miljoen jaar de groen om 40 procent te vergroten van de groen.
2023-05-28 07:29:48,609 - INFO - joeynmt.training - Example #1
2023-05-28 07:29:48,609 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:29:48,609 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:29:48,609 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'veel', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'specifieke', 'probleem', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'st', '.', '</s>']
2023-05-28 07:29:48,609 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:29:48,609 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:29:48,609 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet veel genoeg de oogst van dit specifieke probleem, want het is niet de dikke van het ijst.
2023-05-28 07:29:48,609 - INFO - joeynmt.training - Example #2
2023-05-28 07:29:48,609 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:29:48,609 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:29:48,609 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'la@@', 'st', 'het', 'hart', 'van', 'ons', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 07:29:48,609 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:29:48,609 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:29:48,609 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het schlast het hart van ons wereldwijde klimaatsysteem.
2023-05-28 07:29:48,609 - INFO - joeynmt.training - Example #3
2023-05-28 07:29:48,609 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:29:48,609 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:29:48,609 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:29:48,610 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:29:48,610 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:29:48,610 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schropen in de zomer.
2023-05-28 07:29:48,610 - INFO - joeynmt.training - Example #4
2023-05-28 07:29:48,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:29:48,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:29:48,610 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', ',', 'is', 'een', 'teken@@', 'ing', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 07:29:48,610 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:29:48,610 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:29:48,610 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien, is een tekening wat er in de afgelopen 25 jaar.
2023-05-28 07:30:26,195 - INFO - joeynmt.training - Epoch   4, Step:    13600, Batch Loss:     2.090740, Batch Acc: 0.492721, Tokens per Sec:     1795, Lr: 0.000300
2023-05-28 07:31:03,617 - INFO - joeynmt.training - Epoch   4, Step:    13700, Batch Loss:     2.215328, Batch Acc: 0.479853, Tokens per Sec:     1807, Lr: 0.000300
2023-05-28 07:31:38,645 - INFO - joeynmt.training - Epoch   4, Step:    13800, Batch Loss:     2.097484, Batch Acc: 0.489757, Tokens per Sec:     1911, Lr: 0.000300
2023-05-28 07:32:14,126 - INFO - joeynmt.training - Epoch   4, Step:    13900, Batch Loss:     1.773697, Batch Acc: 0.486480, Tokens per Sec:     1923, Lr: 0.000300
2023-05-28 07:32:47,951 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     1.913266, Batch Acc: 0.477999, Tokens per Sec:     2000, Lr: 0.000300
2023-05-28 07:32:47,953 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:32:47,953 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:33:37,412 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.14, ppl:   8.52, acc:   0.46, generation: 49.3638[sec], evaluation: 0.0000[sec]
2023-05-28 07:33:37,416 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:33:37,541 - INFO - joeynmt.helpers - delete models/transformer_c/11500.ckpt
2023-05-28 07:33:37,556 - INFO - joeynmt.training - Example #0
2023-05-28 07:33:37,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:33:37,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:33:37,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', '<unk>', 'ap@@', 'os@@', ';', 's', ',', 'om', 'te', 'ver@@', 'kennen', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'iën', 'die', 'voor', 'voor', 'de', 'gro@@', 'en', 'drie', 'miljoen', 'jaar', 'de', 'gro@@', 'en', 'van', 'de', 'grootste', 'grootste', 'grootste', 'grootste', 'grootste', 'gesch@@', 'ool@@', 'de', '.', '</s>']
2023-05-28 07:33:37,557 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:33:37,557 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:33:37,557 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia <unk> apos; s, om te verkennen dat de arctische ijskiën die voor voor de groen drie miljoen jaar de groen van de grootste grootste grootste grootste grootste geschoolde.
2023-05-28 07:33:37,557 - INFO - joeynmt.training - Example #1
2023-05-28 07:33:37,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:33:37,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:33:37,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'specifieke', 'probleem', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'je', '.', '</s>']
2023-05-28 07:33:37,557 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:33:37,557 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:33:37,557 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo genoeg de oogst van dit specifieke probleem, want het is niet de dikke van het ijsje.
2023-05-28 07:33:37,557 - INFO - joeynmt.training - Example #2
2023-05-28 07:33:37,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:33:37,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:33:37,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 'sk@@', 'aar@@', 'tje', 'het', 'sch@@', 'la@@', 'p', 'het', 'hart', 'van', 'ons', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 07:33:37,557 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:33:37,557 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:33:37,557 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijskaartje het schlap het hart van ons klimaatsysteem.
2023-05-28 07:33:37,557 - INFO - joeynmt.training - Example #3
2023-05-28 07:33:37,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:33:37,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:33:37,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'wind', 'en', 'sch@@', 'aal@@', 'f', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:33:37,558 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:33:37,558 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:33:37,558 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de wind en schaalf in de zomer.
2023-05-28 07:33:37,558 - INFO - joeynmt.training - Example #4
2023-05-28 07:33:37,558 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:33:37,558 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:33:37,558 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'zal', 'laten', 'zien', 'is', 'een', 'tijd@@', 'je', 'van', 'wat', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 07:33:37,558 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:33:37,562 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:33:37,562 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik zal laten zien is een tijdje van wat in de laatste 25 jaar is.
2023-05-28 07:34:12,894 - INFO - joeynmt.training - Epoch   4, Step:    14100, Batch Loss:     1.838646, Batch Acc: 0.486317, Tokens per Sec:     1881, Lr: 0.000300
2023-05-28 07:34:46,975 - INFO - joeynmt.training - Epoch   4, Step:    14200, Batch Loss:     1.950618, Batch Acc: 0.480885, Tokens per Sec:     1965, Lr: 0.000300
2023-05-28 07:34:57,357 - INFO - joeynmt.training - Epoch   4: total training loss 7189.48
2023-05-28 07:34:57,357 - INFO - joeynmt.training - EPOCH 5
2023-05-28 07:34:57,388 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=4
2023-05-28 07:35:23,377 - INFO - joeynmt.training - Epoch   5, Step:    14300, Batch Loss:     1.883829, Batch Acc: 0.505665, Tokens per Sec:     1825, Lr: 0.000300
2023-05-28 07:35:57,754 - INFO - joeynmt.training - Epoch   5, Step:    14400, Batch Loss:     1.728757, Batch Acc: 0.499212, Tokens per Sec:     1937, Lr: 0.000300
2023-05-28 07:36:33,016 - INFO - joeynmt.training - Epoch   5, Step:    14500, Batch Loss:     2.116022, Batch Acc: 0.495192, Tokens per Sec:     1923, Lr: 0.000300
2023-05-28 07:36:33,017 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:36:33,017 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:37:32,440 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.13, ppl:   8.46, acc:   0.45, generation: 59.3266[sec], evaluation: 0.0000[sec]
2023-05-28 07:37:32,442 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:37:32,580 - INFO - joeynmt.helpers - delete models/transformer_c/12000.ckpt
2023-05-28 07:37:32,595 - INFO - joeynmt.training - Example #0
2023-05-28 07:37:32,596 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:37:32,596 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:37:32,596 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'gevolgen', 'om', 'te', 'ver@@', 'kennen', 'dat', 'de', 'Arab@@', 'ische', 'ij@@', 'sk@@', 'app@@', 'e', 'die', 'voor', 'de', 'meest', 'van', '4@@', '8', 'st@@', 'aten', ',', 'die', 'de', 'grootte', 'van', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'wen@@', 'd', '.', '</s>']
2023-05-28 07:37:32,596 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:37:32,596 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:37:32,596 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen om te verkennen dat de Arabische ijskappe die voor de meest van 48 staten, die de grootte van 48 staten had gewend.
2023-05-28 07:37:32,596 - INFO - joeynmt.training - Example #1
2023-05-28 07:37:32,596 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:37:32,596 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:37:32,596 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'veel', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'specifieke', 'probleem', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'je', 'laat', 'zien', '.', '</s>']
2023-05-28 07:37:32,596 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:37:32,596 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:37:32,596 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet veel genoeg de oogst van dit specifieke probleem, omdat het niet de dikke van het ijsje laat zien.
2023-05-28 07:37:32,596 - INFO - joeynmt.training - Example #2
2023-05-28 07:37:32,596 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:37:32,596 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:37:32,596 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'la@@', 'st', 'het', 's@@', 's@@', 's@@', 'oe@@', 'p', 'van', 'het', 'hart', 'van', 'de', 'klimaat@@', 'systemen', '.', '</s>']
2023-05-28 07:37:32,597 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:37:32,597 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:37:32,597 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijkappe het schlast het sssoep van het hart van de klimaatsystemen.
2023-05-28 07:37:32,597 - INFO - joeynmt.training - Example #3
2023-05-28 07:37:32,597 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:37:32,597 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:37:32,597 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'aal@@', 't', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:37:32,597 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:37:32,597 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:37:32,597 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schaalt in de zomer.
2023-05-28 07:37:32,597 - INFO - joeynmt.training - Example #4
2023-05-28 07:37:32,597 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:37:32,597 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:37:32,597 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'gevolgen', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'te@@', 'vor@@', 'en', ',', 'is', 'een', 'te@@', 'vor@@', 'en', ',', 'wat', 'er', 'gebeurt', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 07:37:32,597 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:37:32,597 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:37:32,597 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolgen die ik laat zien is een tevoren, is een tevoren, wat er gebeurt in de afgelopen 25 jaar.
2023-05-28 07:38:09,327 - INFO - joeynmt.training - Epoch   5, Step:    14600, Batch Loss:     1.896291, Batch Acc: 0.499862, Tokens per Sec:     1863, Lr: 0.000300
2023-05-28 07:38:45,434 - INFO - joeynmt.training - Epoch   5, Step:    14700, Batch Loss:     1.986912, Batch Acc: 0.501080, Tokens per Sec:     1911, Lr: 0.000300
2023-05-28 07:39:21,751 - INFO - joeynmt.training - Epoch   5, Step:    14800, Batch Loss:     2.071667, Batch Acc: 0.499110, Tokens per Sec:     1871, Lr: 0.000300
2023-05-28 07:39:58,899 - INFO - joeynmt.training - Epoch   5, Step:    14900, Batch Loss:     1.818629, Batch Acc: 0.501019, Tokens per Sec:     1809, Lr: 0.000300
2023-05-28 07:40:35,482 - INFO - joeynmt.training - Epoch   5, Step:    15000, Batch Loss:     1.843476, Batch Acc: 0.491287, Tokens per Sec:     1825, Lr: 0.000300
2023-05-28 07:40:35,482 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:40:35,482 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:41:44,736 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.13, ppl:   8.38, acc:   0.46, generation: 69.1581[sec], evaluation: 0.0000[sec]
2023-05-28 07:41:44,740 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:41:44,885 - INFO - joeynmt.helpers - delete models/transformer_c/12500.ckpt
2023-05-28 07:41:44,902 - INFO - joeynmt.training - Example #0
2023-05-28 07:41:44,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:41:44,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:41:44,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'aange@@', 'to@@', 'ond', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 's@@', 'sk@@', 'ap@@', 'e', ',', 'die', 'voor', 'de', 'meest', 'onder@@', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'die', 'de', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', 'van', 'de', 'grootte', 'van', '4@@', '8', '%', '.', '</s>']
2023-05-28 07:41:44,903 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:41:44,903 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:41:44,903 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia aangetoond dat de arctische ijsskape, die voor de meest onderonderste 48 staten, die de 48 staten, om 40 procent van de grootte van 48%.
2023-05-28 07:41:44,903 - INFO - joeynmt.training - Example #1
2023-05-28 07:41:44,903 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:41:44,903 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:41:44,903 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'soort', 'soort', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'f', '.', '</s>']
2023-05-28 07:41:44,903 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:41:44,903 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:41:44,903 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de oogst van dit soort soort problemen, omdat het niet de dikke van het ijf.
2023-05-28 07:41:44,903 - INFO - joeynmt.training - Example #2
2023-05-28 07:41:44,903 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:41:44,903 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:41:44,903 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 'sk@@', 'aar@@', 't@@', 'iek', ',', 'het', 'sch@@', 'la@@', 'st', 'het', 'hart', 'van', 'onze', 'wereldwijde', 'klimaat@@', 'systemen', '.', '</s>']
2023-05-28 07:41:44,903 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:41:44,903 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:41:44,903 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijskaartiek, het schlast het hart van onze wereldwijde klimaatsystemen.
2023-05-28 07:41:44,904 - INFO - joeynmt.training - Example #3
2023-05-28 07:41:44,904 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:41:44,904 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:41:44,904 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'aal@@', 't', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:41:44,904 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:41:44,904 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:41:44,904 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schaalt in de zomer.
2023-05-28 07:41:44,904 - INFO - joeynmt.training - Example #4
2023-05-28 07:41:44,904 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:41:44,904 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:41:44,904 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'zal', 'laten', 'zien', 'is', 'een', 'tijd@@', 'schrift', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 07:41:44,904 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:41:44,904 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:41:44,904 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie zal laten zien is een tijdschrift wat er in de laatste 25 jaar is.
2023-05-28 07:42:21,918 - INFO - joeynmt.training - Epoch   5, Step:    15100, Batch Loss:     1.889517, Batch Acc: 0.499550, Tokens per Sec:     1762, Lr: 0.000300
2023-05-28 07:42:58,244 - INFO - joeynmt.training - Epoch   5, Step:    15200, Batch Loss:     1.842119, Batch Acc: 0.497155, Tokens per Sec:     1858, Lr: 0.000300
2023-05-28 07:43:34,549 - INFO - joeynmt.training - Epoch   5, Step:    15300, Batch Loss:     2.063389, Batch Acc: 0.500499, Tokens per Sec:     1878, Lr: 0.000300
2023-05-28 07:44:12,103 - INFO - joeynmt.training - Epoch   5, Step:    15400, Batch Loss:     1.821785, Batch Acc: 0.500862, Tokens per Sec:     1823, Lr: 0.000300
2023-05-28 07:44:48,992 - INFO - joeynmt.training - Epoch   5, Step:    15500, Batch Loss:     2.157255, Batch Acc: 0.487709, Tokens per Sec:     1758, Lr: 0.000300
2023-05-28 07:44:48,992 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:44:48,993 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:45:51,966 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.12, ppl:   8.33, acc:   0.45, generation: 62.8746[sec], evaluation: 0.0000[sec]
2023-05-28 07:45:51,969 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:45:52,113 - INFO - joeynmt.helpers - delete models/transformer_c/13000.ckpt
2023-05-28 07:45:52,131 - INFO - joeynmt.training - Example #0
2023-05-28 07:45:52,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:45:52,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:45:52,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kennen', 'dat', 'de', 'Arab@@', 'ische', 'ij@@', 'sk@@', 'app@@', 'e', ',', 'die', 'voor', 'de', 'meest', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'die', 'de', 'grote', 'grote', 'grote', 'grote', 'grote', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', 'van', 'de', 'st@@', 'aten', 'te', 'zijn', '.', '</s>']
2023-05-28 07:45:52,132 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:45:52,132 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:45:52,132 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkennen dat de Arabische ijskappe, die voor de meest onderste 48 staten, die de grote grote grote grote grote van de onderste 48 staten, om 40 procent van de staten te zijn.
2023-05-28 07:45:52,132 - INFO - joeynmt.training - Example #1
2023-05-28 07:45:52,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:45:52,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:45:52,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'zo', 'genoeg', 'de', 'ser@@', 'ieuze', 'ser@@', 'ie', 'van', 'dit', 'soort', 'soort', 'soort', 'soort', 'soort', 'soort', 'soort', 'soort', 'soort', 'soort', 'dingen', 'uit', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'f', 'laat', 'zien', '.', '</s>']
2023-05-28 07:45:52,132 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:45:52,132 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:45:52,132 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet zo genoeg de serieuze serie van dit soort soort soort soort soort soort soort soort soort soort dingen uit, omdat het niet de dikke van het ijf laat zien.
2023-05-28 07:45:52,132 - INFO - joeynmt.training - Example #2
2023-05-28 07:45:52,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:45:52,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:45:52,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 's@@', 's@@', 's@@', 'app@@', 'e', 'het', 'sch@@', 'ep@@', 'pen', 'van', 'ons', 'wereld@@', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 07:45:52,133 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:45:52,133 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:45:52,133 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijsssappe het scheppen van ons wereldklimaatsysteem.
2023-05-28 07:45:52,133 - INFO - joeynmt.training - Example #3
2023-05-28 07:45:52,133 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:45:52,133 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:45:52,133 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ep@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:45:52,133 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:45:52,133 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:45:52,133 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppen in de zomer.
2023-05-28 07:45:52,133 - INFO - joeynmt.training - Example #4
2023-05-28 07:45:52,133 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:45:52,133 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:45:52,133 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'schrift', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'gebeurd', 'is', '.', '</s>']
2023-05-28 07:45:52,133 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:45:52,133 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:45:52,133 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien, is een tijdschrift wat er in de afgelopen 25 jaar gebeurd is.
2023-05-28 07:46:29,735 - INFO - joeynmt.training - Epoch   5, Step:    15600, Batch Loss:     1.801413, Batch Acc: 0.490127, Tokens per Sec:     1739, Lr: 0.000300
2023-05-28 07:47:05,552 - INFO - joeynmt.training - Epoch   5, Step:    15700, Batch Loss:     1.894194, Batch Acc: 0.495509, Tokens per Sec:     1899, Lr: 0.000300
2023-05-28 07:47:40,961 - INFO - joeynmt.training - Epoch   5, Step:    15800, Batch Loss:     1.874028, Batch Acc: 0.498647, Tokens per Sec:     1952, Lr: 0.000300
2023-05-28 07:48:18,017 - INFO - joeynmt.training - Epoch   5, Step:    15900, Batch Loss:     1.784709, Batch Acc: 0.501291, Tokens per Sec:     1830, Lr: 0.000300
2023-05-28 07:48:54,796 - INFO - joeynmt.training - Epoch   5, Step:    16000, Batch Loss:     1.930272, Batch Acc: 0.498297, Tokens per Sec:     1844, Lr: 0.000300
2023-05-28 07:48:54,798 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:48:54,798 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:49:57,810 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.10, ppl:   8.20, acc:   0.46, generation: 62.9164[sec], evaluation: 0.0000[sec]
2023-05-28 07:49:57,813 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:49:57,965 - INFO - joeynmt.helpers - delete models/transformer_c/13500.ckpt
2023-05-28 07:49:57,985 - INFO - joeynmt.training - Example #0
2023-05-28 07:49:57,985 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:49:57,985 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:49:57,985 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', '<unk>', 'ap@@', 'os@@', ';', 's', 'laten', 'zien', 'dat', 'de', 'Arab@@', 'ische', 'ij@@', 's@@', 's@@', 's@@', 's@@', 'app@@', 'e', ',', 'die', 'voor', 'drie', 'miljoen', 'jaar', 'de', 'ge@@', 'wen@@', 'd', 'drie', 'miljoen', 'jaar', 'de', 'ge@@', 'wen@@', 'd', 'van', 'de', 'landen', ',', 'om', '40', 'procent', 'ge@@', 'slaa@@', 'gd', 'te', 'zijn', '.', '</s>']
2023-05-28 07:49:57,985 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:49:57,985 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:49:57,985 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia <unk> apos; s laten zien dat de Arabische ijssssappe, die voor drie miljoen jaar de gewend drie miljoen jaar de gewend van de landen, om 40 procent geslaagd te zijn.
2023-05-28 07:49:57,985 - INFO - joeynmt.training - Example #1
2023-05-28 07:49:57,985 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:49:57,985 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:49:57,985 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'druk', 'niet', 'veel', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'speciale', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'ver@@', 'toont', '.', '</s>']
2023-05-28 07:49:57,986 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:49:57,986 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:49:57,986 - INFO - joeynmt.training - 	Hypothesis: Maar dat druk niet veel genoeg de oogst van dit speciale problemen, omdat het niet de dikke van de ijsvertoont.
2023-05-28 07:49:57,986 - INFO - joeynmt.training - Example #2
2023-05-28 07:49:57,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:49:57,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:49:57,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'tische', 'ij@@', 's@@', 's@@', 'app@@', 'e', ',', 'het', 'hart', 'van', 'onze', 'mondiale', 'klimaat@@', 'systemen', '.', '</s>']
2023-05-28 07:49:57,986 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:49:57,986 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:49:57,986 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabtische ijssappe, het hart van onze mondiale klimaatsystemen.
2023-05-28 07:49:57,986 - INFO - joeynmt.training - Example #3
2023-05-28 07:49:57,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:49:57,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:49:57,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'zijn', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'aal@@', 't', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'aal@@', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:49:57,986 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:49:57,986 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:49:57,986 - INFO - joeynmt.training - 	Hypothesis: Ze zijn in de winter en schaalt in de winter en schaalde zomer.
2023-05-28 07:49:57,986 - INFO - joeynmt.training - Example #4
2023-05-28 07:49:57,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:49:57,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:49:57,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'tijd@@', 'schrift', 'wat', 'in', 'de', 'afgelopen', '25', 'jaar', 'gebeurd', 'is', '.', '</s>']
2023-05-28 07:49:57,987 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:49:57,987 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:49:57,987 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tijdschrift wat in de afgelopen 25 jaar gebeurd is.
2023-05-28 07:50:34,942 - INFO - joeynmt.training - Epoch   5, Step:    16100, Batch Loss:     2.022546, Batch Acc: 0.495760, Tokens per Sec:     1817, Lr: 0.000300
2023-05-28 07:51:11,945 - INFO - joeynmt.training - Epoch   5, Step:    16200, Batch Loss:     2.022813, Batch Acc: 0.503854, Tokens per Sec:     1795, Lr: 0.000300
2023-05-28 07:51:48,208 - INFO - joeynmt.training - Epoch   5, Step:    16300, Batch Loss:     1.763466, Batch Acc: 0.493765, Tokens per Sec:     1906, Lr: 0.000300
2023-05-28 07:52:22,732 - INFO - joeynmt.training - Epoch   5, Step:    16400, Batch Loss:     1.959299, Batch Acc: 0.500574, Tokens per Sec:     1994, Lr: 0.000300
2023-05-28 07:52:58,881 - INFO - joeynmt.training - Epoch   5, Step:    16500, Batch Loss:     1.997979, Batch Acc: 0.502891, Tokens per Sec:     1852, Lr: 0.000300
2023-05-28 07:52:58,883 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:52:58,883 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:54:06,982 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.10, ppl:   8.13, acc:   0.46, generation: 68.0041[sec], evaluation: 0.0000[sec]
2023-05-28 07:54:06,986 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:54:07,126 - INFO - joeynmt.helpers - delete models/transformer_c/14000.ckpt
2023-05-28 07:54:07,138 - INFO - joeynmt.training - Example #0
2023-05-28 07:54:07,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:54:07,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:54:07,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'aange@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kennen', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'jes', 'die', 'voor', 'de', 'meest', 'van', 'de', 'drie', 'miljoen', 'jaar', ',', 'de', 'grootste', 'grootste', 'grootste', 'ge@@', 'vers', 'van', 'de', 'st@@', 'aten', 'van', 'de', 'st@@', 'aten', 'van', 'de', 'st@@', 'aten', 'van', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', '.', '</s>']
2023-05-28 07:54:07,139 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:54:07,139 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:54:07,139 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia aangetoond om te verkennen dat de arctische ijkjes die voor de meest van de drie miljoen jaar, de grootste grootste grootste gevers van de staten van de staten van de staten van 48 staten, om 40 procent.
2023-05-28 07:54:07,139 - INFO - joeynmt.training - Example #1
2023-05-28 07:54:07,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:54:07,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:54:07,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'zo', 'genoeg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'soort', 'soort', 'problemen', 'uit', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 's@@', 'es', 'laat', 'zien', '.', '</s>']
2023-05-28 07:54:07,139 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:54:07,139 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:54:07,139 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet zo genoeg genoeg de oogst van dit soort soort problemen uit, omdat het niet de dikke van het ijsses laat zien.
2023-05-28 07:54:07,139 - INFO - joeynmt.training - Example #2
2023-05-28 07:54:07,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:54:07,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:54:07,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'la@@', 'st', 'van', 'ons', 'globale', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 07:54:07,140 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:54:07,140 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:54:07,140 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe het schlast van ons globale klimaatsysteem.
2023-05-28 07:54:07,140 - INFO - joeynmt.training - Example #3
2023-05-28 07:54:07,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:54:07,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:54:07,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ep@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:54:07,140 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:54:07,140 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:54:07,140 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppen in de zomer.
2023-05-28 07:54:07,140 - INFO - joeynmt.training - Example #4
2023-05-28 07:54:07,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:54:07,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:54:07,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', 'tijden', 'van', 'een', 'tijd@@', 'schrift', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 07:54:07,140 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:54:07,140 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:54:07,140 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijden van een tijdschrift van de laatste 25 jaar.
2023-05-28 07:54:43,761 - INFO - joeynmt.training - Epoch   5, Step:    16600, Batch Loss:     1.938810, Batch Acc: 0.496459, Tokens per Sec:     1850, Lr: 0.000300
2023-05-28 07:55:20,747 - INFO - joeynmt.training - Epoch   5, Step:    16700, Batch Loss:     1.988209, Batch Acc: 0.495743, Tokens per Sec:     1874, Lr: 0.000300
2023-05-28 07:55:56,054 - INFO - joeynmt.training - Epoch   5, Step:    16800, Batch Loss:     1.828770, Batch Acc: 0.499271, Tokens per Sec:     1905, Lr: 0.000300
2023-05-28 07:56:32,044 - INFO - joeynmt.training - Epoch   5, Step:    16900, Batch Loss:     2.051727, Batch Acc: 0.492741, Tokens per Sec:     1845, Lr: 0.000300
2023-05-28 07:57:07,733 - INFO - joeynmt.training - Epoch   5, Step:    17000, Batch Loss:     2.135880, Batch Acc: 0.495881, Tokens per Sec:     1861, Lr: 0.000300
2023-05-28 07:57:07,735 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 07:57:07,735 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 07:58:09,492 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.09, ppl:   8.12, acc:   0.46, generation: 61.6623[sec], evaluation: 0.0000[sec]
2023-05-28 07:58:09,495 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 07:58:09,628 - INFO - joeynmt.helpers - delete models/transformer_c/14500.ckpt
2023-05-28 07:58:09,645 - INFO - joeynmt.training - Example #0
2023-05-28 07:58:09,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 07:58:09,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 07:58:09,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'jes', 'die', 'voor', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'jes', 'die', 'voor', 'een', 'paar', 'miljoen', 'jaar', ',', 'de', 'gro@@', 'en', 'van', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'kregen', 'om', '40', 'procent', '.', '</s>']
2023-05-28 07:58:09,645 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 07:58:09,645 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 07:58:09,645 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien dat de arctische ijkjes die voor de arctische ijkjes die voor een paar miljoen jaar, de groen van 48 staten had gekregen om 40 procent.
2023-05-28 07:58:09,645 - INFO - joeynmt.training - Example #1
2023-05-28 07:58:09,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 07:58:09,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 07:58:09,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'zo', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'soort', 'soort', 'soort', 'soort', 'soort', 'soort', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'ver@@', 'toont', '.', '</s>']
2023-05-28 07:58:09,646 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 07:58:09,646 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 07:58:09,646 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet zo genoeg de oogst van dit soort soort soort soort soort soort problemen, omdat het niet de dikke van de ijsvertoont.
2023-05-28 07:58:09,646 - INFO - joeynmt.training - Example #2
2023-05-28 07:58:09,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 07:58:09,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 07:58:09,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'jes', 'het', 'sch@@', 'la@@', 'st', 'van', 'onze', 'wereldwijde', 'klimaat@@', 'systemen', '.', '</s>']
2023-05-28 07:58:09,646 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 07:58:09,646 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 07:58:09,646 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkjes het schlast van onze wereldwijde klimaatsystemen.
2023-05-28 07:58:09,646 - INFO - joeynmt.training - Example #3
2023-05-28 07:58:09,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 07:58:09,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 07:58:09,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'mp@@', 'je', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 07:58:09,646 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 07:58:09,646 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 07:58:09,646 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompje in de zomer.
2023-05-28 07:58:09,646 - INFO - joeynmt.training - Example #4
2023-05-28 07:58:09,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 07:58:09,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 07:58:09,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tijd@@', 'je', 'dat', 'er', 'een', 'tijd@@', 'je', 'zou', 'zien', 'dat', 'er', 'al', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 07:58:09,647 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 07:58:09,647 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 07:58:09,647 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje dat er een tijdje zou zien dat er al 25 jaar is.
2023-05-28 07:58:45,919 - INFO - joeynmt.training - Epoch   5, Step:    17100, Batch Loss:     2.016524, Batch Acc: 0.498654, Tokens per Sec:     1867, Lr: 0.000300
2023-05-28 07:59:22,370 - INFO - joeynmt.training - Epoch   5, Step:    17200, Batch Loss:     1.776662, Batch Acc: 0.499874, Tokens per Sec:     1851, Lr: 0.000300
2023-05-28 07:59:57,373 - INFO - joeynmt.training - Epoch   5, Step:    17300, Batch Loss:     2.033412, Batch Acc: 0.496526, Tokens per Sec:     1949, Lr: 0.000300
2023-05-28 08:00:32,377 - INFO - joeynmt.training - Epoch   5, Step:    17400, Batch Loss:     1.938031, Batch Acc: 0.500301, Tokens per Sec:     1897, Lr: 0.000300
2023-05-28 08:01:07,783 - INFO - joeynmt.training - Epoch   5, Step:    17500, Batch Loss:     1.973210, Batch Acc: 0.497349, Tokens per Sec:     1918, Lr: 0.000300
2023-05-28 08:01:07,784 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:01:07,784 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:02:06,310 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.08, ppl:   8.04, acc:   0.47, generation: 58.4323[sec], evaluation: 0.0000[sec]
2023-05-28 08:02:06,313 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 08:02:06,485 - INFO - joeynmt.helpers - delete models/transformer_c/15000.ckpt
2023-05-28 08:02:06,503 - INFO - joeynmt.training - Example #0
2023-05-28 08:02:06,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:02:06,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:02:06,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'dit', 'jaar', 'vorig', 'jaar', 'geleden', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kennen', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'sk@@', 'appen', 'die', 'een', 'groot', 'deel', 'van', '4@@', '8', 'st@@', 'aten', ',', 'die', 'de', 'Gro@@', 'ene', 'van', '4@@', '8', 'st@@', 'aten', 'had', ',', 'om', '40', '%', 'ge@@', 'slaa@@', 'gd', '.', '</s>']
2023-05-28 08:02:06,503 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:02:06,503 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:02:06,503 - INFO - joeynmt.training - 	Hypothesis: Ik heb dit jaar vorig jaar geleden getoond om te verkennen dat de arctische ijskskappen die een groot deel van 48 staten, die de Groene van 48 staten had, om 40% geslaagd.
2023-05-28 08:02:06,503 - INFO - joeynmt.training - Example #1
2023-05-28 08:02:06,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:02:06,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:02:06,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'dru@@', 'kt', 'niet', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'het', 'ijs', 'laat', 'zien', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ijs', 'laat', 'zien', '.', '</s>']
2023-05-28 08:02:06,504 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:02:06,504 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:02:06,504 - INFO - joeynmt.training - 	Hypothesis: Maar dat drukt niet sterk genoeg de oogst van het ijs laat zien, omdat het niet de dikke van het ijs laat zien.
2023-05-28 08:02:06,504 - INFO - joeynmt.training - Example #2
2023-05-28 08:02:06,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:02:06,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:02:06,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'aar@@', 'en', 'het', 'sch@@', 'la@@', 'st', 'van', 'ons', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 08:02:06,504 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:02:06,504 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:02:06,504 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskaaren het schlast van ons wereldwijde klimaatsysteem.
2023-05-28 08:02:06,504 - INFO - joeynmt.training - Example #3
2023-05-28 08:02:06,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:02:06,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:02:06,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ep@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:02:06,504 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:02:06,506 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:02:06,506 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppen in de zomer.
2023-05-28 08:02:06,506 - INFO - joeynmt.training - Example #4
2023-05-28 08:02:06,506 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:02:06,506 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:02:06,506 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'tijd@@', 'je', 'van', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 08:02:06,506 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:02:06,506 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:02:06,506 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tijdje van wat er in de afgelopen 25 jaar.
2023-05-28 08:02:43,665 - INFO - joeynmt.training - Epoch   5, Step:    17600, Batch Loss:     1.884762, Batch Acc: 0.500135, Tokens per Sec:     1785, Lr: 0.000300
2023-05-28 08:03:22,216 - INFO - joeynmt.training - Epoch   5, Step:    17700, Batch Loss:     1.872084, Batch Acc: 0.502198, Tokens per Sec:     1800, Lr: 0.000300
2023-05-28 08:03:47,590 - INFO - joeynmt.training - Epoch   5: total training loss 6826.89
2023-05-28 08:03:47,590 - INFO - joeynmt.training - EPOCH 6
2023-05-28 08:03:47,625 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=5
2023-05-28 08:03:58,322 - INFO - joeynmt.training - Epoch   6, Step:    17800, Batch Loss:     1.937991, Batch Acc: 0.525181, Tokens per Sec:     1961, Lr: 0.000300
2023-05-28 08:04:35,133 - INFO - joeynmt.training - Epoch   6, Step:    17900, Batch Loss:     1.896722, Batch Acc: 0.520211, Tokens per Sec:     1802, Lr: 0.000300
2023-05-28 08:05:12,012 - INFO - joeynmt.training - Epoch   6, Step:    18000, Batch Loss:     1.896384, Batch Acc: 0.509971, Tokens per Sec:     1841, Lr: 0.000300
2023-05-28 08:05:12,013 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:05:12,013 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:06:08,258 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.09, ppl:   8.05, acc:   0.47, generation: 56.1499[sec], evaluation: 0.0000[sec]
2023-05-28 08:06:08,431 - INFO - joeynmt.helpers - delete models/transformer_c/15500.ckpt
2023-05-28 08:06:08,449 - INFO - joeynmt.training - Example #0
2023-05-28 08:06:08,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:06:08,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:06:08,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'c@@', 'c@@', 'ti@@', 's', 'die', 'voor', 'een', 'uit@@', 'ing', 'van', 'de', 'drie', 'miljoen', 'jaar', 'die', 'de', 'Gr@@', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', '%', 'ge@@', 'ste@@', 'md', 'te', 'zijn', '.', '</s>']
2023-05-28 08:06:08,449 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:06:08,449 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:06:08,449 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien dat de arccctis die voor een uiting van de drie miljoen jaar die de Grreden van de onderste 48 staten, om 40% gestemd te zijn.
2023-05-28 08:06:08,449 - INFO - joeynmt.training - Example #1
2023-05-28 08:06:08,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:06:08,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:06:08,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'es', 'laat', 'zien', '.', '</s>']
2023-05-28 08:06:08,450 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:06:08,450 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:06:08,450 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo sterk genoeg de oogst dat het niet de dikke van het ijses laat zien.
2023-05-28 08:06:08,450 - INFO - joeynmt.training - Example #2
2023-05-28 08:06:08,450 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:06:08,450 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:06:08,450 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'c@@', 'ti@@', 'ti@@', 's', 'het', 'sch@@', 'it@@', 'ter@@', 'ende', 'hart', 'van', 'ons', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 08:06:08,450 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:06:08,450 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:06:08,450 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arcctitis het schitterende hart van ons wereldwijde klimaatsysteem.
2023-05-28 08:06:08,450 - INFO - joeynmt.training - Example #3
2023-05-28 08:06:08,450 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:06:08,450 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:06:08,450 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ep@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:06:08,450 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:06:08,450 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:06:08,450 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppen in de zomer.
2023-05-28 08:06:08,450 - INFO - joeynmt.training - Example #4
2023-05-28 08:06:08,450 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:06:08,450 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:06:08,450 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tijd@@', 'je', 'van', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 08:06:08,451 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:06:08,451 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:06:08,451 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje van wat er in de afgelopen 25 jaar is.
2023-05-28 08:06:44,282 - INFO - joeynmt.training - Epoch   6, Step:    18100, Batch Loss:     1.842091, Batch Acc: 0.510702, Tokens per Sec:     1903, Lr: 0.000300
2023-05-28 08:07:20,001 - INFO - joeynmt.training - Epoch   6, Step:    18200, Batch Loss:     1.841143, Batch Acc: 0.510555, Tokens per Sec:     1886, Lr: 0.000300
2023-05-28 08:07:55,092 - INFO - joeynmt.training - Epoch   6, Step:    18300, Batch Loss:     1.977503, Batch Acc: 0.511109, Tokens per Sec:     1933, Lr: 0.000300
2023-05-28 08:08:30,463 - INFO - joeynmt.training - Epoch   6, Step:    18400, Batch Loss:     1.731744, Batch Acc: 0.505316, Tokens per Sec:     1875, Lr: 0.000300
2023-05-28 08:09:06,859 - INFO - joeynmt.training - Epoch   6, Step:    18500, Batch Loss:     1.708796, Batch Acc: 0.509946, Tokens per Sec:     1839, Lr: 0.000300
2023-05-28 08:09:06,860 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:09:06,860 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:10:12,672 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.07, ppl:   7.94, acc:   0.47, generation: 65.7165[sec], evaluation: 0.0000[sec]
2023-05-28 08:10:12,674 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 08:10:12,843 - INFO - joeynmt.helpers - delete models/transformer_c/16000.ckpt
2023-05-28 08:10:12,862 - INFO - joeynmt.training - Example #0
2023-05-28 08:10:12,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:10:12,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:10:12,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'vorig', 'jaar', 'geleden', 'ge@@', 'to@@', 'ond', 'om', 'deze', 'twee', 'di@@', 'a', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'sk@@', 'y@@', 's@@', 'ij@@', 'sk@@', 'y@@', 's@@', 'ij@@', 'sk@@', 'y@@', 'app@@', 'e', ',', 'die', 'voor', 'de', '4@@', '8', ',', 'drie', 'miljoen', 'jaar', 'geleden', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', '.', '</s>']
2023-05-28 08:10:12,863 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:10:12,863 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:10:12,863 - INFO - joeynmt.training - 	Hypothesis: Ik heb vorig jaar geleden getoond om deze twee dia te zien dat de arctische ijskskysijskysijskyappe, die voor de 48, drie miljoen jaar geleden de grootte van de onderste 48 staten, om 40 procent.
2023-05-28 08:10:12,863 - INFO - joeynmt.training - Example #1
2023-05-28 08:10:12,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:10:12,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:10:12,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'de', 'ser@@', 'ie', 'van', 'deze', 'specifieke', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'ing', 'is', '.', '</s>']
2023-05-28 08:10:12,863 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:10:12,863 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:10:12,863 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg de serie van deze specifieke problemen, omdat het niet de dikke van de ijsing is.
2023-05-28 08:10:12,863 - INFO - joeynmt.training - Example #2
2023-05-28 08:10:12,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:10:12,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:10:12,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'ti@@', 'ti@@', 'les', 'dat', 'het', 's@@', 'oe@@', 'p', 'hart', 'van', 'de', 'klimaat@@', 'systemen', '.', '</s>']
2023-05-28 08:10:12,864 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:10:12,864 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:10:12,864 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctititiles dat het soep hart van de klimaatsystemen.
2023-05-28 08:10:12,864 - INFO - joeynmt.training - Example #3
2023-05-28 08:10:12,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:10:12,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:10:12,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ep@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:10:12,864 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:10:12,864 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:10:12,864 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppen in de zomer.
2023-05-28 08:10:12,864 - INFO - joeynmt.training - Example #4
2023-05-28 08:10:12,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:10:12,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:10:12,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', ',', 'is', 'een', 'tijd@@', 'je', 'dat', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2023-05-28 08:10:12,864 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:10:12,864 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:10:12,864 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdje dat de laatste 25 jaar is gebeurd.
2023-05-28 08:10:49,768 - INFO - joeynmt.training - Epoch   6, Step:    18600, Batch Loss:     1.771555, Batch Acc: 0.506592, Tokens per Sec:     1818, Lr: 0.000300
2023-05-28 08:11:26,798 - INFO - joeynmt.training - Epoch   6, Step:    18700, Batch Loss:     1.799431, Batch Acc: 0.509309, Tokens per Sec:     1715, Lr: 0.000300
2023-05-28 08:12:03,722 - INFO - joeynmt.training - Epoch   6, Step:    18800, Batch Loss:     1.882547, Batch Acc: 0.511303, Tokens per Sec:     1825, Lr: 0.000300
2023-05-28 08:12:39,292 - INFO - joeynmt.training - Epoch   6, Step:    18900, Batch Loss:     1.827587, Batch Acc: 0.511447, Tokens per Sec:     1934, Lr: 0.000300
2023-05-28 08:13:17,299 - INFO - joeynmt.training - Epoch   6, Step:    19000, Batch Loss:     1.769095, Batch Acc: 0.506730, Tokens per Sec:     1812, Lr: 0.000300
2023-05-28 08:13:17,300 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:13:17,300 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:14:18,598 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.07, ppl:   7.95, acc:   0.47, generation: 61.2011[sec], evaluation: 0.0000[sec]
2023-05-28 08:14:18,728 - INFO - joeynmt.helpers - delete models/transformer_c/16500.ckpt
2023-05-28 08:14:18,742 - INFO - joeynmt.training - Example #0
2023-05-28 08:14:18,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:14:18,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:14:18,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'dat', 'de', 'Arab@@', 'isch', 'ij@@', 'sk@@', 'sk@@', 'y@@', 'app@@', 'e', 'die', 'voor', 'bij', 'de', 'aan@@', 'wij@@', 'zingen', 'van', 'de', '4@@', '8', 'st@@', 'aten', ',', 'de', 'gro@@', 'ten', 'van', 'de', 'grootte', 'van', 'de', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', 'te', 'ver@@', 'laten', '.', '</s>']
2023-05-28 08:14:18,743 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:14:18,743 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:14:18,743 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien dat de Arabisch ijskskyappe die voor bij de aanwijzingen van de 48 staten, de groten van de grootte van de 48 staten, om 40 procent te verlaten.
2023-05-28 08:14:18,743 - INFO - joeynmt.training - Example #1
2023-05-28 08:14:18,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:14:18,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:14:18,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'veel', 'genoeg', 'de', 'oog@@', 'st@@', 'icht@@', 'ings@@', 'vermogen', 'van', 'dit', 'soort', 'problemen', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'zer', '.', '</s>']
2023-05-28 08:14:18,743 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:14:18,743 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:14:18,743 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet veel genoeg de oogstichtingsvermogen van dit soort problemen, want het is niet de dikke van het ijzer.
2023-05-28 08:14:18,743 - INFO - joeynmt.training - Example #2
2023-05-28 08:14:18,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:14:18,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:14:18,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'isch', 'ij@@', 'sk@@', 'sk@@', 'y@@', 'app@@', 'e', 'het', 'hart', 'van', 'de', 'wereldwijde', 'klimaat@@', 'systemen', '.', '</s>']
2023-05-28 08:14:18,743 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:14:18,743 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:14:18,743 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabisch ijskskyappe het hart van de wereldwijde klimaatsystemen.
2023-05-28 08:14:18,743 - INFO - joeynmt.training - Example #3
2023-05-28 08:14:18,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:14:18,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:14:18,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ep@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:14:18,744 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:14:18,744 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:14:18,744 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppen in de zomer.
2023-05-28 08:14:18,744 - INFO - joeynmt.training - Example #4
2023-05-28 08:14:18,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:14:18,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:14:18,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'je', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 08:14:18,744 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:14:18,744 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:14:18,744 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien, is een tijdje van wat er in de laatste 25 jaar.
2023-05-28 08:14:55,739 - INFO - joeynmt.training - Epoch   6, Step:    19100, Batch Loss:     1.831621, Batch Acc: 0.514328, Tokens per Sec:     1857, Lr: 0.000300
2023-05-28 08:15:31,267 - INFO - joeynmt.training - Epoch   6, Step:    19200, Batch Loss:     1.888032, Batch Acc: 0.513042, Tokens per Sec:     1928, Lr: 0.000300
2023-05-28 08:16:07,459 - INFO - joeynmt.training - Epoch   6, Step:    19300, Batch Loss:     1.843912, Batch Acc: 0.507091, Tokens per Sec:     1796, Lr: 0.000300
2023-05-28 08:16:43,075 - INFO - joeynmt.training - Epoch   6, Step:    19400, Batch Loss:     1.774674, Batch Acc: 0.506116, Tokens per Sec:     1859, Lr: 0.000300
2023-05-28 08:17:20,633 - INFO - joeynmt.training - Epoch   6, Step:    19500, Batch Loss:     1.831723, Batch Acc: 0.510824, Tokens per Sec:     1745, Lr: 0.000300
2023-05-28 08:17:20,634 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:17:20,634 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:18:30,517 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.06, ppl:   7.87, acc:   0.47, generation: 69.7865[sec], evaluation: 0.0000[sec]
2023-05-28 08:18:30,520 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 08:18:30,687 - INFO - joeynmt.helpers - delete models/transformer_c/17000.ckpt
2023-05-28 08:18:30,701 - INFO - joeynmt.training - Example #0
2023-05-28 08:18:30,701 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:18:30,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:18:30,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'dat', 'de', 'Arab@@', 'ische', 'ij@@', 'sk@@', 'sk@@', 'sk@@', 'oe@@', 'p', 'die', 'voor', 'een', 'paar', 'jaar', 'geleden', ',', 'die', 'voor', 'een', 'gro@@', 'en@@', 'en@@', 'te@@', 'er', 'van', 'van', 'van', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', 'van', 'de', 'onder@@', 'kant', 'van', 'de', 'onder@@', 'kant', 'van', 'de', 'VS', ',', 'om', '40', 'procent', 'van', 'de', 'onder@@', 'nemers', '.', '</s>']
2023-05-28 08:18:30,702 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:18:30,702 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:18:30,702 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien dat de Arabische ijskskskoep die voor een paar jaar geleden, die voor een groenenteer van van van 48 staten, om 40 procent van de onderkant van de onderkant van de VS, om 40 procent van de ondernemers.
2023-05-28 08:18:30,702 - INFO - joeynmt.training - Example #1
2023-05-28 08:18:30,702 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:18:30,702 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:18:30,702 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'druk', 'niet', 'sterk', 'genoeg', 'is', 'het', 'oog@@', 'st', 'van', 'het', 'probleem', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ijs', 'laat', 'zien', '.', '</s>']
2023-05-28 08:18:30,702 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:18:30,702 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:18:30,702 - INFO - joeynmt.training - 	Hypothesis: Maar dat druk niet sterk genoeg is het oogst van het probleem, want het is niet de dikke van het ijs laat zien.
2023-05-28 08:18:30,702 - INFO - joeynmt.training - Example #2
2023-05-28 08:18:30,702 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:18:30,702 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:18:30,702 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 'sk@@', 'sk@@', 'oe@@', 'p', 'het', 'sch@@', 'la@@', 'p', 'het', 'hart', 'van', 'de', 'klimaat@@', 'verandering', '.', '</s>']
2023-05-28 08:18:30,702 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:18:30,702 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:18:30,702 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijskskoep het schlap het hart van de klimaatverandering.
2023-05-28 08:18:30,702 - INFO - joeynmt.training - Example #3
2023-05-28 08:18:30,702 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:18:30,702 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:18:30,702 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'wind', 'en', 'sch@@', 'ep@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:18:30,703 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:18:30,703 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:18:30,703 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de wind en scheppen in de zomer.
2023-05-28 08:18:30,703 - INFO - joeynmt.training - Example #4
2023-05-28 08:18:30,703 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:18:30,703 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:18:30,703 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'teken@@', 'ing', 'van', 'wat', 'er', 'is', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 08:18:30,703 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:18:30,703 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:18:30,703 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tekening van wat er is in de afgelopen 25 jaar.
2023-05-28 08:19:09,106 - INFO - joeynmt.training - Epoch   6, Step:    19600, Batch Loss:     1.962384, Batch Acc: 0.506817, Tokens per Sec:     1754, Lr: 0.000300
2023-05-28 08:19:45,137 - INFO - joeynmt.training - Epoch   6, Step:    19700, Batch Loss:     1.923344, Batch Acc: 0.503177, Tokens per Sec:     1861, Lr: 0.000300
2023-05-28 08:20:22,181 - INFO - joeynmt.training - Epoch   6, Step:    19800, Batch Loss:     1.746655, Batch Acc: 0.512685, Tokens per Sec:     1798, Lr: 0.000300
2023-05-28 08:21:00,060 - INFO - joeynmt.training - Epoch   6, Step:    19900, Batch Loss:     1.845970, Batch Acc: 0.511278, Tokens per Sec:     1752, Lr: 0.000300
2023-05-28 08:21:36,202 - INFO - joeynmt.training - Epoch   6, Step:    20000, Batch Loss:     1.880175, Batch Acc: 0.510329, Tokens per Sec:     1874, Lr: 0.000300
2023-05-28 08:21:36,203 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:21:36,204 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:22:45,835 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.06, ppl:   7.88, acc:   0.47, generation: 69.5356[sec], evaluation: 0.0000[sec]
2023-05-28 08:22:46,000 - INFO - joeynmt.helpers - delete models/transformer_c/18000.ckpt
2023-05-28 08:22:46,018 - INFO - joeynmt.training - Example #0
2023-05-28 08:22:46,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:22:46,018 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:22:46,018 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'ver@@', 'kennen', 'dat', 'de', 'Arab@@', 'ische', 'ij@@', 's@@', 'sk@@', 'sk@@', 'sk@@', 'sk@@', 'sk@@', 'oe@@', 'p', 'die', 'voor', 'een', 'aantal', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', 'st@@', 'aten', 'van', 'de', 'VS', ',', '40', '%', 'ge@@', 'slaa@@', 'gd', '.', '</s>']
2023-05-28 08:22:46,018 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:22:46,018 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:22:46,018 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te verkennen dat de Arabische ijsskskskskskoep die voor een aantal van de onderste 48 staten, de onderste 48 staten van de onderste staten van de VS, 40% geslaagd.
2023-05-28 08:22:46,019 - INFO - joeynmt.training - Example #1
2023-05-28 08:22:46,019 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:22:46,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:22:46,019 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'soort', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 's@@', 'es', 'laat', 'zien', '.', '</s>']
2023-05-28 08:22:46,019 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:22:46,019 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:22:46,019 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg de oogst van dit soort problemen, omdat het niet de dikke van de ijsses laat zien.
2023-05-28 08:22:46,019 - INFO - joeynmt.training - Example #2
2023-05-28 08:22:46,019 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:22:46,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:22:46,019 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 's@@', 'sk@@', 'sk@@', 'oe@@', 'p', 'het', 'sch@@', 'la@@', 'p', 'van', 'ons', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 08:22:46,019 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:22:46,019 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:22:46,019 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijsskskoep het schlap van ons wereldwijde klimaatsysteem.
2023-05-28 08:22:46,019 - INFO - joeynmt.training - Example #3
2023-05-28 08:22:46,019 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:22:46,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:22:46,019 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'wind', 'en', 'sch@@', 'ro@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:22:46,020 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:22:46,020 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:22:46,020 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de wind en schropen in de zomer.
2023-05-28 08:22:46,020 - INFO - joeynmt.training - Example #4
2023-05-28 08:22:46,020 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:22:46,020 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:22:46,020 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tijd@@', 'je', 'van', 'wat', 'er', 'gebeurt', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 08:22:46,020 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:22:46,020 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:22:46,020 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje van wat er gebeurt in de laatste 25 jaar.
2023-05-28 08:23:21,737 - INFO - joeynmt.training - Epoch   6, Step:    20100, Batch Loss:     1.884994, Batch Acc: 0.509123, Tokens per Sec:     1866, Lr: 0.000300
2023-05-28 08:23:58,611 - INFO - joeynmt.training - Epoch   6, Step:    20200, Batch Loss:     1.765163, Batch Acc: 0.509260, Tokens per Sec:     1832, Lr: 0.000300
2023-05-28 08:24:34,388 - INFO - joeynmt.training - Epoch   6, Step:    20300, Batch Loss:     1.940225, Batch Acc: 0.509106, Tokens per Sec:     1883, Lr: 0.000300
2023-05-28 08:25:11,015 - INFO - joeynmt.training - Epoch   6, Step:    20400, Batch Loss:     1.997362, Batch Acc: 0.506618, Tokens per Sec:     1852, Lr: 0.000300
2023-05-28 08:25:46,333 - INFO - joeynmt.training - Epoch   6, Step:    20500, Batch Loss:     1.709371, Batch Acc: 0.512893, Tokens per Sec:     1846, Lr: 0.000300
2023-05-28 08:25:46,334 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:25:46,335 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:26:44,735 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.05, ppl:   7.76, acc:   0.47, generation: 58.3060[sec], evaluation: 0.0000[sec]
2023-05-28 08:26:44,740 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 08:26:44,909 - INFO - joeynmt.helpers - delete models/transformer_c/17500.ckpt
2023-05-28 08:26:44,925 - INFO - joeynmt.training - Example #0
2023-05-28 08:26:44,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:26:44,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:26:44,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'ver@@', 'kennen', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'voor', 'een', 'aan@@', 'val', 'drie', 'miljoen', 'jaar', 'de', 'gro@@', 'ten@@', 'deels', 'van', 'de', 'onder@@', 'ste', 'st@@', 'aten', ',', 'om', '40', 'procent', '.', '</s>']
2023-05-28 08:26:44,926 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:26:44,926 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:26:44,926 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te verkennen dat de arctische ijskappe die voor een aanval drie miljoen jaar de grotendeels van de onderste staten, om 40 procent.
2023-05-28 08:26:44,926 - INFO - joeynmt.training - Example #1
2023-05-28 08:26:44,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:26:44,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:26:44,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'soort', 'problemen', ',', 'omdat', 'het', 'niet', 'zo', 'erg', 'genoeg', 'is', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'es', '.', '</s>']
2023-05-28 08:26:44,926 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:26:44,926 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:26:44,926 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg de oogst van dit soort problemen, omdat het niet zo erg genoeg is, omdat het niet de dikke van het ijses.
2023-05-28 08:26:44,926 - INFO - joeynmt.training - Example #2
2023-05-28 08:26:44,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:26:44,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:26:44,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 'k@@', 'jes', 'het', 'sch@@', 'ep@@', 'sel', 'van', 'onze', 'mondiale', 'klimaat@@', 'verandering', '.', '</s>']
2023-05-28 08:26:44,927 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:26:44,927 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:26:44,927 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijkjes het schepsel van onze mondiale klimaatverandering.
2023-05-28 08:26:44,927 - INFO - joeynmt.training - Example #3
2023-05-28 08:26:44,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:26:44,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:26:44,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'roe@@', 'p', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:26:44,927 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:26:44,927 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:26:44,927 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroep in de zomer.
2023-05-28 08:26:44,927 - INFO - joeynmt.training - Example #4
2023-05-28 08:26:44,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:26:44,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:26:44,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'teken@@', 'ing', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 08:26:44,927 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:26:44,927 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:26:44,927 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tekening van wat er in de laatste 25 jaar is.
2023-05-28 08:27:21,106 - INFO - joeynmt.training - Epoch   6, Step:    20600, Batch Loss:     1.652492, Batch Acc: 0.506532, Tokens per Sec:     1814, Lr: 0.000300
2023-05-28 08:27:56,743 - INFO - joeynmt.training - Epoch   6, Step:    20700, Batch Loss:     1.868752, Batch Acc: 0.513709, Tokens per Sec:     1877, Lr: 0.000300
2023-05-28 08:28:31,191 - INFO - joeynmt.training - Epoch   6, Step:    20800, Batch Loss:     1.757483, Batch Acc: 0.503571, Tokens per Sec:     1963, Lr: 0.000300
2023-05-28 08:29:06,657 - INFO - joeynmt.training - Epoch   6, Step:    20900, Batch Loss:     1.802000, Batch Acc: 0.506512, Tokens per Sec:     1886, Lr: 0.000300
2023-05-28 08:29:41,500 - INFO - joeynmt.training - Epoch   6, Step:    21000, Batch Loss:     1.876396, Batch Acc: 0.508626, Tokens per Sec:     1930, Lr: 0.000300
2023-05-28 08:29:41,502 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:29:41,502 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:30:50,731 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.05, ppl:   7.74, acc:   0.47, generation: 69.1332[sec], evaluation: 0.0000[sec]
2023-05-28 08:30:50,735 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 08:30:50,863 - INFO - joeynmt.helpers - delete models/transformer_c/19000.ckpt
2023-05-28 08:30:50,877 - INFO - joeynmt.training - Example #0
2023-05-28 08:30:50,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:30:50,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:30:50,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'ver@@', 'beelden', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'sk@@', 'sk@@', 'appen', 'die', 'voor', 'een', 'paar', 'jaar', 'van', 'de', 'onder@@', 'ste', 'van', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', 'ge@@', 'p@@', 'aard', 'te', 'zien', '.', '</s>']
2023-05-28 08:30:50,877 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:30:50,877 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:30:50,877 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te verbeelden dat de arctische ijskskskappen die voor een paar jaar van de onderste van 48 staten, om 40 procent gepaard te zien.
2023-05-28 08:30:50,877 - INFO - joeynmt.training - Example #1
2023-05-28 08:30:50,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:30:50,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:30:50,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'specifieke', 'problemen', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ijs', 'laat', 'zien', '.', '</s>']
2023-05-28 08:30:50,878 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:30:50,878 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:30:50,878 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de oogst van deze specifieke problemen, want het is niet de dikke van het ijs laat zien.
2023-05-28 08:30:50,878 - INFO - joeynmt.training - Example #2
2023-05-28 08:30:50,878 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:30:50,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:30:50,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'ep@@', 'je', 'het', 'hart', 'van', 'onze', 'wereldwijde', 'klimaat@@', 'systemen', '.', '</s>']
2023-05-28 08:30:50,878 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:30:50,878 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:30:50,878 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het schepje het hart van onze wereldwijde klimaatsystemen.
2023-05-28 08:30:50,878 - INFO - joeynmt.training - Example #3
2023-05-28 08:30:50,878 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:30:50,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:30:50,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sl@@', 'op@@', 'pen@@', 'w@@', 'ijk', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:30:50,878 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:30:50,878 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:30:50,878 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sloppenwijk in de zomer.
2023-05-28 08:30:50,878 - INFO - joeynmt.training - Example #4
2023-05-28 08:30:50,878 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:30:50,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:30:50,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'toon', 'is', 'een', 'teken@@', 'ing', 'van', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 08:30:50,879 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:30:50,879 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:30:50,879 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik toon is een tekening van wat er in de afgelopen 25 jaar is.
2023-05-28 08:31:26,294 - INFO - joeynmt.training - Epoch   6, Step:    21100, Batch Loss:     1.887496, Batch Acc: 0.510478, Tokens per Sec:     1888, Lr: 0.000300
2023-05-28 08:32:02,005 - INFO - joeynmt.training - Epoch   6, Step:    21200, Batch Loss:     1.799376, Batch Acc: 0.505661, Tokens per Sec:     1848, Lr: 0.000300
2023-05-28 08:32:37,106 - INFO - joeynmt.training - Epoch   6, Step:    21300, Batch Loss:     1.702341, Batch Acc: 0.505824, Tokens per Sec:     1925, Lr: 0.000300
2023-05-28 08:32:50,432 - INFO - joeynmt.training - Epoch   6: total training loss 6671.87
2023-05-28 08:32:50,433 - INFO - joeynmt.training - EPOCH 7
2023-05-28 08:32:50,465 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=6
2023-05-28 08:33:13,195 - INFO - joeynmt.training - Epoch   7, Step:    21400, Batch Loss:     1.761155, Batch Acc: 0.524912, Tokens per Sec:     1904, Lr: 0.000300
2023-05-28 08:33:48,371 - INFO - joeynmt.training - Epoch   7, Step:    21500, Batch Loss:     1.856573, Batch Acc: 0.523341, Tokens per Sec:     1893, Lr: 0.000300
2023-05-28 08:33:48,372 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:33:48,372 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:35:00,572 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.04, ppl:   7.69, acc:   0.48, generation: 72.1028[sec], evaluation: 0.0000[sec]
2023-05-28 08:35:00,575 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 08:35:00,717 - INFO - joeynmt.helpers - delete models/transformer_c/18500.ckpt
2023-05-28 08:35:00,734 - INFO - joeynmt.training - Example #0
2023-05-28 08:35:00,734 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:35:00,734 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:35:00,734 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'ver@@', 'kennen', 'dat', 'de', 'ar@@', 'ie@@', 'ij@@', 'sk@@', 'sk@@', 'sk@@', 'appen', 'die', 'voor', 'de', 'negen', 'miljoen', 'jaar', 'de', 'gro@@', 'en@@', 'deels', 'onder@@', 'aan', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', '.', '</s>']
2023-05-28 08:35:00,734 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:35:00,734 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:35:00,734 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te verkennen dat de arieijskskskappen die voor de negen miljoen jaar de groendeels onderaan de onderste 48 staten, om 40 procent.
2023-05-28 08:35:00,734 - INFO - joeynmt.training - Example #1
2023-05-28 08:35:00,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:35:00,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:35:00,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'soort', 'problemen', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'es', 'toont', '.', '</s>']
2023-05-28 08:35:00,735 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:35:00,735 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:35:00,735 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de oogst van dit soort problemen omdat het niet de dikke van de ijses toont.
2023-05-28 08:35:00,735 - INFO - joeynmt.training - Example #2
2023-05-28 08:35:00,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:35:00,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:35:00,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 'sk@@', 'sk@@', 'aar@@', 'tje', 'het', 'sch@@', 'aar@@', 'dig', 'hart', 'van', 'ons', 'mondiale', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 08:35:00,735 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:35:00,735 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:35:00,735 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijskskaartje het schaardig hart van ons mondiale klimaatsysteem.
2023-05-28 08:35:00,735 - INFO - joeynmt.training - Example #3
2023-05-28 08:35:00,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:35:00,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:35:00,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'roe@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:35:00,735 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:35:00,735 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:35:00,735 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroepen in de zomer.
2023-05-28 08:35:00,735 - INFO - joeynmt.training - Example #4
2023-05-28 08:35:00,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:35:00,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:35:00,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'ti@@', 'me', 'op@@', 'name', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'gebeurd', 'is', '.', '</s>']
2023-05-28 08:35:00,736 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:35:00,736 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:35:00,736 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een time opname wat er in de laatste 25 jaar gebeurd is.
2023-05-28 08:35:36,690 - INFO - joeynmt.training - Epoch   7, Step:    21600, Batch Loss:     1.664254, Batch Acc: 0.522158, Tokens per Sec:     1821, Lr: 0.000300
2023-05-28 08:36:11,966 - INFO - joeynmt.training - Epoch   7, Step:    21700, Batch Loss:     1.938188, Batch Acc: 0.522225, Tokens per Sec:     1901, Lr: 0.000300
2023-05-28 08:36:48,542 - INFO - joeynmt.training - Epoch   7, Step:    21800, Batch Loss:     1.763613, Batch Acc: 0.523001, Tokens per Sec:     1809, Lr: 0.000300
2023-05-28 08:37:25,882 - INFO - joeynmt.training - Epoch   7, Step:    21900, Batch Loss:     2.002709, Batch Acc: 0.518477, Tokens per Sec:     1811, Lr: 0.000300
2023-05-28 08:38:02,748 - INFO - joeynmt.training - Epoch   7, Step:    22000, Batch Loss:     1.850113, Batch Acc: 0.517475, Tokens per Sec:     1809, Lr: 0.000300
2023-05-28 08:38:02,748 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:38:02,749 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:39:03,631 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.04, ppl:   7.69, acc:   0.48, generation: 60.7852[sec], evaluation: 0.0000[sec]
2023-05-28 08:39:03,634 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 08:39:03,806 - INFO - joeynmt.helpers - delete models/transformer_c/20000.ckpt
2023-05-28 08:39:03,822 - INFO - joeynmt.training - Example #0
2023-05-28 08:39:03,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:39:03,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:39:03,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'liet', 'deze', 'twee', 'di@@', 'a', 'zien', 'om', 'te', 'ver@@', 'beelden', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'voor', 'de', 'aan@@', 'val', 'drie', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', '40', 'procent', '.', '</s>']
2023-05-28 08:39:03,822 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:39:03,822 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:39:03,822 - INFO - joeynmt.training - 	Hypothesis: Ik liet deze twee dia zien om te verbeelden dat de arctische ijskappe die voor de aanval drie miljoen jaar de grootte van de grootte van de onderste 48 staten, 40 procent.
2023-05-28 08:39:03,822 - INFO - joeynmt.training - Example #1
2023-05-28 08:39:03,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:39:03,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:39:03,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'de', 'oog@@', 'st', 'van', 'dit', 'soort', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 'f', '.', '</s>']
2023-05-28 08:39:03,823 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:39:03,823 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:39:03,823 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg de oogst van de oogst van dit soort problemen, omdat het niet de dikke van de ijf.
2023-05-28 08:39:03,823 - INFO - joeynmt.training - Example #2
2023-05-28 08:39:03,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:39:03,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:39:03,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'it@@', 'ter@@', 'ende', 'hart', 'van', 'onze', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 08:39:03,823 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:39:03,823 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:39:03,823 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het schitterende hart van onze wereldwijde klimaatsysteem.
2023-05-28 08:39:03,823 - INFO - joeynmt.training - Example #3
2023-05-28 08:39:03,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:39:03,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:39:03,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'roe@@', 'pt', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:39:03,823 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:39:03,823 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:39:03,823 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroept in de zomer.
2023-05-28 08:39:03,823 - INFO - joeynmt.training - Example #4
2023-05-28 08:39:03,824 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:39:03,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:39:03,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tijd@@', 'je', 'dat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 08:39:03,824 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:39:03,824 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:39:03,824 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje dat er in de afgelopen 25 jaar is.
2023-05-28 08:39:42,668 - INFO - joeynmt.training - Epoch   7, Step:    22100, Batch Loss:     1.829141, Batch Acc: 0.518033, Tokens per Sec:     1695, Lr: 0.000300
2023-05-28 08:40:19,867 - INFO - joeynmt.training - Epoch   7, Step:    22200, Batch Loss:     1.682498, Batch Acc: 0.515634, Tokens per Sec:     1837, Lr: 0.000300
2023-05-28 08:40:56,132 - INFO - joeynmt.training - Epoch   7, Step:    22300, Batch Loss:     1.829952, Batch Acc: 0.513689, Tokens per Sec:     1786, Lr: 0.000300
2023-05-28 08:41:31,851 - INFO - joeynmt.training - Epoch   7, Step:    22400, Batch Loss:     1.764075, Batch Acc: 0.516055, Tokens per Sec:     1853, Lr: 0.000300
2023-05-28 08:42:08,020 - INFO - joeynmt.training - Epoch   7, Step:    22500, Batch Loss:     1.753255, Batch Acc: 0.516959, Tokens per Sec:     1823, Lr: 0.000300
2023-05-28 08:42:08,022 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:42:08,022 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:43:04,721 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.04, ppl:   7.69, acc:   0.48, generation: 56.6045[sec], evaluation: 0.0000[sec]
2023-05-28 08:43:04,726 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 08:43:04,860 - INFO - joeynmt.helpers - delete models/transformer_c/19500.ckpt
2023-05-28 08:43:04,878 - INFO - joeynmt.training - Example #0
2023-05-28 08:43:04,878 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:43:04,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:43:04,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'ver@@', 'beelden', 'dat', 'de', 'ar@@', 'c@@', 'tiv@@', 'iteit', 'van', 'de', 'ar@@', 'c@@', 'tiv@@', 'iteit', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', '%', '.', '</s>']
2023-05-28 08:43:04,878 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:43:04,878 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:43:04,878 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te verbeelden dat de arctiviteit van de arctiviteit van de onderste 48 staten, om 40%.
2023-05-28 08:43:04,878 - INFO - joeynmt.training - Example #1
2023-05-28 08:43:04,878 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:43:04,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:43:04,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'speci@@', 'aal', 'probleem', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'ing', 'is', '.', '</s>']
2023-05-28 08:43:04,879 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:43:04,879 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:43:04,879 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo sterk genoeg de oogst van dit speciaal probleem, omdat het niet de dikke van het ijsing is.
2023-05-28 08:43:04,879 - INFO - joeynmt.training - Example #2
2023-05-28 08:43:04,879 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:43:04,879 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:43:04,879 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'ep@@', 'pen', 'van', 'onze', 'wereld@@', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 08:43:04,879 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:43:04,879 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:43:04,879 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het scheppen van onze wereldklimaatsysteem.
2023-05-28 08:43:04,879 - INFO - joeynmt.training - Example #3
2023-05-28 08:43:04,879 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:43:04,879 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:43:04,879 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'roe@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:43:04,879 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:43:04,879 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:43:04,879 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroepen in de zomer.
2023-05-28 08:43:04,879 - INFO - joeynmt.training - Example #4
2023-05-28 08:43:04,879 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:43:04,879 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:43:04,879 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'ge@@', 'spe@@', 'eld', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 08:43:04,880 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:43:04,880 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:43:04,880 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien, is een tijdgespeeld van wat er in de laatste 25 jaar is.
2023-05-28 08:43:41,213 - INFO - joeynmt.training - Epoch   7, Step:    22600, Batch Loss:     1.699612, Batch Acc: 0.518364, Tokens per Sec:     1835, Lr: 0.000300
2023-05-28 08:44:17,084 - INFO - joeynmt.training - Epoch   7, Step:    22700, Batch Loss:     1.666742, Batch Acc: 0.522505, Tokens per Sec:     1870, Lr: 0.000300
2023-05-28 08:44:51,897 - INFO - joeynmt.training - Epoch   7, Step:    22800, Batch Loss:     1.777240, Batch Acc: 0.520590, Tokens per Sec:     1920, Lr: 0.000300
2023-05-28 08:45:27,012 - INFO - joeynmt.training - Epoch   7, Step:    22900, Batch Loss:     1.816551, Batch Acc: 0.516044, Tokens per Sec:     1946, Lr: 0.000300
2023-05-28 08:46:03,728 - INFO - joeynmt.training - Epoch   7, Step:    23000, Batch Loss:     1.639224, Batch Acc: 0.524464, Tokens per Sec:     1821, Lr: 0.000300
2023-05-28 08:46:03,730 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:46:03,730 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:46:58,539 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.04, ppl:   7.69, acc:   0.48, generation: 54.7148[sec], evaluation: 0.0000[sec]
2023-05-28 08:46:58,698 - INFO - joeynmt.helpers - delete models/transformer_c/20500.ckpt
2023-05-28 08:46:58,713 - INFO - joeynmt.training - Example #0
2023-05-28 08:46:58,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:46:58,713 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:46:58,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'ver@@', 'beelden', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'jes', 'die', 'voor', 'de', 'lag@@', 'ere', '4@@', '8', 'st@@', 'aten', ',', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', '.', '</s>']
2023-05-28 08:46:58,714 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:46:58,714 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:46:58,714 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te verbeelden dat de arctische ijkjes die voor de lagere 48 staten, de grootte van de onderste 48 staten, om 40 procent.
2023-05-28 08:46:58,714 - INFO - joeynmt.training - Example #1
2023-05-28 08:46:58,714 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:46:58,714 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:46:58,714 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'specifieke', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 'zer', 'laat', 'zien', '.', '</s>']
2023-05-28 08:46:58,714 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:46:58,714 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:46:58,714 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de oogst van deze specifieke problemen, omdat het niet de dikke van de ijzer laat zien.
2023-05-28 08:46:58,714 - INFO - joeynmt.training - Example #2
2023-05-28 08:46:58,714 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:46:58,714 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:46:58,714 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'elen', 'van', 'de', 'klimaat@@', 'verandering', '.', '</s>']
2023-05-28 08:46:58,715 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:46:58,715 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:46:58,715 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het schelen van de klimaatverandering.
2023-05-28 08:46:58,715 - INFO - joeynmt.training - Example #3
2023-05-28 08:46:58,715 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:46:58,715 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:46:58,715 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ep@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:46:58,715 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:46:58,715 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:46:58,715 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppen in de zomer.
2023-05-28 08:46:58,715 - INFO - joeynmt.training - Example #4
2023-05-28 08:46:58,715 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:46:58,715 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:46:58,715 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'st@@', 'ip', 'van', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 08:46:58,715 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:46:58,715 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:46:58,715 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien, is een tijdstip van wat er in de afgelopen 25 jaar.
2023-05-28 08:47:36,329 - INFO - joeynmt.training - Epoch   7, Step:    23100, Batch Loss:     1.776319, Batch Acc: 0.516645, Tokens per Sec:     1765, Lr: 0.000300
2023-05-28 08:48:13,853 - INFO - joeynmt.training - Epoch   7, Step:    23200, Batch Loss:     1.676105, Batch Acc: 0.519881, Tokens per Sec:     1775, Lr: 0.000300
2023-05-28 08:48:49,634 - INFO - joeynmt.training - Epoch   7, Step:    23300, Batch Loss:     1.811673, Batch Acc: 0.519468, Tokens per Sec:     1927, Lr: 0.000300
2023-05-28 08:49:28,082 - INFO - joeynmt.training - Epoch   7, Step:    23400, Batch Loss:     1.744232, Batch Acc: 0.516660, Tokens per Sec:     1767, Lr: 0.000300
2023-05-28 08:50:05,461 - INFO - joeynmt.training - Epoch   7, Step:    23500, Batch Loss:     1.888409, Batch Acc: 0.521728, Tokens per Sec:     1741, Lr: 0.000300
2023-05-28 08:50:05,462 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:50:05,462 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:51:13,248 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.03, ppl:   7.59, acc:   0.48, generation: 67.6893[sec], evaluation: 0.0000[sec]
2023-05-28 08:51:13,252 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 08:51:13,423 - INFO - joeynmt.helpers - delete models/transformer_c/21000.ckpt
2023-05-28 08:51:13,439 - INFO - joeynmt.training - Example #0
2023-05-28 08:51:13,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:51:13,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:51:13,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'ver@@', 'beelden', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'sk@@', 'aar@@', 'en', 'die', 'voor', 'een', 'paar', 'jaar', ',', 'de', 'grootte', 'van', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', '.', '</s>']
2023-05-28 08:51:13,439 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:51:13,439 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:51:13,439 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te verbeelden dat de arctische ijskskaaren die voor een paar jaar, de grootte van 48 staten, om 40 procent.
2023-05-28 08:51:13,439 - INFO - joeynmt.training - Example #1
2023-05-28 08:51:13,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:51:13,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:51:13,440 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'soort', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ijs', 'toont', '.', '</s>']
2023-05-28 08:51:13,440 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:51:13,440 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:51:13,440 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de oogst van dit soort problemen, omdat het niet de dikke van het ijs toont.
2023-05-28 08:51:13,440 - INFO - joeynmt.training - Example #2
2023-05-28 08:51:13,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:51:13,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:51:13,440 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'la@@', 'p', 'van', 'ons', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 08:51:13,440 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:51:13,440 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:51:13,440 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het schlap van ons wereldwijde klimaatsysteem.
2023-05-28 08:51:13,440 - INFO - joeynmt.training - Example #3
2023-05-28 08:51:13,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:51:13,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:51:13,440 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ep@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:51:13,440 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:51:13,440 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:51:13,440 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppen in de zomer.
2023-05-28 08:51:13,440 - INFO - joeynmt.training - Example #4
2023-05-28 08:51:13,441 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:51:13,441 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:51:13,441 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', 'tijden', 'van', 'een', 'tijden', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 08:51:13,441 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:51:13,441 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:51:13,441 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een tijden van een tijden van wat er in de laatste 25 jaar is.
2023-05-28 08:51:50,202 - INFO - joeynmt.training - Epoch   7, Step:    23600, Batch Loss:     1.707643, Batch Acc: 0.511410, Tokens per Sec:     1816, Lr: 0.000300
2023-05-28 08:52:28,588 - INFO - joeynmt.training - Epoch   7, Step:    23700, Batch Loss:     1.689074, Batch Acc: 0.514128, Tokens per Sec:     1698, Lr: 0.000300
2023-05-28 08:53:05,109 - INFO - joeynmt.training - Epoch   7, Step:    23800, Batch Loss:     1.900371, Batch Acc: 0.519492, Tokens per Sec:     1827, Lr: 0.000300
2023-05-28 08:53:41,586 - INFO - joeynmt.training - Epoch   7, Step:    23900, Batch Loss:     2.012452, Batch Acc: 0.516487, Tokens per Sec:     1881, Lr: 0.000300
2023-05-28 08:54:19,119 - INFO - joeynmt.training - Epoch   7, Step:    24000, Batch Loss:     1.749596, Batch Acc: 0.520701, Tokens per Sec:     1826, Lr: 0.000300
2023-05-28 08:54:19,120 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:54:19,120 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:55:24,970 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.02, ppl:   7.57, acc:   0.48, generation: 65.7535[sec], evaluation: 0.0000[sec]
2023-05-28 08:55:24,973 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 08:55:25,134 - INFO - joeynmt.helpers - delete models/transformer_c/23000.ckpt
2023-05-28 08:55:25,154 - INFO - joeynmt.training - Example #0
2023-05-28 08:55:25,155 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:55:25,155 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:55:25,155 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'jes', 'die', 'voor', 'een', 'paar', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'en', 'van', '4@@', '8', 'st@@', 'aten', 'had', 'om', '40', '%', '.', '</s>']
2023-05-28 08:55:25,155 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:55:25,155 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:55:25,155 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te zien dat de arctische ijkjes die voor een paar miljoen jaar de grootte van de onderen van 48 staten had om 40%.
2023-05-28 08:55:25,155 - INFO - joeynmt.training - Example #1
2023-05-28 08:55:25,155 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:55:25,155 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:55:25,155 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ijs', 'laat', 'zien', '.', '</s>']
2023-05-28 08:55:25,155 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:55:25,155 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:55:25,155 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de oogst van dit specifieke probleem omdat het niet de dikke van het ijs laat zien.
2023-05-28 08:55:25,155 - INFO - joeynmt.training - Example #2
2023-05-28 08:55:25,156 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:55:25,156 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:55:25,156 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'la@@', 'p', 'van', 'ons', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 08:55:25,156 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:55:25,156 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:55:25,156 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het schlap van ons wereldwijde klimaatsysteem.
2023-05-28 08:55:25,156 - INFO - joeynmt.training - Example #3
2023-05-28 08:55:25,156 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:55:25,156 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:55:25,156 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ij@@', 'f', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:55:25,156 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:55:25,156 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:55:25,156 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schijf in de zomer.
2023-05-28 08:55:25,156 - INFO - joeynmt.training - Example #4
2023-05-28 08:55:25,156 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:55:25,156 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:55:25,156 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'je', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 08:55:25,156 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:55:25,157 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:55:25,157 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien, is een tijdje van de laatste 25 jaar.
2023-05-28 08:56:03,944 - INFO - joeynmt.training - Epoch   7, Step:    24100, Batch Loss:     1.816560, Batch Acc: 0.515220, Tokens per Sec:     1745, Lr: 0.000300
2023-05-28 08:56:40,585 - INFO - joeynmt.training - Epoch   7, Step:    24200, Batch Loss:     1.759025, Batch Acc: 0.518634, Tokens per Sec:     1862, Lr: 0.000300
2023-05-28 08:57:17,704 - INFO - joeynmt.training - Epoch   7, Step:    24300, Batch Loss:     1.904534, Batch Acc: 0.516928, Tokens per Sec:     1821, Lr: 0.000300
2023-05-28 08:57:52,793 - INFO - joeynmt.training - Epoch   7, Step:    24400, Batch Loss:     1.498301, Batch Acc: 0.520590, Tokens per Sec:     1842, Lr: 0.000300
2023-05-28 08:58:27,652 - INFO - joeynmt.training - Epoch   7, Step:    24500, Batch Loss:     1.625547, Batch Acc: 0.520239, Tokens per Sec:     1941, Lr: 0.000300
2023-05-28 08:58:27,653 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 08:58:27,653 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 08:59:27,230 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.02, ppl:   7.53, acc:   0.48, generation: 59.4803[sec], evaluation: 0.0000[sec]
2023-05-28 08:59:27,234 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 08:59:27,372 - INFO - joeynmt.helpers - delete models/transformer_c/21500.ckpt
2023-05-28 08:59:27,385 - INFO - joeynmt.training - Example #0
2023-05-28 08:59:27,385 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 08:59:27,385 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 08:59:27,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'sk@@', 'sk@@', 'appen', 'die', 'voor', 'de', 'drie', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'had', '40', 'procent', 'gesch@@', 'ru@@', 'mp@@', 'eld', '.', '</s>']
2023-05-28 08:59:27,385 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 08:59:27,385 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 08:59:27,386 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te zien dat de arctische ijskskskappen die voor de drie miljoen jaar de grootte van de onderste 48 staten, had 40 procent geschrumpeld.
2023-05-28 08:59:27,386 - INFO - joeynmt.training - Example #1
2023-05-28 08:59:27,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 08:59:27,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 08:59:27,386 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'problemen', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'heid', 'van', 'het', 'ij@@', 'zer', '.', '</s>']
2023-05-28 08:59:27,386 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 08:59:27,386 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 08:59:27,386 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg de oogst van deze problemen omdat het niet de dikke van de ijsheid van het ijzer.
2023-05-28 08:59:27,386 - INFO - joeynmt.training - Example #2
2023-05-28 08:59:27,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 08:59:27,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 08:59:27,386 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'it@@', 'ter@@', 'ende', 'hart', 'van', 'onze', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 08:59:27,386 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 08:59:27,386 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 08:59:27,386 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het schitterende hart van onze wereldwijde klimaatsysteem.
2023-05-28 08:59:27,386 - INFO - joeynmt.training - Example #3
2023-05-28 08:59:27,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 08:59:27,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 08:59:27,386 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ep@@', 'pen', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 08:59:27,387 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 08:59:27,387 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 08:59:27,387 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppen in de zomer.
2023-05-28 08:59:27,387 - INFO - joeynmt.training - Example #4
2023-05-28 08:59:27,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 08:59:27,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 08:59:27,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'ds@@', 'ver@@', 'houding', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 08:59:27,387 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 08:59:27,387 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 08:59:27,387 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsverhouding van wat er in de laatste 25 jaar is.
2023-05-28 09:00:01,622 - INFO - joeynmt.training - Epoch   7, Step:    24600, Batch Loss:     1.995142, Batch Acc: 0.514945, Tokens per Sec:     1910, Lr: 0.000300
2023-05-28 09:00:38,184 - INFO - joeynmt.training - Epoch   7, Step:    24700, Batch Loss:     1.866168, Batch Acc: 0.518832, Tokens per Sec:     1858, Lr: 0.000300
2023-05-28 09:01:13,188 - INFO - joeynmt.training - Epoch   7, Step:    24800, Batch Loss:     1.981543, Batch Acc: 0.519820, Tokens per Sec:     1921, Lr: 0.000300
2023-05-28 09:01:50,351 - INFO - joeynmt.training - Epoch   7, Step:    24900, Batch Loss:     1.635431, Batch Acc: 0.521352, Tokens per Sec:     1788, Lr: 0.000300
2023-05-28 09:01:56,790 - INFO - joeynmt.training - Epoch   7: total training loss 6535.45
2023-05-28 09:01:56,790 - INFO - joeynmt.training - EPOCH 8
2023-05-28 09:01:56,825 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=7
2023-05-28 09:02:26,328 - INFO - joeynmt.training - Epoch   8, Step:    25000, Batch Loss:     1.907035, Batch Acc: 0.527279, Tokens per Sec:     1860, Lr: 0.000300
2023-05-28 09:02:26,329 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:02:26,329 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:03:34,292 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.02, ppl:   7.52, acc:   0.48, generation: 67.8635[sec], evaluation: 0.0000[sec]
2023-05-28 09:03:34,295 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 09:03:34,420 - INFO - joeynmt.helpers - delete models/transformer_c/22000.ckpt
2023-05-28 09:03:34,438 - INFO - joeynmt.training - Example #0
2023-05-28 09:03:34,438 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:03:34,438 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:03:34,438 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'zien', 'dat', 'de', 'Arab@@', 'ische', 'ij@@', 'k@@', 'app@@', 'e', ',', 'die', 'voor', 'de', 'negen', ',', 'drie', 'miljoen', 'jaar', ',', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', 'te', 'ver@@', 'p@@', 'oot', 'te', 'zijn', '.', '</s>']
2023-05-28 09:03:34,438 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:03:34,438 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:03:34,438 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te zien dat de Arabische ijkappe, die voor de negen, drie miljoen jaar, de grootte van de onderste 48 staten, om 40 procent te verpoot te zijn.
2023-05-28 09:03:34,438 - INFO - joeynmt.training - Example #1
2023-05-28 09:03:34,438 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:03:34,438 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:03:34,438 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'veel', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'bepaalde', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'st', 'van', 'het', 'ij@@', 'st', '.', '</s>']
2023-05-28 09:03:34,439 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:03:34,439 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:03:34,439 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo veel genoeg de oogst van deze bepaalde problemen, omdat het niet de dikke van het ijst van het ijst.
2023-05-28 09:03:34,439 - INFO - joeynmt.training - Example #2
2023-05-28 09:03:34,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:03:34,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:03:34,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'de', 'arm@@', 'ste', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'it@@', 'ter@@', 'ende', 'hart', 'van', 'ons', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 09:03:34,439 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:03:34,439 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:03:34,439 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de de armste ijkappe het schitterende hart van ons wereldwijde klimaatsysteem.
2023-05-28 09:03:34,439 - INFO - joeynmt.training - Example #3
2023-05-28 09:03:34,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:03:34,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:03:34,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'aal@@', 't', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 09:03:34,439 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:03:34,439 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:03:34,439 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schaalt in de zomer.
2023-05-28 09:03:34,439 - INFO - joeynmt.training - Example #4
2023-05-28 09:03:34,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:03:34,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:03:34,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'toon', ',', 'is', 'een', 'ti@@', 'ende', 'op@@', 'name', 'dat', 'er', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 09:03:34,440 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:03:34,440 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:03:34,440 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie toon, is een tiende opname dat er in de laatste 25 jaar.
2023-05-28 09:04:11,606 - INFO - joeynmt.training - Epoch   8, Step:    25100, Batch Loss:     1.701471, Batch Acc: 0.532885, Tokens per Sec:     1835, Lr: 0.000300
2023-05-28 09:04:48,472 - INFO - joeynmt.training - Epoch   8, Step:    25200, Batch Loss:     1.876374, Batch Acc: 0.532690, Tokens per Sec:     1824, Lr: 0.000300
2023-05-28 09:05:25,818 - INFO - joeynmt.training - Epoch   8, Step:    25300, Batch Loss:     1.444663, Batch Acc: 0.535250, Tokens per Sec:     1813, Lr: 0.000300
2023-05-28 09:06:02,804 - INFO - joeynmt.training - Epoch   8, Step:    25400, Batch Loss:     1.726676, Batch Acc: 0.530007, Tokens per Sec:     1814, Lr: 0.000300
2023-05-28 09:06:40,109 - INFO - joeynmt.training - Epoch   8, Step:    25500, Batch Loss:     1.906454, Batch Acc: 0.533164, Tokens per Sec:     1798, Lr: 0.000300
2023-05-28 09:06:40,110 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:06:40,110 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:07:37,341 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.01, ppl:   7.50, acc:   0.48, generation: 57.1343[sec], evaluation: 0.0000[sec]
2023-05-28 09:07:37,344 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 09:07:37,516 - INFO - joeynmt.helpers - delete models/transformer_c/22500.ckpt
2023-05-28 09:07:37,530 - INFO - joeynmt.training - Example #0
2023-05-28 09:07:37,530 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:07:37,530 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:07:37,530 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'ver@@', 'beelden', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'sk@@', 'aar@@', 'tje', ',', 'die', 'voor', 'de', 'drie', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'had', '40', 'procent', 'gesch@@', 'ru@@', 'ft', '.', '</s>']
2023-05-28 09:07:37,530 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:07:37,530 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:07:37,530 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te verbeelden dat de arctische ijskskaartje, die voor de drie miljoen jaar de grootte van de onderste 48 staten, had 40 procent geschruft.
2023-05-28 09:07:37,530 - INFO - joeynmt.training - Example #1
2023-05-28 09:07:37,531 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:07:37,531 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:07:37,531 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'specifieke', 'probleem', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'f', '.', '</s>']
2023-05-28 09:07:37,531 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:07:37,531 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:07:37,531 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg de oogst van dit specifieke probleem, want het is niet de dikke van het ijf.
2023-05-28 09:07:37,531 - INFO - joeynmt.training - Example #2
2023-05-28 09:07:37,531 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:07:37,531 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:07:37,531 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'la@@', 'p', 'van', 'het', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 09:07:37,531 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:07:37,531 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:07:37,531 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het schlap van het wereldwijde klimaatsysteem.
2023-05-28 09:07:37,531 - INFO - joeynmt.training - Example #3
2023-05-28 09:07:37,531 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:07:37,531 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:07:37,531 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'roe@@', 'pt', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 09:07:37,531 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:07:37,531 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:07:37,531 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroept in de zomer.
2023-05-28 09:07:37,531 - INFO - joeynmt.training - Example #4
2023-05-28 09:07:37,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:07:37,532 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:07:37,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', ',', 'is', 'een', 'tijd@@', 'je', 'dat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 09:07:37,532 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:07:37,532 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:07:37,532 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdje dat er in de afgelopen 25 jaar is.
2023-05-28 09:08:14,691 - INFO - joeynmt.training - Epoch   8, Step:    25600, Batch Loss:     1.647205, Batch Acc: 0.534487, Tokens per Sec:     1783, Lr: 0.000300
2023-05-28 09:08:52,425 - INFO - joeynmt.training - Epoch   8, Step:    25700, Batch Loss:     1.537123, Batch Acc: 0.524351, Tokens per Sec:     1751, Lr: 0.000300
2023-05-28 09:09:30,456 - INFO - joeynmt.training - Epoch   8, Step:    25800, Batch Loss:     1.765487, Batch Acc: 0.531966, Tokens per Sec:     1757, Lr: 0.000300
2023-05-28 09:10:08,298 - INFO - joeynmt.training - Epoch   8, Step:    25900, Batch Loss:     1.699398, Batch Acc: 0.528989, Tokens per Sec:     1713, Lr: 0.000300
2023-05-28 09:10:45,766 - INFO - joeynmt.training - Epoch   8, Step:    26000, Batch Loss:     1.746391, Batch Acc: 0.529456, Tokens per Sec:     1784, Lr: 0.000300
2023-05-28 09:10:45,767 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:10:45,767 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:11:46,984 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.01, ppl:   7.48, acc:   0.48, generation: 61.1218[sec], evaluation: 0.0000[sec]
2023-05-28 09:11:46,988 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 09:11:47,109 - INFO - joeynmt.helpers - delete models/transformer_c/23500.ckpt
2023-05-28 09:11:47,125 - INFO - joeynmt.training - Example #0
2023-05-28 09:11:47,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:11:47,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:11:47,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'beelden', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'sk@@', 'aar@@', 'en', 'die', 'voor', 'de', 'achter@@', 'grond', 'drie', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', ',', '40', 'procent', 'gesch@@', 'ikt', '.', '</s>']
2023-05-28 09:11:47,125 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:11:47,125 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:11:47,125 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verbeelden dat de arctische ijskskaaren die voor de achtergrond drie miljoen jaar de grootte van de onderste 48 staten had, 40 procent geschikt.
2023-05-28 09:11:47,125 - INFO - joeynmt.training - Example #1
2023-05-28 09:11:47,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:11:47,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:11:47,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'soort', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'het', 'ij@@', 'st', 'van', 'het', 'ij@@', 'st', 'van', 'het', 'ij@@', 'st', '.', '</s>']
2023-05-28 09:11:47,126 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:11:47,126 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:11:47,126 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo sterk genoeg de oogst van dit soort problemen, omdat het niet de dikke het ijst van het ijst van het ijst.
2023-05-28 09:11:47,126 - INFO - joeynmt.training - Example #2
2023-05-28 09:11:47,126 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:11:47,126 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:11:47,126 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'sk@@', 'appen', 'het', 'sch@@', 'ep@@', 'sel', 'van', 'onze', 'wereldwijde', 'klimaat@@', 'verandering', '.', '</s>']
2023-05-28 09:11:47,126 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:11:47,126 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:11:47,126 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskskappen het schepsel van onze wereldwijde klimaatverandering.
2023-05-28 09:11:47,126 - INFO - joeynmt.training - Example #3
2023-05-28 09:11:47,126 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:11:47,126 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:11:47,126 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'pt', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 09:11:47,126 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:11:47,126 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:11:47,126 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrupt in de zomer.
2023-05-28 09:11:47,126 - INFO - joeynmt.training - Example #4
2023-05-28 09:11:47,126 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:11:47,126 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:11:47,126 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'je', 'zal', 'laten', 'zien', ',', 'is', 'een', 'tijd@@', 'je', 'dat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 09:11:47,127 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:11:47,127 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:11:47,127 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je zal laten zien, is een tijdje dat er in de laatste 25 jaar is.
2023-05-28 09:12:24,210 - INFO - joeynmt.training - Epoch   8, Step:    26100, Batch Loss:     2.127025, Batch Acc: 0.522060, Tokens per Sec:     1807, Lr: 0.000300
2023-05-28 09:13:01,829 - INFO - joeynmt.training - Epoch   8, Step:    26200, Batch Loss:     1.921401, Batch Acc: 0.530069, Tokens per Sec:     1765, Lr: 0.000300
2023-05-28 09:13:37,318 - INFO - joeynmt.training - Epoch   8, Step:    26300, Batch Loss:     1.828322, Batch Acc: 0.523880, Tokens per Sec:     1892, Lr: 0.000300
2023-05-28 09:14:13,606 - INFO - joeynmt.training - Epoch   8, Step:    26400, Batch Loss:     2.190412, Batch Acc: 0.522359, Tokens per Sec:     1840, Lr: 0.000300
2023-05-28 09:14:48,326 - INFO - joeynmt.training - Epoch   8, Step:    26500, Batch Loss:     1.844267, Batch Acc: 0.527734, Tokens per Sec:     1920, Lr: 0.000300
2023-05-28 09:14:48,327 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:14:48,328 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:15:55,990 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.01, ppl:   7.47, acc:   0.48, generation: 67.5666[sec], evaluation: 0.0000[sec]
2023-05-28 09:15:55,994 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 09:15:56,116 - INFO - joeynmt.helpers - delete models/transformer_c/24000.ckpt
2023-05-28 09:15:56,131 - INFO - joeynmt.training - Example #0
2023-05-28 09:15:56,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:15:56,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:15:56,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'aange@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'beelden', 'dat', 'de', 'Arab@@', 'ische', 'ij@@', 'k@@', 'sk@@', 'appen', ',', 'die', 'voor', 'de', 'lan@@', 'delijke', 'ij@@', 'k@@', 'sk@@', 'appen', ',', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'en', '40', 'procent', 'gesch@@', 'ru@@', 'ft', '.', '</s>']
2023-05-28 09:15:56,131 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:15:56,131 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:15:56,131 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia aangetoond om te verbeelden dat de Arabische ijkskappen, die voor de landelijke ijkskappen, die voor de onderste 48 staten, en 40 procent geschruft.
2023-05-28 09:15:56,131 - INFO - joeynmt.training - Example #1
2023-05-28 09:15:56,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:15:56,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:15:56,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'specifieke', 'probleem', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ker', 'van', 'het', 'ij@@', 's@@', 'ver@@', 'toont', '.', '</s>']
2023-05-28 09:15:56,132 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:15:56,132 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:15:56,132 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de oogst van dit specifieke probleem, omdat het niet de dikker van het ijsvertoont.
2023-05-28 09:15:56,132 - INFO - joeynmt.training - Example #2
2023-05-28 09:15:56,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:15:56,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:15:56,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'ij@@', 'k@@', 'app@@', 'e', ',', 'het', 'sch@@', 'it@@', 'ter@@', 'ende', 'hart', 'van', 'de', 'klimaat@@', 'verandering', '.', '</s>']
2023-05-28 09:15:56,132 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:15:56,132 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:15:56,132 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkkappe het schijkappe, het schitterende hart van de klimaatverandering.
2023-05-28 09:15:56,132 - INFO - joeynmt.training - Example #3
2023-05-28 09:15:56,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:15:56,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:15:56,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sl@@', 'ij@@', 'p@@', 'je', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 09:15:56,132 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:15:56,132 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:15:56,132 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slijpje in de zomer.
2023-05-28 09:15:56,132 - INFO - joeynmt.training - Example #4
2023-05-28 09:15:56,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:15:56,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:15:56,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', ',', 'is', 'een', 'tijd@@', 'st@@', 'ip', 'van', 'wat', 'er', 'gebeurd', 'is', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 09:15:56,133 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:15:56,133 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:15:56,133 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdstip van wat er gebeurd is in de laatste 25 jaar.
2023-05-28 09:16:32,695 - INFO - joeynmt.training - Epoch   8, Step:    26600, Batch Loss:     1.862757, Batch Acc: 0.526020, Tokens per Sec:     1870, Lr: 0.000300
2023-05-28 09:17:07,731 - INFO - joeynmt.training - Epoch   8, Step:    26700, Batch Loss:     1.791294, Batch Acc: 0.526616, Tokens per Sec:     1910, Lr: 0.000300
2023-05-28 09:17:42,917 - INFO - joeynmt.training - Epoch   8, Step:    26800, Batch Loss:     1.892004, Batch Acc: 0.522449, Tokens per Sec:     1911, Lr: 0.000300
2023-05-28 09:18:18,517 - INFO - joeynmt.training - Epoch   8, Step:    26900, Batch Loss:     1.786820, Batch Acc: 0.530782, Tokens per Sec:     1871, Lr: 0.000300
2023-05-28 09:18:53,773 - INFO - joeynmt.training - Epoch   8, Step:    27000, Batch Loss:     1.832879, Batch Acc: 0.528524, Tokens per Sec:     1848, Lr: 0.000300
2023-05-28 09:18:53,773 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:18:53,773 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:20:03,352 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.42, acc:   0.48, generation: 69.4831[sec], evaluation: 0.0000[sec]
2023-05-28 09:20:03,355 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 09:20:03,527 - INFO - joeynmt.helpers - delete models/transformer_c/24500.ckpt
2023-05-28 09:20:03,545 - INFO - joeynmt.training - Example #0
2023-05-28 09:20:03,545 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:20:03,545 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:20:03,545 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'laatste', 'jaar', 'liet', 'ik', 'deze', 'di@@', 'a', 'zien', 'om', 'te', 'ver@@', 'beelden', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'sk@@', 'aar@@', 'tje', 'dat', 'de', 'de', 'gro@@', 'en', 'van', 'de', 'grootste', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'had', '40', 'procent', 'ge@@', 'vest@@', 'ig@@', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'had', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'en', '40', 'procent', 'gesch@@', 'ru@@', 'ft', '.', '</s>']
2023-05-28 09:20:03,546 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:20:03,546 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:20:03,546 - INFO - joeynmt.training - 	Hypothesis: Het laatste jaar liet ik deze dia zien om te verbeelden dat de arctische ijskskaartje dat de de groen van de grootste van de onderste 48 staten, had 40 procent gevestigde grootte van de onderste 48 staten, had de grootte van de onderste 48 staten, en 40 procent geschruft.
2023-05-28 09:20:03,546 - INFO - joeynmt.training - Example #1
2023-05-28 09:20:03,546 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:20:03,546 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:20:03,546 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'soort', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'st', 'toont', '.', '</s>']
2023-05-28 09:20:03,546 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:20:03,546 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:20:03,546 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg de oogst van dit soort problemen, omdat het niet de dikke van het ijst toont.
2023-05-28 09:20:03,546 - INFO - joeynmt.training - Example #2
2023-05-28 09:20:03,546 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:20:03,546 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:20:03,546 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'it@@', 'ter@@', 'ende', 'hart', 'van', 'de', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 09:20:03,546 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:20:03,546 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:20:03,546 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het schitterende hart van de klimaatsysteem.
2023-05-28 09:20:03,546 - INFO - joeynmt.training - Example #3
2023-05-28 09:20:03,546 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:20:03,546 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:20:03,546 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sl@@', 'ij@@', 'f', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 09:20:03,547 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:20:03,547 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:20:03,547 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slijf in de zomer.
2023-05-28 09:20:03,547 - INFO - joeynmt.training - Example #4
2023-05-28 09:20:03,547 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:20:03,547 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:20:03,547 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ti@@', 'me@@', '-@@', 'op@@', 'name', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 09:20:03,547 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:20:03,547 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:20:03,547 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een time-opname wat er in de laatste 25 jaar is.
2023-05-28 09:20:40,330 - INFO - joeynmt.training - Epoch   8, Step:    27100, Batch Loss:     1.727247, Batch Acc: 0.522366, Tokens per Sec:     1823, Lr: 0.000300
2023-05-28 09:21:17,401 - INFO - joeynmt.training - Epoch   8, Step:    27200, Batch Loss:     1.652232, Batch Acc: 0.529295, Tokens per Sec:     1879, Lr: 0.000300
2023-05-28 09:21:53,213 - INFO - joeynmt.training - Epoch   8, Step:    27300, Batch Loss:     1.898182, Batch Acc: 0.522348, Tokens per Sec:     1852, Lr: 0.000300
2023-05-28 09:22:30,791 - INFO - joeynmt.training - Epoch   8, Step:    27400, Batch Loss:     1.788692, Batch Acc: 0.531267, Tokens per Sec:     1766, Lr: 0.000300
2023-05-28 09:23:07,991 - INFO - joeynmt.training - Epoch   8, Step:    27500, Batch Loss:     1.837549, Batch Acc: 0.527424, Tokens per Sec:     1781, Lr: 0.000300
2023-05-28 09:23:07,992 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:23:07,992 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:24:15,052 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.34, acc:   0.48, generation: 66.9625[sec], evaluation: 0.0000[sec]
2023-05-28 09:24:15,056 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 09:24:15,192 - INFO - joeynmt.helpers - delete models/transformer_c/25000.ckpt
2023-05-28 09:24:15,206 - INFO - joeynmt.training - Example #0
2023-05-28 09:24:15,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:24:15,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:24:15,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'afbeel@@', 'dingen', 'laten', 'zien', 'om', 'te', 'ver@@', 'beelden', 'dat', 'de', 'k@@', 'app@@', 'e', 'ij@@', 'sk@@', 'app@@', 'e', 'ij@@', 'sk@@', 'app@@', 'e', ',', 'die', 'voor', 'de', 'jon@@', 'g', 'drie', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', 'te', 'ver@@', 'laten', '.', '</s>']
2023-05-28 09:24:15,207 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:24:15,207 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:24:15,207 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee afbeeldingen laten zien om te verbeelden dat de kappe ijskappe ijskappe, die voor de jong drie miljoen jaar de grootte van de onderste 48 staten, om 40 procent te verlaten.
2023-05-28 09:24:15,207 - INFO - joeynmt.training - Example #1
2023-05-28 09:24:15,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:24:15,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:24:15,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'problemen', 'van', 'het', 'ijs', 'laat', 'zien', '.', '</s>']
2023-05-28 09:24:15,207 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:24:15,207 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:24:15,207 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg de oogst van deze problemen, omdat het niet de dikke problemen van het ijs laat zien.
2023-05-28 09:24:15,207 - INFO - joeynmt.training - Example #2
2023-05-28 09:24:15,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:24:15,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:24:15,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'app@@', 'e', 'het', 'sch@@', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'ep@@', 'pen', 'van', 'het', 'systeem', '.', '</s>']
2023-05-28 09:24:15,208 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:24:15,208 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:24:15,208 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de de arctische ijskappe het schijkappe het schijkappe het scheppen van het systeem.
2023-05-28 09:24:15,208 - INFO - joeynmt.training - Example #3
2023-05-28 09:24:15,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:24:15,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:24:15,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sl@@', 'ij@@', 'p@@', 'je', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 09:24:15,208 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:24:15,208 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:24:15,208 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slijpje in de zomer.
2023-05-28 09:24:15,208 - INFO - joeynmt.training - Example #4
2023-05-28 09:24:15,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:24:15,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:24:15,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', 'te@@', 'kort', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 09:24:15,208 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:24:15,208 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:24:15,208 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien, is een tekort wat er in de afgelopen 25 jaar.
2023-05-28 09:24:52,284 - INFO - joeynmt.training - Epoch   8, Step:    27600, Batch Loss:     1.719140, Batch Acc: 0.523858, Tokens per Sec:     1785, Lr: 0.000300
2023-05-28 09:25:32,509 - INFO - joeynmt.training - Epoch   8, Step:    27700, Batch Loss:     1.741083, Batch Acc: 0.525132, Tokens per Sec:     1648, Lr: 0.000300
2023-05-28 09:26:11,580 - INFO - joeynmt.training - Epoch   8, Step:    27800, Batch Loss:     1.782713, Batch Acc: 0.517743, Tokens per Sec:     1727, Lr: 0.000300
2023-05-28 09:26:46,465 - INFO - joeynmt.training - Epoch   8, Step:    27900, Batch Loss:     1.965457, Batch Acc: 0.526740, Tokens per Sec:     1990, Lr: 0.000300
2023-05-28 09:27:21,887 - INFO - joeynmt.training - Epoch   8, Step:    28000, Batch Loss:     1.864197, Batch Acc: 0.530471, Tokens per Sec:     1911, Lr: 0.000300
2023-05-28 09:27:21,889 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:27:21,889 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:28:15,241 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.33, acc:   0.49, generation: 53.2570[sec], evaluation: 0.0000[sec]
2023-05-28 09:28:15,244 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 09:28:15,410 - INFO - joeynmt.helpers - delete models/transformer_c/25500.ckpt
2023-05-28 09:28:15,427 - INFO - joeynmt.training - Example #0
2023-05-28 09:28:15,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:28:15,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:28:15,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'zien', 'dat', 'de', 'Arab@@', 'ische', 'ij@@', 'k@@', 'app@@', 'e', 'ij@@', 'sk@@', 'aar@@', 'tje', 'dat', 'voor', 'een', 'half', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'landen', ',', 'om', '40', 'procent', '.', '</s>']
2023-05-28 09:28:15,428 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:28:15,428 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:28:15,428 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te zien dat de Arabische ijkappe ijskaartje dat voor een half miljoen jaar de grootte van de onderste 48 landen, om 40 procent.
2023-05-28 09:28:15,428 - INFO - joeynmt.training - Example #1
2023-05-28 09:28:15,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:28:15,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:28:15,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'zo', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'specifieke', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ijs', 'toont', '.', '</s>']
2023-05-28 09:28:15,428 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:28:15,428 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:28:15,428 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet zo sterk genoeg de oogst van deze specifieke problemen, omdat het niet de dikke van het ijs toont.
2023-05-28 09:28:15,428 - INFO - joeynmt.training - Example #2
2023-05-28 09:28:15,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:28:15,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:28:15,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'ij@@', 'f', 'van', 'onze', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 09:28:15,429 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:28:15,429 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:28:15,429 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijkappe het schijkappe het schijf van onze klimaatsysteem.
2023-05-28 09:28:15,429 - INFO - joeynmt.training - Example #3
2023-05-28 09:28:15,429 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:28:15,429 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:28:15,429 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'ru@@', 'f', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 09:28:15,429 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:28:15,429 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:28:15,429 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sruf in de zomer.
2023-05-28 09:28:15,429 - INFO - joeynmt.training - Example #4
2023-05-28 09:28:15,429 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:28:15,429 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:28:15,429 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'te@@', 'ge@@', 'per@@', 'ste', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 09:28:15,429 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:28:15,429 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:28:15,429 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tegeperste van wat er in de laatste 25 jaar.
2023-05-28 09:28:52,487 - INFO - joeynmt.training - Epoch   8, Step:    28100, Batch Loss:     1.877302, Batch Acc: 0.516645, Tokens per Sec:     1765, Lr: 0.000300
2023-05-28 09:29:29,207 - INFO - joeynmt.training - Epoch   8, Step:    28200, Batch Loss:     1.773086, Batch Acc: 0.525368, Tokens per Sec:     1789, Lr: 0.000300
2023-05-28 09:30:05,600 - INFO - joeynmt.training - Epoch   8, Step:    28300, Batch Loss:     1.686081, Batch Acc: 0.531376, Tokens per Sec:     1881, Lr: 0.000300
2023-05-28 09:30:40,510 - INFO - joeynmt.training - Epoch   8, Step:    28400, Batch Loss:     1.709328, Batch Acc: 0.521401, Tokens per Sec:     1924, Lr: 0.000300
2023-05-28 09:31:12,719 - INFO - joeynmt.training - Epoch   8: total training loss 6372.47
2023-05-28 09:31:12,719 - INFO - joeynmt.training - EPOCH 9
2023-05-28 09:31:12,750 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=8
2023-05-28 09:31:18,404 - INFO - joeynmt.training - Epoch   9, Step:    28500, Batch Loss:     1.618413, Batch Acc: 0.532533, Tokens per Sec:     1774, Lr: 0.000300
2023-05-28 09:31:18,405 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:31:18,405 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:32:14,643 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.34, acc:   0.49, generation: 56.1383[sec], evaluation: 0.0000[sec]
2023-05-28 09:32:14,782 - INFO - joeynmt.helpers - delete models/transformer_c/26000.ckpt
2023-05-28 09:32:14,797 - INFO - joeynmt.training - Example #0
2023-05-28 09:32:14,797 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:32:14,797 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:32:14,797 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'app@@', 'e', 'ij@@', 'sk@@', 'app@@', 'e', ',', 'die', 'voor', 'een', 'half', 'miljoen', 'jaar', ',', 'de', 'gro@@', 'en', 'van', '40', 'procent', '.', '</s>']
2023-05-28 09:32:14,798 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:32:14,798 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:32:14,798 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te zien dat de arctische ijskappe ijskappe, die voor een half miljoen jaar, de groen van 40 procent.
2023-05-28 09:32:14,798 - INFO - joeynmt.training - Example #1
2023-05-28 09:32:14,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:32:14,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:32:14,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'dat', 'het', 'niet', 'zo', 'veel', 'veel', 'problemen', 'uit', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ijs', '.', '</s>']
2023-05-28 09:32:14,798 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:32:14,798 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:32:14,798 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo sterk genoeg de oogst dat het niet zo veel veel problemen uit, want het is niet de dikke van het ijs.
2023-05-28 09:32:14,798 - INFO - joeynmt.training - Example #2
2023-05-28 09:32:14,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:32:14,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:32:14,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'de', 'ar@@', 'c@@', 'tic@@', 'ale', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'it@@', 'ter@@', 'ende', 'hart', 'van', 'onze', 'mondiale', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 09:32:14,798 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:32:14,798 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:32:14,798 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de de arcticale ijkappe het schitterende hart van onze mondiale klimaatsysteem.
2023-05-28 09:32:14,798 - INFO - joeynmt.training - Example #3
2023-05-28 09:32:14,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:32:14,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:32:14,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'me@@', 'el', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 09:32:14,799 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:32:14,799 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:32:14,799 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en smeel in de zomer.
2023-05-28 09:32:14,799 - INFO - joeynmt.training - Example #4
2023-05-28 09:32:14,799 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:32:14,799 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:32:14,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'je', 'dat', 'er', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 09:32:14,799 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:32:14,799 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:32:14,799 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien, is een tijdje dat er in de laatste 25 jaar.
2023-05-28 09:32:52,204 - INFO - joeynmt.training - Epoch   9, Step:    28600, Batch Loss:     1.496629, Batch Acc: 0.536063, Tokens per Sec:     1864, Lr: 0.000300
2023-05-28 09:33:28,104 - INFO - joeynmt.training - Epoch   9, Step:    28700, Batch Loss:     1.781769, Batch Acc: 0.541138, Tokens per Sec:     1845, Lr: 0.000300
2023-05-28 09:34:04,963 - INFO - joeynmt.training - Epoch   9, Step:    28800, Batch Loss:     1.856671, Batch Acc: 0.540635, Tokens per Sec:     1828, Lr: 0.000300
2023-05-28 09:34:41,599 - INFO - joeynmt.training - Epoch   9, Step:    28900, Batch Loss:     1.679238, Batch Acc: 0.536742, Tokens per Sec:     1837, Lr: 0.000300
2023-05-28 09:35:18,752 - INFO - joeynmt.training - Epoch   9, Step:    29000, Batch Loss:     1.780346, Batch Acc: 0.532122, Tokens per Sec:     1856, Lr: 0.000300
2023-05-28 09:35:18,753 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:35:18,753 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:36:21,458 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.38, acc:   0.49, generation: 62.6084[sec], evaluation: 0.0000[sec]
2023-05-28 09:36:21,617 - INFO - joeynmt.helpers - delete models/transformer_c/26500.ckpt
2023-05-28 09:36:21,635 - INFO - joeynmt.training - Example #0
2023-05-28 09:36:21,635 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:36:21,635 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:36:21,635 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', ',', 'om', 'te', 'ver@@', 'beelden', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'app@@', 'e', 'die', 'voor', 'een', 'half', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'en', '4@@', '8', 'st@@', 'aten', ',', '4@@', '8', 'st@@', 'aten', ',', 'en', '40', 'procent', 'gesch@@', 'ikt', '.', '</s>']
2023-05-28 09:36:21,635 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:36:21,635 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:36:21,635 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien, om te verbeelden dat de arctische ijskappe die voor een half miljoen jaar de grootte van de onderen 48 staten, 48 staten, en 40 procent geschikt.
2023-05-28 09:36:21,635 - INFO - joeynmt.training - Example #1
2023-05-28 09:36:21,635 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:36:21,635 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:36:21,635 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'doet', 'niet', 'zo', 'sterk', 'genoeg', 'de', 'ser@@', 'ieuze', 'ser@@', 'ie', 'van', 'dit', 'soort', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'het', 'ij@@', 's@@', 'ing', 'is', '.', '</s>']
2023-05-28 09:36:21,636 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:36:21,636 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:36:21,636 - INFO - joeynmt.training - 	Hypothesis: Maar dat doet niet zo sterk genoeg de serieuze serie van dit soort problemen, omdat het niet de dikke het ijsing is.
2023-05-28 09:36:21,636 - INFO - joeynmt.training - Example #2
2023-05-28 09:36:21,636 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:36:21,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:36:21,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'app@@', 'e', 'het', 'sch@@', 'it@@', 'ter@@', 'ende', 'hart', 'van', 'onze', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 09:36:21,636 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:36:21,636 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:36:21,636 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe het schitterende hart van onze klimaatsysteem.
2023-05-28 09:36:21,636 - INFO - joeynmt.training - Example #3
2023-05-28 09:36:21,636 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:36:21,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:36:21,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sl@@', 'ij@@', 'd', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 09:36:21,636 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:36:21,636 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:36:21,636 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slijd in de zomer.
2023-05-28 09:36:21,636 - INFO - joeynmt.training - Example #4
2023-05-28 09:36:21,636 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:36:21,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:36:21,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'tijd@@', 'je', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 09:36:21,637 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:36:21,637 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:36:21,637 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tijdje van wat er in de laatste 25 jaar is.
2023-05-28 09:36:58,049 - INFO - joeynmt.training - Epoch   9, Step:    29100, Batch Loss:     1.693705, Batch Acc: 0.541268, Tokens per Sec:     1786, Lr: 0.000300
2023-05-28 09:37:35,401 - INFO - joeynmt.training - Epoch   9, Step:    29200, Batch Loss:     1.833180, Batch Acc: 0.538269, Tokens per Sec:     1816, Lr: 0.000300
2023-05-28 09:38:13,136 - INFO - joeynmt.training - Epoch   9, Step:    29300, Batch Loss:     1.700495, Batch Acc: 0.532973, Tokens per Sec:     1785, Lr: 0.000300
2023-05-28 09:38:48,840 - INFO - joeynmt.training - Epoch   9, Step:    29400, Batch Loss:     1.652876, Batch Acc: 0.528994, Tokens per Sec:     1849, Lr: 0.000300
2023-05-28 09:39:28,138 - INFO - joeynmt.training - Epoch   9, Step:    29500, Batch Loss:     1.977556, Batch Acc: 0.535292, Tokens per Sec:     1774, Lr: 0.000300
2023-05-28 09:39:28,139 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:39:28,139 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:40:44,177 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.31, acc:   0.48, generation: 75.9404[sec], evaluation: 0.0000[sec]
2023-05-28 09:40:44,180 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 09:40:44,317 - INFO - joeynmt.helpers - delete models/transformer_c/27000.ckpt
2023-05-28 09:40:44,332 - INFO - joeynmt.training - Example #0
2023-05-28 09:40:44,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:40:44,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:40:44,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'app@@', 'e', 'ij@@', 'sk@@', 'app@@', 'e', 'die', 'voor', 'de', 'aan@@', 'val', 'drie', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', 'landen', '.', '</s>']
2023-05-28 09:40:44,333 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:40:44,333 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:40:44,333 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te zien dat de arctische ijskappe ijskappe die voor de aanval drie miljoen jaar de grootte van de onderste landen.
2023-05-28 09:40:44,333 - INFO - joeynmt.training - Example #1
2023-05-28 09:40:44,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:40:44,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:40:44,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'veel', 'veel', 'ser@@', 'ieuze', 'ser@@', 'ie', 'van', 'dit', 'specifieke', 'probleem', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'ver@@', 'd', '.', '</s>']
2023-05-28 09:40:44,333 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:40:44,333 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:40:44,333 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo veel veel serieuze serie van dit specifieke probleem, want het is niet de dikke van de ijsverd.
2023-05-28 09:40:44,333 - INFO - joeynmt.training - Example #2
2023-05-28 09:40:44,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:40:44,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:40:44,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'app@@', 'e', 'het', 'sch@@', 'it@@', 'ter@@', 'ende', 'hart', 'van', 'onze', 'klimaat@@', 'systemen', '.', '</s>']
2023-05-28 09:40:44,334 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:40:44,334 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:40:44,334 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe het schitterende hart van onze klimaatsystemen.
2023-05-28 09:40:44,334 - INFO - joeynmt.training - Example #3
2023-05-28 09:40:44,334 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:40:44,334 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:40:44,334 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'f', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 09:40:44,334 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:40:44,334 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:40:44,334 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schruf in de zomer.
2023-05-28 09:40:44,334 - INFO - joeynmt.training - Example #4
2023-05-28 09:40:44,334 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:40:44,334 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:40:44,334 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'je', 'dat', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 09:40:44,334 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:40:44,334 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:40:44,334 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien, is een tijdje dat in de laatste 25 jaar is.
2023-05-28 09:41:21,779 - INFO - joeynmt.training - Epoch   9, Step:    29600, Batch Loss:     1.796815, Batch Acc: 0.534207, Tokens per Sec:     1828, Lr: 0.000300
2023-05-28 09:41:57,578 - INFO - joeynmt.training - Epoch   9, Step:    29700, Batch Loss:     1.930043, Batch Acc: 0.532645, Tokens per Sec:     1900, Lr: 0.000300
2023-05-28 09:42:33,537 - INFO - joeynmt.training - Epoch   9, Step:    29800, Batch Loss:     1.810808, Batch Acc: 0.534771, Tokens per Sec:     1868, Lr: 0.000300
2023-05-28 09:43:10,771 - INFO - joeynmt.training - Epoch   9, Step:    29900, Batch Loss:     1.879067, Batch Acc: 0.536571, Tokens per Sec:     1824, Lr: 0.000300
2023-05-28 09:43:46,583 - INFO - joeynmt.training - Epoch   9, Step:    30000, Batch Loss:     1.919259, Batch Acc: 0.539526, Tokens per Sec:     1813, Lr: 0.000300
2023-05-28 09:43:46,584 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:43:46,584 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:44:46,318 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.34, acc:   0.49, generation: 59.6374[sec], evaluation: 0.0000[sec]
2023-05-28 09:44:46,481 - INFO - joeynmt.helpers - delete models/transformer_c/29000.ckpt
2023-05-28 09:44:46,495 - INFO - joeynmt.training - Example #0
2023-05-28 09:44:46,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:44:46,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:44:46,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'gevolgen', 'laten', 'zien', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'app@@', 'e', ',', 'die', 'voor', 'de', 'jon@@', 'g', 'van', 'drie', 'miljoen', 'jaar', ',', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'landen', ',', 'om', '40', 'procent', '.', '</s>']
2023-05-28 09:44:46,496 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:44:46,496 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:44:46,496 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen laten zien om te zien dat de arctische ijskappe, die voor de jong van drie miljoen jaar, de grootte van de onderste van de onderste 48 landen, om 40 procent.
2023-05-28 09:44:46,496 - INFO - joeynmt.training - Example #1
2023-05-28 09:44:46,496 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:44:46,496 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:44:46,496 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'veel', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'specifieke', 'probleem', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ijs', '.', '</s>']
2023-05-28 09:44:46,496 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:44:46,496 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:44:46,496 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo veel genoeg de oogst van dit specifieke probleem, want het is niet de dikke van het ijs.
2023-05-28 09:44:46,496 - INFO - joeynmt.training - Example #2
2023-05-28 09:44:46,496 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:44:46,496 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:44:46,496 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'jes', 'het', 'sch@@', 'it@@', 'ter@@', 'ende', 'hart', 'van', 'onze', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 09:44:46,496 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:44:46,496 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:44:46,496 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkjes het schitterende hart van onze klimaatsysteem.
2023-05-28 09:44:46,496 - INFO - joeynmt.training - Example #3
2023-05-28 09:44:46,496 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:44:46,496 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:44:46,496 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sl@@', 'ij@@', 'f', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 09:44:46,497 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:44:46,497 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:44:46,497 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slijf in de zomer.
2023-05-28 09:44:46,497 - INFO - joeynmt.training - Example #4
2023-05-28 09:44:46,497 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:44:46,497 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:44:46,497 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', ',', 'die', 'ik', 'je', 'zal', 'laten', 'zien', ',', 'is', 'een', 'tijd@@', 'je', 'dat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2023-05-28 09:44:46,497 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:44:46,497 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:44:46,497 - INFO - joeynmt.training - 	Hypothesis: De volgende dia, die ik je zal laten zien, is een tijdje dat er in de afgelopen 25 jaar is gebeurd.
2023-05-28 09:45:21,320 - INFO - joeynmt.training - Epoch   9, Step:    30100, Batch Loss:     1.874226, Batch Acc: 0.535561, Tokens per Sec:     1908, Lr: 0.000300
2023-05-28 09:45:56,108 - INFO - joeynmt.training - Epoch   9, Step:    30200, Batch Loss:     1.744712, Batch Acc: 0.525548, Tokens per Sec:     1957, Lr: 0.000300
2023-05-28 09:46:32,501 - INFO - joeynmt.training - Epoch   9, Step:    30300, Batch Loss:     1.586819, Batch Acc: 0.527918, Tokens per Sec:     1822, Lr: 0.000300
2023-05-28 09:47:08,882 - INFO - joeynmt.training - Epoch   9, Step:    30400, Batch Loss:     1.878954, Batch Acc: 0.538692, Tokens per Sec:     1839, Lr: 0.000300
2023-05-28 09:47:45,670 - INFO - joeynmt.training - Epoch   9, Step:    30500, Batch Loss:     1.831933, Batch Acc: 0.532671, Tokens per Sec:     1851, Lr: 0.000300
2023-05-28 09:47:45,671 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:47:45,671 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:48:51,346 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.26, acc:   0.49, generation: 65.5798[sec], evaluation: 0.0000[sec]
2023-05-28 09:48:51,348 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 09:48:51,481 - INFO - joeynmt.helpers - delete models/transformer_c/30000.ckpt
2023-05-28 09:48:51,483 - INFO - joeynmt.training - Example #0
2023-05-28 09:48:51,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:48:51,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:48:51,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'aange@@', 'to@@', 'ond', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'appen', ',', 'die', 'voor', 'de', 'jon@@', 'geren', 'die', 'voor', 'de', 'drie', 'miljoen', 'jaar', 'de', 'gro@@', 'ten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', '.', '</s>']
2023-05-28 09:48:51,483 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:48:51,484 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:48:51,484 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia aangetoond om te zien dat de arctische ijskappen, die voor de jongeren die voor de drie miljoen jaar de groten van de onderste 48 staten, om 40 procent.
2023-05-28 09:48:51,484 - INFO - joeynmt.training - Example #1
2023-05-28 09:48:51,484 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:48:51,484 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:48:51,484 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'doet', 'niet', 'veel', 'genoeg', 'de', 'ser@@', 'ieuze', 'wereld', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'problemen', 'van', 'het', 'ijs', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ijs', 'laat', 'zien', '.', '</s>']
2023-05-28 09:48:51,484 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:48:51,484 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:48:51,484 - INFO - joeynmt.training - 	Hypothesis: Maar dat doet niet veel genoeg de serieuze wereld, omdat het niet de dikke problemen van het ijs, omdat het niet de dikke van het ijs laat zien.
2023-05-28 09:48:51,484 - INFO - joeynmt.training - Example #2
2023-05-28 09:48:51,484 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:48:51,484 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:48:51,484 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 's@@', 'ke@@', 'ver', 'het', 'zwe@@', 'et', 'hart', 'van', 'ons', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 09:48:51,484 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:48:51,484 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:48:51,484 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het skever het zweet hart van ons wereldwijde klimaatsysteem.
2023-05-28 09:48:51,484 - INFO - joeynmt.training - Example #3
2023-05-28 09:48:51,484 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:48:51,484 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:48:51,484 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sl@@', 'ij@@', 'f@@', 'd', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 09:48:51,484 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:48:51,485 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:48:51,485 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slijfd in de zomer.
2023-05-28 09:48:51,485 - INFO - joeynmt.training - Example #4
2023-05-28 09:48:51,485 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:48:51,485 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:48:51,485 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'toon', 'is', 'een', 'tijd@@', 'je', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'gebeurt', '.', '</s>']
2023-05-28 09:48:51,485 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:48:51,485 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:48:51,485 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik toon is een tijdje van wat er in de laatste 25 jaar gebeurt.
2023-05-28 09:49:27,659 - INFO - joeynmt.training - Epoch   9, Step:    30600, Batch Loss:     1.738591, Batch Acc: 0.527134, Tokens per Sec:     1818, Lr: 0.000300
2023-05-28 09:50:04,924 - INFO - joeynmt.training - Epoch   9, Step:    30700, Batch Loss:     1.700515, Batch Acc: 0.533317, Tokens per Sec:     1796, Lr: 0.000300
2023-05-28 09:50:42,158 - INFO - joeynmt.training - Epoch   9, Step:    30800, Batch Loss:     1.851297, Batch Acc: 0.532615, Tokens per Sec:     1805, Lr: 0.000300
2023-05-28 09:51:19,171 - INFO - joeynmt.training - Epoch   9, Step:    30900, Batch Loss:     1.637215, Batch Acc: 0.534288, Tokens per Sec:     1751, Lr: 0.000300
2023-05-28 09:51:55,525 - INFO - joeynmt.training - Epoch   9, Step:    31000, Batch Loss:     1.801682, Batch Acc: 0.528567, Tokens per Sec:     1866, Lr: 0.000300
2023-05-28 09:51:55,525 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:51:55,525 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:52:58,243 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.32, acc:   0.49, generation: 62.6200[sec], evaluation: 0.0000[sec]
2023-05-28 09:52:58,388 - INFO - joeynmt.helpers - delete models/transformer_c/28500.ckpt
2023-05-28 09:52:58,404 - INFO - joeynmt.training - Example #0
2023-05-28 09:52:58,404 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:52:58,404 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:52:58,404 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'zien', 'dat', 'de', 'aar@@', 'dige', 'ij@@', 'sk@@', 'app@@', 'e', 'die', 'voor', 'een', 'paar', 'miljoen', 'jaar', 'de', 'gro@@', 'en', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', 'gesch@@', 'ru@@', 'mp@@', 'eld', 'is', '.', '</s>']
2023-05-28 09:52:58,404 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:52:58,404 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:52:58,404 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee twee dia laten zien om te zien dat de aardige ijskappe die voor een paar miljoen jaar de groen van de onderste 48 staten, om 40 procent geschrumpeld is.
2023-05-28 09:52:58,404 - INFO - joeynmt.training - Example #1
2023-05-28 09:52:58,404 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:52:58,404 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:52:58,404 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'dru@@', 'kt', 'niet', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'specifieke', 'probleem', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'het', 'ij@@', 'z@@', 'eren', 'van', 'het', 'ijs', '.', '</s>']
2023-05-28 09:52:58,405 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:52:58,405 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:52:58,405 - INFO - joeynmt.training - 	Hypothesis: Maar dat drukt niet sterk genoeg de oogst van dit specifieke probleem, want het is niet de dikke het ijzeren van het ijs.
2023-05-28 09:52:58,405 - INFO - joeynmt.training - Example #2
2023-05-28 09:52:58,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:52:58,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:52:58,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'arm@@', 'ste', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'oon', 'het', 'sl@@', 'aan', 'van', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 09:52:58,405 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:52:58,405 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:52:58,405 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de armste ijkappe het schoon het slaan van klimaatsysteem.
2023-05-28 09:52:58,405 - INFO - joeynmt.training - Example #3
2023-05-28 09:52:58,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:52:58,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:52:58,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sl@@', 'ij@@', 'f@@', 'd', '.', '</s>']
2023-05-28 09:52:58,405 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:52:58,405 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:52:58,408 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slijfd.
2023-05-28 09:52:58,408 - INFO - joeynmt.training - Example #4
2023-05-28 09:52:58,408 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:52:58,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:52:58,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'st@@', 'ip', 'op@@', 'name', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2023-05-28 09:52:58,408 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:52:58,408 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:52:58,408 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien, is een tijdstip opname wat er in de laatste 25 jaar is gebeurd.
2023-05-28 09:53:35,137 - INFO - joeynmt.training - Epoch   9, Step:    31100, Batch Loss:     1.834792, Batch Acc: 0.527252, Tokens per Sec:     1784, Lr: 0.000300
2023-05-28 09:54:11,470 - INFO - joeynmt.training - Epoch   9, Step:    31200, Batch Loss:     1.686737, Batch Acc: 0.540321, Tokens per Sec:     1864, Lr: 0.000300
2023-05-28 09:54:47,397 - INFO - joeynmt.training - Epoch   9, Step:    31300, Batch Loss:     1.792268, Batch Acc: 0.534440, Tokens per Sec:     1862, Lr: 0.000300
2023-05-28 09:55:24,766 - INFO - joeynmt.training - Epoch   9, Step:    31400, Batch Loss:     1.547415, Batch Acc: 0.531218, Tokens per Sec:     1767, Lr: 0.000300
2023-05-28 09:56:02,456 - INFO - joeynmt.training - Epoch   9, Step:    31500, Batch Loss:     1.559526, Batch Acc: 0.527472, Tokens per Sec:     1808, Lr: 0.000300
2023-05-28 09:56:02,456 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 09:56:02,457 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 09:57:07,918 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.22, acc:   0.49, generation: 65.3660[sec], evaluation: 0.0000[sec]
2023-05-28 09:57:07,921 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 09:57:08,054 - INFO - joeynmt.helpers - delete models/transformer_c/27500.ckpt
2023-05-28 09:57:08,070 - INFO - joeynmt.training - Example #0
2023-05-28 09:57:08,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 09:57:08,071 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 09:57:08,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'aange@@', 'to@@', 'ond', 'om', 'te', 'zien', 'dat', 'de', 'aar@@', 'dige', 'ij@@', 'sk@@', 'appen', 'die', 'er', 'drie', 'miljoen', 'jaar', 'aan', 'de', 'onder@@', 'kant', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', '.', '</s>']
2023-05-28 09:57:08,071 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 09:57:08,071 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 09:57:08,071 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia aangetoond om te zien dat de aardige ijskappen die er drie miljoen jaar aan de onderkant van de onderste 48 staten, om 40 procent.
2023-05-28 09:57:08,071 - INFO - joeynmt.training - Example #1
2023-05-28 09:57:08,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 09:57:08,071 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 09:57:08,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'dru@@', 'kt', 'niet', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'specifieke', 'probleem', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'z@@', 'eren', 'van', 'het', 'ij@@', 's@@', 'ver@@', 't', '.', '</s>']
2023-05-28 09:57:08,071 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 09:57:08,071 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 09:57:08,071 - INFO - joeynmt.training - 	Hypothesis: Maar dat drukt niet sterk genoeg de oogst van dit specifieke probleem, omdat het niet de dikke van het ijzeren van het ijsvert.
2023-05-28 09:57:08,071 - INFO - joeynmt.training - Example #2
2023-05-28 09:57:08,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 09:57:08,071 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 09:57:08,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'arm@@', 'ste', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'la@@', 'p', 'van', 'ons', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 09:57:08,072 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 09:57:08,072 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 09:57:08,072 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de armste ijkappe het schlap van ons wereldwijde klimaatsysteem.
2023-05-28 09:57:08,072 - INFO - joeynmt.training - Example #3
2023-05-28 09:57:08,072 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 09:57:08,072 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 09:57:08,072 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'z@@', 'enden', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 09:57:08,072 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 09:57:08,072 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 09:57:08,072 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en verzenden in de zomer.
2023-05-28 09:57:08,072 - INFO - joeynmt.training - Example #4
2023-05-28 09:57:08,072 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 09:57:08,072 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 09:57:08,072 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', 'tij@@', 'delijke', 'op@@', 'name', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 09:57:08,072 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 09:57:08,072 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 09:57:08,072 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien, is een tijdelijke opname wat er in de afgelopen 25 jaar is.
2023-05-28 09:57:43,540 - INFO - joeynmt.training - Epoch   9, Step:    31600, Batch Loss:     1.674896, Batch Acc: 0.535682, Tokens per Sec:     1850, Lr: 0.000300
2023-05-28 09:58:19,397 - INFO - joeynmt.training - Epoch   9, Step:    31700, Batch Loss:     1.791682, Batch Acc: 0.526081, Tokens per Sec:     1870, Lr: 0.000300
2023-05-28 09:58:55,785 - INFO - joeynmt.training - Epoch   9, Step:    31800, Batch Loss:     1.796030, Batch Acc: 0.531567, Tokens per Sec:     1890, Lr: 0.000300
2023-05-28 09:59:31,717 - INFO - joeynmt.training - Epoch   9, Step:    31900, Batch Loss:     1.976798, Batch Acc: 0.529443, Tokens per Sec:     1838, Lr: 0.000300
2023-05-28 10:00:07,244 - INFO - joeynmt.training - Epoch   9, Step:    32000, Batch Loss:     1.894749, Batch Acc: 0.531927, Tokens per Sec:     1865, Lr: 0.000300
2023-05-28 10:00:07,246 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 10:00:07,246 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 10:01:11,121 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.28, acc:   0.49, generation: 63.7804[sec], evaluation: 0.0000[sec]
2023-05-28 10:01:11,249 - INFO - joeynmt.helpers - delete models/transformer_c/28000.ckpt
2023-05-28 10:01:11,264 - INFO - joeynmt.training - Example #0
2023-05-28 10:01:11,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 10:01:11,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 10:01:11,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'aange@@', 'to@@', 'ond', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'jes', 'ij@@', 'k@@', 'jes', 'voor', 'de', 'jon@@', 'geren', 'die', 'voor', 'de', 'jon@@', 'geren', 'van', '4@@', '8', 'landen', ',', '40', 'procent', 'gesch@@', 'ikt', 'is', '.', '</s>']
2023-05-28 10:01:11,264 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 10:01:11,264 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 10:01:11,264 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia aangetoond om te zien dat de arctische ijkjes ijkjes voor de jongeren die voor de jongeren van 48 landen, 40 procent geschikt is.
2023-05-28 10:01:11,264 - INFO - joeynmt.training - Example #1
2023-05-28 10:01:11,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 10:01:11,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 10:01:11,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'specifieke', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'st', 'van', 'het', 'ij@@', 'st', '.', '</s>']
2023-05-28 10:01:11,265 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 10:01:11,265 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 10:01:11,265 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de oogst van deze specifieke problemen, omdat het niet de dikke van het ijst van het ijst.
2023-05-28 10:01:11,265 - INFO - joeynmt.training - Example #2
2023-05-28 10:01:11,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 10:01:11,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 10:01:11,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'jes', 'het', 's@@', 'j@@', 'ou@@', 'we', 'het', 'zwe@@', 'm@@', 'ba@@', 'd', 'van', 'onze', 'wereld@@', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 10:01:11,265 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 10:01:11,269 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 10:01:11,269 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkjes het sjouwe het zwembad van onze wereldklimaatsysteem.
2023-05-28 10:01:11,269 - INFO - joeynmt.training - Example #3
2023-05-28 10:01:11,269 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 10:01:11,269 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 10:01:11,269 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sl@@', 'ij@@', 'f', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 10:01:11,269 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 10:01:11,269 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 10:01:11,269 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slijf in de zomer.
2023-05-28 10:01:11,269 - INFO - joeynmt.training - Example #4
2023-05-28 10:01:11,269 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 10:01:11,270 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 10:01:11,270 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'je', 'van', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 10:01:11,270 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 10:01:11,270 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 10:01:11,270 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien, is een tijdje van de afgelopen 25 jaar.
2023-05-28 10:01:27,943 - INFO - joeynmt.training - Epoch   9: total training loss 6252.04
2023-05-28 10:01:27,944 - INFO - joeynmt.training - EPOCH 10
2023-05-28 10:01:27,975 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=9
2023-05-28 10:01:46,222 - INFO - joeynmt.training - Epoch  10, Step:    32100, Batch Loss:     1.794591, Batch Acc: 0.538728, Tokens per Sec:     1930, Lr: 0.000300
2023-05-28 10:02:21,649 - INFO - joeynmt.training - Epoch  10, Step:    32200, Batch Loss:     1.621418, Batch Acc: 0.546564, Tokens per Sec:     1884, Lr: 0.000300
2023-05-28 10:02:56,565 - INFO - joeynmt.training - Epoch  10, Step:    32300, Batch Loss:     1.676554, Batch Acc: 0.548377, Tokens per Sec:     1942, Lr: 0.000300
2023-05-28 10:03:34,310 - INFO - joeynmt.training - Epoch  10, Step:    32400, Batch Loss:     1.752264, Batch Acc: 0.545991, Tokens per Sec:     1750, Lr: 0.000300
2023-05-28 10:04:12,330 - INFO - joeynmt.training - Epoch  10, Step:    32500, Batch Loss:     1.811992, Batch Acc: 0.545764, Tokens per Sec:     1801, Lr: 0.000300
2023-05-28 10:04:12,331 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 10:04:12,331 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 10:05:17,683 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.27, acc:   0.49, generation: 65.2540[sec], evaluation: 0.0000[sec]
2023-05-28 10:05:17,820 - INFO - joeynmt.helpers - delete models/transformer_c/31000.ckpt
2023-05-28 10:05:17,839 - INFO - joeynmt.training - Example #0
2023-05-28 10:05:17,839 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 10:05:17,839 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 10:05:17,839 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'aange@@', 'to@@', 'ond', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'app@@', 'e', 'voor', 'de', 'jon@@', 'g', 'van', 'drie', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'landen', ',', 'om', '40', 'procent', '.', '</s>']
2023-05-28 10:05:17,840 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 10:05:17,840 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 10:05:17,840 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia aangetoond dat de arctische ijskappe voor de jong van drie miljoen jaar de grootte van de onderste 48 landen, om 40 procent.
2023-05-28 10:05:17,840 - INFO - joeynmt.training - Example #1
2023-05-28 10:05:17,840 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 10:05:17,840 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 10:05:17,840 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'dru@@', 'kt', 'niet', 'zo', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'specifieke', 'problemen', 'uit', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'za@@', 'ken@@', 'merken', '.', '</s>']
2023-05-28 10:05:17,840 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 10:05:17,840 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 10:05:17,840 - INFO - joeynmt.training - 	Hypothesis: Maar dat drukt niet zo sterk genoeg de oogst van deze specifieke problemen uit, omdat het niet de dikke zakenmerken.
2023-05-28 10:05:17,840 - INFO - joeynmt.training - Example #2
2023-05-28 10:05:17,840 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 10:05:17,840 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 10:05:17,840 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'app@@', 'e', 'het', 'sch@@', 'la@@', 'p', 'van', 'ons', 'mondiale', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 10:05:17,841 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 10:05:17,841 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 10:05:17,841 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe het schlap van ons mondiale klimaatsysteem.
2023-05-28 10:05:17,841 - INFO - joeynmt.training - Example #3
2023-05-28 10:05:17,841 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 10:05:17,841 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 10:05:17,841 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'ru@@', 'm@@', 'pt', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 10:05:17,841 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 10:05:17,841 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 10:05:17,841 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en srumpt in de zomer.
2023-05-28 10:05:17,841 - INFO - joeynmt.training - Example #4
2023-05-28 10:05:17,841 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 10:05:17,841 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 10:05:17,841 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'sc@@', 're@@', 'ent', 'dat', 'in', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2023-05-28 10:05:17,841 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 10:05:17,841 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 10:05:17,841 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien, is een tijdscreent dat in de laatste 25 jaar is gebeurd.
2023-05-28 10:05:55,207 - INFO - joeynmt.training - Epoch  10, Step:    32600, Batch Loss:     1.651816, Batch Acc: 0.544125, Tokens per Sec:     1793, Lr: 0.000300
2023-05-28 10:06:33,227 - INFO - joeynmt.training - Epoch  10, Step:    32700, Batch Loss:     1.875334, Batch Acc: 0.537265, Tokens per Sec:     1696, Lr: 0.000300
2023-05-28 10:07:09,539 - INFO - joeynmt.training - Epoch  10, Step:    32800, Batch Loss:     1.692727, Batch Acc: 0.543182, Tokens per Sec:     1816, Lr: 0.000300
2023-05-28 10:07:47,487 - INFO - joeynmt.training - Epoch  10, Step:    32900, Batch Loss:     1.768698, Batch Acc: 0.536087, Tokens per Sec:     1731, Lr: 0.000300
2023-05-28 10:08:25,103 - INFO - joeynmt.training - Epoch  10, Step:    33000, Batch Loss:     1.804150, Batch Acc: 0.540303, Tokens per Sec:     1868, Lr: 0.000300
2023-05-28 10:08:25,104 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 10:08:25,104 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 10:09:27,787 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.22, acc:   0.49, generation: 62.5875[sec], evaluation: 0.0000[sec]
2023-05-28 10:09:27,912 - INFO - joeynmt.helpers - delete models/transformer_c/29500.ckpt
2023-05-28 10:09:27,927 - INFO - joeynmt.training - Example #0
2023-05-28 10:09:27,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 10:09:27,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 10:09:27,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'zien', 'dat', 'de', 'Arab@@', 'ische', 'ij@@', 'k@@', 'k@@', 'k@@', 'app@@', 'e', ',', 'die', 'voor', 'de', 'jon@@', 'geren', 'van', '4@@', '8', 'st@@', 'aten', ',', 'de', 'gro@@', 'en@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', 'te', 'ver@@', 'sl@@', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', '.', '</s>']
2023-05-28 10:09:27,927 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 10:09:27,927 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 10:09:27,927 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te zien dat de Arabische ijkkkappe, die voor de jongeren van 48 staten, de groenste 48 staten, om 40 procent te verslijskappe is.
2023-05-28 10:09:27,927 - INFO - joeynmt.training - Example #1
2023-05-28 10:09:27,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 10:09:27,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 10:09:27,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'sterk', 'genoeg', 'de', 'ser@@', 'ieuze', 'ser@@', 'ie', 'van', 'dit', 'specifieke', 'probleem', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'zer', 'van', 'het', 'ijs', 'toont', '.', '</s>']
2023-05-28 10:09:27,928 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 10:09:27,928 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 10:09:27,928 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de serieuze serie van dit specifieke probleem, omdat het niet de dikke van het ijzer van het ijs toont.
2023-05-28 10:09:27,928 - INFO - joeynmt.training - Example #2
2023-05-28 10:09:27,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 10:09:27,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 10:09:27,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'Arab@@', 'ische', 'ij@@', 'k@@', 'k@@', 'app@@', 'e', 'het', 's@@', 'lo@@', 'p@@', 'je', 'het', 'hart', 'van', 'de', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 10:09:27,928 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 10:09:27,928 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 10:09:27,928 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de Arabische ijkkappe het slopje het hart van de wereldwijde klimaatsysteem.
2023-05-28 10:09:27,928 - INFO - joeynmt.training - Example #3
2023-05-28 10:09:27,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 10:09:27,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 10:09:27,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'ru@@', 'ft', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 10:09:27,928 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 10:09:27,929 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 10:09:27,929 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sruft in de zomer.
2023-05-28 10:09:27,929 - INFO - joeynmt.training - Example #4
2023-05-28 10:09:27,929 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 10:09:27,929 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 10:09:27,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', 'tijd@@', 'st@@', 'ip', ',', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 10:09:27,929 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 10:09:27,929 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 10:09:27,929 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien, is een tijdstip, wat er in de afgelopen 25 jaar.
2023-05-28 10:10:06,845 - INFO - joeynmt.training - Epoch  10, Step:    33100, Batch Loss:     1.496708, Batch Acc: 0.539882, Tokens per Sec:     1753, Lr: 0.000300
2023-05-28 10:10:45,985 - INFO - joeynmt.training - Epoch  10, Step:    33200, Batch Loss:     1.519740, Batch Acc: 0.541917, Tokens per Sec:     1718, Lr: 0.000300
2023-05-28 10:11:24,076 - INFO - joeynmt.training - Epoch  10, Step:    33300, Batch Loss:     1.417328, Batch Acc: 0.536421, Tokens per Sec:     1812, Lr: 0.000300
2023-05-28 10:12:03,158 - INFO - joeynmt.training - Epoch  10, Step:    33400, Batch Loss:     1.655062, Batch Acc: 0.541698, Tokens per Sec:     1677, Lr: 0.000300
2023-05-28 10:12:39,518 - INFO - joeynmt.training - Epoch  10, Step:    33500, Batch Loss:     1.759195, Batch Acc: 0.542630, Tokens per Sec:     1807, Lr: 0.000300
2023-05-28 10:12:39,519 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 10:12:39,519 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 10:13:47,077 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.23, acc:   0.49, generation: 67.4622[sec], evaluation: 0.0000[sec]
2023-05-28 10:13:47,222 - INFO - joeynmt.helpers - delete models/transformer_c/32000.ckpt
2023-05-28 10:13:47,239 - INFO - joeynmt.training - Example #0
2023-05-28 10:13:47,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 10:13:47,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 10:13:47,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'k@@', 'k@@', 'app@@', 'e', ',', 'die', 'voor', 'een', 'half', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', '.', '</s>']
2023-05-28 10:13:47,240 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 10:13:47,240 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 10:13:47,240 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te zien dat de arctische ijkkkappe, die voor een half miljoen jaar de grootte van de onderste 48 staten, om 40 procent.
2023-05-28 10:13:47,240 - INFO - joeynmt.training - Example #1
2023-05-28 10:13:47,240 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 10:13:47,240 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 10:13:47,240 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'je', 'ziet', '.', '</s>']
2023-05-28 10:13:47,240 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 10:13:47,240 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 10:13:47,240 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg de oogst van dit specifieke probleem omdat het niet de dikke van het ijsje ziet.
2023-05-28 10:13:47,240 - INFO - joeynmt.training - Example #2
2023-05-28 10:13:47,240 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 10:13:47,240 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 10:13:47,240 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'ap', 'het', 'sch@@', 'it@@', 'ter@@', 'ende', 'hart', 'van', 'onze', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 10:13:47,240 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 10:13:47,240 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 10:13:47,240 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskap het schitterende hart van onze klimaatsysteem.
2023-05-28 10:13:47,240 - INFO - joeynmt.training - Example #3
2023-05-28 10:13:47,240 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 10:13:47,240 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 10:13:47,240 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'z@@', 'enden', 'van', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 10:13:47,241 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 10:13:47,241 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 10:13:47,241 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en verzenden van de zomer.
2023-05-28 10:13:47,241 - INFO - joeynmt.training - Example #4
2023-05-28 10:13:47,241 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 10:13:47,241 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 10:13:47,241 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', 'ti@@', 'me@@', '-@@', 'op@@', 'name', 'wat', 'er', 'gebeurt', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 10:13:47,241 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 10:13:47,241 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 10:13:47,241 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien, is een time-opname wat er gebeurt in de afgelopen 25 jaar.
2023-05-28 10:14:22,437 - INFO - joeynmt.training - Epoch  10, Step:    33600, Batch Loss:     1.616852, Batch Acc: 0.535879, Tokens per Sec:     1909, Lr: 0.000300
2023-05-28 10:14:57,103 - INFO - joeynmt.training - Epoch  10, Step:    33700, Batch Loss:     1.741534, Batch Acc: 0.541663, Tokens per Sec:     1972, Lr: 0.000300
2023-05-28 10:15:32,125 - INFO - joeynmt.training - Epoch  10, Step:    33800, Batch Loss:     1.953535, Batch Acc: 0.534462, Tokens per Sec:     1878, Lr: 0.000300
2023-05-28 10:16:08,245 - INFO - joeynmt.training - Epoch  10, Step:    33900, Batch Loss:     1.635156, Batch Acc: 0.536507, Tokens per Sec:     1863, Lr: 0.000300
2023-05-28 10:16:44,063 - INFO - joeynmt.training - Epoch  10, Step:    34000, Batch Loss:     1.795761, Batch Acc: 0.536088, Tokens per Sec:     1859, Lr: 0.000300
2023-05-28 10:16:44,063 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 10:16:44,063 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 10:17:42,680 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.19, acc:   0.49, generation: 58.5219[sec], evaluation: 0.0000[sec]
2023-05-28 10:17:42,682 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 10:17:42,829 - INFO - joeynmt.helpers - delete models/transformer_c/32500.ckpt
2023-05-28 10:17:42,847 - INFO - joeynmt.training - Example #0
2023-05-28 10:17:42,847 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 10:17:42,847 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 10:17:42,847 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'aange@@', 'to@@', 'ond', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'jes', 'van', 'de', 'onder@@', 'ste', 'drie', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'landen', ',', 'om', '40', 'procent', 'gesch@@', 'ikt', 'te', 'zijn', '.', '</s>']
2023-05-28 10:17:42,847 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 10:17:42,847 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 10:17:42,847 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia aangetoond om te zien dat de arctische ijkjes van de onderste drie miljoen jaar de grootte van de onderste 48 landen, om 40 procent geschikt te zijn.
2023-05-28 10:17:42,847 - INFO - joeynmt.training - Example #1
2023-05-28 10:17:42,848 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 10:17:42,848 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 10:17:42,848 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'zo', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'problemen', 'van', 'het', 'ijs', 'laat', 'zien', '.', '</s>']
2023-05-28 10:17:42,848 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 10:17:42,848 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 10:17:42,848 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet zo sterk genoeg de oogst van deze problemen, omdat het niet de dikke problemen van het ijs laat zien.
2023-05-28 10:17:42,848 - INFO - joeynmt.training - Example #2
2023-05-28 10:17:42,848 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 10:17:42,848 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 10:17:42,848 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tic@@', 'sche', 'ij@@', 'k@@', 'jes', 'het', 'sch@@', 'aar@@', 'dig', 'hart', 'van', 'onze', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 10:17:42,848 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 10:17:42,848 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 10:17:42,848 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arcticsche ijkjes het schaardig hart van onze wereldwijde klimaatsysteem.
2023-05-28 10:17:42,848 - INFO - joeynmt.training - Example #3
2023-05-28 10:17:42,848 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 10:17:42,848 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 10:17:42,848 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'loten', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 10:17:42,848 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 10:17:42,848 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 10:17:42,848 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sloten in de zomer.
2023-05-28 10:17:42,848 - INFO - joeynmt.training - Example #4
2023-05-28 10:17:42,849 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 10:17:42,849 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 10:17:42,849 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', ',', 'is', 'een', 'ver@@', 'teken@@', 'ing', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2023-05-28 10:17:42,849 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 10:17:42,849 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 10:17:42,849 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een vertekening wat er in de afgelopen 25 jaar is gebeurd.
2023-05-28 10:18:19,839 - INFO - joeynmt.training - Epoch  10, Step:    34100, Batch Loss:     2.009857, Batch Acc: 0.535392, Tokens per Sec:     1830, Lr: 0.000300
2023-05-28 10:18:55,966 - INFO - joeynmt.training - Epoch  10, Step:    34200, Batch Loss:     1.992837, Batch Acc: 0.537361, Tokens per Sec:     1786, Lr: 0.000300
2023-05-28 10:19:32,904 - INFO - joeynmt.training - Epoch  10, Step:    34300, Batch Loss:     1.849848, Batch Acc: 0.533175, Tokens per Sec:     1798, Lr: 0.000300
2023-05-28 10:20:09,603 - INFO - joeynmt.training - Epoch  10, Step:    34400, Batch Loss:     1.912878, Batch Acc: 0.532521, Tokens per Sec:     1859, Lr: 0.000300
2023-05-28 10:20:45,670 - INFO - joeynmt.training - Epoch  10, Step:    34500, Batch Loss:     1.551893, Batch Acc: 0.529800, Tokens per Sec:     1815, Lr: 0.000300
2023-05-28 10:20:45,671 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 10:20:45,671 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 10:21:52,293 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.17, acc:   0.49, generation: 66.5260[sec], evaluation: 0.0000[sec]
2023-05-28 10:21:52,296 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 10:21:52,448 - INFO - joeynmt.helpers - delete models/transformer_c/30500.ckpt
2023-05-28 10:21:52,466 - INFO - joeynmt.training - Example #0
2023-05-28 10:21:52,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 10:21:52,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 10:21:52,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'laten', 'zien', 'om', 'te', 'zien', 'dat', 'de', 'Arab@@', 'ische', 'ij@@', 'k@@', 'jes', 'die', 'voor', 'de', 'jon@@', 'geren', 'die', 'drie', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '40', 'procent', '.', '</s>']
2023-05-28 10:21:52,467 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 10:21:52,467 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 10:21:52,467 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laten zien om te zien dat de Arabische ijkjes die voor de jongeren die drie miljoen jaar de grootte van de onderste van de onderste 48 staten, om 40 procent.
2023-05-28 10:21:52,467 - INFO - joeynmt.training - Example #1
2023-05-28 10:21:52,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 10:21:52,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 10:21:52,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'dru@@', 'kt', 'niet', 'zo', 'sterk', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'z@@', 'ert', '.', '</s>']
2023-05-28 10:21:52,467 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 10:21:52,467 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 10:21:52,467 - INFO - joeynmt.training - 	Hypothesis: Maar dat drukt niet zo sterk genoeg de oogst van deze problemen, omdat het niet de dikke van het ijzert.
2023-05-28 10:21:52,467 - INFO - joeynmt.training - Example #2
2023-05-28 10:21:52,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 10:21:52,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 10:21:52,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'ij@@', 'k@@', 'jes', 'van', 'ons', 'wereld@@', 'systeem', '.', '</s>']
2023-05-28 10:21:52,467 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 10:21:52,467 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 10:21:52,467 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het schijkjes van ons wereldsysteem.
2023-05-28 10:21:52,467 - INFO - joeynmt.training - Example #3
2023-05-28 10:21:52,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 10:21:52,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 10:21:52,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'aal@@', 't', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 10:21:52,468 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 10:21:52,468 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 10:21:52,468 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schaalt in de zomer.
2023-05-28 10:21:52,468 - INFO - joeynmt.training - Example #4
2023-05-28 10:21:52,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 10:21:52,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 10:21:52,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', ',', 'is', 'een', 'ti@@', 'me@@', '-@@', 'af@@', 'name', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 10:21:52,468 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 10:21:52,468 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 10:21:52,468 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien, is een time-afname wat er in de afgelopen 25 jaar.
2023-05-28 10:22:31,034 - INFO - joeynmt.training - Epoch  10, Step:    34600, Batch Loss:     1.740060, Batch Acc: 0.539517, Tokens per Sec:     1786, Lr: 0.000300
2023-05-28 10:23:09,899 - INFO - joeynmt.training - Epoch  10, Step:    34700, Batch Loss:     1.538144, Batch Acc: 0.531485, Tokens per Sec:     1709, Lr: 0.000300
2023-05-28 10:23:47,458 - INFO - joeynmt.training - Epoch  10, Step:    34800, Batch Loss:     1.647663, Batch Acc: 0.536947, Tokens per Sec:     1803, Lr: 0.000300
2023-05-28 10:24:24,592 - INFO - joeynmt.training - Epoch  10, Step:    34900, Batch Loss:     1.674302, Batch Acc: 0.533508, Tokens per Sec:     1845, Lr: 0.000300
2023-05-28 10:25:01,127 - INFO - joeynmt.training - Epoch  10, Step:    35000, Batch Loss:     1.911980, Batch Acc: 0.534765, Tokens per Sec:     1791, Lr: 0.000300
2023-05-28 10:25:01,127 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 10:25:01,127 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 10:26:01,964 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.96, ppl:   7.13, acc:   0.49, generation: 60.7416[sec], evaluation: 0.0000[sec]
2023-05-28 10:26:01,966 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 10:26:02,099 - INFO - joeynmt.helpers - delete models/transformer_c/33500.ckpt
2023-05-28 10:26:02,115 - INFO - joeynmt.training - Example #0
2023-05-28 10:26:02,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 10:26:02,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 10:26:02,116 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', 'zien', 'om', 'te', 'zien', 'dat', 'de', 'aar@@', 'dige', 'ij@@', 'k@@', 'jes', 'die', 'voor', 'drie', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'kant', 'van', 'de', '4@@', '8', 'st@@', 'aten', ',', 'de', '4@@', '8', 'st@@', 'aten', ',', 'was', '40', 'procent', '.', '</s>']
2023-05-28 10:26:02,116 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 10:26:02,116 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 10:26:02,116 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar liet ik deze twee dia zien om te zien dat de aardige ijkjes die voor drie miljoen jaar de grootte van de onderkant van de 48 staten, de 48 staten, was 40 procent.
2023-05-28 10:26:02,116 - INFO - joeynmt.training - Example #1
2023-05-28 10:26:02,116 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 10:26:02,116 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 10:26:02,116 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'dru@@', 'kt', 'niet', 'erg', 'genoeg', 'de', 'oog@@', 'st', 'van', 'deze', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ijs', 'laat', 'zien', '.', '</s>']
2023-05-28 10:26:02,116 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 10:26:02,116 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 10:26:02,116 - INFO - joeynmt.training - 	Hypothesis: Maar dat drukt niet erg genoeg de oogst van deze problemen, omdat het niet de dikke van het ijs laat zien.
2023-05-28 10:26:02,116 - INFO - joeynmt.training - Example #2
2023-05-28 10:26:02,116 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 10:26:02,116 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 10:26:02,116 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'ij@@', 'k@@', 'app@@', 'e', 'het', 'sch@@', 'ij@@', 'k@@', 'jes', 'van', 'het', 'grootste', 'deel', 'van', 'onze', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 10:26:02,117 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 10:26:02,117 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 10:26:02,117 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijkappe het schijkappe het schijkjes van het grootste deel van onze wereldwijde klimaatsysteem.
2023-05-28 10:26:02,117 - INFO - joeynmt.training - Example #3
2023-05-28 10:26:02,117 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 10:26:02,117 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 10:26:02,117 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'roe@@', 'p', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 10:26:02,117 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 10:26:02,117 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 10:26:02,117 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroep in de zomer.
2023-05-28 10:26:02,117 - INFO - joeynmt.training - Example #4
2023-05-28 10:26:02,117 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 10:26:02,117 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 10:26:02,117 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'tij@@', 'dig', 'op@@', 'name', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 10:26:02,117 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 10:26:02,117 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 10:26:02,117 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tijdig opname wat er in de afgelopen 25 jaar is.
2023-05-28 10:26:36,460 - INFO - joeynmt.training - Epoch  10, Step:    35100, Batch Loss:     1.677163, Batch Acc: 0.537659, Tokens per Sec:     1932, Lr: 0.000300
2023-05-28 10:27:13,666 - INFO - joeynmt.training - Epoch  10, Step:    35200, Batch Loss:     1.743323, Batch Acc: 0.536615, Tokens per Sec:     1819, Lr: 0.000300
2023-05-28 10:27:50,126 - INFO - joeynmt.training - Epoch  10, Step:    35300, Batch Loss:     1.743323, Batch Acc: 0.537682, Tokens per Sec:     1913, Lr: 0.000300
2023-05-28 10:28:26,688 - INFO - joeynmt.training - Epoch  10, Step:    35400, Batch Loss:     1.673749, Batch Acc: 0.539960, Tokens per Sec:     1783, Lr: 0.000300
2023-05-28 10:29:00,947 - INFO - joeynmt.training - Epoch  10, Step:    35500, Batch Loss:     1.962759, Batch Acc: 0.533456, Tokens per Sec:     1975, Lr: 0.000300
2023-05-28 10:29:00,948 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 10:29:00,948 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 10:30:05,270 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.14, acc:   0.49, generation: 64.2269[sec], evaluation: 0.0000[sec]
2023-05-28 10:30:05,395 - INFO - joeynmt.helpers - delete models/transformer_c/33000.ckpt
2023-05-28 10:30:05,412 - INFO - joeynmt.training - Example #0
2023-05-28 10:30:05,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Fol@@', 'ien', 'gezeigt', ',', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'sse', 'der', 'unter@@', 'en', '4@@', '8', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 10:30:05,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'os@@', ';', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 'sk@@', 'ap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vast@@', 'el@@', 'and', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gek@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 10:30:05,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'di@@', 'a', 'zien', 'om', 'te', 'ver@@', 'beelden', 'dat', 'de', 'aar@@', 'dige', 'ij@@', 'sk@@', 'sk@@', 'app@@', 'e', ',', 'die', 'voor', 'een', 'half', 'miljoen', 'jaar', 'de', 'grootte', 'van', 'de', 'onder@@', 'ste', 'van', 'de', 'onder@@', 'ste', 'van', 'de', 'st@@', 'aten', ',', '40', 'procent', '.', '</s>']
2023-05-28 10:30:05,412 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 10:30:05,412 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 10:30:05,412 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar liet ik deze twee dia zien om te verbeelden dat de aardige ijskskappe, die voor een half miljoen jaar de grootte van de onderste van de onderste van de staten, 40 procent.
2023-05-28 10:30:05,412 - INFO - joeynmt.training - Example #1
2023-05-28 10:30:05,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drück@@', 't', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tig@@', 'keit', 'dieses', 'spezi@@', 'ellen', 'Proble@@', 'ms', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'cke', 'des', 'Eis@@', 'es', 'zeigt', '.']
2023-05-28 10:30:05,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigenlijk', 'de', 'ern@@', 'st', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 10:30:05,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'zo', 'sterk', 'genoeg', 'de', 'ge@@', 'wassen', 'deze', 'problemen', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'z@@', 'eren', 'van', 'het', 'ij@@', 'z@@', 'eren', 'van', 'het', 'ij@@', 'st', '.', '</s>']
2023-05-28 10:30:05,413 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 10:30:05,413 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 10:30:05,413 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet zo sterk genoeg de gewassen deze problemen, omdat het niet de dikke van het ijzeren van het ijzeren van het ijst.
2023-05-28 10:30:05,413 - INFO - joeynmt.training - Example #2
2023-05-28 10:30:05,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewiss@@', 'em', 'Sinne', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'Eis@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'syste@@', 'ms', '.']
2023-05-28 10:30:05,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 'sk@@', 'ap', 'op', 'de', 'Noor@@', 'd@@', 'p@@', 'ool', 'is', 'in', 'zekere', 'zin', 'het', 'klop@@', 'p@@', 'end', 'hart', 'van', 'ons', 'glob@@', 'aal', 'klimaat@@', 'systeem', '.']
2023-05-28 10:30:05,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', 'ar@@', 'c@@', 'tische', 'ij@@', 'sk@@', 'ap', 'het', 'zwe@@', 'et', 'het', 'zwe@@', 'et', 'van', 'onze', 'wereldwijde', 'klimaat@@', 'systeem', '.', '</s>']
2023-05-28 10:30:05,413 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 10:30:05,413 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 10:30:05,413 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskap het zweet het zweet van onze wereldwijde klimaatsysteem.
2023-05-28 10:30:05,413 - INFO - joeynmt.training - Example #3
2023-05-28 10:30:05,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'ächst', 'im', 'Win@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'ommer', '.']
2023-05-28 10:30:05,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'zom@@', 'er', '.']
2023-05-28 10:30:05,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'sl@@', 'aan', 'in', 'de', 'zom@@', 'er', '.', '</s>']
2023-05-28 10:30:05,413 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 10:30:05,413 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 10:30:05,413 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en verslaan in de zomer.
2023-05-28 10:30:05,413 - INFO - joeynmt.training - Example #4
2023-05-28 10:30:05,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Fol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ffer@@', 'auf@@', 'nahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 10:30:05,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'ver@@', 'snel@@', 'de', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 10:30:05,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', 'di@@', 'a', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'tijd@@', 'je', 'laat', 'zien', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2023-05-28 10:30:05,414 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 10:30:05,414 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 10:30:05,414 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tijdje laat zien wat er in de afgelopen 25 jaar is gebeurd.
2023-05-28 10:30:41,767 - INFO - joeynmt.training - Epoch  10, Step:    35600, Batch Loss:     1.759293, Batch Acc: 0.536370, Tokens per Sec:     1816, Lr: 0.000300
2023-05-28 10:30:43,291 - INFO - joeynmt.training - Epoch  10: total training loss 6156.70
2023-05-28 10:30:43,291 - INFO - joeynmt.training - Training ended after  10 epochs.
2023-05-28 10:30:43,291 - INFO - joeynmt.training - Best validation result (greedy) at step    35000:   7.13 ppl.
2023-05-28 10:30:43,302 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-28 10:30:43,372 - INFO - joeynmt.model - Enc-dec model built.
2023-05-28 10:30:43,405 - INFO - joeynmt.helpers - Load model from /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_c/35000.ckpt.
2023-05-28 10:30:43,409 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=9988),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=9988),
	loss_function=None)
2023-05-28 10:30:43,412 - INFO - joeynmt.prediction - Decoding on dev set...
2023-05-28 10:30:43,412 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 10:30:43,412 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 10:31:50,926 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 67.4200[sec], evaluation: 0.0000[sec]
2023-05-28 10:31:50,927 - INFO - joeynmt.prediction - Translations saved to: /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_c/00035000.hyps.dev.
2023-05-28 10:31:50,927 - INFO - joeynmt.prediction - Decoding on test set...
2023-05-28 10:31:50,927 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 10:31:50,927 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 10:33:15,732 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 84.6531[sec], evaluation: 0.0000[sec]
2023-05-28 10:33:15,735 - INFO - joeynmt.prediction - Translations saved to: /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_c/00035000.hyps.test.
