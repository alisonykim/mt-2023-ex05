2023-05-28 16:50:00,325 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2023-05-28 16:50:01,342 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-28 16:50:01,407 - INFO - joeynmt.model - Enc-dec model built.
2023-05-28 16:50:01,478 - INFO - joeynmt.helpers - Load model from /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_c/35000.ckpt.
2023-05-28 16:50:01,524 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses, tokenizer=BPE, separator=@@, dropout=0.0)
2023-05-28 16:50:01,524 - INFO - joeynmt.tokenizers - nl tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses, tokenizer=BPE, separator=@@, dropout=0.0)
2023-05-28 16:50:01,627 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 16:50:01,627 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 16:51:25,371 - INFO - joeynmt.prediction - Generation took 83.6655[sec]. (No references given)
2023-05-28 17:00:29,062 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2023-05-28 17:00:30,083 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-28 17:00:30,148 - INFO - joeynmt.model - Enc-dec model built.
2023-05-28 17:00:30,202 - INFO - joeynmt.helpers - Load model from /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_c/35000.ckpt.
2023-05-28 17:00:30,252 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses, tokenizer=BPE, separator=@@, dropout=0.0)
2023-05-28 17:00:30,252 - INFO - joeynmt.tokenizers - nl tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses, tokenizer=BPE, separator=@@, dropout=0.0)
2023-05-28 17:00:30,357 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 17:00:30,358 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 17:01:56,050 - INFO - joeynmt.prediction - Generation took 85.6140[sec]. (No references given)
