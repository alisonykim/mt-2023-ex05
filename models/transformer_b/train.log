2023-05-28 01:00:34,773 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -                           cfg.name : transformer_b
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -                     cfg.data.train : ../mt-2023-ex05/data/train.de-nl
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -                       cfg.data.dev : ../mt-2023-ex05/data/dev.de-nl
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -                      cfg.data.test : ../mt-2023-ex05/data/test.de-nl
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -       cfg.data.sample_train_subset : 100000
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -             cfg.data.src.normalize : False
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : ../mt-2023-ex05/vocab/vocab-2000-joint.txt
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenizer : moses
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.num_merges : 2000
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : ../mt-2023-ex05/vocab/codes2000.bpe
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.dropout : 0.0
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.model_type : bpe
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : nl
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -             cfg.data.trg.normalize : False
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : ../mt-2023-ex05/vocab/vocab-2000-joint.txt
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenizer : moses
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.num_merges : 2000
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : ../mt-2023-ex05/vocab/codes2000.bpe
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.dropout : 0.0
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.model_type : bpe
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2023-05-28 01:00:34,774 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/transformer_b
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -             cfg.training.overwrite : True
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2023-05-28 01:00:34,775 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2023-05-28 01:00:34,777 - INFO - joeynmt.data - Building tokenizer...
2023-05-28 01:00:34,809 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses, tokenizer=BPE, separator=@@, dropout=0.0)
2023-05-28 01:00:34,809 - INFO - joeynmt.tokenizers - nl tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses, tokenizer=BPE, separator=@@, dropout=0.0)
2023-05-28 01:00:34,809 - INFO - joeynmt.data - Loading train set...
2023-05-28 01:00:56,623 - INFO - joeynmt.data - Building vocabulary...
2023-05-28 01:00:56,671 - INFO - joeynmt.data - Loading dev set...
2023-05-28 01:00:56,774 - INFO - joeynmt.data - Loading test set...
2023-05-28 01:00:56,946 - INFO - joeynmt.data - Data loaded.
2023-05-28 01:00:56,946 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=216893, src_lang=de, trg_lang=nl, has_trg=True, random_subset=100000)
2023-05-28 01:00:56,946 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1001, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2023-05-28 01:00:56,946 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1779, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2023-05-28 01:00:56,946 - INFO - joeynmt.data - First training example:
	[SRC] A@@ l G@@ or@@ e : Die Ab@@ wen@@ dung der K@@ li@@ ma@@ k@@ at@@ ast@@ rop@@ he
	[TRG] A@@ l G@@ or@@ e over het af@@ wen@@ den van de kl@@ im@@ aat@@ c@@ r@@ is@@ is
2023-05-28 01:00:56,946 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) die (5) und (6) der (7) , (8) in (9) .
2023-05-28 01:00:56,946 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) die (5) und (6) der (7) , (8) in (9) .
2023-05-28 01:00:56,946 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2002
2023-05-28 01:00:56,947 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2002
2023-05-28 01:00:56,947 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-28 01:00:56,985 - INFO - joeynmt.model - Enc-dec model built.
2023-05-28 01:00:56,986 - INFO - joeynmt.model - Total params: 3411712
2023-05-28 01:00:56,987 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2023-05-28 01:00:56,987 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2002),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2002),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2023-05-28 01:00:56,987 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2023-05-28 01:00:56,987 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2023-05-28 01:00:56,987 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2023-05-28 01:00:56,987 - INFO - joeynmt.training - EPOCH 1
2023-05-28 01:00:57,014 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=0
2023-05-28 01:01:18,569 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.851358, Batch Acc: 0.056407, Tokens per Sec:     3410, Lr: 0.000300
2023-05-28 01:01:41,049 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     3.815688, Batch Acc: 0.084942, Tokens per Sec:     3120, Lr: 0.000300
2023-05-28 01:02:02,126 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.464024, Batch Acc: 0.108140, Tokens per Sec:     3400, Lr: 0.000300
2023-05-28 01:02:22,853 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.294722, Batch Acc: 0.115896, Tokens per Sec:     3415, Lr: 0.000300
2023-05-28 01:02:45,420 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.409164, Batch Acc: 0.124043, Tokens per Sec:     3136, Lr: 0.000300
2023-05-28 01:02:45,420 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:02:45,421 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:04:36,170 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.38, ppl:  29.46, acc:   0.12, generation: 110.6145[sec], evaluation: 0.0000[sec]
2023-05-28 01:04:36,172 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:04:36,268 - INFO - joeynmt.training - Example #0
2023-05-28 01:04:36,269 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:04:36,269 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:04:36,269 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', 'het', 'is', 'het', 'is', 'het', 'is', 'is', 'is', 'het', 'het', 'is', ',', 'het', 'het', 'het', 'het', 'een', 'is', ',', 'dat', 'de', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', ',', 'dat', 'de', 'is', 'is', 'het', 'is', 'is', ',', 'dat', 'de', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', ',', 'dat', 'het', 'het', 'het', 'het', 'het', 'het', 'het', 'het', 'het', 'het', 'het', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', '.', '</s>']
2023-05-28 01:04:36,269 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:04:36,269 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:04:36,269 - INFO - joeynmt.training - 	Hypothesis: Het is het is het is het is is is het het is, het het het het een is, dat de is is is is is is is is is is is, dat de is is het is is, dat de is is is is is is is is is is, dat het het het het het het het het het het het is is is is is is is is is is is is.
2023-05-28 01:04:36,269 - INFO - joeynmt.training - Example #1
2023-05-28 01:04:36,269 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:04:36,269 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:04:36,269 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'het', 'is', 'het', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'v@@', 'oo@@', 't', '.', '</s>']
2023-05-28 01:04:36,269 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:04:36,269 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:04:36,269 - INFO - joeynmt.training - 	Hypothesis: Maar het het is het bebebebebebebebebebebebebebebevoot.
2023-05-28 01:04:36,269 - INFO - joeynmt.training - Example #2
2023-05-28 01:04:36,269 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:04:36,269 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:04:36,269 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', 'het', 'is', 'een', 'is', 'een', 'is', 'een', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', '.', '</s>']
2023-05-28 01:04:36,270 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:04:36,270 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:04:36,270 - INFO - joeynmt.training - 	Hypothesis: Het is het is een is een is een is is is is is is is is is is is is is is is is is is is is is is is.
2023-05-28 01:04:36,270 - INFO - joeynmt.training - Example #3
2023-05-28 01:04:36,270 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:04:36,270 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:04:36,270 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', 'een', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'v@@', 'u@@', 'en', '.', '</s>']
2023-05-28 01:04:36,270 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:04:36,270 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:04:36,270 - INFO - joeynmt.training - 	Hypothesis: Het is een bebebebebebebebebebebebebebebevuen.
2023-05-28 01:04:36,270 - INFO - joeynmt.training - Example #4
2023-05-28 01:04:36,270 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:04:36,270 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:04:36,270 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', 'is', 'het', 'is', 'is', 'is', 'het', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'is', '.', '</s>']
2023-05-28 01:04:36,270 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:04:36,270 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:04:36,270 - INFO - joeynmt.training - 	Hypothesis: Het is is het is is is het is is is is is is is is is is is is is is is is is is is is is is is is is is.
2023-05-28 01:04:59,000 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.435281, Batch Acc: 0.137871, Tokens per Sec:     2972, Lr: 0.000300
2023-05-28 01:05:21,602 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.177968, Batch Acc: 0.143907, Tokens per Sec:     3131, Lr: 0.000300
2023-05-28 01:05:44,528 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.154233, Batch Acc: 0.157354, Tokens per Sec:     3144, Lr: 0.000300
2023-05-28 01:06:07,341 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.083570, Batch Acc: 0.165541, Tokens per Sec:     3121, Lr: 0.000300
2023-05-28 01:06:28,122 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.097896, Batch Acc: 0.181489, Tokens per Sec:     3487, Lr: 0.000300
2023-05-28 01:06:28,122 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:06:28,123 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:08:34,925 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.11, ppl:  22.41, acc:   0.17, generation: 126.7085[sec], evaluation: 0.0000[sec]
2023-05-28 01:08:34,929 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:08:35,048 - INFO - joeynmt.training - Example #0
2023-05-28 01:08:35,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:08:35,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:08:35,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'denk', 'dat', 'ik', 'dat', 'ik', 'een', 're@@', 'den', ',', 'en', 'ik', 'een', 'be@@', 'be@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'd@@', 'oe@@', 'd', ',', 'en', ',', 'en', 'en', 'en', 'de', 'wereld', '.', '</s>']
2023-05-28 01:08:35,049 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:08:35,049 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:08:35,049 - INFO - joeynmt.training - 	Hypothesis: Ik denk dat ik dat ik een reden, en ik een bebedddddddddddddddddddddddddddddddddddddddddoed, en, en en en de wereld.
2023-05-28 01:08:35,049 - INFO - joeynmt.training - Example #1
2023-05-28 01:08:35,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:08:35,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:08:35,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', ',', 'maar', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', '.', '</s>']
2023-05-28 01:08:35,049 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:08:35,049 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:08:35,049 - INFO - joeynmt.training - 	Hypothesis: Maar het niet niet niet niet niet niet, maar niet niet niet niet niet niet niet.
2023-05-28 01:08:35,049 - INFO - joeynmt.training - Example #2
2023-05-28 01:08:35,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:08:35,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:08:35,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'wereld', 'is', 'de', 'de', 'de', 'de', 'wereld', 'van', 'de', 'wereld', ',', 'maar', 'de', 'de', 'de', 'wereld', '.', '</s>']
2023-05-28 01:08:35,050 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:08:35,050 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:08:35,050 - INFO - joeynmt.training - 	Hypothesis: In de wereld is de de de de wereld van de wereld, maar de de de wereld.
2023-05-28 01:08:35,050 - INFO - joeynmt.training - Example #3
2023-05-28 01:08:35,050 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:08:35,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:08:35,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'hebben', 'een', 'een', 'een', 'een', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'or@@', 'or@@', 'ten', '.', '</s>']
2023-05-28 01:08:35,050 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:08:35,050 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:08:35,050 - INFO - joeynmt.training - 	Hypothesis: Ze hebben een een een een ppppppppppppppppppppppororten.
2023-05-28 01:08:35,050 - INFO - joeynmt.training - Example #4
2023-05-28 01:08:35,050 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:08:35,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:08:35,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'is', 'een', 'een', 'een', 'een', 'een', 'een', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@', 'f@@']
2023-05-28 01:08:35,050 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:08:35,050 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:08:35,050 - INFO - joeynmt.training - 	Hypothesis: De is een een een een een een fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff
2023-05-28 01:08:56,315 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.052911, Batch Acc: 0.191691, Tokens per Sec:     3363, Lr: 0.000300
2023-05-28 01:09:17,740 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     2.907688, Batch Acc: 0.202380, Tokens per Sec:     3197, Lr: 0.000300
2023-05-28 01:09:39,273 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     2.830256, Batch Acc: 0.212659, Tokens per Sec:     3279, Lr: 0.000300
2023-05-28 01:10:00,250 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     2.917684, Batch Acc: 0.217669, Tokens per Sec:     3377, Lr: 0.000300
2023-05-28 01:10:20,462 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     2.913395, Batch Acc: 0.229391, Tokens per Sec:     3505, Lr: 0.000300
2023-05-28 01:10:20,462 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:10:20,462 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:12:01,072 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.87, ppl:  17.67, acc:   0.21, generation: 100.5110[sec], evaluation: 0.0000[sec]
2023-05-28 01:12:01,073 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:12:01,183 - INFO - joeynmt.training - Example #0
2023-05-28 01:12:01,183 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:12:01,183 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:12:01,183 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'ik', 'een', 'voor@@', 'beeld', 'van', 'de', 'eerste', 'eerste', 'eerste', ',', 'dat', 'de', 'eerste', 'eerste', 'van', 'de', '1@@', '00', 'jaar', 'jaar', 'jaar', 'gele@@', 'den', ',', 'dat', 'de', '1@@', '00', 'jaar', 'jaar', 'jaar', 'jaar', 'gele@@', 'den', 'van', 'de', '1@@', '00', 'jaar', 'gele@@', 'den', ',', 'de', 'de', 'de', 'de', '1@@', '00', 'jaar', 'jaar', 'jaar', 'gele@@', 'den', 'van', 'de', '1@@', '00', 'jaar', 'jaar', 'jaar', 'jaar', 'jaar', '.', '</s>']
2023-05-28 01:12:01,183 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:12:01,183 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:12:01,183 - INFO - joeynmt.training - 	Hypothesis: Ik heb ik een voorbeeld van de eerste eerste eerste, dat de eerste eerste van de 100 jaar jaar jaar geleden, dat de 100 jaar jaar jaar jaar geleden van de 100 jaar geleden, de de de de 100 jaar jaar jaar geleden van de 100 jaar jaar jaar jaar jaar.
2023-05-28 01:12:01,183 - INFO - joeynmt.training - Example #1
2023-05-28 01:12:01,183 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:12:01,183 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:12:01,183 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'de', 'be@@', 'ter', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 'wereld', '.', '</s>']
2023-05-28 01:12:01,183 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:12:01,183 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:12:01,184 - INFO - joeynmt.training - 	Hypothesis: Maar het niet niet niet niet niet niet de beter van de wereld van de wereld van de wereld van de wereld van de wereld van de wereld.
2023-05-28 01:12:01,184 - INFO - joeynmt.training - Example #2
2023-05-28 01:12:01,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:12:01,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:12:01,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'eerste', 'is', 'de', 'p@@', 'la@@', 'k', 'is', 'de', 're@@', 'c@@', 'ul@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'at@@', 'at@@', 'ies', 'van', 'de', 'wereld', '.', '</s>']
2023-05-28 01:12:01,184 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:12:01,184 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:12:01,184 - INFO - joeynmt.training - 	Hypothesis: In de eerste is de plak is de reculppppppataties van de wereld.
2023-05-28 01:12:01,184 - INFO - joeynmt.training - Example #3
2023-05-28 01:12:01,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:12:01,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:12:01,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'zijn', 'de', 'b@@', 'oo@@', 'g', 'en', 'en', 'de', 'de', 'b@@', 'oo@@', 'l', '.', '</s>']
2023-05-28 01:12:01,184 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:12:01,184 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:12:01,184 - INFO - joeynmt.training - 	Hypothesis: Ze zijn de boog en en de de bool.
2023-05-28 01:12:01,184 - INFO - joeynmt.training - Example #4
2023-05-28 01:12:01,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:12:01,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:12:01,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eerste', 'eerste', 'eerste', ',', 'ik', 'een', 'be@@', 'ter', 'dat', 'ik', 'een', 'een', 'een', 'een', 'p@@', 'ub@@', 'lie@@', 'k', 'is', 'is', 'van', 'de', 'wereld', '.', '</s>']
2023-05-28 01:12:01,184 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:12:01,184 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:12:01,184 - INFO - joeynmt.training - 	Hypothesis: De eerste eerste eerste, ik een beter dat ik een een een een publiek is is van de wereld.
2023-05-28 01:12:22,908 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     2.345782, Batch Acc: 0.231410, Tokens per Sec:     3180, Lr: 0.000300
2023-05-28 01:12:44,227 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     2.544750, Batch Acc: 0.235624, Tokens per Sec:     3372, Lr: 0.000300
2023-05-28 01:13:06,413 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.723554, Batch Acc: 0.244916, Tokens per Sec:     3190, Lr: 0.000300
2023-05-28 01:13:28,831 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     2.610533, Batch Acc: 0.249641, Tokens per Sec:     3203, Lr: 0.000300
2023-05-28 01:13:51,401 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.929111, Batch Acc: 0.260999, Tokens per Sec:     3246, Lr: 0.000300
2023-05-28 01:13:51,403 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:13:51,403 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:15:06,149 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.70, ppl:  14.94, acc:   0.24, generation: 74.6509[sec], evaluation: 0.0000[sec]
2023-05-28 01:15:06,150 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:15:06,252 - INFO - joeynmt.training - Example #0
2023-05-28 01:15:06,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:15:06,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:15:06,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'ben', 'de', 'eerste', 'jaar', 'jaar', 'gele@@', 'den', ',', 'en', 'ik', 'de', 're@@', 'gel@@', 's', 'om', 'te', 'te', 'te', 'te', 'te', 'ver@@', 'anderen', ',', 'dat', 'de', 'de', 'de', 'eerste', 'jaar', 'gele@@', 'den', ',', 'die', 'de', '1@@', '5', 'jaar', 'jaar', 'gele@@', 'den', '.', '</s>']
2023-05-28 01:15:06,253 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:15:06,253 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:15:06,253 - INFO - joeynmt.training - 	Hypothesis: Ik ben de eerste jaar jaar geleden, en ik de regels om te te te te te veranderen, dat de de de eerste jaar geleden, die de 15 jaar jaar geleden.
2023-05-28 01:15:06,253 - INFO - joeynmt.training - Example #1
2023-05-28 01:15:06,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:15:06,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:15:06,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'de', 're@@', 'cht@@', 'cht@@', 's@@', 'el', 'is', 'niet', 'de', 'in@@', 'form@@', 'atie', 'van', 'de', 'in@@', 'form@@', 'atie', 'van', 'de', 'proble@@', 'em', '.', '</s>']
2023-05-28 01:15:06,253 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:15:06,253 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:15:06,253 - INFO - joeynmt.training - 	Hypothesis: Maar de rechtchtsel is niet de informatie van de informatie van de probleem.
2023-05-28 01:15:06,253 - INFO - joeynmt.training - Example #2
2023-05-28 01:15:06,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:15:06,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:15:06,254 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 're@@', 'cht@@', 'ige', 'is', 'de', 'in@@', 'form@@', 'atie', 'is', 'de', 'in@@', 'form@@', 'atie', 'van', 'de', 'in@@', 'form@@', 'atie', 'van', 'de', 'in@@', 'form@@', 'atie', 'van', 'de', 'b@@', 'la@@', 'st@@', 'st@@', 'st@@', 'ige', '.', '</s>']
2023-05-28 01:15:06,254 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:15:06,254 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:15:06,254 - INFO - joeynmt.training - 	Hypothesis: In de rechtige is de informatie is de informatie van de informatie van de informatie van de blastststige.
2023-05-28 01:15:06,254 - INFO - joeynmt.training - Example #3
2023-05-28 01:15:06,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:15:06,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:15:06,254 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'zijn', 'de', 'b@@', 'oo@@', 'g', 'in', 'de', 'b@@', 'oo@@', 'g', '.', '</s>']
2023-05-28 01:15:06,254 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:15:06,254 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:15:06,254 - INFO - joeynmt.training - 	Hypothesis: Ze zijn de boog in de boog.
2023-05-28 01:15:06,254 - INFO - joeynmt.training - Example #4
2023-05-28 01:15:06,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:15:06,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:15:06,254 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eerste', 'is', 'de', 're@@', 'den', ',', 'ik', 'een', 'be@@', 'ter', 'van', 'de', 'eerste', ',', 'een', 'een', 'jaar', 'jaar', 'gele@@', 'den', '.', '</s>']
2023-05-28 01:15:06,254 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:15:06,254 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:15:06,254 - INFO - joeynmt.training - 	Hypothesis: De eerste is de reden, ik een beter van de eerste, een een jaar jaar geleden.
2023-05-28 01:15:29,149 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.485131, Batch Acc: 0.260226, Tokens per Sec:     3065, Lr: 0.000300
2023-05-28 01:15:51,923 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.509848, Batch Acc: 0.268404, Tokens per Sec:     3145, Lr: 0.000300
2023-05-28 01:16:14,327 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.675461, Batch Acc: 0.272260, Tokens per Sec:     3205, Lr: 0.000300
2023-05-28 01:16:37,977 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.498698, Batch Acc: 0.275316, Tokens per Sec:     3065, Lr: 0.000300
2023-05-28 01:17:01,630 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.478867, Batch Acc: 0.284436, Tokens per Sec:     2892, Lr: 0.000300
2023-05-28 01:17:01,631 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:17:01,631 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:18:35,588 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.59, ppl:  13.32, acc:   0.27, generation: 93.8631[sec], evaluation: 0.0000[sec]
2023-05-28 01:18:35,589 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:18:35,699 - INFO - joeynmt.training - Example #0
2023-05-28 01:18:35,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:18:35,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:18:35,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'ik', 'deze', 'jaar', 'gele@@', 'den', ',', 'ik', 'deze', 'v@@', 'ij@@', 'f', 'van', 'de', 'v@@', 'ij@@', 'f', 'jaar', 'dat', 'de', 're@@', 'cht@@', 'ige', 'in@@', 'form@@', 'atie', 'van', 'de', 'eerste', 'eerste', 'eerste', 'jaren', 'die', 'twee', 'jaar', 'jaar', 'gele@@', 'den', '.', '</s>']
2023-05-28 01:18:35,700 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:18:35,700 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:18:35,700 - INFO - joeynmt.training - 	Hypothesis: Laten ik deze jaar geleden, ik deze vijf van de vijf jaar dat de rechtige informatie van de eerste eerste eerste jaren die twee jaar jaar geleden.
2023-05-28 01:18:35,700 - INFO - joeynmt.training - Example #1
2023-05-28 01:18:35,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:18:35,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:18:35,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'is', 'niet', 'niet', 'dat', 'het', 'is', 'van', 'de', 'proble@@', 'men', 'die', 'die', 'het', 'proble@@', 'men', 'van', 'het', 'proble@@', 'em', 'van', 'de', 'proble@@', 'men', 'van', 'de', 'wereld', '.', '</s>']
2023-05-28 01:18:35,700 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:18:35,700 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:18:35,700 - INFO - joeynmt.training - 	Hypothesis: Maar het is niet niet dat het is van de problemen die die het problemen van het probleem van de problemen van de wereld.
2023-05-28 01:18:35,700 - INFO - joeynmt.training - Example #2
2023-05-28 01:18:35,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:18:35,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:18:35,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'S@@', 'omm@@', 'ige', 'z@@', 'es', 'is', 'de', 'c@@', 'r@@', 'is@@', 'is@@', 'is@@', 'is@@', 'c@@', 'ontro@@', 'le', '.', '</s>']
2023-05-28 01:18:35,700 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:18:35,700 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:18:35,700 - INFO - joeynmt.training - 	Hypothesis: In de Sommige zes is de crisisisiscontrole.
2023-05-28 01:18:35,700 - INFO - joeynmt.training - Example #3
2023-05-28 01:18:35,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:18:35,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:18:35,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'ver@@', 'tel@@', 't', 'in', 'de', 'b@@', 'oo@@', 'pt', 'en', 'in', 'de', 'b@@', 'oo@@', 'pt', '.', '</s>']
2023-05-28 01:18:35,701 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:18:35,701 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:18:35,701 - INFO - joeynmt.training - 	Hypothesis: Ze vertelt in de boopt en in de boopt.
2023-05-28 01:18:35,701 - INFO - joeynmt.training - Example #4
2023-05-28 01:18:35,701 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:18:35,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:18:35,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'p@@', 'ol@@', 'ie', 'van', 'de', 'p@@', 'ol@@', 'ie', ',', 'ik', 'je', 'een', 'be@@', 'd@@', 'ollar', '.', '</s>']
2023-05-28 01:18:35,701 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:18:35,701 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:18:35,701 - INFO - joeynmt.training - 	Hypothesis: De polie van de polie, ik je een bedollar.
2023-05-28 01:18:58,592 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.495614, Batch Acc: 0.292180, Tokens per Sec:     3043, Lr: 0.000300
2023-05-28 01:19:21,369 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.636539, Batch Acc: 0.292362, Tokens per Sec:     3071, Lr: 0.000300
2023-05-28 01:19:43,967 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.555822, Batch Acc: 0.301794, Tokens per Sec:     3131, Lr: 0.000300
2023-05-28 01:20:07,656 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.594547, Batch Acc: 0.306171, Tokens per Sec:     2946, Lr: 0.000300
2023-05-28 01:20:31,761 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.652315, Batch Acc: 0.311253, Tokens per Sec:     2931, Lr: 0.000300
2023-05-28 01:20:31,762 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:20:31,762 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:21:35,621 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.49, ppl:  12.08, acc:   0.29, generation: 63.7683[sec], evaluation: 0.0000[sec]
2023-05-28 01:21:35,623 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:21:35,742 - INFO - joeynmt.helpers - delete models/transformer_b/500.ckpt
2023-05-28 01:21:35,754 - INFO - joeynmt.training - Example #0
2023-05-28 01:21:35,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:21:35,755 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:21:35,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['D@@', 'an', 'heb', 'ik', 'deze', 'f@@', 'eite', 'de', 'f@@', 'ol@@', 'i@@', 'ë', ',', 'om', 'de', 'f@@', 'amil@@', 'ie', 'te', 'ver@@', 'mo@@', 'gen', ',', 'de', 'in@@', 'di@@', 'vi@@', 'du@@', 'c@@', 'c@@', 'ontro@@', 'le', 'en', 'jaar', 'gele@@', 'den', ',', 'de', 'drie', 'jaar', 'gele@@', 'den', '.', '</s>']
2023-05-28 01:21:35,755 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:21:35,755 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:21:35,755 - INFO - joeynmt.training - 	Hypothesis: Dan heb ik deze feite de folië, om de familie te vermogen, de individuccontrole en jaar geleden, de drie jaar geleden.
2023-05-28 01:21:35,755 - INFO - joeynmt.training - Example #1
2023-05-28 01:21:35,755 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:21:35,755 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:21:35,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'is', 'niet', 'zo', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'de', 'in@@', 'di@@', 'vi@@', 'du@@', 'c@@', 'ellen', 'van', 'deze', 'proble@@', 'em', 'van', 'de', 'proble@@', 'em', 'van', 'de', 'E@@', 'u@@', 'rop@@', 'e@@', 'se', 'proble@@', 'em', '.', '</s>']
2023-05-28 01:21:35,755 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:21:35,755 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:21:35,755 - INFO - joeynmt.training - 	Hypothesis: Maar het is niet zo 's de individucellen van deze probleem van de probleem van de Europese probleem.
2023-05-28 01:21:35,755 - INFO - joeynmt.training - Example #2
2023-05-28 01:21:35,755 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:21:35,755 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:21:35,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'p@@', 'ati@@', 'ë@@', 'n@@', 't', 'is', 'de', 'e@@', 'ct@@', 'uur', 'de', 'e@@', 'conom@@', 'ische', 'e@@', 'conom@@', 'ische', 'e@@', 'conom@@', 'ische', 'e@@', 'conom@@', 'ische', 'c@@', 'r@@', 'is@@', 'me', '.', '</s>']
2023-05-28 01:21:35,756 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:21:35,756 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:21:35,756 - INFO - joeynmt.training - 	Hypothesis: In de patiënt is de ectuur de economische economische economische economische crisme.
2023-05-28 01:21:35,756 - INFO - joeynmt.training - Example #3
2023-05-28 01:21:35,756 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:21:35,756 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:21:35,756 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'be@@', 'ste', 'de', 'sch@@', 'e@@', 'ven', 'in', 'de', 'z@@', 'ich@@', 'zelf', '.', '</s>']
2023-05-28 01:21:35,756 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:21:35,756 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:21:35,756 - INFO - joeynmt.training - 	Hypothesis: Ze beste de scheven in de zichzelf.
2023-05-28 01:21:35,756 - INFO - joeynmt.training - Example #4
2023-05-28 01:21:35,756 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:21:35,756 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:21:35,756 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eerste', 'is', 'een', 'f@@', 'eit', 'die', 'ik', 'wil', 'een', 'paar', 'jaar', ',', 'een', 'paar', 'jaar', 'gele@@', 'den', 'is', 'een', 'laat@@', 'ste', 'laat@@', 'ste', 'jaar', '.', '</s>']
2023-05-28 01:21:35,756 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:21:35,756 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:21:35,756 - INFO - joeynmt.training - 	Hypothesis: De eerste is een feit die ik wil een paar jaar, een paar jaar geleden is een laatste laatste jaar.
2023-05-28 01:21:58,152 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.470169, Batch Acc: 0.314835, Tokens per Sec:     3055, Lr: 0.000300
2023-05-28 01:22:20,579 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.545056, Batch Acc: 0.323130, Tokens per Sec:     3071, Lr: 0.000300
2023-05-28 01:22:41,268 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.372837, Batch Acc: 0.329733, Tokens per Sec:     3496, Lr: 0.000300
2023-05-28 01:23:02,532 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.491089, Batch Acc: 0.335477, Tokens per Sec:     3268, Lr: 0.000300
2023-05-28 01:23:23,276 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.349127, Batch Acc: 0.340448, Tokens per Sec:     3381, Lr: 0.000300
2023-05-28 01:23:23,278 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:23:23,278 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:24:31,868 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.40, ppl:  11.01, acc:   0.32, generation: 68.4985[sec], evaluation: 0.0000[sec]
2023-05-28 01:24:31,869 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:24:31,977 - INFO - joeynmt.helpers - delete models/transformer_b/1000.ckpt
2023-05-28 01:24:31,992 - INFO - joeynmt.training - Example #0
2023-05-28 01:24:31,992 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:24:31,992 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:24:31,992 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aat', 'het', 'jaar', 'gele@@', 'den', 'heb', 'ik', 'deze', 'f@@', 'ol@@', 'i@@', 'ë', ',', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'e@@', 'conom@@', 'ische', 'e@@', 'ct@@', 'uur', 'van', 'de', 'e@@', 'conom@@', 'ische', 'e@@', 'conom@@', 'ische', 'miljo@@', 'enen', 'miljo@@', 'en', 'jaar', 'gele@@', 'den', ',', 'die', 'drie', 'jaar', 'gele@@', 'den', '.', '</s>']
2023-05-28 01:24:31,992 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:24:31,992 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:24:31,992 - INFO - joeynmt.training - 	Hypothesis: Laat het jaar geleden heb ik deze folië, om te bekijken dat de economische ectuur van de economische economische miljoenen miljoen jaar geleden, die drie jaar geleden.
2023-05-28 01:24:31,992 - INFO - joeynmt.training - Example #1
2023-05-28 01:24:31,992 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:24:31,992 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:24:31,992 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'de', 'in@@', 'st@@', 'aan', 'die', 'het', 'proble@@', 'em', 'is', ',', 'het', 'proble@@', 'em', 'van', 'de', 'e@@', 'conom@@', 'ische', 'e@@', 'conom@@', 'ische', 'e@@', 'conom@@', 'ische', 'e@@', 'conom@@', 'ische', 'e@@', 'conom@@', 'ische', 'e@@', 'conom@@', 'ische', 'e@@', 'conom@@', 'ie', '.', '</s>']
2023-05-28 01:24:31,992 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:24:31,992 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:24:31,993 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo 's de instaan die het probleem is, het probleem van de economische economische economische economische economische economische economie.
2023-05-28 01:24:31,993 - INFO - joeynmt.training - Example #2
2023-05-28 01:24:31,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:24:31,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:24:31,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'k@@', 'oo@@', 'p', 'is', 'de', 'e@@', 'ct@@', 'ar@@', 'is@@', 'c@@', 'ar@@', 'is@@', 'c@@', 'e', 'is', ',', 'het', 'het', 'ver@@', 'mo@@', 'gen', 'van', 'ons', '.', '</s>']
2023-05-28 01:24:31,993 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:24:31,993 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:24:31,993 - INFO - joeynmt.training - 	Hypothesis: In de koop is de ectariscarisce is, het het vermogen van ons.
2023-05-28 01:24:31,993 - INFO - joeynmt.training - Example #3
2023-05-28 01:24:31,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:24:31,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:24:31,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'be@@', 'v@@', 'l@@', 'icht', 'in', 'het', 'z@@', 'it', '.', '</s>']
2023-05-28 01:24:31,993 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:24:31,993 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:24:31,993 - INFO - joeynmt.training - 	Hypothesis: Ze bevlicht in het zit.
2023-05-28 01:24:31,993 - INFO - joeynmt.training - Example #4
2023-05-28 01:24:31,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:24:31,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:24:31,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'gende', 'v@@', 'ij@@', 'f', ',', 'is', 'een', 'be@@', 'ste', ',', 'is', 'een', 'be@@', 'et@@', 'je', 'van', 'de', 'laat@@', 'ste', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 01:24:31,993 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:24:31,993 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:24:31,994 - INFO - joeynmt.training - 	Hypothesis: De volgende gende vijf, is een beste, is een beetje van de laatste ste 25 jaar.
2023-05-28 01:24:54,194 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     2.269789, Batch Acc: 0.340217, Tokens per Sec:     3115, Lr: 0.000300
2023-05-28 01:25:15,752 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.172019, Batch Acc: 0.352285, Tokens per Sec:     3255, Lr: 0.000300
2023-05-28 01:25:38,087 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.411314, Batch Acc: 0.351460, Tokens per Sec:     3244, Lr: 0.000300
2023-05-28 01:25:59,532 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.381929, Batch Acc: 0.355422, Tokens per Sec:     3381, Lr: 0.000300
2023-05-28 01:26:20,658 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     2.237027, Batch Acc: 0.365007, Tokens per Sec:     3247, Lr: 0.000300
2023-05-28 01:26:20,661 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:26:20,661 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:27:45,024 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.32, ppl:  10.14, acc:   0.34, generation: 84.2657[sec], evaluation: 0.0000[sec]
2023-05-28 01:27:45,026 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:27:45,128 - INFO - joeynmt.helpers - delete models/transformer_b/1500.ckpt
2023-05-28 01:27:45,139 - INFO - joeynmt.training - Example #0
2023-05-28 01:27:45,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:27:45,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:27:45,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'ik', 'deze', 'jaar', 'gele@@', 'den', 'van', 'de', 'v@@', 'ol@@', 'ie', ',', 'om', 'de', 'v@@', 'al@@', 't', 'te', 'be@@', 'kijken', 'dat', 'de', 'e@@', 'c@@', 'ten', 'van', 'de', 'e@@', 'c@@', 'e', 'e@@', 'c@@', 'e', ',', 'de', 'drie', 'jaar', 'gele@@', 'den', 'van', 'de', 'jaren', '4@@', '0', 'miljo@@', 'en', 'jaar', 'gele@@', 'den', '.', '</s>']
2023-05-28 01:27:45,139 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:27:45,139 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:27:45,139 - INFO - joeynmt.training - 	Hypothesis: Laten ik deze jaar geleden van de volie, om de valt te bekijken dat de ecten van de ece ece, de drie jaar geleden van de jaren 40 miljoen jaar geleden.
2023-05-28 01:27:45,139 - INFO - joeynmt.training - Example #1
2023-05-28 01:27:45,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:27:45,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:27:45,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'de', 're@@', 's@@', 'ult@@', 'aat', 'van', 'dit', 'proble@@', 'em', 'van', 'het', 'proble@@', 'em', 'van', 'het', 'niet', 'de', 'proble@@', 'em', 'van', 'de', 'e@@', 'conom@@', 'ie', 'van', 'het', 'e@@', 'conom@@', 'ie', '.', '</s>']
2023-05-28 01:27:45,140 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:27:45,140 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:27:45,140 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo 's de resultaat van dit probleem van het probleem van het niet de probleem van de economie van het economie.
2023-05-28 01:27:45,140 - INFO - joeynmt.training - Example #2
2023-05-28 01:27:45,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:27:45,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:27:45,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'het', 'is', 'de', 'S@@', 'an', 'is', 'de', 'e@@', 'c@@', 'is@@', 'c@@', 'ont@@', 'c@@', 'ar@@', 'c@@', 'c@@', 'c@@', 'r@@', 'is@@', 'c@@', 'ont@@', 'ac@@', 't', 'van', 'onze', 'c@@', 'ont@@', 'ac@@', 't', 'van', 'onze', 'c@@', 'ij@@', 's@@', '-@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 01:27:45,140 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:27:45,140 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:27:45,140 - INFO - joeynmt.training - 	Hypothesis: In het is de San is de eciscontcarcccriscontact van onze contact van onze cijs-systeem.
2023-05-28 01:27:45,140 - INFO - joeynmt.training - Example #3
2023-05-28 01:27:45,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:27:45,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:27:45,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'l@@', 'aat', 'het', 'in', 'het', 'W@@', 'in@@', 'ter', 'en', 'het', 'in', 'de', 'S@@', 'S@@', '-@@', 'S@@', '-@@', '.', '</s>']
2023-05-28 01:27:45,140 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:27:45,140 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:27:45,140 - INFO - joeynmt.training - 	Hypothesis: Ze laat het in het Winter en het in de SS-S-.
2023-05-28 01:27:45,140 - INFO - joeynmt.training - Example #4
2023-05-28 01:27:45,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:27:45,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:27:45,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ol@@', 'ie', ',', 'de', 'ik', 'jullie', 'zien', 'dat', 'ik', 'jullie', 'een', 'be@@', 'et@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'is', '.', '</s>']
2023-05-28 01:27:45,141 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:27:45,141 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:27:45,141 - INFO - joeynmt.training - 	Hypothesis: De volgende volie, de ik jullie zien dat ik jullie een beetje in de laatste 25 jaar geleden is.
2023-05-28 01:28:06,684 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     2.209382, Batch Acc: 0.372099, Tokens per Sec:     3253, Lr: 0.000300
2023-05-28 01:28:28,424 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     2.092619, Batch Acc: 0.370265, Tokens per Sec:     3280, Lr: 0.000300
2023-05-28 01:28:50,227 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     2.200577, Batch Acc: 0.374406, Tokens per Sec:     3272, Lr: 0.000300
2023-05-28 01:29:12,159 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:     2.104980, Batch Acc: 0.385793, Tokens per Sec:     3264, Lr: 0.000300
2023-05-28 01:29:15,855 - INFO - joeynmt.training - Epoch   1: total training loss 12045.32
2023-05-28 01:29:15,855 - INFO - joeynmt.training - EPOCH 2
2023-05-28 01:29:15,886 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=1
2023-05-28 01:29:34,587 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     2.212507, Batch Acc: 0.388848, Tokens per Sec:     3143, Lr: 0.000300
2023-05-28 01:29:34,590 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:29:34,590 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:30:43,582 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.37, acc:   0.37, generation: 68.8941[sec], evaluation: 0.0000[sec]
2023-05-28 01:30:43,583 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:30:43,673 - INFO - joeynmt.helpers - delete models/transformer_b/2000.ckpt
2023-05-28 01:30:43,688 - INFO - joeynmt.training - Example #0
2023-05-28 01:30:43,688 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:30:43,688 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:30:43,688 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Toen', 'ik', 'deze', 'jaar', 'gele@@', 'den', 'heb', 'ik', 'deze', 'v@@', 'ol@@', 'gens', ',', 'om', 'de', 're@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'amer@@', 'a', 'te', 'ver@@', 'van@@', 'gen', ',', 'die', 'de', 'in@@', 'gen@@', 'en', ',', 'voor', 'de', 'h@@', 'onder@@', 'den', 'miljo@@', 'en', 'jaar', 'gele@@', 'den', ',', 'om', 'de', '4@@', '0', 'miljo@@', 'en', 'jaar', 'gele@@', 'den', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'z@@', 'ich@@', 'ten', '.', '</s>']
2023-05-28 01:30:43,688 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:30:43,688 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:30:43,688 - INFO - joeynmt.training - 	Hypothesis: Toen ik deze jaar geleden heb ik deze volgens, om de reccccccamera te vervangen, die de ingenen, voor de honderden miljoen jaar geleden, om de 40 miljoen jaar geleden, om 40 procent te verzichten.
2023-05-28 01:30:43,688 - INFO - joeynmt.training - Example #1
2023-05-28 01:30:43,689 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:30:43,689 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:30:43,689 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'zo', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'die', 'de', 're@@', 'st@@', 'aan', ',', 'het', 'niet', 'de', 'proble@@', 'em', 'van', 'de', 'e@@', 'conom@@', 'ische', 'proble@@', 'em', '.', '</s>']
2023-05-28 01:30:43,689 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:30:43,689 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:30:43,689 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo zo 's die de restaan, het niet de probleem van de economische probleem.
2023-05-28 01:30:43,689 - INFO - joeynmt.training - Example #2
2023-05-28 01:30:43,689 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:30:43,689 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:30:43,689 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'p@@', 'at@@', 'ron@@', 'en', 'is', 'de', 'in@@', 'stru@@', 'ct@@', 'uur', 'van', 'de', 'e@@', 'k@@', 'k@@', 'k@@', 'k@@', 'k@@', 'ap@@', 'pen', 'van', 'onze', 'op@@', 'lo@@', 'b@@', 'ale', 'c@@', 'ont@@', 'wer@@', 'p', '.', '</s>']
2023-05-28 01:30:43,689 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:30:43,689 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:30:43,689 - INFO - joeynmt.training - 	Hypothesis: In de patronen is de instructuur van de ekkkkkappen van onze oplobale contwerp.
2023-05-28 01:30:43,689 - INFO - joeynmt.training - Example #3
2023-05-28 01:30:43,689 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:30:43,689 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:30:43,689 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'aaro@@', 'p', 'hij', 'een', 'sch@@', 'o@@', 'f@@', 'f@@', 'el@@', 'ijk', 'en', 'sch@@', 'ap@@', 'pen', '.', '</s>']
2023-05-28 01:30:43,689 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:30:43,689 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:30:43,690 - INFO - joeynmt.training - 	Hypothesis: Ze waarop hij een schoffelijk en schappen.
2023-05-28 01:30:43,690 - INFO - joeynmt.training - Example #4
2023-05-28 01:30:43,690 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:30:43,690 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:30:43,690 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ol@@', 'ie', ',', 'is', 'een', 'be@@', 'et@@', 'je', 't@@', 'on@@', 'en', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'is', 'ge@@', 'maakt', '.', '</s>']
2023-05-28 01:30:43,690 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:30:43,690 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:30:43,690 - INFO - joeynmt.training - 	Hypothesis: De volgende volie, is een beetje tonen wat er gebeurt in de laatste 25 jaar geleden is gemaakt.
2023-05-28 01:31:06,213 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     1.978300, Batch Acc: 0.393266, Tokens per Sec:     3146, Lr: 0.000300
2023-05-28 01:31:28,370 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     2.222671, Batch Acc: 0.402619, Tokens per Sec:     3233, Lr: 0.000300
2023-05-28 01:31:51,383 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     2.204399, Batch Acc: 0.401449, Tokens per Sec:     3028, Lr: 0.000300
2023-05-28 01:32:14,456 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     2.134108, Batch Acc: 0.410646, Tokens per Sec:     3075, Lr: 0.000300
2023-05-28 01:32:37,868 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     2.099717, Batch Acc: 0.405701, Tokens per Sec:     3052, Lr: 0.000300
2023-05-28 01:32:37,869 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:32:37,869 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:33:44,943 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.18, ppl:   8.83, acc:   0.38, generation: 66.9802[sec], evaluation: 0.0000[sec]
2023-05-28 01:33:44,945 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:33:45,036 - INFO - joeynmt.helpers - delete models/transformer_b/2500.ckpt
2023-05-28 01:33:45,052 - INFO - joeynmt.training - Example #0
2023-05-28 01:33:45,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:33:45,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:33:45,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'oor', 'de', 'jaar', 'gele@@', 'den', 'heb', 'ik', 'deze', 'f@@', 'ol@@', 'i@@', 'ë', ',', 'om', 'de', 't@@', 'hu@@', 'is@@', 'k@@', 'k@@', 'k@@', 'aar@@', 't', ',', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ele@@', 'kt@@', 'es', ',', 'voor', 'drie', 'miljo@@', 'en', 'jaar', 'gele@@', 'den', ',', 'en', 'jaar', 'gele@@', 'den', ',', 'en', 'ongeveer', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'mee@@', 'ste', 'sta@@', 'd', '.', '</s>']
2023-05-28 01:33:45,053 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:33:45,053 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:33:45,053 - INFO - joeynmt.training - 	Hypothesis: Voor de jaar geleden heb ik deze folië, om de thuiskkkaart, voor de artische elektes, voor drie miljoen jaar geleden, en jaar geleden, en ongeveer 40 procent van de meeste stad.
2023-05-28 01:33:45,053 - INFO - joeynmt.training - Example #1
2023-05-28 01:33:45,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:33:45,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:33:45,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', '&@@', 'ap@@', 'o@@', 's@@', ';', 'n', 'be@@', 'sl@@', 'aa@@', 'g@@', 'ste', 'proble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'c@@', 'e', 'proble@@', 'em', '.', '</s>']
2023-05-28 01:33:45,053 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:33:45,054 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:33:45,054 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo 'n beslaagste probleem dat het niet de dice probleem.
2023-05-28 01:33:45,054 - INFO - joeynmt.training - Example #2
2023-05-28 01:33:45,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:33:45,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:33:45,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'aar@@', 'de', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', ',', 'het', 'is', 'de', 'k@@', 'ap@@', 'pen', 'van', 'ons', '.', '</s>']
2023-05-28 01:33:45,054 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:33:45,054 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:33:45,054 - INFO - joeynmt.training - 	Hypothesis: In de aarde is de artische Eiscussie, het is de kappen van ons.
2023-05-28 01:33:45,054 - INFO - joeynmt.training - Example #3
2023-05-28 01:33:45,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:33:45,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:33:45,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ap', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 01:33:45,054 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:33:45,054 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:33:45,054 - INFO - joeynmt.training - 	Hypothesis: Ze wist in de winter en schap in de zomer.
2023-05-28 01:33:45,054 - INFO - joeynmt.training - Example #4
2023-05-28 01:33:45,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:33:45,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:33:45,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ol@@', 'ie', ',', 'de', 'ik', 'zie', 'je', 'een', 'te@@', 'am', ',', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ap', '.', '</s>']
2023-05-28 01:33:45,054 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:33:45,055 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:33:45,055 - INFO - joeynmt.training - 	Hypothesis: De volgende volie, de ik zie je een team, is een tijdschap.
2023-05-28 01:34:08,865 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     1.980902, Batch Acc: 0.410146, Tokens per Sec:     2987, Lr: 0.000300
2023-05-28 01:34:32,760 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     2.211623, Batch Acc: 0.412065, Tokens per Sec:     2974, Lr: 0.000300
2023-05-28 01:34:57,197 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     2.092564, Batch Acc: 0.412907, Tokens per Sec:     2812, Lr: 0.000300
2023-05-28 01:35:20,796 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     2.077645, Batch Acc: 0.411699, Tokens per Sec:     2862, Lr: 0.000300
2023-05-28 01:35:44,711 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     2.310772, Batch Acc: 0.416672, Tokens per Sec:     3031, Lr: 0.000300
2023-05-28 01:35:44,712 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:35:44,712 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:37:00,364 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.13, ppl:   8.42, acc:   0.40, generation: 75.5590[sec], evaluation: 0.0000[sec]
2023-05-28 01:37:00,367 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:37:00,477 - INFO - joeynmt.helpers - delete models/transformer_b/3000.ckpt
2023-05-28 01:37:00,498 - INFO - joeynmt.training - Example #0
2023-05-28 01:37:00,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:37:00,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:37:00,498 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Toen', 'ik', 'deze', 'twee', 'jaar', 'heb', 'ik', 'deze', 'twee', ',', 'om', 'te', 'ver@@', 'lie@@', 'f@@', 'de', ',', 'om', 'te', 'ver@@', 'lie@@', 'f@@', 'de', ',', 'de', 'ar@@', 'ti@@', 'sche', 'ele@@', 'kt@@', 'es', 'van', 'de', 'om@@', 'gev@@', 'ing', ',', 'en', 'ongeveer', 'ongeveer', 'drie', 'miljo@@', 'en', 'jaar', 'gele@@', 'den', ',', 'en', '4@@', '8', 'uur', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 01:37:00,498 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:37:00,498 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:37:00,498 - INFO - joeynmt.training - 	Hypothesis: Toen ik deze twee jaar heb ik deze twee, om te verliefde, om te verliefde, de artische elektes van de omgeving, en ongeveer ongeveer drie miljoen jaar geleden, en 48 uur, om 40 procent van 40 procent.
2023-05-28 01:37:00,498 - INFO - joeynmt.training - Example #1
2023-05-28 01:37:00,499 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:37:00,499 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:37:00,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'goed', 'dat', 'de', 're@@', 'c@@', 'ent', 'van', 'de', 'aar@@', 'de', ',', 'dat', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'c@@', 'tion@@', 'ele', 'proble@@', 'em', 'van', 'het', 'E@@', 'is@@', 'es', '.', '</s>']
2023-05-28 01:37:00,499 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:37:00,499 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:37:00,499 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet goed dat de recent van de aarde, dat is dat het niet de dictionele probleem van het Eises.
2023-05-28 01:37:00,499 - INFO - joeynmt.training - Example #2
2023-05-28 01:37:00,499 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:37:00,499 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:37:00,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'laat@@', 'ste', 's@@', 'inn@@', 'ig', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'li@@', 'ma@@', 'y', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'ale', 'c@@', 'li@@', 'ma@@', 'ss@@', 'a', '.', '</s>']
2023-05-28 01:37:00,499 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:37:00,499 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:37:00,499 - INFO - joeynmt.training - 	Hypothesis: In de laatste sinnig is de artische Eisclimay 's van ons globale climassa.
2023-05-28 01:37:00,499 - INFO - joeynmt.training - Example #3
2023-05-28 01:37:00,499 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:37:00,499 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:37:00,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'het', 'W@@', 'in@@', 'ter', 'en', 'sch@@', 'o@@', 'f@@', 'f@@', 'f@@', 'el@@', 'ijk', '.', '</s>']
2023-05-28 01:37:00,499 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:37:00,500 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:37:00,500 - INFO - joeynmt.training - 	Hypothesis: Ze wist in het Winter en schofffelijk.
2023-05-28 01:37:00,500 - INFO - joeynmt.training - Example #4
2023-05-28 01:37:00,500 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:37:00,500 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:37:00,500 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ol@@', 'ie', ',', 'de', 'vol@@', 'gende', 'v@@', 'ij@@', 'f', ',', 'is', 'een', 'le@@', 'ver@@', 'en', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 01:37:00,500 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:37:00,500 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:37:00,500 - INFO - joeynmt.training - 	Hypothesis: De volgende volie, de volgende vijf, is een leveren in de laatste 25 jaar.
2023-05-28 01:37:22,057 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     2.094312, Batch Acc: 0.424249, Tokens per Sec:     3087, Lr: 0.000300
2023-05-28 01:37:42,834 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     1.951353, Batch Acc: 0.426416, Tokens per Sec:     3384, Lr: 0.000300
2023-05-28 01:38:03,169 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     2.118698, Batch Acc: 0.423431, Tokens per Sec:     3261, Lr: 0.000300
2023-05-28 01:38:23,453 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     2.084260, Batch Acc: 0.426570, Tokens per Sec:     3453, Lr: 0.000300
2023-05-28 01:38:45,019 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     1.884741, Batch Acc: 0.433039, Tokens per Sec:     3319, Lr: 0.000300
2023-05-28 01:38:45,019 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:38:45,019 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:39:51,464 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.09, ppl:   8.05, acc:   0.41, generation: 66.3513[sec], evaluation: 0.0000[sec]
2023-05-28 01:39:51,466 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:39:51,587 - INFO - joeynmt.helpers - delete models/transformer_b/3500.ckpt
2023-05-28 01:39:51,600 - INFO - joeynmt.training - Example #0
2023-05-28 01:39:51,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:39:51,600 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:39:51,600 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'we', 'deze', 'twee', 'v@@', 'al@@', 't', ',', 'om', 'deze', 'twee', 'v@@', 'al@@', 't', 'te', 'ver@@', 'vol@@', 'gens', 'mij', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ten', 'van', 'de', 'aar@@', 's', 'van', 'de', 'hele', 'e@@', 'c@@', 'ten', 'van', '4@@', '0', 'miljo@@', 'en', 'jaar', 'gele@@', 'den', '.', '</s>']
2023-05-28 01:39:51,600 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:39:51,600 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:39:51,601 - INFO - joeynmt.training - 	Hypothesis: Laten we deze twee valt, om deze twee valt te vervolgens mij dat de artische ecten van de aars van de hele ecten van 40 miljoen jaar geleden.
2023-05-28 01:39:51,601 - INFO - joeynmt.training - Example #1
2023-05-28 01:39:51,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:39:51,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:39:51,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 'op@@', 'lo@@', 'ss@@', 'ing', 'van', 'het', 'e@@', 'st@@', 'op@@', 'pen', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'het', 'E@@', 'is@@', 'es', 'niet', 'de', 'di@@', 'ck@@', 'e', 'proble@@', 'em', '.', '</s>']
2023-05-28 01:39:51,601 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:39:51,601 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:39:51,601 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de oplossing van het estoppen van dit speciale probleem van het Eises niet de dicke probleem.
2023-05-28 01:39:51,601 - INFO - joeynmt.training - Example #2
2023-05-28 01:39:51,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:39:51,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:39:51,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'hele', 's@@', 'inn@@', 'en@@', 'kan@@', 't', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'u@@', 'c@@', 'ont@@', 'c@@', 'ul@@', 'a@@', 'ir@@', 'e', 'van', 'onze', 'op@@', 'lo@@', 'b@@', 'ale', 'c@@', 'li@@', 'ma@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 01:39:51,601 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:39:51,601 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:39:51,601 - INFO - joeynmt.training - 	Hypothesis: In de hele sinnenkant is de artische Eiscucontculaire van onze oplobale climasysteem.
2023-05-28 01:39:51,601 - INFO - joeynmt.training - Example #3
2023-05-28 01:39:51,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:39:51,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:39:51,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'het', 'W@@', 'in@@', 'ter', 'en', 'sch@@', 'o@@', 'k@@', 'ken@@', 'nen', 'in', 'het', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 01:39:51,602 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:39:51,602 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:39:51,602 - INFO - joeynmt.training - 	Hypothesis: Ze wist in het Winter en schokkennen in het zomer.
2023-05-28 01:39:51,602 - INFO - joeynmt.training - Example #4
2023-05-28 01:39:51,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:39:51,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:39:51,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'al@@', 't', ',', 'is', 'een', 'te@@', 'ch@@', 'nie@@', 'k', 'die', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd', 'is', '.', '</s>']
2023-05-28 01:39:51,602 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:39:51,602 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:39:51,602 - INFO - joeynmt.training - 	Hypothesis: De volgende valt, is een techniek die laatste 25 jaar gebeurd is.
2023-05-28 01:40:12,761 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     1.908366, Batch Acc: 0.433507, Tokens per Sec:     3326, Lr: 0.000300
2023-05-28 01:40:33,866 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     2.165079, Batch Acc: 0.436512, Tokens per Sec:     3227, Lr: 0.000300
2023-05-28 01:40:54,961 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     1.996884, Batch Acc: 0.434146, Tokens per Sec:     3359, Lr: 0.000300
2023-05-28 01:41:16,082 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     1.936339, Batch Acc: 0.441037, Tokens per Sec:     3406, Lr: 0.000300
2023-05-28 01:41:37,041 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     1.878062, Batch Acc: 0.440819, Tokens per Sec:     3370, Lr: 0.000300
2023-05-28 01:41:37,043 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:41:37,043 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:43:19,242 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.05, ppl:   7.75, acc:   0.42, generation: 102.1009[sec], evaluation: 0.0000[sec]
2023-05-28 01:43:19,244 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:43:19,335 - INFO - joeynmt.helpers - delete models/transformer_b/4000.ckpt
2023-05-28 01:43:19,352 - INFO - joeynmt.training - Example #0
2023-05-28 01:43:19,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:43:19,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:43:19,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'f@@', 'ol@@', 'i@@', 'ë', ',', 'ik', 'deze', 'f@@', 'ol@@', 'i@@', 'ë', ',', 'om', 'te', 'ver@@', 'vol@@', 'gens', 'mij', 'te', 'ver@@', 'sp@@', 'rei@@', 'den', ',', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'ap@@', 'e', ',', 'de', 're@@', 'gel@@', 's', 'van', 'de', 'hele', 'hele', 'hele', 'hele', 'hele', 'hele', 'hele', 'sta@@', 'p', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 01:43:19,352 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:43:19,352 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:43:19,352 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee folië, ik deze folië, om te vervolgens mij te verspreiden, de artische ecapape, de regels van de hele hele hele hele hele hele hele stap, om 40 procent van 40 procent.
2023-05-28 01:43:19,352 - INFO - joeynmt.training - Example #1
2023-05-28 01:43:19,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:43:19,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:43:19,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'dat', 'is', 'niet', 'de', 're@@', 'st', 'van', 'het', 're@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'e@@', 'ven@@', 'o@@', 'on@@', 'en', 'dat', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'is', '.', '</s>']
2023-05-28 01:43:19,353 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:43:19,353 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:43:19,353 - INFO - joeynmt.training - 	Hypothesis: Maar dat dat is niet de rest van het rest van dit speciale probleem van dit evenoonen dat niet de dikke probleem is.
2023-05-28 01:43:19,353 - INFO - joeynmt.training - Example #2
2023-05-28 01:43:19,353 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:43:19,353 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:43:19,353 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'ct@@', 'ie@@', 'us', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'ac@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ul@@', 'ma@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 01:43:19,353 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:43:19,353 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:43:19,353 - INFO - joeynmt.training - 	Hypothesis: In de artische ectieus is de artische ecapactische eculmasysteem.
2023-05-28 01:43:19,353 - INFO - joeynmt.training - Example #3
2023-05-28 01:43:19,353 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:43:19,353 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:43:19,353 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'aa@@', 'st', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'on@@', 'ver@@', 'm@@', 'ij@@', 'nen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 01:43:19,353 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:43:19,353 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:43:19,353 - INFO - joeynmt.training - 	Hypothesis: Ze waast in de winter en schoonvermijnen in de zomer.
2023-05-28 01:43:19,353 - INFO - joeynmt.training - Example #4
2023-05-28 01:43:19,353 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:43:19,353 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:43:19,353 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', ',', 'een', 'kleine', 'kleine', 'kleine', ',', 'een', 'kleine', 'kleine', ',', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 01:43:19,354 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:43:19,354 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:43:19,354 - INFO - joeynmt.training - 	Hypothesis: De volgende volie die ik jullie tonen, een kleine kleine kleine, een kleine kleine, in de laatste 25 jaar gebeurt.
2023-05-28 01:43:40,928 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     2.044002, Batch Acc: 0.446649, Tokens per Sec:     3301, Lr: 0.000300
2023-05-28 01:44:02,887 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     1.987810, Batch Acc: 0.440612, Tokens per Sec:     3195, Lr: 0.000300
2023-05-28 01:44:24,340 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     1.878646, Batch Acc: 0.442784, Tokens per Sec:     3334, Lr: 0.000300
2023-05-28 01:44:45,719 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     2.030443, Batch Acc: 0.448088, Tokens per Sec:     3341, Lr: 0.000300
2023-05-28 01:45:07,548 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     1.833446, Batch Acc: 0.453547, Tokens per Sec:     3303, Lr: 0.000300
2023-05-28 01:45:07,549 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:45:07,549 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:46:17,334 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.02, ppl:   7.51, acc:   0.43, generation: 69.6881[sec], evaluation: 0.0000[sec]
2023-05-28 01:46:17,335 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:46:17,427 - INFO - joeynmt.helpers - delete models/transformer_b/4500.ckpt
2023-05-28 01:46:17,442 - INFO - joeynmt.training - Example #0
2023-05-28 01:46:17,442 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:46:17,442 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:46:17,442 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'dit', 'ge@@', 'zien', 'dat', 'de', 'twee', 'miljo@@', 'en', 'de', 'v@@', 'ol@@', 'ie@@', 'ën', 'om', 'te', 'ver@@', 'lie@@', 'f@@', 'de', 'van', 'de', 'ar@@', 'ti@@', 'sche', 'ele@@', 'kt@@', 'es', ',', 'die', 'voor', 'de', 're@@', 'c@@', 'en@@', 'ten', 'van', 'drie', 'miljo@@', 'en', 'jaar', 'gele@@', 'den', ',', 'de', 'groot@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 01:46:17,442 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:46:17,443 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:46:17,443 - INFO - joeynmt.training - 	Hypothesis: Ik heb dit gezien dat de twee miljoen de volieën om te verliefde van de artische elektes, die voor de recenten van drie miljoen jaar geleden, de grootste 40 procent van 40 procent van 40 procent.
2023-05-28 01:46:17,443 - INFO - joeynmt.training - Example #1
2023-05-28 01:46:17,443 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:46:17,443 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:46:17,443 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', '&@@', 'ap@@', 'o@@', 's@@', ';', 'n', 'be@@', 'per@@', 'kt', 'de', 'aar@@', 'de', ',', 'dat', 'het', 'niet', 'de', 'di@@', 'c@@', 'ellen', 'van', 'het', 'ij@@', 's', 'van', 'het', 'e@@', 'c@@', 'ten', '.', '</s>']
2023-05-28 01:46:17,443 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:46:17,443 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:46:17,443 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo 'n beperkt de aarde, dat het niet de dicellen van het ijs van het ecten.
2023-05-28 01:46:17,443 - INFO - joeynmt.training - Example #2
2023-05-28 01:46:17,443 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:46:17,443 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:46:17,443 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'het', 'gev@@', 'al', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ele@@', 'kt@@', 'ri@@', 'c@@', 'eer@@', 't', 'het', 'sch@@', 'a@@', 'kel@@', 's', 'het', 'mo@@', 'eil@@', 'ijk', 'om', 'te', 'l@@', 'eren', '.', '</s>']
2023-05-28 01:46:17,443 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:46:17,443 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:46:17,443 - INFO - joeynmt.training - 	Hypothesis: In het geval is de artische elektriceert het schakels het moeilijk om te leren.
2023-05-28 01:46:17,443 - INFO - joeynmt.training - Example #3
2023-05-28 01:46:17,443 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:46:17,443 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:46:17,443 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'aa@@', 'st', 'in', 'het', 'w@@', 'ijn', 'in', 'de', 'w@@', 'on@@', 'en', '.', '</s>']
2023-05-28 01:46:17,444 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:46:17,444 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:46:17,444 - INFO - joeynmt.training - 	Hypothesis: Ze waast in het wijn in de wonen.
2023-05-28 01:46:17,444 - INFO - joeynmt.training - Example #4
2023-05-28 01:46:17,444 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:46:17,444 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:46:17,444 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'aar@@', 'dig@@', 'he@@', 'den', ',', 'is', 'een', 'te@@', 'k@@', 'st', ',', 'is', 'een', 'te@@', 'k@@', 'st', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 01:46:17,444 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:46:17,444 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:46:17,444 - INFO - joeynmt.training - 	Hypothesis: De volgende vaardigheden, is een tekst, is een tekst van de laatste 25 jaar gebeurt.
2023-05-28 01:46:40,696 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     1.888888, Batch Acc: 0.445423, Tokens per Sec:     3019, Lr: 0.000300
2023-05-28 01:47:03,654 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     1.968795, Batch Acc: 0.451320, Tokens per Sec:     3073, Lr: 0.000300
2023-05-28 01:47:27,011 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     1.975937, Batch Acc: 0.460073, Tokens per Sec:     3040, Lr: 0.000300
2023-05-28 01:47:50,272 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     1.880822, Batch Acc: 0.444753, Tokens per Sec:     3015, Lr: 0.000300
2023-05-28 01:48:13,119 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     1.962936, Batch Acc: 0.451160, Tokens per Sec:     3155, Lr: 0.000300
2023-05-28 01:48:13,121 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:48:13,121 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:49:25,679 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.30, acc:   0.44, generation: 72.4614[sec], evaluation: 0.0000[sec]
2023-05-28 01:49:25,680 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:49:25,779 - INFO - joeynmt.helpers - delete models/transformer_b/5000.ckpt
2023-05-28 01:49:25,798 - INFO - joeynmt.training - Example #0
2023-05-28 01:49:25,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:49:25,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:49:25,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Toen', 'ik', 'deze', 'twee', 'f@@', 'ol@@', 'ie@@', 'ën', 'ge@@', 'zien', 'dat', 'de', 'v@@', 'al@@', 't', 'van', 'de', 'v@@', 'al@@', 't', 'van', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', ',', 'de', 'drie', 'miljo@@', 'enen', 'jaren', 'de', 're@@', 'den', 'van', 'de', 'groot@@', 'ste', 'van', 'de', 'groot@@', 'ste', 'jaren', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 01:49:25,798 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:49:25,798 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:49:25,798 - INFO - joeynmt.training - 	Hypothesis: Toen ik deze twee folieën gezien dat de valt van de valt van de artische Eiscussie, de drie miljoenen jaren de reden van de grootste van de grootste jaren, om 40 procent van 40 procent.
2023-05-28 01:49:25,798 - INFO - joeynmt.training - Example #1
2023-05-28 01:49:25,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:49:25,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:49:25,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ge@@', 'maakt', ',', 'dat', 'is', 'de', 'aar@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'van', 'het', 'e@@', 'chte', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', '.', '</s>']
2023-05-28 01:49:25,799 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:49:25,799 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:49:25,799 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet gemaakt, dat is de aarde van dit specifieke probleem van het echte probleem, want het is niet.
2023-05-28 01:49:25,799 - INFO - joeynmt.training - Example #2
2023-05-28 01:49:25,799 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:49:25,799 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:49:25,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', 'van', 'onze', 'g@@', 'lo@@', 'b@@', 'ale', 'c@@', 'li@@', 'ma@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 01:49:25,799 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:49:25,799 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:49:25,799 - INFO - joeynmt.training - 	Hypothesis: In de artische Eiscussie is de artische Eiscussie van onze globale climasysteem.
2023-05-28 01:49:25,799 - INFO - joeynmt.training - Example #3
2023-05-28 01:49:25,799 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:49:25,799 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:49:25,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'aa@@', 'st', 'in', 'het', 'W@@', 'in@@', 'ter', 'en', 'sch@@', 'ap@@', 'pen', 'in', 'het', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 01:49:25,801 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:49:25,801 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:49:25,801 - INFO - joeynmt.training - 	Hypothesis: Ze waast in het Winter en schappen in het zomer.
2023-05-28 01:49:25,801 - INFO - joeynmt.training - Example #4
2023-05-28 01:49:25,801 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:49:25,801 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:49:25,801 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ele', 'v@@', 'al@@', 't', ',', 'is', 'een', 'te@@', 'mp@@', 'je', ',', 'is', 'een', 'te@@', 'ff@@', 'er@@', 'ie', 'van', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 01:49:25,802 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:49:25,802 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:49:25,802 - INFO - joeynmt.training - 	Hypothesis: De volgende vele valt, is een tempje, is een tefferie van 25 jaar gebeurt.
2023-05-28 01:49:49,149 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     1.893301, Batch Acc: 0.455311, Tokens per Sec:     3026, Lr: 0.000300
2023-05-28 01:50:11,139 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     1.999582, Batch Acc: 0.454751, Tokens per Sec:     3265, Lr: 0.000300
2023-05-28 01:50:32,447 - INFO - joeynmt.training - Epoch   2, Step:     7800, Batch Loss:     1.863179, Batch Acc: 0.457876, Tokens per Sec:     3317, Lr: 0.000300
2023-05-28 01:50:55,835 - INFO - joeynmt.training - Epoch   2, Step:     7900, Batch Loss:     2.006526, Batch Acc: 0.460211, Tokens per Sec:     3094, Lr: 0.000300
2023-05-28 01:51:17,629 - INFO - joeynmt.training - Epoch   2, Step:     8000, Batch Loss:     1.929262, Batch Acc: 0.460583, Tokens per Sec:     3179, Lr: 0.000300
2023-05-28 01:51:17,631 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:51:17,631 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:52:34,042 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.15, acc:   0.44, generation: 76.3190[sec], evaluation: 0.0000[sec]
2023-05-28 01:52:34,046 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:52:34,148 - INFO - joeynmt.helpers - delete models/transformer_b/5500.ckpt
2023-05-28 01:52:34,163 - INFO - joeynmt.training - Example #0
2023-05-28 01:52:34,163 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:52:34,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:52:34,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'v@@', 'al@@', 't', 'jaar', 'gele@@', 'den', ',', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'ap@@', 'ac@@', 'e', ',', 'die', 'voor', 'de', 're@@', 'c@@', 'l@@', 'aat', ',', 'om', '4@@', '8', 'uur', 'te', 'ver@@', 'wij@@', 'der@@', 'en', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'z@@', 'am@@', 'e', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'ï@@', 'n@@', 'ter@@', 'ess@@', 'eerd', '.', '</s>']
2023-05-28 01:52:34,163 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:52:34,163 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:52:34,163 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee valt jaar geleden, om te verwijderen om te verwijderen dat de artische Eiscapace, die voor de reclaat, om 48 uur te verwijderen, om 40 procent te verzame 40 procent van 40 procent geïnteresseerd.
2023-05-28 01:52:34,163 - INFO - joeynmt.training - Example #1
2023-05-28 01:52:34,163 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:52:34,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:52:34,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'het', 'niet', 'ster@@', 'k', 'genoe@@', 'g', ',', 'dat', 'is', 'het', 'niet', 'de', 'aar@@', 's', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'het', 'E@@', 'is@@', 'es', 'van', 'het', 'E@@', 'is@@', 'es', '.', '</s>']
2023-05-28 01:52:34,164 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:52:34,164 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:52:34,164 - INFO - joeynmt.training - 	Hypothesis: Maar dat is het niet sterk genoeg, dat is het niet de aars van dit speciale probleem van het Eises van het Eises.
2023-05-28 01:52:34,164 - INFO - joeynmt.training - Example #2
2023-05-28 01:52:34,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:52:34,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:52:34,164 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'het', 'gev@@', 'al', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'ap@@', 'ac@@', 't', 'het', 'mo@@', 'eil@@', 'ijk', 'om', 'ons', 'te', 'doen', '.', '</s>']
2023-05-28 01:52:34,164 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:52:34,164 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:52:34,164 - INFO - joeynmt.training - 	Hypothesis: In het geval is de artische eiscapact het moeilijk om ons te doen.
2023-05-28 01:52:34,164 - INFO - joeynmt.training - Example #3
2023-05-28 01:52:34,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:52:34,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:52:34,164 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'aa@@', 'st', 'in', 'het', 'W@@', 'in@@', 'ter', 'en', 'sch@@', 're@@', 'pen', 'in', 'het', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 01:52:34,164 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:52:34,166 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:52:34,166 - INFO - joeynmt.training - 	Hypothesis: Ze waast in het Winter en schrepen in het zomer.
2023-05-28 01:52:34,166 - INFO - joeynmt.training - Example #4
2023-05-28 01:52:34,166 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:52:34,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:52:34,166 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ij@@', 'f', 'van', 'de', 'vol@@', 'gende', 'v@@', 'ij@@', 'f', 'jaar', 'gebeur@@', 't', ',', 'is', 'een', 'te@@', 'ff@@', 'er@@', 'ie', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 01:52:34,166 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:52:34,166 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:52:34,166 - INFO - joeynmt.training - 	Hypothesis: De volgende vijf van de volgende vijf jaar gebeurt, is een tefferie van de laatste 25 jaar.
2023-05-28 01:52:55,820 - INFO - joeynmt.training - Epoch   2, Step:     8100, Batch Loss:     2.002977, Batch Acc: 0.460524, Tokens per Sec:     3264, Lr: 0.000300
2023-05-28 01:53:16,807 - INFO - joeynmt.training - Epoch   2, Step:     8200, Batch Loss:     1.836109, Batch Acc: 0.456996, Tokens per Sec:     3319, Lr: 0.000300
2023-05-28 01:53:38,199 - INFO - joeynmt.training - Epoch   2, Step:     8300, Batch Loss:     1.836456, Batch Acc: 0.463267, Tokens per Sec:     3304, Lr: 0.000300
2023-05-28 01:53:58,965 - INFO - joeynmt.training - Epoch   2, Step:     8400, Batch Loss:     2.004329, Batch Acc: 0.462479, Tokens per Sec:     3432, Lr: 0.000300
2023-05-28 01:54:19,702 - INFO - joeynmt.training - Epoch   2, Step:     8500, Batch Loss:     1.968983, Batch Acc: 0.467285, Tokens per Sec:     3450, Lr: 0.000300
2023-05-28 01:54:19,702 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:54:19,702 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:55:36,798 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.01, acc:   0.44, generation: 77.0000[sec], evaluation: 0.0000[sec]
2023-05-28 01:55:36,801 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:55:36,929 - INFO - joeynmt.helpers - delete models/transformer_b/6000.ckpt
2023-05-28 01:55:36,944 - INFO - joeynmt.training - Example #0
2023-05-28 01:55:36,944 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:55:36,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:55:36,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', ',', 'om', 'de', 'twee', 'jaar', 'te', 'ver@@', 'antwoor@@', 'del@@', 'ijk@@', 'heid', 'te', 'ver@@', 'antwoor@@', 'del@@', 'ijk@@', 'heid', 'te', 'ver@@', 'van@@', 'gen', ',', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'e', ',', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'de', 're@@', 'denen', 'van', 'de', 're@@', 'den', 'van', 'de', 'jaren', '4@@', '0', '.', '</s>']
2023-05-28 01:55:36,944 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:55:36,944 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:55:36,944 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden, om de twee jaar te verantwoordelijkheid te verantwoordelijkheid te vervangen, de artische ecape, de drie miljoen jaar de redenen van de reden van de jaren 40.
2023-05-28 01:55:36,944 - INFO - joeynmt.training - Example #1
2023-05-28 01:55:36,944 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:55:36,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:55:36,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'der@@', 'de', 'niet', 'ster@@', 'k', 'genoe@@', 'g', ',', 'de', 'eerste', 'is', 'dat', 'het', 'niet', 'de', 're@@', 'st@@', 'h@@', 'aa@@', 'm@@', 'd', 'van', 'dit', 'e@@', 'c@@', 'ten', '.', '</s>']
2023-05-28 01:55:36,945 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:55:36,945 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:55:36,945 - INFO - joeynmt.training - 	Hypothesis: Maar dit derde niet sterk genoeg, de eerste is dat het niet de resthaamd van dit ecten.
2023-05-28 01:55:36,945 - INFO - joeynmt.training - Example #2
2023-05-28 01:55:36,945 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:55:36,945 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:55:36,945 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'gev@@', 'al', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ten', 'het', 'mo@@', 'eil@@', 'ijk', 'is', 'het', 'mo@@', 'eil@@', 'ijk', '.', '</s>']
2023-05-28 01:55:36,945 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:55:36,945 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:55:36,945 - INFO - joeynmt.training - 	Hypothesis: In de geval is de artische ecten het moeilijk is het moeilijk.
2023-05-28 01:55:36,945 - INFO - joeynmt.training - Example #3
2023-05-28 01:55:36,945 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:55:36,945 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:55:36,945 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'aa@@', 'st', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'u@@', 'p@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 01:55:36,945 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:55:36,945 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:55:36,945 - INFO - joeynmt.training - 	Hypothesis: Ze waast in de winter en schuppen in de zomer.
2023-05-28 01:55:36,945 - INFO - joeynmt.training - Example #4
2023-05-28 01:55:36,945 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:55:36,945 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:55:36,945 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'al@@', 't', 'van', 'jullie', 't@@', 'oon', 'die', 'ik', 'jullie', 't@@', 'oon', 'zien', ',', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'de', '2@@', '5', 'jaar', 'gebeur@@', 'd', '.', '</s>']
2023-05-28 01:55:36,946 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:55:36,946 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:55:36,946 - INFO - joeynmt.training - 	Hypothesis: De volgende valt van jullie toon die ik jullie toon zien, is een tijdje van de 25 jaar gebeurd.
2023-05-28 01:55:58,013 - INFO - joeynmt.training - Epoch   2, Step:     8600, Batch Loss:     1.614076, Batch Acc: 0.464736, Tokens per Sec:     3320, Lr: 0.000300
2023-05-28 01:56:19,481 - INFO - joeynmt.training - Epoch   2, Step:     8700, Batch Loss:     1.730858, Batch Acc: 0.464333, Tokens per Sec:     3280, Lr: 0.000300
2023-05-28 01:56:41,024 - INFO - joeynmt.training - Epoch   2, Step:     8800, Batch Loss:     2.028146, Batch Acc: 0.463959, Tokens per Sec:     3354, Lr: 0.000300
2023-05-28 01:56:51,351 - INFO - joeynmt.training - Epoch   2: total training loss 8791.32
2023-05-28 01:56:51,352 - INFO - joeynmt.training - EPOCH 3
2023-05-28 01:56:51,382 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=2
2023-05-28 01:57:02,078 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     1.833001, Batch Acc: 0.475109, Tokens per Sec:     3127, Lr: 0.000300
2023-05-28 01:57:23,594 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     1.798633, Batch Acc: 0.474070, Tokens per Sec:     3320, Lr: 0.000300
2023-05-28 01:57:23,594 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 01:57:23,594 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:58:25,738 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.86, acc:   0.45, generation: 62.0532[sec], evaluation: 0.0000[sec]
2023-05-28 01:58:25,740 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 01:58:25,846 - INFO - joeynmt.helpers - delete models/transformer_b/6500.ckpt
2023-05-28 01:58:25,857 - INFO - joeynmt.training - Example #0
2023-05-28 01:58:25,857 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 01:58:25,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 01:58:25,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'f@@', 'eite', 'jaar', 'heb', 'ik', 'deze', 'twee', 'v@@', 'ol@@', 'ie@@', 'ke', 'v@@', 'al@@', 't', ',', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', ',', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'groot@@', 'te', 'van', '4@@', '0', '%', '.', '</s>']
2023-05-28 01:58:25,857 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 01:58:25,857 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 01:58:25,857 - INFO - joeynmt.training - 	Hypothesis: In feite jaar heb ik deze twee volieke valt, dat de artische eiscussie voor de artische eiscussie, en jaar de grootte van de grootte van 40%.
2023-05-28 01:58:25,857 - INFO - joeynmt.training - Example #1
2023-05-28 01:58:25,857 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 01:58:25,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 01:58:25,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'r@@', 'en@@', 'stel@@', 'ijke', 'in@@', 'st@@', 'ro@@', 'om@@', 't', ',', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'proble@@', 'em', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's@@', '-@@', 'e@@', 'is@@', 'es', '.', '</s>']
2023-05-28 01:58:25,858 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 01:58:25,858 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 01:58:25,858 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterrenstelijke instroomt, dat het niet de dicke probleem van het ijs van het ijs-eises.
2023-05-28 01:58:25,858 - INFO - joeynmt.training - Example #2
2023-05-28 01:58:25,858 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 01:58:25,858 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 01:58:25,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'u@@', 'u@@', 'c@@', 'e', 'is', 'het', 'mo@@', 'eil@@', 'ijk', 'om', 'te', 'k@@', 'eren', '.', '</s>']
2023-05-28 01:58:25,858 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 01:58:25,858 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 01:58:25,858 - INFO - joeynmt.training - 	Hypothesis: In de artische eiscuuce is het moeilijk om te keren.
2023-05-28 01:58:25,858 - INFO - joeynmt.training - Example #3
2023-05-28 01:58:25,858 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 01:58:25,858 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 01:58:25,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 're@@', 'ef', 'in', 'de', 's@@', 'om@@', 'er', '.', '</s>']
2023-05-28 01:58:25,858 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 01:58:25,858 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 01:58:25,858 - INFO - joeynmt.training - 	Hypothesis: Ze wist in het winter en schreef in de somer.
2023-05-28 01:58:25,858 - INFO - joeynmt.training - Example #4
2023-05-28 01:58:25,858 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 01:58:25,858 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 01:58:25,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'al@@', 't', 'van', 'de', 'vol@@', 'gende', 'v@@', 'al@@', 't', ',', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ap', '.', '</s>']
2023-05-28 01:58:25,859 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 01:58:25,859 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 01:58:25,859 - INFO - joeynmt.training - 	Hypothesis: De volgende valt van de volgende valt, is een tijdschap.
2023-05-28 01:58:48,081 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     1.780114, Batch Acc: 0.480010, Tokens per Sec:     3146, Lr: 0.000300
2023-05-28 01:59:09,864 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     1.762653, Batch Acc: 0.480055, Tokens per Sec:     3313, Lr: 0.000300
2023-05-28 01:59:30,414 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     1.870918, Batch Acc: 0.477910, Tokens per Sec:     3325, Lr: 0.000300
2023-05-28 01:59:52,853 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     1.826224, Batch Acc: 0.474525, Tokens per Sec:     3162, Lr: 0.000300
2023-05-28 02:00:14,569 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     1.772656, Batch Acc: 0.478849, Tokens per Sec:     3324, Lr: 0.000300
2023-05-28 02:00:14,570 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:00:14,570 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:01:23,860 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.80, acc:   0.45, generation: 69.1931[sec], evaluation: 0.0000[sec]
2023-05-28 02:01:23,862 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:01:23,948 - INFO - joeynmt.helpers - delete models/transformer_b/7000.ckpt
2023-05-28 02:01:23,959 - INFO - joeynmt.training - Example #0
2023-05-28 02:01:23,959 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:01:23,959 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:01:23,959 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'oor', 'de', 'twee', 'v@@', 'ol@@', 'i@@', 'ë', ',', 'en', 'ik', 'heb', 'deze', 'twee', 'v@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', 'van', 'de', 'af@@', 'v@@', 'al', 'drie', 'miljo@@', 'en', 'jaar', 'gele@@', 'den', 'de', 'gr@@', 'on@@', 'd@@', 'w@@', 'is@@', 'kun@@', 'de', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 02:01:23,959 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:01:23,959 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:01:23,959 - INFO - joeynmt.training - 	Hypothesis: Voor de twee volië, en ik heb deze twee volië gezien dat de artische Eiscussie van de afval drie miljoen jaar geleden de grondwiskunde van 40 procent van 40 procent.
2023-05-28 02:01:23,959 - INFO - joeynmt.training - Example #1
2023-05-28 02:01:23,960 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:01:23,960 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:01:23,960 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'zo', '&@@', 'ap@@', 'o@@', 's@@', ';', 'n', 'be@@', 'et@@', 'je', 'de', 'op@@', 'lo@@', 'ss@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 't', '.', '</s>']
2023-05-28 02:01:23,960 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:01:23,960 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:01:23,960 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet zo 'n beetje de oplossing van dit speciale probleem, want het is het niet de dikke ijt.
2023-05-28 02:01:23,960 - INFO - joeynmt.training - Example #2
2023-05-28 02:01:23,960 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:01:23,960 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:01:23,960 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'ap@@', 'e', 'van', 'onze', 'g@@', 'lo@@', 'b@@', 'ale', 'c@@', 'li@@', 'ma@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 02:01:23,960 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:01:23,960 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:01:23,960 - INFO - joeynmt.training - 	Hypothesis: In zeker zin is de artische Eiscape van onze globale climasysteem.
2023-05-28 02:01:23,960 - INFO - joeynmt.training - Example #3
2023-05-28 02:01:23,960 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:01:23,960 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:01:23,960 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 're@@', 'ef', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:01:23,960 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:01:23,960 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:01:23,960 - INFO - joeynmt.training - 	Hypothesis: Ze wist in het winter en schreef in de zomer.
2023-05-28 02:01:23,961 - INFO - joeynmt.training - Example #4
2023-05-28 02:01:23,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:01:23,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:01:23,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'al@@', 't', 'van', 'jullie', ',', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 02:01:23,961 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:01:23,961 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:01:23,961 - INFO - joeynmt.training - 	Hypothesis: De volgende valt van jullie, is een tijdperk van de afgelopen 25 jaar.
2023-05-28 02:01:45,848 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     1.811974, Batch Acc: 0.479632, Tokens per Sec:     3336, Lr: 0.000300
2023-05-28 02:02:07,586 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     1.847807, Batch Acc: 0.484697, Tokens per Sec:     3193, Lr: 0.000300
2023-05-28 02:02:30,362 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     1.780692, Batch Acc: 0.471776, Tokens per Sec:     3086, Lr: 0.000300
2023-05-28 02:02:53,293 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     1.687703, Batch Acc: 0.479340, Tokens per Sec:     3071, Lr: 0.000300
2023-05-28 02:03:16,262 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     1.770591, Batch Acc: 0.481334, Tokens per Sec:     3001, Lr: 0.000300
2023-05-28 02:03:16,263 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:03:16,263 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:04:30,158 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.72, acc:   0.46, generation: 73.7992[sec], evaluation: 0.0000[sec]
2023-05-28 02:04:30,160 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:04:30,261 - INFO - joeynmt.helpers - delete models/transformer_b/7500.ckpt
2023-05-28 02:04:30,274 - INFO - joeynmt.training - Example #0
2023-05-28 02:04:30,274 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:04:30,274 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:04:30,274 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'f@@', 'ou@@', 't', ',', 'ik', 'heb', 'deze', 'twee', 'f@@', 'ou@@', 't', ',', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'e', 'e@@', 'chte', 'e@@', 'chte', 'e@@', 'chte', 'e@@', 'chte', 'e@@', 'chte', 'e@@', 'chte', 'e@@', 'chte', 'e@@', 'chte', 'e@@', 'chte', 're@@', 'e@@', 'ks', 'van', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 02:04:30,275 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:04:30,275 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:04:30,275 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee fout, ik heb deze twee fout, om te bekijken dat de artische eiscusse echte echte echte echte echte echte echte echte echte reeks van 40 procent.
2023-05-28 02:04:30,275 - INFO - joeynmt.training - Example #1
2023-05-28 02:04:30,275 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:04:30,275 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:04:30,275 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'de', 're@@', 'st@@', 'oe@@', 'l', ',', 'omdat', 'het', 'niet', 'de', 'p@@', 'i@@', 'o@@', 'en', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 02:04:30,275 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:04:30,275 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:04:30,275 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet de restoel, omdat het niet de pioen dat het niet de dikke probleem van het ijs van het ijs.
2023-05-28 02:04:30,275 - INFO - joeynmt.training - Example #2
2023-05-28 02:04:30,275 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:04:30,275 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:04:30,275 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'u@@', 'u@@', 'u@@', 'w', 'het', 'mo@@', 'gelijk', 'is', 'het', 'mo@@', 'gelijk', 'om', 'het', 'te', 'be@@', 'stu@@', 'ur@@', 't', '.', '</s>']
2023-05-28 02:04:30,275 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:04:30,275 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:04:30,275 - INFO - joeynmt.training - 	Hypothesis: In de zin is de artische eiscuuuw het mogelijk is het mogelijk om het te bestuurt.
2023-05-28 02:04:30,276 - INFO - joeynmt.training - Example #3
2023-05-28 02:04:30,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:04:30,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:04:30,276 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ein@@', 'ig', 'en', 'sch@@', 'e@@', 'p@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:04:30,276 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:04:30,276 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:04:30,276 - INFO - joeynmt.training - 	Hypothesis: Ze weinig en scheppen in de zomer.
2023-05-28 02:04:30,276 - INFO - joeynmt.training - Example #4
2023-05-28 02:04:30,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:04:30,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:04:30,276 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'enen', ',', 'is', 'een', 'tij@@', 'd@@', 'je', ',', 'is', 'een', 'tij@@', 'd@@', 'je', ',', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 02:04:30,276 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:04:30,276 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:04:30,276 - INFO - joeynmt.training - 	Hypothesis: De volgende dienen, is een tijdje, is een tijdje, is een tijdje in de laatste 25 jaar.
2023-05-28 02:04:53,166 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     1.725215, Batch Acc: 0.478460, Tokens per Sec:     3076, Lr: 0.000300
2023-05-28 02:05:16,012 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     1.925955, Batch Acc: 0.480032, Tokens per Sec:     3215, Lr: 0.000300
2023-05-28 02:05:38,808 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     1.946685, Batch Acc: 0.479768, Tokens per Sec:     3018, Lr: 0.000300
2023-05-28 02:06:02,088 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     1.771840, Batch Acc: 0.480000, Tokens per Sec:     2997, Lr: 0.000300
2023-05-28 02:06:23,279 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     1.967070, Batch Acc: 0.482947, Tokens per Sec:     3349, Lr: 0.000300
2023-05-28 02:06:23,280 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:06:23,280 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:07:34,286 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.60, acc:   0.46, generation: 70.9154[sec], evaluation: 0.0000[sec]
2023-05-28 02:07:34,287 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:07:34,386 - INFO - joeynmt.helpers - delete models/transformer_b/8000.ckpt
2023-05-28 02:07:34,399 - INFO - joeynmt.training - Example #0
2023-05-28 02:07:34,399 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:07:34,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:07:34,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'v@@', 'ol@@', 'ie@@', 'ën', 'ge@@', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', 'is', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'ap@@', 'e', 'ele@@', 'kt@@', 'es', 'van', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'V@@', 'S', '.', '</s>']
2023-05-28 02:07:34,399 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:07:34,399 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:07:34,399 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee volieën gezien dat de artische eiscussie is dat de artische eiscape elektes van drie miljoen jaar de grootte van de grootte van de grootte van de VS.
2023-05-28 02:07:34,400 - INFO - joeynmt.training - Example #1
2023-05-28 02:07:34,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:07:34,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:07:34,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 'uit@@', 'st@@', 'ij@@', 'l', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', '.', '</s>']
2023-05-28 02:07:34,400 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:07:34,400 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:07:34,400 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de uitstijl van dit speciale probleem van dit speciale probleem.
2023-05-28 02:07:34,400 - INFO - joeynmt.training - Example #2
2023-05-28 02:07:34,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:07:34,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:07:34,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', '.', '</s>']
2023-05-28 02:07:34,400 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:07:34,400 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:07:34,400 - INFO - joeynmt.training - 	Hypothesis: In de artische eiscussie is de artische eiscussie.
2023-05-28 02:07:34,400 - INFO - joeynmt.training - Example #3
2023-05-28 02:07:34,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:07:34,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:07:34,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ap@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:07:34,400 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:07:34,400 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:07:34,401 - INFO - joeynmt.training - 	Hypothesis: Ze wist in de winter en schappen in de zomer.
2023-05-28 02:07:34,401 - INFO - joeynmt.training - Example #4
2023-05-28 02:07:34,401 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:07:34,401 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:07:34,401 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'enen', 'van', 'de', 'vol@@', 'gende', 'di@@', 'a', ',', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 02:07:34,401 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:07:34,401 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:07:34,401 - INFO - joeynmt.training - 	Hypothesis: De volgende dienen van de volgende dia, is een tijdperk van wat er gebeurt in de afgelopen 25 jaar.
2023-05-28 02:07:56,538 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     1.930413, Batch Acc: 0.482054, Tokens per Sec:     3199, Lr: 0.000300
2023-05-28 02:08:17,993 - INFO - joeynmt.training - Epoch   3, Step:    10700, Batch Loss:     1.931199, Batch Acc: 0.482901, Tokens per Sec:     3258, Lr: 0.000300
2023-05-28 02:08:40,880 - INFO - joeynmt.training - Epoch   3, Step:    10800, Batch Loss:     1.815911, Batch Acc: 0.487608, Tokens per Sec:     2983, Lr: 0.000300
2023-05-28 02:09:02,124 - INFO - joeynmt.training - Epoch   3, Step:    10900, Batch Loss:     1.738841, Batch Acc: 0.487653, Tokens per Sec:     3445, Lr: 0.000300
2023-05-28 02:09:23,541 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     1.704700, Batch Acc: 0.488276, Tokens per Sec:     3380, Lr: 0.000300
2023-05-28 02:09:23,543 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:09:23,543 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:10:42,420 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.52, acc:   0.46, generation: 78.7827[sec], evaluation: 0.0000[sec]
2023-05-28 02:10:42,422 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:10:42,521 - INFO - joeynmt.helpers - delete models/transformer_b/8500.ckpt
2023-05-28 02:10:42,535 - INFO - joeynmt.training - Example #0
2023-05-28 02:10:42,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:10:42,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:10:42,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'een', 'jaar', 'gele@@', 'den', 'had', 'ik', 'deze', 'twee', 'v@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'ond', ',', 'om', 'te', 'ver@@', 'zoe@@', 'ken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'ap@@', 'e', ',', 'die', 'voor', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'St@@', 'aten', ',', 'die', 'de', 'groot@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'groot@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 02:10:42,536 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:10:42,536 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:10:42,536 - INFO - joeynmt.training - 	Hypothesis: Ik heb een jaar geleden had ik deze twee volië getoond, om te verzoeken dat de artische eiscape, die voor de Verenigde Staten, die de grootste 40 procent van de grootste 40 procent van 40 procent.
2023-05-28 02:10:42,536 - INFO - joeynmt.training - Example #1
2023-05-28 02:10:42,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:10:42,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:10:42,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 'aar@@', 'de', 'van', 'de', 'aar@@', 'de', 'van', 'deze', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'uit', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'im@@', 'p@@', 'el', '.', '</s>']
2023-05-28 02:10:42,536 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:10:42,536 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:10:42,536 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de aarde van de aarde van deze speciale problemen uit, want het is het niet de dikke van de ijsimpel.
2023-05-28 02:10:42,536 - INFO - joeynmt.training - Example #2
2023-05-28 02:10:42,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:10:42,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:10:42,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'ap@@', 'e', 'het', 'is', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'har@@', 't', 'van', 'de', 'hele', 'wereld', '.', '</s>']
2023-05-28 02:10:42,536 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:10:42,536 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:10:42,536 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische eiscape het is van onze wereldwijde hart van de hele wereld.
2023-05-28 02:10:42,536 - INFO - joeynmt.training - Example #3
2023-05-28 02:10:42,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:10:42,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:10:42,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ap@@', 'pen', 'in', 'de', 'win@@', 'ter', '.', '</s>']
2023-05-28 02:10:42,537 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:10:42,537 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:10:42,537 - INFO - joeynmt.training - 	Hypothesis: Ze wist in het winter en schappen in de winter.
2023-05-28 02:10:42,537 - INFO - joeynmt.training - Example #4
2023-05-28 02:10:42,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:10:42,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:10:42,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'zien', ',', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 02:10:42,537 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:10:42,537 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:10:42,537 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie zien, is een tijdperk van de laatste 25 jaar.
2023-05-28 02:11:04,909 - INFO - joeynmt.training - Epoch   3, Step:    11100, Batch Loss:     1.567995, Batch Acc: 0.486538, Tokens per Sec:     3166, Lr: 0.000300
2023-05-28 02:11:25,990 - INFO - joeynmt.training - Epoch   3, Step:    11200, Batch Loss:     1.830077, Batch Acc: 0.483374, Tokens per Sec:     3458, Lr: 0.000300
2023-05-28 02:11:48,099 - INFO - joeynmt.training - Epoch   3, Step:    11300, Batch Loss:     1.908767, Batch Acc: 0.490422, Tokens per Sec:     3294, Lr: 0.000300
2023-05-28 02:12:10,991 - INFO - joeynmt.training - Epoch   3, Step:    11400, Batch Loss:     1.588248, Batch Acc: 0.485692, Tokens per Sec:     3123, Lr: 0.000300
2023-05-28 02:12:32,452 - INFO - joeynmt.training - Epoch   3, Step:    11500, Batch Loss:     1.797570, Batch Acc: 0.492759, Tokens per Sec:     3224, Lr: 0.000300
2023-05-28 02:12:32,452 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:12:32,452 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:13:41,512 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.43, acc:   0.47, generation: 68.9658[sec], evaluation: 0.0000[sec]
2023-05-28 02:13:41,513 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:13:41,615 - INFO - joeynmt.helpers - delete models/transformer_b/9000.ckpt
2023-05-28 02:13:41,629 - INFO - joeynmt.training - Example #0
2023-05-28 02:13:41,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:13:41,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:13:41,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'een', 'jaar', 'gele@@', 'den', 'ik', 'deze', 'twee', 'v@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'ond', ',', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'app@@', 'ar@@', 'aat', ',', 'de', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'app@@', 'ar@@', 'aat', ',', 'die', 'voor', 'de', 'groot@@', 'te', 'van', '4@@', '0', 'proc@@', 'ent', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 02:13:41,630 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:13:41,630 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:13:41,630 - INFO - joeynmt.training - 	Hypothesis: Ik heb een jaar geleden ik deze twee volië getoond, de artische ecapparaat, de voor de artische ecapparaat, die voor de grootte van 40 procent, om 40 procent van 40 procent.
2023-05-28 02:13:41,630 - INFO - joeynmt.training - Example #1
2023-05-28 02:13:41,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:13:41,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:13:41,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'der@@', 'de', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'in@@', 'st@@', 'st@@', 'ri@@', 'v@@', 'ier@@', 'kan@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'c@@', 'e', 'van', 'het', 'ij@@', 's@@', 'im@@', 'p@@', 'el@@', 's', '.', '</s>']
2023-05-28 02:13:41,630 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:13:41,630 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:13:41,630 - INFO - joeynmt.training - 	Hypothesis: Maar dit derde niet sterk genoeg de eerste inststrivierkant van dit speciale probleem, omdat het niet de dice van het ijsimpels.
2023-05-28 02:13:41,630 - INFO - joeynmt.training - Example #2
2023-05-28 02:13:41,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:13:41,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:13:41,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'app@@', 'e', 'dat', 'het', 'mo@@', 'gelijk', 'is', 'het', 'mo@@', 'gelijk', 'de', 'mo@@', 'gelijk@@', 'heid', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'ale', 'syste@@', 'em', '.', '</s>']
2023-05-28 02:13:41,630 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:13:41,630 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:13:41,630 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ecappe dat het mogelijk is het mogelijk de mogelijkheid van ons globale systeem.
2023-05-28 02:13:41,630 - INFO - joeynmt.training - Example #3
2023-05-28 02:13:41,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:13:41,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:13:41,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'enen', 'in', 'het', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:13:41,631 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:13:41,631 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:13:41,631 - INFO - joeynmt.training - 	Hypothesis: Ze wist in het winter en schoenen in het zomer.
2023-05-28 02:13:41,631 - INFO - joeynmt.training - Example #4
2023-05-28 02:13:41,631 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:13:41,631 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:13:41,631 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ij@@', 'f', 'van', 'jullie', 'zien', ',', 'is', 'een', 'te@@', 'ff@@', 'er@@', 'op@@', 'nam@@', 'e', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 02:13:41,631 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:13:41,631 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:13:41,631 - INFO - joeynmt.training - 	Hypothesis: De volgende vijf van jullie zien, is een tefferopname van de laatste 25 jaar gebeurt.
2023-05-28 02:14:04,479 - INFO - joeynmt.training - Epoch   3, Step:    11600, Batch Loss:     1.806074, Batch Acc: 0.488364, Tokens per Sec:     3055, Lr: 0.000300
2023-05-28 02:14:27,230 - INFO - joeynmt.training - Epoch   3, Step:    11700, Batch Loss:     1.821582, Batch Acc: 0.494096, Tokens per Sec:     3075, Lr: 0.000300
2023-05-28 02:14:49,766 - INFO - joeynmt.training - Epoch   3, Step:    11800, Batch Loss:     1.710070, Batch Acc: 0.487996, Tokens per Sec:     3179, Lr: 0.000300
2023-05-28 02:15:12,740 - INFO - joeynmt.training - Epoch   3, Step:    11900, Batch Loss:     1.670757, Batch Acc: 0.489836, Tokens per Sec:     3088, Lr: 0.000300
2023-05-28 02:15:35,474 - INFO - joeynmt.training - Epoch   3, Step:    12000, Batch Loss:     1.550731, Batch Acc: 0.496752, Tokens per Sec:     3115, Lr: 0.000300
2023-05-28 02:15:35,476 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:15:35,476 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:16:36,382 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.34, acc:   0.47, generation: 60.8114[sec], evaluation: 0.0000[sec]
2023-05-28 02:16:36,383 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:16:36,490 - INFO - joeynmt.helpers - delete models/transformer_b/9500.ckpt
2023-05-28 02:16:36,505 - INFO - joeynmt.training - Example #0
2023-05-28 02:16:36,505 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:16:36,505 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:16:36,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'f@@', 'ou@@', 't', 'jaar', 'gele@@', 'den', ',', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'ac@@', 'c@@', 'ap@@', 'ac@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'e', ',', 'die', 'voor', 'de', 're@@', 'c@@', 'en@@', 'te', 'zijn', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'c@@', 'en@@', 'te', 'van', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 02:16:36,506 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:16:36,506 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:16:36,506 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee fout jaar geleden, om te zien dat de artische ecapaccapactische ecape, die voor de recente zijn, om 40 procent van de recente van 40 procent.
2023-05-28 02:16:36,506 - INFO - joeynmt.training - Example #1
2023-05-28 02:16:36,506 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:16:36,506 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:16:36,506 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'uit@@', 'st@@', 'and@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'van', 'het', 'ij@@', 's@@', 'heid', 'van', 'het', 'ij@@', 's@@', 's@@', 's@@', 'el', '.', '</s>']
2023-05-28 02:16:36,506 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:16:36,506 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:16:36,506 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de uitstandheid van dit specifieke probleem van het ijsheid van het ijsssel.
2023-05-28 02:16:36,506 - INFO - joeynmt.training - Example #2
2023-05-28 02:16:36,506 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:16:36,506 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:16:36,506 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker', 'is', 'het', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'e', 'het', 'sch@@', 'o@@', 'k@@', 'app@@', 'e', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', '.', '</s>']
2023-05-28 02:16:36,507 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:16:36,507 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:16:36,507 - INFO - joeynmt.training - 	Hypothesis: In zeker is het artische ecape het schokappe van onze wereldwijd.
2023-05-28 02:16:36,507 - INFO - joeynmt.training - Example #3
2023-05-28 02:16:36,507 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:16:36,507 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:16:36,507 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'on@@', 'en', 'het', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:16:36,507 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:16:36,507 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:16:36,507 - INFO - joeynmt.training - 	Hypothesis: Ze wonen het zomer.
2023-05-28 02:16:36,507 - INFO - joeynmt.training - Example #4
2023-05-28 02:16:36,507 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:16:36,507 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:16:36,507 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ou@@', 't', ',', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', ',', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 02:16:36,507 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:16:36,507 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:16:36,507 - INFO - joeynmt.training - 	Hypothesis: De volgende fout, is een tijdperk, is een tijdperk van de laatste 25 jaar.
2023-05-28 02:16:58,750 - INFO - joeynmt.training - Epoch   3, Step:    12100, Batch Loss:     1.777490, Batch Acc: 0.492836, Tokens per Sec:     3139, Lr: 0.000300
2023-05-28 02:17:22,435 - INFO - joeynmt.training - Epoch   3, Step:    12200, Batch Loss:     1.764655, Batch Acc: 0.497067, Tokens per Sec:     3067, Lr: 0.000300
2023-05-28 02:17:46,071 - INFO - joeynmt.training - Epoch   3, Step:    12300, Batch Loss:     1.889175, Batch Acc: 0.492573, Tokens per Sec:     3071, Lr: 0.000300
2023-05-28 02:18:09,910 - INFO - joeynmt.training - Epoch   3, Step:    12400, Batch Loss:     1.827801, Batch Acc: 0.495260, Tokens per Sec:     2854, Lr: 0.000300
2023-05-28 02:18:31,741 - INFO - joeynmt.training - Epoch   3, Step:    12500, Batch Loss:     1.696643, Batch Acc: 0.499556, Tokens per Sec:     3251, Lr: 0.000300
2023-05-28 02:18:31,743 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:18:31,743 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:19:41,701 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.27, acc:   0.48, generation: 69.8631[sec], evaluation: 0.0000[sec]
2023-05-28 02:19:41,704 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:19:41,799 - INFO - joeynmt.helpers - delete models/transformer_b/10000.ckpt
2023-05-28 02:19:41,810 - INFO - joeynmt.training - Example #0
2023-05-28 02:19:41,810 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:19:41,810 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:19:41,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'oor', 'dit', 'twee', 'jaar', 'heb', 'ik', 'deze', 'twee', 'f@@', 'ou@@', 't', ',', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'ing', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'ap@@', 'ac@@', 't', ',', 'de', 'groot@@', 'ste', 'van', 'de', 'V@@', 'S', ',', 'de', 'groot@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'groot@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'V@@', 'S', '.', '</s>']
2023-05-28 02:19:41,811 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:19:41,811 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:19:41,811 - INFO - joeynmt.training - 	Hypothesis: Voor dit twee jaar heb ik deze twee fout, om te verwijdering te verwijderen dat de artische eiscapact, de grootste van de VS, de grootste 40 procent van de grootste 40 procent van de VS.
2023-05-28 02:19:41,811 - INFO - joeynmt.training - Example #1
2023-05-28 02:19:41,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:19:41,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:19:41,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'der@@', 'de', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'aar@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'ë@@', 'le', 'proble@@', 'em', 'uit', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 02:19:41,811 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:19:41,811 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:19:41,811 - INFO - joeynmt.training - 	Hypothesis: Maar dit derde niet sterk genoeg de aarde van dit speciële probleem uit, omdat het niet de dikke dikke van het ijs.
2023-05-28 02:19:41,811 - INFO - joeynmt.training - Example #2
2023-05-28 02:19:41,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:19:41,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:19:41,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'mo@@', 'gelijk', 'is', 'om', 'het', 'werel@@', 'd@@', 'wij@@', 'd', 'te', 'zien', '.', '</s>']
2023-05-28 02:19:41,812 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:19:41,812 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:19:41,812 - INFO - joeynmt.training - 	Hypothesis: In zeker zin is de artische ijskappen het mogelijk is om het wereldwijd te zien.
2023-05-28 02:19:41,812 - INFO - joeynmt.training - Example #3
2023-05-28 02:19:41,812 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:19:41,812 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:19:41,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'rij@@', 'ver', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:19:41,812 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:19:41,812 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:19:41,812 - INFO - joeynmt.training - 	Hypothesis: Ze wist in het winter en schrijver in de zomer.
2023-05-28 02:19:41,812 - INFO - joeynmt.training - Example #4
2023-05-28 02:19:41,812 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:19:41,812 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:19:41,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ou@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', ',', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 02:19:41,812 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:19:41,812 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:19:41,812 - INFO - joeynmt.training - 	Hypothesis: De volgende fouie die ik jullie tonen, is een tijdperk van de laatste 25 jaar gebeurt.
2023-05-28 02:20:03,859 - INFO - joeynmt.training - Epoch   3, Step:    12600, Batch Loss:     1.854055, Batch Acc: 0.490799, Tokens per Sec:     3034, Lr: 0.000300
2023-05-28 02:20:26,184 - INFO - joeynmt.training - Epoch   3, Step:    12700, Batch Loss:     1.613592, Batch Acc: 0.498803, Tokens per Sec:     3238, Lr: 0.000300
2023-05-28 02:20:49,675 - INFO - joeynmt.training - Epoch   3, Step:    12800, Batch Loss:     1.707204, Batch Acc: 0.488751, Tokens per Sec:     2948, Lr: 0.000300
2023-05-28 02:21:10,841 - INFO - joeynmt.training - Epoch   3, Step:    12900, Batch Loss:     1.750471, Batch Acc: 0.499921, Tokens per Sec:     3275, Lr: 0.000300
2023-05-28 02:21:33,009 - INFO - joeynmt.training - Epoch   3, Step:    13000, Batch Loss:     1.633033, Batch Acc: 0.500501, Tokens per Sec:     3198, Lr: 0.000300
2023-05-28 02:21:33,010 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:21:33,010 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:22:28,588 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.27, acc:   0.47, generation: 55.4868[sec], evaluation: 0.0000[sec]
2023-05-28 02:22:28,589 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:22:28,683 - INFO - joeynmt.helpers - delete models/transformer_b/10500.ckpt
2023-05-28 02:22:28,698 - INFO - joeynmt.training - Example #0
2023-05-28 02:22:28,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:22:28,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:22:28,698 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'an', 'de', 'twee', 'van', 'de', 'c@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'ond', 'om', 'te', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'e', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'van', 'de', 'grote', '.', '</s>']
2023-05-28 02:22:28,698 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:22:28,698 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:22:28,699 - INFO - joeynmt.training - 	Hypothesis: Van de twee van de colië getoond om te kijken dat de artische ecape Eiskappe Eiskappe van de grote.
2023-05-28 02:22:28,699 - INFO - joeynmt.training - Example #1
2023-05-28 02:22:28,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:22:28,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:22:28,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 'uit@@', 'z@@', 'onder@@', 'lijk', 'genoe@@', 'g', 'de', 'A@@', 'n@@', 'st@@', 'ri@@', 'v@@', 'iteit', 'van', 'dit', 'spe@@', 'ci@@', 'ë@@', 'le', 'proble@@', 'em', ',', 'omdat', 'het', 'het', 'het', 'ij@@', 's@@', '-@@', 'd@@', 'es', 'van', 'het', 'ij@@', 's@@', 'el', '.', '</s>']
2023-05-28 02:22:28,699 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:22:28,699 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:22:28,699 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de uitzonderlijk genoeg de Anstriviteit van dit speciële probleem, omdat het het het ijs-des van het ijsel.
2023-05-28 02:22:28,699 - INFO - joeynmt.training - Example #2
2023-05-28 02:22:28,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:22:28,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:22:28,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'mo@@', 'gelijk', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'd', '.', '</s>']
2023-05-28 02:22:28,699 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:22:28,699 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:22:28,699 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het mogelijk van ons wereldwijd.
2023-05-28 02:22:28,699 - INFO - joeynmt.training - Example #3
2023-05-28 02:22:28,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:22:28,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:22:28,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ap@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:22:28,700 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:22:28,702 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:22:28,702 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en schappen in de zomer.
2023-05-28 02:22:28,702 - INFO - joeynmt.training - Example #4
2023-05-28 02:22:28,702 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:22:28,702 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:22:28,702 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'enen', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', ',', 'is', 'een', 'te@@', 'ff@@', 'er@@', 'ie', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 02:22:28,703 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:22:28,703 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:22:28,703 - INFO - joeynmt.training - 	Hypothesis: De volgende dienen die ik jullie tonen, is een tefferie van de laatste 25 jaar.
2023-05-28 02:22:49,439 - INFO - joeynmt.training - Epoch   3, Step:    13100, Batch Loss:     1.716669, Batch Acc: 0.493965, Tokens per Sec:     3302, Lr: 0.000300
2023-05-28 02:23:12,023 - INFO - joeynmt.training - Epoch   3, Step:    13200, Batch Loss:     1.726829, Batch Acc: 0.498677, Tokens per Sec:     3181, Lr: 0.000300
2023-05-28 02:23:28,412 - INFO - joeynmt.training - Epoch   3: total training loss 7957.12
2023-05-28 02:23:28,412 - INFO - joeynmt.training - EPOCH 4
2023-05-28 02:23:28,440 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=3
2023-05-28 02:23:32,220 - INFO - joeynmt.training - Epoch   4, Step:    13300, Batch Loss:     1.835773, Batch Acc: 0.497836, Tokens per Sec:     3155, Lr: 0.000300
2023-05-28 02:23:53,385 - INFO - joeynmt.training - Epoch   4, Step:    13400, Batch Loss:     1.764951, Batch Acc: 0.506289, Tokens per Sec:     3324, Lr: 0.000300
2023-05-28 02:24:14,053 - INFO - joeynmt.training - Epoch   4, Step:    13500, Batch Loss:     1.772942, Batch Acc: 0.501987, Tokens per Sec:     3397, Lr: 0.000300
2023-05-28 02:24:14,054 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:24:14,054 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:25:11,946 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.19, acc:   0.48, generation: 57.8013[sec], evaluation: 0.0000[sec]
2023-05-28 02:25:11,947 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:25:12,033 - INFO - joeynmt.helpers - delete models/transformer_b/11000.ckpt
2023-05-28 02:25:12,047 - INFO - joeynmt.training - Example #0
2023-05-28 02:25:12,047 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:25:12,047 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:25:12,047 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'v@@', 'ele', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'kijken', 'naar', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'k@@', 'app@@', 'ar@@', 'aten', ',', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'k@@', 'app@@', 'ar@@', 'aten', 'die', 'voor', 'de', 'onder@@', 'wij@@', 's', 'van', '4@@', '0', '%', '.', '</s>']
2023-05-28 02:25:12,048 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:25:12,048 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:25:12,048 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee vele dia getoond om te kijken naar de artische eiskapparaten, dat de artische eiskapparaten die voor de onderwijs van 40%.
2023-05-28 02:25:12,048 - INFO - joeynmt.training - Example #1
2023-05-28 02:25:12,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:25:12,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:25:12,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'der@@', 'de', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'aar@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ën', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'l@@', 't', '.', '</s>']
2023-05-28 02:25:12,048 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:25:12,048 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:25:12,048 - INFO - joeynmt.training - 	Hypothesis: Maar dat derde niet sterk genoeg de aarde van dit specifieën, want het is het niet de dikke dikke van het ijslt.
2023-05-28 02:25:12,048 - INFO - joeynmt.training - Example #2
2023-05-28 02:25:12,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:25:12,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:25:12,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'k@@', 'app@@', 'el@@', 'ijke', 'd@@', 'oe@@', 'l', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', '.', '</s>']
2023-05-28 02:25:12,048 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:25:12,048 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:25:12,048 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische eiskappelijke doel van onze wereldwijd.
2023-05-28 02:25:12,049 - INFO - joeynmt.training - Example #3
2023-05-28 02:25:12,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:25:12,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:25:12,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'p@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:25:12,049 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:25:12,049 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:25:12,049 - INFO - joeynmt.training - 	Hypothesis: Ze wist in het winter en schruppen in de zomer.
2023-05-28 02:25:12,049 - INFO - joeynmt.training - Example #4
2023-05-28 02:25:12,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:25:12,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:25:12,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'oon', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 02:25:12,049 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:25:12,049 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:25:12,049 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie toon tonen is een tijdperk van de laatste 25 jaar.
2023-05-28 02:25:33,375 - INFO - joeynmt.training - Epoch   4, Step:    13600, Batch Loss:     1.582188, Batch Acc: 0.506152, Tokens per Sec:     3341, Lr: 0.000300
2023-05-28 02:25:54,004 - INFO - joeynmt.training - Epoch   4, Step:    13700, Batch Loss:     1.860995, Batch Acc: 0.510188, Tokens per Sec:     3407, Lr: 0.000300
2023-05-28 02:26:16,069 - INFO - joeynmt.training - Epoch   4, Step:    13800, Batch Loss:     1.742805, Batch Acc: 0.501872, Tokens per Sec:     3050, Lr: 0.000300
2023-05-28 02:26:38,502 - INFO - joeynmt.training - Epoch   4, Step:    13900, Batch Loss:     1.559978, Batch Acc: 0.507133, Tokens per Sec:     3178, Lr: 0.000300
2023-05-28 02:27:00,050 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     1.764325, Batch Acc: 0.512398, Tokens per Sec:     3210, Lr: 0.000300
2023-05-28 02:27:00,051 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:27:00,051 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:28:06,334 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.14, acc:   0.48, generation: 66.1902[sec], evaluation: 0.0000[sec]
2023-05-28 02:28:06,336 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:28:06,454 - INFO - joeynmt.helpers - delete models/transformer_b/11500.ckpt
2023-05-28 02:28:06,467 - INFO - joeynmt.training - Example #0
2023-05-28 02:28:06,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:28:06,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:28:06,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'an', 'de', 'twee', 'f@@', 'ol@@', 'ie@@', 'ën', ',', 'om', 'te', 'ver@@', 'tro@@', 'uw@@', 'en', 'om', 'te', 'ver@@', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'e', 'E@@', 'is@@', 'c@@', 'ap@@', 'e', ',', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'had', 'de', 're@@', 'eu@@', 'w@@', 'en', 'van', 'de', 'groot@@', 'ste', 'jaren', ',', '4@@', '0', '.', '</s>']
2023-05-28 02:28:06,468 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:28:06,468 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:28:06,468 - INFO - joeynmt.training - 	Hypothesis: Van de twee folieën, om te vertrouwen om te verbekijken dat de artische ecape Eiscape, de drie miljoen jaar had de reeuwen van de grootste jaren, 40.
2023-05-28 02:28:06,468 - INFO - joeynmt.training - Example #1
2023-05-28 02:28:06,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:28:06,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:28:06,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'der@@', 'gel@@', 'ijke', 'proble@@', 'em', 'is', 'de', 'eerste', 'eerste', 'n@@', 'i@@', 've@@', 'au', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'men', 'uit', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ijk', '.', '</s>']
2023-05-28 02:28:06,468 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:28:06,468 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:28:06,468 - INFO - joeynmt.training - 	Hypothesis: Maar dit dergelijke probleem is de eerste eerste niveau van dit specifieke problemen uit, want het is het niet de dikke van het ijskijk.
2023-05-28 02:28:06,468 - INFO - joeynmt.training - Example #2
2023-05-28 02:28:06,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:28:06,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:28:06,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 02:28:06,468 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:28:06,468 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:28:06,468 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape van onze wereldwijde klimaatsysteem.
2023-05-28 02:28:06,468 - INFO - joeynmt.training - Example #3
2023-05-28 02:28:06,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:28:06,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:28:06,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'aa@@', 'st', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:28:06,469 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:28:06,469 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:28:06,469 - INFO - joeynmt.training - 	Hypothesis: Ze waast in het winter en schrompen in de zomer.
2023-05-28 02:28:06,469 - INFO - joeynmt.training - Example #4
2023-05-28 02:28:06,469 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:28:06,469 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:28:06,469 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'kom@@', 'ende', 'di@@', 're@@', 'ct', 'die', 'ik', 'jullie', 't@@', 'oon', 't@@', 'oon', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'ende', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 02:28:06,469 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:28:06,469 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:28:06,469 - INFO - joeynmt.training - 	Hypothesis: De komende direct die ik jullie toon toon is een tijdtrafferende 25 jaar.
2023-05-28 02:28:29,309 - INFO - joeynmt.training - Epoch   4, Step:    14100, Batch Loss:     1.599144, Batch Acc: 0.507303, Tokens per Sec:     3102, Lr: 0.000300
2023-05-28 02:28:52,612 - INFO - joeynmt.training - Epoch   4, Step:    14200, Batch Loss:     1.704217, Batch Acc: 0.505460, Tokens per Sec:     3049, Lr: 0.000300
2023-05-28 02:29:15,067 - INFO - joeynmt.training - Epoch   4, Step:    14300, Batch Loss:     1.634510, Batch Acc: 0.501522, Tokens per Sec:     3160, Lr: 0.000300
2023-05-28 02:29:37,563 - INFO - joeynmt.training - Epoch   4, Step:    14400, Batch Loss:     1.610547, Batch Acc: 0.513911, Tokens per Sec:     3068, Lr: 0.000300
2023-05-28 02:30:00,441 - INFO - joeynmt.training - Epoch   4, Step:    14500, Batch Loss:     1.342048, Batch Acc: 0.507854, Tokens per Sec:     3044, Lr: 0.000300
2023-05-28 02:30:00,442 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:30:00,442 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:31:14,297 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.10, acc:   0.48, generation: 73.7574[sec], evaluation: 0.0000[sec]
2023-05-28 02:31:14,299 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:31:14,422 - INFO - joeynmt.helpers - delete models/transformer_b/12000.ckpt
2023-05-28 02:31:14,438 - INFO - joeynmt.training - Example #0
2023-05-28 02:31:14,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:31:14,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:31:14,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'et@@', 'te', 'ik', 'deze', 'twee', 'f@@', 'ou@@', 't', ',', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'te', 'ver@@', 'wij@@', 'der@@', 'ing', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'en', ',', 'voor', 'de', 'eerste', 'drie', 'miljo@@', 'en', 'jaar', ',', 'de', 'groot@@', 'ste', 'van', 'de', 'grote', 'grote', 'grote', ',', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 02:31:14,439 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:31:14,439 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:31:14,439 - INFO - joeynmt.training - 	Hypothesis: Lette ik deze twee fout, om te verwijderen te verwijdering te zien dat de artische ecapen, voor de eerste drie miljoen jaar, de grootste van de grote grote grote, 40 procent.
2023-05-28 02:31:14,439 - INFO - joeynmt.training - Example #1
2023-05-28 02:31:14,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:31:14,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:31:14,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'der@@', 'heid', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'aar@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'l@@', 't', '.', '</s>']
2023-05-28 02:31:14,439 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:31:14,439 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:31:14,439 - INFO - joeynmt.training - 	Hypothesis: Maar dit derheid is niet sterk genoeg de aarde van dit speciale probleem van dit speciale probleem, want de dikke van het ijslt.
2023-05-28 02:31:14,439 - INFO - joeynmt.training - Example #2
2023-05-28 02:31:14,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:31:14,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:31:14,440 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 02:31:14,440 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:31:14,440 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:31:14,440 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische eiscussie van onze wereldwijde klimaatsysteem.
2023-05-28 02:31:14,440 - INFO - joeynmt.training - Example #3
2023-05-28 02:31:14,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:31:14,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:31:14,440 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 'je', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:31:14,440 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:31:14,440 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:31:14,444 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schroepje in de zomer.
2023-05-28 02:31:14,444 - INFO - joeynmt.training - Example #4
2023-05-28 02:31:14,444 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:31:14,444 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:31:14,444 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', ',', 'is', 'een', 'te@@', 'ff@@', 'er@@', 'ie', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 't', '.', '</s>']
2023-05-28 02:31:14,445 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:31:14,445 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:31:14,445 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen, is een tefferie van de laatste 25 jaar is gebeurt.
2023-05-28 02:31:37,070 - INFO - joeynmt.training - Epoch   4, Step:    14600, Batch Loss:     1.601143, Batch Acc: 0.510943, Tokens per Sec:     3000, Lr: 0.000300
2023-05-28 02:31:59,187 - INFO - joeynmt.training - Epoch   4, Step:    14700, Batch Loss:     1.661276, Batch Acc: 0.509660, Tokens per Sec:     3188, Lr: 0.000300
2023-05-28 02:32:21,895 - INFO - joeynmt.training - Epoch   4, Step:    14800, Batch Loss:     1.646508, Batch Acc: 0.506144, Tokens per Sec:     3064, Lr: 0.000300
2023-05-28 02:32:45,732 - INFO - joeynmt.training - Epoch   4, Step:    14900, Batch Loss:     1.759107, Batch Acc: 0.511912, Tokens per Sec:     2925, Lr: 0.000300
2023-05-28 02:33:08,531 - INFO - joeynmt.training - Epoch   4, Step:    15000, Batch Loss:     1.595934, Batch Acc: 0.515405, Tokens per Sec:     3094, Lr: 0.000300
2023-05-28 02:33:08,531 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:33:08,531 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:34:19,120 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.04, acc:   0.49, generation: 70.4936[sec], evaluation: 0.0000[sec]
2023-05-28 02:34:19,121 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:34:19,243 - INFO - joeynmt.helpers - delete models/transformer_b/12500.ckpt
2023-05-28 02:34:19,251 - INFO - joeynmt.training - Example #0
2023-05-28 02:34:19,252 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:34:19,252 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:34:19,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'ol@@', 'gens', 'mij', 'jaar', 'heb', 'ik', 'deze', 'twee', 'f@@', 'ol@@', 'ie@@', 'ën', 'ge@@', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'voor', 'de', 'mee@@', 'st', 'in@@', 'ge@@', 'wikkel@@', 'de', ',', 'de', 're@@', 'eu@@', 'w@@', 'en', 'jaar', '.', '</s>']
2023-05-28 02:34:19,252 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:34:19,252 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:34:19,252 - INFO - joeynmt.training - 	Hypothesis: Volgens mij jaar heb ik deze twee folieën gezien dat de artische ijskappen voor de meest ingewikkelde, de reeuwen jaar.
2023-05-28 02:34:19,252 - INFO - joeynmt.training - Example #1
2023-05-28 02:34:19,252 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:34:19,252 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:34:19,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'aar@@', 'de', ',', 'dat', 'is', 'dat', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', '.', '</s>']
2023-05-28 02:34:19,252 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:34:19,252 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:34:19,252 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de aarde, dat is dat speciale problemen van dit speciale probleem, omdat het niet de dikke probleem.
2023-05-28 02:34:19,252 - INFO - joeynmt.training - Example #2
2023-05-28 02:34:19,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:34:19,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:34:19,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'sch@@', 'u@@', 'wel@@', 'k', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'zie@@', 'kte', 'van', 'onze', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 02:34:19,253 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:34:19,253 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:34:19,253 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het schuwelk van ons wereldwijde ziekte van onze globale klimaatsysteem.
2023-05-28 02:34:19,253 - INFO - joeynmt.training - Example #3
2023-05-28 02:34:19,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:34:19,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:34:19,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'rij@@', 'ver', 'in', 'het', 'win@@', 'ter', '.', '</s>']
2023-05-28 02:34:19,253 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:34:19,253 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:34:19,253 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schrijver in het winter.
2023-05-28 02:34:19,253 - INFO - joeynmt.training - Example #4
2023-05-28 02:34:19,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:34:19,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:34:19,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 're@@', 'ct', 'is', 'dat', 'ik', 'jullie', 't@@', 'on@@', 'en', 'dat', 'ik', 'jullie', 'een', 'te@@', 'ch@@', 'nie@@', 'k', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 02:34:19,253 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:34:19,253 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:34:19,253 - INFO - joeynmt.training - 	Hypothesis: De volgende direct is dat ik jullie tonen dat ik jullie een techniek van de laatste 25 jaar.
2023-05-28 02:34:42,589 - INFO - joeynmt.training - Epoch   4, Step:    15100, Batch Loss:     1.678499, Batch Acc: 0.510251, Tokens per Sec:     2845, Lr: 0.000300
2023-05-28 02:35:06,908 - INFO - joeynmt.training - Epoch   4, Step:    15200, Batch Loss:     1.611891, Batch Acc: 0.502277, Tokens per Sec:     2907, Lr: 0.000300
2023-05-28 02:35:29,525 - INFO - joeynmt.training - Epoch   4, Step:    15300, Batch Loss:     1.675870, Batch Acc: 0.516391, Tokens per Sec:     3044, Lr: 0.000300
2023-05-28 02:35:52,924 - INFO - joeynmt.training - Epoch   4, Step:    15400, Batch Loss:     1.689106, Batch Acc: 0.514940, Tokens per Sec:     3064, Lr: 0.000300
2023-05-28 02:36:15,534 - INFO - joeynmt.training - Epoch   4, Step:    15500, Batch Loss:     1.768987, Batch Acc: 0.508704, Tokens per Sec:     3034, Lr: 0.000300
2023-05-28 02:36:15,535 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:36:15,535 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:37:13,203 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   6.00, acc:   0.49, generation: 57.5754[sec], evaluation: 0.0000[sec]
2023-05-28 02:37:13,205 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:37:13,295 - INFO - joeynmt.helpers - delete models/transformer_b/13000.ckpt
2023-05-28 02:37:13,308 - INFO - joeynmt.training - Example #0
2023-05-28 02:37:13,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:37:13,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:37:13,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'oor', 'de', 'di@@', 'ver@@', 'sit@@', 'eit', 'van', 'deze', 'twee', 'f@@', 'ol@@', 'ie@@', 'ke', 'E@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'd', 'te', 'zijn', 'voor', 'de', 'ar@@', 'ti@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'ap@@', 'e', 'van', 'de', 'drie', 'miljo@@', 'en', 'jaar', '.', '</s>']
2023-05-28 02:37:13,308 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:37:13,308 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:37:13,308 - INFO - joeynmt.training - 	Hypothesis: Voor de diversiteit van deze twee folieke Eiscussie om te verwijderd te zijn voor de artitische Eiscape van de drie miljoen jaar.
2023-05-28 02:37:13,308 - INFO - joeynmt.training - Example #1
2023-05-28 02:37:13,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:37:13,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:37:13,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'genoe@@', 'g', 'de', 'A@@', 'n@@', 'st@@', 'ri@@', 'ct', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'de', 'E@@', 'is@@', 'es', '.', '</s>']
2023-05-28 02:37:13,309 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:37:13,309 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:37:13,309 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet genoeg de Anstrict van dit speciale probleem van dit speciale probleem van de Eises.
2023-05-28 02:37:13,309 - INFO - joeynmt.training - Example #2
2023-05-28 02:37:13,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:37:13,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:37:13,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'mo@@', 'eil@@', 'ijk', 'om', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 02:37:13,309 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:37:13,309 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:37:13,309 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het moeilijk om ons wereldwijde klimaatsysteem.
2023-05-28 02:37:13,309 - INFO - joeynmt.training - Example #3
2023-05-28 02:37:13,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:37:13,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:37:13,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'rij@@', 'ven', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:37:13,309 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:37:13,309 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:37:13,309 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrijven in de zomer.
2023-05-28 02:37:13,309 - INFO - joeynmt.training - Example #4
2023-05-28 02:37:13,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:37:13,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:37:13,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'zien', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'oo@@', 'd@@', 'sch@@', 'ap', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', '.', '</s>']
2023-05-28 02:37:13,310 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:37:13,310 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:37:13,310 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie zien is een tijdtrafferoodschap wat er in de laatste 25 jaar is.
2023-05-28 02:37:34,938 - INFO - joeynmt.training - Epoch   4, Step:    15600, Batch Loss:     1.619561, Batch Acc: 0.515182, Tokens per Sec:     3213, Lr: 0.000300
2023-05-28 02:37:55,339 - INFO - joeynmt.training - Epoch   4, Step:    15700, Batch Loss:     2.053710, Batch Acc: 0.507248, Tokens per Sec:     3416, Lr: 0.000300
2023-05-28 02:38:17,934 - INFO - joeynmt.training - Epoch   4, Step:    15800, Batch Loss:     1.620029, Batch Acc: 0.516550, Tokens per Sec:     3093, Lr: 0.000300
2023-05-28 02:38:39,857 - INFO - joeynmt.training - Epoch   4, Step:    15900, Batch Loss:     1.711551, Batch Acc: 0.507957, Tokens per Sec:     3139, Lr: 0.000300
2023-05-28 02:39:02,918 - INFO - joeynmt.training - Epoch   4, Step:    16000, Batch Loss:     1.759735, Batch Acc: 0.514154, Tokens per Sec:     2995, Lr: 0.000300
2023-05-28 02:39:02,919 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:39:02,920 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:40:12,323 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   5.97, acc:   0.49, generation: 69.3116[sec], evaluation: 0.0000[sec]
2023-05-28 02:40:12,325 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:40:12,419 - INFO - joeynmt.helpers - delete models/transformer_b/13500.ckpt
2023-05-28 02:40:12,428 - INFO - joeynmt.training - Example #0
2023-05-28 02:40:12,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:40:12,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:40:12,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'we', 'deze', 'twee', 'f@@', 'ol@@', 'ie@@', 'ën', 'ge@@', 'zien', 'om', 'te', 'ver@@', 'lie@@', 'ten', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', '4@@', '0', 'jaar', ',', 'de', 'gro@@', 'ot', 'van', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 02:40:12,429 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:40:12,429 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:40:12,429 - INFO - joeynmt.training - 	Hypothesis: Laten we deze twee folieën gezien om te verlieten dat de artische ijskappen die voor de artische ijskappen van 40 jaar, de groot van 40 procent.
2023-05-28 02:40:12,429 - INFO - joeynmt.training - Example #1
2023-05-28 02:40:12,429 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:40:12,429 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:40:12,429 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'aar@@', 'de', 'is', 'dat', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 02:40:12,429 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:40:12,429 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:40:12,429 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aarde is dat speciale problemen van dit speciale probleem, want het is het niet de dikke van het ijs.
2023-05-28 02:40:12,429 - INFO - joeynmt.training - Example #2
2023-05-28 02:40:12,429 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:40:12,429 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:40:12,429 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'd', '.', '</s>']
2023-05-28 02:40:12,429 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:40:12,429 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:40:12,429 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is het artische ijskappen van ons wereldwijd.
2023-05-28 02:40:12,429 - INFO - joeynmt.training - Example #3
2023-05-28 02:40:12,429 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:40:12,429 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:40:12,429 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:40:12,430 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:40:12,430 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:40:12,430 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schroepen in de zomer.
2023-05-28 02:40:12,430 - INFO - joeynmt.training - Example #4
2023-05-28 02:40:12,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:40:12,430 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:40:12,430 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'je', ',', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', '2@@', '5', 'jaar', 'gebeur@@', 'd', 'is', '.', '</s>']
2023-05-28 02:40:12,430 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:40:12,430 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:40:12,430 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdje, is een tijdje van 25 jaar gebeurd is.
2023-05-28 02:40:35,223 - INFO - joeynmt.training - Epoch   4, Step:    16100, Batch Loss:     1.605472, Batch Acc: 0.508005, Tokens per Sec:     3112, Lr: 0.000300
2023-05-28 02:40:56,847 - INFO - joeynmt.training - Epoch   4, Step:    16200, Batch Loss:     2.055474, Batch Acc: 0.512928, Tokens per Sec:     3332, Lr: 0.000300
2023-05-28 02:41:18,301 - INFO - joeynmt.training - Epoch   4, Step:    16300, Batch Loss:     1.675527, Batch Acc: 0.517628, Tokens per Sec:     3368, Lr: 0.000300
2023-05-28 02:41:39,368 - INFO - joeynmt.training - Epoch   4, Step:    16400, Batch Loss:     1.542577, Batch Acc: 0.515268, Tokens per Sec:     3369, Lr: 0.000300
2023-05-28 02:42:01,746 - INFO - joeynmt.training - Epoch   4, Step:    16500, Batch Loss:     1.709662, Batch Acc: 0.514563, Tokens per Sec:     3141, Lr: 0.000300
2023-05-28 02:42:01,747 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:42:01,747 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:43:20,853 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.93, acc:   0.49, generation: 79.0113[sec], evaluation: 0.0000[sec]
2023-05-28 02:43:20,855 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:43:20,941 - INFO - joeynmt.helpers - delete models/transformer_b/14000.ckpt
2023-05-28 02:43:20,952 - INFO - joeynmt.training - Example #0
2023-05-28 02:43:20,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:43:20,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:43:20,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'f@@', 'ol@@', 'ie@@', 'ën', 'ge@@', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'ac@@', 't', 'om', 'te', 'ver@@', 'van@@', 'gen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'ac@@', 't', 'die', 'voor', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'St@@', 'aten', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'anderen', '.', '</s>']
2023-05-28 02:43:20,953 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:43:20,953 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:43:20,953 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee folieën gezien dat de artische ecapact om te vervangen dat de artische ecapact die voor de Verenigde Staten, om 40 procent te veranderen.
2023-05-28 02:43:20,953 - INFO - joeynmt.training - Example #1
2023-05-28 02:43:20,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:43:20,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:43:20,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 'aar@@', 'de', 'niet', 'st@@', 'ri@@', 'ct', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's@@', 'heid', 'van', 'het', 'ij@@', 's@@', 'heid', '.', '</s>']
2023-05-28 02:43:20,953 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:43:20,953 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:43:20,953 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de aarde niet strict van dit speciale probleem van dit speciale probleem, omdat het niet de dik van het ijsheid van het ijsheid.
2023-05-28 02:43:20,953 - INFO - joeynmt.training - Example #2
2023-05-28 02:43:20,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:43:20,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:43:20,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 't', 'het', 'sch@@', 'aal', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 02:43:20,954 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:43:20,954 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:43:20,954 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapt het schaal van ons wereldwijde klimaatsysteem.
2023-05-28 02:43:20,954 - INFO - joeynmt.training - Example #3
2023-05-28 02:43:20,954 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:43:20,954 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:43:20,954 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:43:20,954 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:43:20,954 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:43:20,954 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schroept in de zomer.
2023-05-28 02:43:20,954 - INFO - joeynmt.training - Example #4
2023-05-28 02:43:20,954 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:43:20,954 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:43:20,954 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'te@@', 'tra@@', 'ff@@', 'er@@', 'ende', 'ge@@', 'vol@@', 'g', 'is', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 02:43:20,954 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:43:20,954 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:43:20,954 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie tonen is een tetrafferende gevolg is in de laatste 25 jaar gebeurt.
2023-05-28 02:43:44,239 - INFO - joeynmt.training - Epoch   4, Step:    16600, Batch Loss:     1.682838, Batch Acc: 0.514072, Tokens per Sec:     3046, Lr: 0.000300
2023-05-28 02:44:05,950 - INFO - joeynmt.training - Epoch   4, Step:    16700, Batch Loss:     1.665300, Batch Acc: 0.513970, Tokens per Sec:     3182, Lr: 0.000300
2023-05-28 02:44:29,142 - INFO - joeynmt.training - Epoch   4, Step:    16800, Batch Loss:     1.909274, Batch Acc: 0.514386, Tokens per Sec:     2962, Lr: 0.000300
2023-05-28 02:44:52,029 - INFO - joeynmt.training - Epoch   4, Step:    16900, Batch Loss:     1.647108, Batch Acc: 0.520409, Tokens per Sec:     3074, Lr: 0.000300
2023-05-28 02:45:15,969 - INFO - joeynmt.training - Epoch   4, Step:    17000, Batch Loss:     1.534149, Batch Acc: 0.519554, Tokens per Sec:     2917, Lr: 0.000300
2023-05-28 02:45:15,970 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:45:15,970 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:46:38,249 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.91, acc:   0.49, generation: 82.1814[sec], evaluation: 0.0000[sec]
2023-05-28 02:46:38,250 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:46:38,340 - INFO - joeynmt.helpers - delete models/transformer_b/14500.ckpt
2023-05-28 02:46:38,350 - INFO - joeynmt.training - Example #0
2023-05-28 02:46:38,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:46:38,350 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:46:38,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'f@@', 'ou@@', 't', 'ge@@', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', ',', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'ac@@', 'iteit', 'die', 'voor', 'de', 'onder@@', 'wer@@', 'p', 'van', 'de', 'onder@@', 'wer@@', 'p', 'van', 'de', 'onder@@', 'wij@@', 's', 'van', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 02:46:38,351 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:46:38,351 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:46:38,351 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee fout gezien dat de artische ijskape, dat de artische ecapaciteit die voor de onderwerp van de onderwerp van de onderwijs van 40 procent.
2023-05-28 02:46:38,351 - INFO - joeynmt.training - Example #1
2023-05-28 02:46:38,351 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:46:38,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:46:38,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'aar@@', 's', 'van', 'het', 'in@@', 'st@@', 'h@@', 'aa@@', 'm@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'in@@', 't@@', 'ell@@', 'icht', '.', '</s>']
2023-05-28 02:46:38,351 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:46:38,351 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:46:38,351 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aars van het insthaamheid van dit speciale probleem, want het is niet de dikke intellicht.
2023-05-28 02:46:38,351 - INFO - joeynmt.training - Example #2
2023-05-28 02:46:38,351 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:46:38,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:46:38,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'sch@@', 'e@@', 'ven', 'van', 'onze', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 02:46:38,352 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:46:38,352 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:46:38,352 - INFO - joeynmt.training - 	Hypothesis: In zeker zin is de artische ijskape het scheven van onze klimaatsysteem.
2023-05-28 02:46:38,352 - INFO - joeynmt.training - Example #3
2023-05-28 02:46:38,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:46:38,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:46:38,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:46:38,352 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:46:38,352 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:46:38,352 - INFO - joeynmt.training - 	Hypothesis: Ze groeide in het winter en schroepen in de zomer.
2023-05-28 02:46:38,352 - INFO - joeynmt.training - Example #4
2023-05-28 02:46:38,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:46:38,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:46:38,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'oon', 'zien', 'is', 'een', 'te@@', 'mp@@', 'o', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de', '.', '</s>']
2023-05-28 02:46:38,352 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:46:38,352 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:46:38,352 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie toon zien is een tempo van de laatste 25 jaar gebeurde.
2023-05-28 02:47:00,521 - INFO - joeynmt.training - Epoch   4, Step:    17100, Batch Loss:     1.695137, Batch Acc: 0.512580, Tokens per Sec:     3134, Lr: 0.000300
2023-05-28 02:47:24,861 - INFO - joeynmt.training - Epoch   4, Step:    17200, Batch Loss:     1.748750, Batch Acc: 0.523724, Tokens per Sec:     2878, Lr: 0.000300
2023-05-28 02:47:49,843 - INFO - joeynmt.training - Epoch   4, Step:    17300, Batch Loss:     1.646392, Batch Acc: 0.521492, Tokens per Sec:     2899, Lr: 0.000300
2023-05-28 02:48:14,366 - INFO - joeynmt.training - Epoch   4, Step:    17400, Batch Loss:     1.414723, Batch Acc: 0.514244, Tokens per Sec:     2904, Lr: 0.000300
2023-05-28 02:48:38,188 - INFO - joeynmt.training - Epoch   4, Step:    17500, Batch Loss:     1.728638, Batch Acc: 0.512092, Tokens per Sec:     2962, Lr: 0.000300
2023-05-28 02:48:38,189 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:48:38,189 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:49:46,087 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.88, acc:   0.50, generation: 67.8040[sec], evaluation: 0.0000[sec]
2023-05-28 02:49:46,090 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:49:46,205 - INFO - joeynmt.helpers - delete models/transformer_b/15000.ckpt
2023-05-28 02:49:46,219 - INFO - joeynmt.training - Example #0
2023-05-28 02:49:46,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:49:46,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:49:46,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'st@@', 'ri@@', 'c@@', 'e', ',', 'om', 'te', 'ver@@', 'lie@@', 't', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'die', 'gro@@', 'ter', 'van', 'de', 'gro@@', 'ter', 'van', '4@@', '0', '%', 'van', 'de', 'gro@@', 'ter', 'van', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 02:49:46,219 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:49:46,219 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:49:46,219 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee districe, om te verliet te zien dat de artische ijskape ijskape van de drie miljoen jaar die groter van de groter van 40% van de groter van 40 procent.
2023-05-28 02:49:46,219 - INFO - joeynmt.training - Example #1
2023-05-28 02:49:46,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:49:46,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:49:46,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'der@@', 'de', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'is', 'dat', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 02:49:46,220 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:49:46,220 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:49:46,220 - INFO - joeynmt.training - 	Hypothesis: Maar dit derde niet sterk genoeg de eerste eerste is dat dit speciale problemen van dit speciale problemen van het ijs.
2023-05-28 02:49:46,220 - INFO - joeynmt.training - Example #2
2023-05-28 02:49:46,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:49:46,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:49:46,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'la@@', 'g', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 02:49:46,220 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:49:46,220 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:49:46,220 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het lag van ons wereldwijde klimaatsysteem.
2023-05-28 02:49:46,220 - INFO - joeynmt.training - Example #3
2023-05-28 02:49:46,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:49:46,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:49:46,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'rij@@', 'ver', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:49:46,220 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:49:46,220 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:49:46,220 - INFO - joeynmt.training - 	Hypothesis: Ze groeide in het winter en schrijver in de zomer.
2023-05-28 02:49:46,220 - INFO - joeynmt.training - Example #4
2023-05-28 02:49:46,221 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:49:46,221 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:49:46,221 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'te@@', 'mp@@', 'o', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 02:49:46,221 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:49:46,221 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:49:46,221 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tempo van de laatste 25 jaar.
2023-05-28 02:50:11,170 - INFO - joeynmt.training - Epoch   4, Step:    17600, Batch Loss:     1.734133, Batch Acc: 0.519089, Tokens per Sec:     2879, Lr: 0.000300
2023-05-28 02:50:35,555 - INFO - joeynmt.training - Epoch   4, Step:    17700, Batch Loss:     1.455453, Batch Acc: 0.513546, Tokens per Sec:     2822, Lr: 0.000300
2023-05-28 02:50:47,624 - INFO - joeynmt.training - Epoch   4: total training loss 7599.60
2023-05-28 02:50:47,624 - INFO - joeynmt.training - EPOCH 5
2023-05-28 02:50:47,655 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=4
2023-05-28 02:50:59,156 - INFO - joeynmt.training - Epoch   5, Step:    17800, Batch Loss:     1.706094, Batch Acc: 0.535411, Tokens per Sec:     3044, Lr: 0.000300
2023-05-28 02:51:21,161 - INFO - joeynmt.training - Epoch   5, Step:    17900, Batch Loss:     1.679651, Batch Acc: 0.530636, Tokens per Sec:     3203, Lr: 0.000300
2023-05-28 02:51:43,187 - INFO - joeynmt.training - Epoch   5, Step:    18000, Batch Loss:     1.676576, Batch Acc: 0.522382, Tokens per Sec:     3160, Lr: 0.000300
2023-05-28 02:51:43,189 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:51:43,189 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:53:08,715 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.85, acc:   0.49, generation: 85.4301[sec], evaluation: 0.0000[sec]
2023-05-28 02:53:08,719 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:53:08,823 - INFO - joeynmt.helpers - delete models/transformer_b/15500.ckpt
2023-05-28 02:53:08,832 - INFO - joeynmt.training - Example #0
2023-05-28 02:53:08,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:53:08,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:53:08,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'ol@@', 'gens', 'mij', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'lie@@', 'zen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'V@@', 'S', ',', 'de', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 02:53:08,833 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:53:08,833 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:53:08,833 - INFO - joeynmt.training - 	Hypothesis: Volgens mij heb ik deze twee dia getoond om te verliezen dat de artische ijskappen die voor de artische ijskappen van de grootte van de VS, de 40 procent.
2023-05-28 02:53:08,833 - INFO - joeynmt.training - Example #1
2023-05-28 02:53:08,833 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:53:08,833 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:53:08,833 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'in@@', 'st@@', 'ie@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'van', 'het', 'ij@@', 's@@', 'heid', 'van', 'het', 'ij@@', 's@@', 'ig', 'is', '.', '</s>']
2023-05-28 02:53:08,833 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:53:08,833 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:53:08,833 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de eerste instiek van dit specifieke probleem van het ijsheid van het ijsig is.
2023-05-28 02:53:08,833 - INFO - joeynmt.training - Example #2
2023-05-28 02:53:08,833 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:53:08,833 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:53:08,833 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'p@@', 'la@@', 'st@@', 'ig', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 02:53:08,833 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:53:08,833 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:53:08,833 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het plastig van onze wereldwijd klimaatsysteem.
2023-05-28 02:53:08,833 - INFO - joeynmt.training - Example #3
2023-05-28 02:53:08,833 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:53:08,834 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:53:08,834 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'wa@@', 'ter', 'en', 'sch@@', 're@@', 'eu@@', 'w@@', 'en', 'en', 'sch@@', 're@@', 'eu@@', 'w@@', 'en', '.', '</s>']
2023-05-28 02:53:08,834 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:53:08,834 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:53:08,834 - INFO - joeynmt.training - 	Hypothesis: Ze water en schreeuwen en schreeuwen.
2023-05-28 02:53:08,834 - INFO - joeynmt.training - Example #4
2023-05-28 02:53:08,834 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:53:08,834 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:53:08,834 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', ',', 'is', 'een', 'te@@', 'tra@@', 'ff@@', 'er@@', 'l@@', 'ingen', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 02:53:08,834 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:53:08,834 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:53:08,834 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie tonen, is een tetrafferlingen van wat er gebeurt in de laatste 25 jaar gebeurt.
2023-05-28 02:53:30,082 - INFO - joeynmt.training - Epoch   5, Step:    18100, Batch Loss:     1.615093, Batch Acc: 0.522183, Tokens per Sec:     3288, Lr: 0.000300
2023-05-28 02:53:50,901 - INFO - joeynmt.training - Epoch   5, Step:    18200, Batch Loss:     1.621367, Batch Acc: 0.525431, Tokens per Sec:     3464, Lr: 0.000300
2023-05-28 02:54:11,502 - INFO - joeynmt.training - Epoch   5, Step:    18300, Batch Loss:     1.585480, Batch Acc: 0.529477, Tokens per Sec:     3561, Lr: 0.000300
2023-05-28 02:54:32,760 - INFO - joeynmt.training - Epoch   5, Step:    18400, Batch Loss:     1.558222, Batch Acc: 0.528056, Tokens per Sec:     3303, Lr: 0.000300
2023-05-28 02:54:53,651 - INFO - joeynmt.training - Epoch   5, Step:    18500, Batch Loss:     1.656725, Batch Acc: 0.527002, Tokens per Sec:     3376, Lr: 0.000300
2023-05-28 02:54:53,651 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:54:53,652 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:55:52,165 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.81, acc:   0.49, generation: 58.4208[sec], evaluation: 0.0000[sec]
2023-05-28 02:55:52,166 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:55:52,273 - INFO - joeynmt.helpers - delete models/transformer_b/16000.ckpt
2023-05-28 02:55:52,287 - INFO - joeynmt.training - Example #0
2023-05-28 02:55:52,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:55:52,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:55:52,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'we', 'deze', 'twee', 'di@@', 'a', 'hebben', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'lie@@', 'f@@', 'd', 'te', 'ver@@', 'lie@@', 'f@@', 'd', 'te', 'ver@@', 'wij@@', 'der@@', 'en', ',', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 'is@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'wij@@', 's', 'van', 'de', 'groot@@', 'ste', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '4@@', '0', '%', '.', '</s>']
2023-05-28 02:55:52,288 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:55:52,288 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:55:52,288 - INFO - joeynmt.training - 	Hypothesis: Laten we deze twee dia hebben getoond om te verliefd te verliefd te verwijderen, dat de artische ijiskappen die voor de onderwijs van de grootste 44444444444444444444444440%.
2023-05-28 02:55:52,288 - INFO - joeynmt.training - Example #1
2023-05-28 02:55:52,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:55:52,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:55:52,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'de', 'eerste', 'eerste', 'eerste', ',', 'dat', 'is', 'de', 'eerste', 'eerste', 'st@@', 'h@@', 'aa@@', 'm@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ru@@', 'ik@@', 't', '.', '</s>']
2023-05-28 02:55:52,288 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:55:52,288 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:55:52,288 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet de eerste eerste eerste, dat is de eerste eerste sthaamheid van dit speciale probleem, omdat het niet de dikke van het ijskruikt.
2023-05-28 02:55:52,288 - INFO - joeynmt.training - Example #2
2023-05-28 02:55:52,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:55:52,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:55:52,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'sch@@', 'u@@', 'wel@@', 'ijke', 'k@@', 'oo@@', 'p', 'van', 'onze', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 02:55:52,288 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:55:52,288 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:55:52,288 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het schuwelijke koop van onze wereldklimaatsysteem.
2023-05-28 02:55:52,288 - INFO - joeynmt.training - Example #3
2023-05-28 02:55:52,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:55:52,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:55:52,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'wi@@', 'ens', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'ik@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:55:52,289 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:55:52,290 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:55:52,290 - INFO - joeynmt.training - 	Hypothesis: Ze wiens in het winter en schruikt in de zomer.
2023-05-28 02:55:52,290 - INFO - joeynmt.training - Example #4
2023-05-28 02:55:52,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:55:52,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:55:52,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'tra@@', 'ff@@', 'er@@', 'ende', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 02:55:52,291 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:55:52,291 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:55:52,291 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijtrafferende 25 jaar gebeurt.
2023-05-28 02:56:15,241 - INFO - joeynmt.training - Epoch   5, Step:    18600, Batch Loss:     1.800549, Batch Acc: 0.529644, Tokens per Sec:     2988, Lr: 0.000300
2023-05-28 02:56:36,675 - INFO - joeynmt.training - Epoch   5, Step:    18700, Batch Loss:     1.730146, Batch Acc: 0.524217, Tokens per Sec:     3325, Lr: 0.000300
2023-05-28 02:56:57,218 - INFO - joeynmt.training - Epoch   5, Step:    18800, Batch Loss:     1.647009, Batch Acc: 0.530096, Tokens per Sec:     3385, Lr: 0.000300
2023-05-28 02:57:19,432 - INFO - joeynmt.training - Epoch   5, Step:    18900, Batch Loss:     1.652159, Batch Acc: 0.525456, Tokens per Sec:     3173, Lr: 0.000300
2023-05-28 02:57:41,271 - INFO - joeynmt.training - Epoch   5, Step:    19000, Batch Loss:     1.589263, Batch Acc: 0.523420, Tokens per Sec:     3264, Lr: 0.000300
2023-05-28 02:57:41,272 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 02:57:41,272 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 02:58:43,200 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.75, acc:   0.50, generation: 61.8365[sec], evaluation: 0.0000[sec]
2023-05-28 02:58:43,202 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 02:58:43,304 - INFO - joeynmt.helpers - delete models/transformer_b/16500.ckpt
2023-05-28 02:58:43,315 - INFO - joeynmt.training - Example #0
2023-05-28 02:58:43,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 02:58:43,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 02:58:43,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'oor', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'di@@', 'enen', 'die', 'twee', 'di@@', 'enen', 'jaar', 'heb', 'ik', 'deze', 'twee', 'f@@', 'ou@@', 't', ',', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'mee@@', 'st', '4@@', '8', 'st@@', 'aten', ',', 'de', 'groot@@', 'ste', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 02:58:43,316 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 02:58:43,316 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 02:58:43,316 - INFO - joeynmt.training - 	Hypothesis: Voor 40 procent van de dienen die twee dienen jaar heb ik deze twee fout, die de artische ijskappen die voor de meest 48 staten, de grootste 40 procent.
2023-05-28 02:58:43,316 - INFO - joeynmt.training - Example #1
2023-05-28 02:58:43,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 02:58:43,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 02:58:43,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'aar@@', 'de', ',', 'dat', 'is', 'de', 'eerste', 'in@@', 'st@@', 'ie@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'is', '.', '</s>']
2023-05-28 02:58:43,316 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 02:58:43,316 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 02:58:43,316 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aarde, dat is de eerste instiet van dit speciale probleem, omdat het niet de dikke probleem is.
2023-05-28 02:58:43,316 - INFO - joeynmt.training - Example #2
2023-05-28 02:58:43,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 02:58:43,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 02:58:43,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'dat', 'het', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 02:58:43,316 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 02:58:43,316 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 02:58:43,316 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape dat het ons wereldwijde klimaatsysteem.
2023-05-28 02:58:43,316 - INFO - joeynmt.training - Example #3
2023-05-28 02:58:43,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 02:58:43,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 02:58:43,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 're@@', 'eu@@', 'w@@', 'en', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 02:58:43,317 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 02:58:43,317 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 02:58:43,317 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schreeuwen in de zomer.
2023-05-28 02:58:43,317 - INFO - joeynmt.training - Example #4
2023-05-28 02:58:43,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 02:58:43,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 02:58:43,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'oon', 'zien', ',', 'is', 'een', 'te@@', 'tra@@', 'ff@@', 'er@@', 'ende', 'm@@', 'ij@@', 'nen', ',', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 02:58:43,317 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 02:58:43,319 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 02:58:43,319 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie toon zien, is een tetrafferende mijnen, wat er gebeurt in de laatste 25 jaar.
2023-05-28 02:59:05,708 - INFO - joeynmt.training - Epoch   5, Step:    19100, Batch Loss:     1.627583, Batch Acc: 0.528385, Tokens per Sec:     3199, Lr: 0.000300
2023-05-28 02:59:27,552 - INFO - joeynmt.training - Epoch   5, Step:    19200, Batch Loss:     1.859971, Batch Acc: 0.529169, Tokens per Sec:     3287, Lr: 0.000300
2023-05-28 02:59:50,783 - INFO - joeynmt.training - Epoch   5, Step:    19300, Batch Loss:     1.647506, Batch Acc: 0.522369, Tokens per Sec:     3031, Lr: 0.000300
2023-05-28 03:00:12,009 - INFO - joeynmt.training - Epoch   5, Step:    19400, Batch Loss:     1.716448, Batch Acc: 0.515806, Tokens per Sec:     3270, Lr: 0.000300
2023-05-28 03:00:33,577 - INFO - joeynmt.training - Epoch   5, Step:    19500, Batch Loss:     1.590440, Batch Acc: 0.523040, Tokens per Sec:     3265, Lr: 0.000300
2023-05-28 03:00:33,577 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:00:33,577 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:01:49,730 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.71, acc:   0.50, generation: 76.0590[sec], evaluation: 0.0000[sec]
2023-05-28 03:01:49,731 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:01:49,817 - INFO - joeynmt.helpers - delete models/transformer_b/17000.ckpt
2023-05-28 03:01:49,826 - INFO - joeynmt.training - Example #0
2023-05-28 03:01:49,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:01:49,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:01:49,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'dit', 'twee', 'jaar', 'gele@@', 'den', 'heb', 'deze', 'twee', 'di@@', 'enen', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'te', 'ver@@', 'wij@@', 'der@@', 'en', ',', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'k@@', 'app@@', 'ar@@', 'c@@', 'ie@@', 'k', ',', 'en', '4@@', '8', 'st@@', 'aten', 'had', 'om', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '8', 'proc@@', 'ent', '.', '</s>']
2023-05-28 03:01:49,827 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:01:49,827 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:01:49,827 - INFO - joeynmt.training - 	Hypothesis: Ik heb dit twee jaar geleden heb deze twee dienen getoond om te verwijderen te verwijderen, die voor de artische eiskapparciek, en 48 staten had om 40 procent van 48 procent.
2023-05-28 03:01:49,827 - INFO - joeynmt.training - Example #1
2023-05-28 03:01:49,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:01:49,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:01:49,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'keer', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k', '.', '</s>']
2023-05-28 03:01:49,827 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:01:49,827 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:01:49,827 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste eerste keer dat het speciale probleem van dit speciale probleem, want het is het niet de dik.
2023-05-28 03:01:49,827 - INFO - joeynmt.training - Example #2
2023-05-28 03:01:49,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:01:49,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:01:49,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', ',', 'het', 'is', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:01:49,828 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:01:49,828 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:01:49,828 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is het artische ijskape, het is van onze wereldwijde klimaatsysteem.
2023-05-28 03:01:49,828 - INFO - joeynmt.training - Example #3
2023-05-28 03:01:49,828 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:01:49,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:01:49,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'pt', 'in', 'het', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:01:49,828 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:01:49,828 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:01:49,828 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schroept in het zomer.
2023-05-28 03:01:49,828 - INFO - joeynmt.training - Example #4
2023-05-28 03:01:49,828 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:01:49,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:01:49,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', ',', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'ende', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 03:01:49,828 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:01:49,828 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:01:49,828 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie tonen, is een tijdtrafferende 25 jaar gebeurt.
2023-05-28 03:02:12,261 - INFO - joeynmt.training - Epoch   5, Step:    19600, Batch Loss:     1.687148, Batch Acc: 0.522835, Tokens per Sec:     3183, Lr: 0.000300
2023-05-28 03:02:34,627 - INFO - joeynmt.training - Epoch   5, Step:    19700, Batch Loss:     1.844378, Batch Acc: 0.526968, Tokens per Sec:     3200, Lr: 0.000300
2023-05-28 03:02:56,610 - INFO - joeynmt.training - Epoch   5, Step:    19800, Batch Loss:     1.661373, Batch Acc: 0.528080, Tokens per Sec:     3229, Lr: 0.000300
2023-05-28 03:03:19,847 - INFO - joeynmt.training - Epoch   5, Step:    19900, Batch Loss:     1.421845, Batch Acc: 0.529338, Tokens per Sec:     3108, Lr: 0.000300
2023-05-28 03:03:42,287 - INFO - joeynmt.training - Epoch   5, Step:    20000, Batch Loss:     1.664505, Batch Acc: 0.527060, Tokens per Sec:     3172, Lr: 0.000300
2023-05-28 03:03:42,287 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:03:42,287 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:04:53,560 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.71, acc:   0.50, generation: 71.1776[sec], evaluation: 0.0000[sec]
2023-05-28 03:04:53,649 - INFO - joeynmt.helpers - delete models/transformer_b/17500.ckpt
2023-05-28 03:04:53,662 - INFO - joeynmt.training - Example #0
2023-05-28 03:04:53,662 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:04:53,662 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:04:53,662 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'an@@', 'da@@', 'ag', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', ',', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'eerste', '4@@', '8', 'st@@', 'aten', ',', 'de', 'groot@@', 'ste', '4@@', '8', 'proc@@', 'ent', '.', '</s>']
2023-05-28 03:04:53,662 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:04:53,662 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:04:53,662 - INFO - joeynmt.training - 	Hypothesis: Vandaag heb ik deze twee dia getoond, om te verwijderen dat de artische ijskappen die voor de eerste 48 staten, de grootste 48 procent.
2023-05-28 03:04:53,662 - INFO - joeynmt.training - Example #1
2023-05-28 03:04:53,662 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:04:53,662 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:04:53,662 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'in@@', 'st@@', 'ie@@', 'ke', 'proble@@', 'em', 'is', 'dat', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'ver@@', 's', '.', '</s>']
2023-05-28 03:04:53,663 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:04:53,663 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:04:53,663 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste instieke probleem is dat speciale probleem, want het is niet de dikke van het ijsvers.
2023-05-28 03:04:53,663 - INFO - joeynmt.training - Example #2
2023-05-28 03:04:53,663 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:04:53,663 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:04:53,663 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'sch@@', 'u@@', 'wel@@', 'ijke', 'k@@', 'oo@@', 'p', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:04:53,663 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:04:53,663 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:04:53,663 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het schuwelijke koop van onze wereldwijde klimaatsysteem.
2023-05-28 03:04:53,663 - INFO - joeynmt.training - Example #3
2023-05-28 03:04:53,663 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:04:53,663 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:04:53,663 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:04:53,663 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:04:53,663 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:04:53,663 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schroept in de zomer.
2023-05-28 03:04:53,663 - INFO - joeynmt.training - Example #4
2023-05-28 03:04:53,663 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:04:53,663 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:04:53,663 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'to@@', 'on@@', 't', 'een', 'teken@@', 'en', ',', 'is', 'een', 'teken@@', 's', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 03:04:53,664 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:04:53,666 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:04:53,666 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie toont een tekenen, is een tekens van de laatste 25 jaar.
2023-05-28 03:05:16,443 - INFO - joeynmt.training - Epoch   5, Step:    20100, Batch Loss:     1.536882, Batch Acc: 0.528337, Tokens per Sec:     2963, Lr: 0.000300
2023-05-28 03:05:39,412 - INFO - joeynmt.training - Epoch   5, Step:    20200, Batch Loss:     1.598996, Batch Acc: 0.534013, Tokens per Sec:     3018, Lr: 0.000300
2023-05-28 03:06:02,587 - INFO - joeynmt.training - Epoch   5, Step:    20300, Batch Loss:     1.640450, Batch Acc: 0.524872, Tokens per Sec:     3070, Lr: 0.000300
2023-05-28 03:06:23,439 - INFO - joeynmt.training - Epoch   5, Step:    20400, Batch Loss:     1.627948, Batch Acc: 0.528543, Tokens per Sec:     3427, Lr: 0.000300
2023-05-28 03:06:44,633 - INFO - joeynmt.training - Epoch   5, Step:    20500, Batch Loss:     2.002829, Batch Acc: 0.533341, Tokens per Sec:     3361, Lr: 0.000300
2023-05-28 03:06:44,635 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:06:44,635 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:07:44,885 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.66, acc:   0.50, generation: 60.1586[sec], evaluation: 0.0000[sec]
2023-05-28 03:07:44,887 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:07:44,975 - INFO - joeynmt.helpers - delete models/transformer_b/18000.ckpt
2023-05-28 03:07:44,992 - INFO - joeynmt.training - Example #0
2023-05-28 03:07:44,992 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:07:44,992 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:07:44,992 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'an@@', 'da@@', 'ag', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 't', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', '4@@', '8', 'uur', 'had', ',', 'de', 'groot@@', 'ste', '4@@', '8', 'proc@@', 'ent', '.', '</s>']
2023-05-28 03:07:44,992 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:07:44,992 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:07:44,992 - INFO - joeynmt.training - 	Hypothesis: Vandaag heb ik deze twee dia getoont om te verwijderen dat de artische eiskappen die voor de artische ijskape van 48 uur had, de grootste 48 procent.
2023-05-28 03:07:44,992 - INFO - joeynmt.training - Example #1
2023-05-28 03:07:44,992 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:07:44,992 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:07:44,992 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'der@@', 'de', 'niet', 'ster@@', 'k', ',', 'is', 'het', 'be@@', 'ste', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', '.', '</s>']
2023-05-28 03:07:44,993 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:07:44,993 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:07:44,993 - INFO - joeynmt.training - 	Hypothesis: Maar dit derde niet sterk, is het beste van dit speciale probleem van dit speciale probleem.
2023-05-28 03:07:44,993 - INFO - joeynmt.training - Example #2
2023-05-28 03:07:44,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:07:44,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:07:44,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'dat', 'het', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:07:44,993 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:07:44,993 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:07:44,993 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape dat het globale klimaatsysteem.
2023-05-28 03:07:44,993 - INFO - joeynmt.training - Example #3
2023-05-28 03:07:44,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:07:44,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:07:44,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:07:44,993 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:07:44,993 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:07:44,993 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schroept in de zomer.
2023-05-28 03:07:44,993 - INFO - joeynmt.training - Example #4
2023-05-28 03:07:44,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:07:44,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:07:44,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'tra@@', 'p@@', 'pen', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 03:07:44,994 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:07:44,994 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:07:44,994 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie tonen is een tijtrappen van de laatste 25 jaar.
2023-05-28 03:08:07,072 - INFO - joeynmt.training - Epoch   5, Step:    20600, Batch Loss:     1.602205, Batch Acc: 0.536375, Tokens per Sec:     3151, Lr: 0.000300
2023-05-28 03:08:29,934 - INFO - joeynmt.training - Epoch   5, Step:    20700, Batch Loss:     1.744447, Batch Acc: 0.524229, Tokens per Sec:     3103, Lr: 0.000300
2023-05-28 03:08:51,584 - INFO - joeynmt.training - Epoch   5, Step:    20800, Batch Loss:     1.654190, Batch Acc: 0.525664, Tokens per Sec:     3258, Lr: 0.000300
2023-05-28 03:09:13,046 - INFO - joeynmt.training - Epoch   5, Step:    20900, Batch Loss:     1.800338, Batch Acc: 0.532636, Tokens per Sec:     3404, Lr: 0.000300
2023-05-28 03:09:35,411 - INFO - joeynmt.training - Epoch   5, Step:    21000, Batch Loss:     1.603831, Batch Acc: 0.524965, Tokens per Sec:     3182, Lr: 0.000300
2023-05-28 03:09:35,413 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:09:35,413 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:10:37,000 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.64, acc:   0.50, generation: 61.4931[sec], evaluation: 0.0000[sec]
2023-05-28 03:10:37,003 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:10:37,104 - INFO - joeynmt.helpers - delete models/transformer_b/18500.ckpt
2023-05-28 03:10:37,113 - INFO - joeynmt.training - Example #0
2023-05-28 03:10:37,113 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:10:37,113 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:10:37,113 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'oor', 'het', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', ',', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', ',', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'hebben', 'de', 'gro@@', 'ot', 'van', 'de', 'groot@@', 'ste', '4@@', '8', 'st@@', 'aten', '.', '</s>']
2023-05-28 03:10:37,113 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:10:37,113 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:10:37,113 - INFO - joeynmt.training - 	Hypothesis: Voor het jaar heb ik deze twee dia getoond, om te verwijderen dat de artische ijskappen, die drie miljoen jaar hebben de groot van de grootste 48 staten.
2023-05-28 03:10:37,113 - INFO - joeynmt.training - Example #1
2023-05-28 03:10:37,113 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:10:37,113 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:10:37,113 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', ',', 'st@@', 'ier@@', 'f', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'is', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 03:10:37,114 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:10:37,114 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:10:37,114 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk, stierf dat het speciale probleem is van dit speciale probleem, omdat het niet de dikke dikke van het ijs.
2023-05-28 03:10:37,114 - INFO - joeynmt.training - Example #2
2023-05-28 03:10:37,114 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:10:37,114 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:10:37,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'dat', 'het', 'gelu@@', 'i@@', 'd', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:10:37,114 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:10:37,114 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:10:37,114 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen dat het geluid van onze wereldwijde klimaatsysteem.
2023-05-28 03:10:37,114 - INFO - joeynmt.training - Example #3
2023-05-28 03:10:37,114 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:10:37,114 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:10:37,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:10:37,114 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:10:37,114 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:10:37,114 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroept in de zomer.
2023-05-28 03:10:37,114 - INFO - joeynmt.training - Example #4
2023-05-28 03:10:37,114 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:10:37,114 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:10:37,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'tra@@', 'ff@@', 'er@@', 'ende', 'op@@', 'z@@', 'ich@@', 'te', 'van', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 03:10:37,115 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:10:37,115 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:10:37,115 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie tonen is een tijtrafferende opzichte van de afgelopen 25 jaar.
2023-05-28 03:10:58,821 - INFO - joeynmt.training - Epoch   5, Step:    21100, Batch Loss:     1.512043, Batch Acc: 0.526218, Tokens per Sec:     3296, Lr: 0.000300
2023-05-28 03:11:20,121 - INFO - joeynmt.training - Epoch   5, Step:    21200, Batch Loss:     1.574145, Batch Acc: 0.531330, Tokens per Sec:     3366, Lr: 0.000300
2023-05-28 03:11:42,483 - INFO - joeynmt.training - Epoch   5, Step:    21300, Batch Loss:     1.988193, Batch Acc: 0.530917, Tokens per Sec:     3231, Lr: 0.000300
2023-05-28 03:12:04,909 - INFO - joeynmt.training - Epoch   5, Step:    21400, Batch Loss:     1.544881, Batch Acc: 0.527714, Tokens per Sec:     3066, Lr: 0.000300
2023-05-28 03:12:27,273 - INFO - joeynmt.training - Epoch   5, Step:    21500, Batch Loss:     1.502613, Batch Acc: 0.528580, Tokens per Sec:     3227, Lr: 0.000300
2023-05-28 03:12:27,274 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:12:27,274 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:13:28,517 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.63, acc:   0.50, generation: 61.1490[sec], evaluation: 0.0000[sec]
2023-05-28 03:13:28,518 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:13:28,612 - INFO - joeynmt.helpers - delete models/transformer_b/19000.ckpt
2023-05-28 03:13:28,628 - INFO - joeynmt.training - Example #0
2023-05-28 03:13:28,628 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:13:28,628 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:13:28,628 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'et@@', 'te', 'jaar', 'heb', 'ik', 'deze', 'twee', 'f@@', 'ol@@', 'ie@@', 'ën', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', ',', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', '4@@', '0', '%', 'van', 'de', 'gro@@', 'ot', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', '4@@', '0', '%', '.', '</s>']
2023-05-28 03:13:28,629 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:13:28,629 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:13:28,629 - INFO - joeynmt.training - 	Hypothesis: Lette jaar heb ik deze twee folieën getoond om te verwijderen, dat de artische ijskape van 40% van de groot van de onderkant van 40%.
2023-05-28 03:13:28,629 - INFO - joeynmt.training - Example #1
2023-05-28 03:13:28,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:13:28,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:13:28,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'het', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'n@@', 'u@@', 'g', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.', '</s>']
2023-05-28 03:13:28,629 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:13:28,629 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:13:28,629 - INFO - joeynmt.training - 	Hypothesis: Maar dat is het niet sterk genoeg de eerste nug van dit speciale problemen, omdat het niet de dikke van het ijs laat zien.
2023-05-28 03:13:28,629 - INFO - joeynmt.training - Example #2
2023-05-28 03:13:28,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:13:28,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:13:28,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'onze', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:13:28,629 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:13:28,629 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:13:28,629 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape van onze globale klimaatsysteem.
2023-05-28 03:13:28,629 - INFO - joeynmt.training - Example #3
2023-05-28 03:13:28,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:13:28,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:13:28,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 're@@', 'eu@@', 'w@@', 'en', '.', '</s>']
2023-05-28 03:13:28,630 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:13:28,630 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:13:28,630 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schreeuwen.
2023-05-28 03:13:28,630 - INFO - joeynmt.training - Example #4
2023-05-28 03:13:28,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:13:28,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:13:28,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', ',', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ap', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 03:13:28,630 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:13:28,632 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:13:28,632 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie tonen, is een tijdschap van wat er gebeurt in de laatste 25 jaar.
2023-05-28 03:13:51,469 - INFO - joeynmt.training - Epoch   5, Step:    21600, Batch Loss:     1.460742, Batch Acc: 0.528579, Tokens per Sec:     3116, Lr: 0.000300
2023-05-28 03:14:14,037 - INFO - joeynmt.training - Epoch   5, Step:    21700, Batch Loss:     1.539805, Batch Acc: 0.531381, Tokens per Sec:     3033, Lr: 0.000300
2023-05-28 03:14:36,936 - INFO - joeynmt.training - Epoch   5, Step:    21800, Batch Loss:     1.650968, Batch Acc: 0.530154, Tokens per Sec:     3110, Lr: 0.000300
2023-05-28 03:15:00,662 - INFO - joeynmt.training - Epoch   5, Step:    21900, Batch Loss:     1.647585, Batch Acc: 0.528631, Tokens per Sec:     2945, Lr: 0.000300
2023-05-28 03:15:24,058 - INFO - joeynmt.training - Epoch   5, Step:    22000, Batch Loss:     1.599501, Batch Acc: 0.532420, Tokens per Sec:     3120, Lr: 0.000300
2023-05-28 03:15:24,059 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:15:24,059 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:16:44,066 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.59, acc:   0.50, generation: 79.9080[sec], evaluation: 0.0000[sec]
2023-05-28 03:16:44,068 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:16:44,158 - INFO - joeynmt.helpers - delete models/transformer_b/20000.ckpt
2023-05-28 03:16:44,170 - INFO - joeynmt.training - Example #0
2023-05-28 03:16:44,170 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:16:44,170 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:16:44,170 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aat@@', 'te', 'ik', 'deze', 'twee', 'di@@', 'a', 'heb', 'ik', 'deze', 'twee', 'f@@', 'ol@@', 'ie@@', 'ën', 'om', 'te', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', ',', 'en', '4@@', '8', 'st@@', 'aten', 'had', ',', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 03:16:44,170 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:16:44,170 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:16:44,170 - INFO - joeynmt.training - 	Hypothesis: Laatte ik deze twee dia heb ik deze twee folieën om te kijken dat de artische ijskappen die voor de artische ijskappen, en 48 staten had, 40 procent.
2023-05-28 03:16:44,170 - INFO - joeynmt.training - Example #1
2023-05-28 03:16:44,170 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:16:44,170 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:16:44,170 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'in@@', 'st@@', 'ro@@', 'om', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.', '</s>']
2023-05-28 03:16:44,171 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:16:44,171 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:16:44,171 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste instroom te verzameling van dit speciale probleem, omdat het niet de dik van het ijs laat zien.
2023-05-28 03:16:44,171 - INFO - joeynmt.training - Example #2
2023-05-28 03:16:44,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:16:44,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:16:44,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'd', '.', '</s>']
2023-05-28 03:16:44,171 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:16:44,171 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:16:44,171 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape van ons wereldwijd.
2023-05-28 03:16:44,171 - INFO - joeynmt.training - Example #3
2023-05-28 03:16:44,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:16:44,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:16:44,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:16:44,171 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:16:44,171 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:16:44,171 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomer.
2023-05-28 03:16:44,171 - INFO - joeynmt.training - Example #4
2023-05-28 03:16:44,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:16:44,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:16:44,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'zien', ',', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'ende', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 03:16:44,172 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:16:44,172 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:16:44,172 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie zien, is een tijdtrafferende dia 's in de laatste 25 jaar.
2023-05-28 03:17:07,814 - INFO - joeynmt.training - Epoch   5, Step:    22100, Batch Loss:     1.589806, Batch Acc: 0.532818, Tokens per Sec:     2976, Lr: 0.000300
2023-05-28 03:17:24,660 - INFO - joeynmt.training - Epoch   5: total training loss 7256.07
2023-05-28 03:17:24,661 - INFO - joeynmt.training - EPOCH 6
2023-05-28 03:17:24,698 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=5
2023-05-28 03:17:30,267 - INFO - joeynmt.training - Epoch   6, Step:    22200, Batch Loss:     1.611074, Batch Acc: 0.545604, Tokens per Sec:     3145, Lr: 0.000300
2023-05-28 03:17:54,423 - INFO - joeynmt.training - Epoch   6, Step:    22300, Batch Loss:     1.504801, Batch Acc: 0.542950, Tokens per Sec:     2863, Lr: 0.000300
2023-05-28 03:18:17,781 - INFO - joeynmt.training - Epoch   6, Step:    22400, Batch Loss:     1.628347, Batch Acc: 0.536564, Tokens per Sec:     3091, Lr: 0.000300
2023-05-28 03:18:41,252 - INFO - joeynmt.training - Epoch   6, Step:    22500, Batch Loss:     1.683718, Batch Acc: 0.539314, Tokens per Sec:     3055, Lr: 0.000300
2023-05-28 03:18:41,253 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:18:41,253 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:19:44,935 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.58, acc:   0.51, generation: 63.5870[sec], evaluation: 0.0000[sec]
2023-05-28 03:19:44,937 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:19:45,021 - INFO - joeynmt.helpers - delete models/transformer_b/19500.ckpt
2023-05-28 03:19:45,030 - INFO - joeynmt.training - Example #0
2023-05-28 03:19:45,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:19:45,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:19:45,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', ',', 'om', 'te', 'ver@@', 'laten', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'el', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', ',', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ot', 'is', 'van', 'de', 'v@@', 'ele', 'c@@', 'ru@@', 'ci@@', 'aal', '.', '</s>']
2023-05-28 03:19:45,030 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:19:45,030 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:19:45,030 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden, om te verlaten zien dat de artische ijskapel ijskape, die voor de artische ijskape van de drie miljoen jaar de groot is van de vele cruciaal.
2023-05-28 03:19:45,030 - INFO - joeynmt.training - Example #1
2023-05-28 03:19:45,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:19:45,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:19:45,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'het', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'oor@@', 'st@@', 'of', ',', 'dat', 'is', 'een', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'van', 'het', 'ij@@', 'z@@', 'ig@@', 'heid', 'van', 'ij@@', 'z@@', 'ig@@', 'heid', '.', '</s>']
2023-05-28 03:19:45,031 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:19:45,031 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:19:45,031 - INFO - joeynmt.training - 	Hypothesis: Maar dat is het niet sterk genoeg de oorstof, dat is een speciale problemen van het ijzigheid van ijzigheid.
2023-05-28 03:19:45,031 - INFO - joeynmt.training - Example #2
2023-05-28 03:19:45,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:19:45,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:19:45,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:19:45,031 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:19:45,031 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:19:45,031 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het hart van ons wereldsysteem.
2023-05-28 03:19:45,031 - INFO - joeynmt.training - Example #3
2023-05-28 03:19:45,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:19:45,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:19:45,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:19:45,031 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:19:45,031 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:19:45,031 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schroept in de zomer.
2023-05-28 03:19:45,031 - INFO - joeynmt.training - Example #4
2023-05-28 03:19:45,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:19:45,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:19:45,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 'jullie', 'zien', ',', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'ende', 'di@@', 're@@', 'c@@', 'te', 'zijn', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 03:19:45,032 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:19:45,032 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:19:45,032 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie jullie zien, is een tijdtrafferende directe zijn in de laatste 25 jaar.
2023-05-28 03:20:06,164 - INFO - joeynmt.training - Epoch   6, Step:    22600, Batch Loss:     1.863434, Batch Acc: 0.540964, Tokens per Sec:     3308, Lr: 0.000300
2023-05-28 03:20:27,898 - INFO - joeynmt.training - Epoch   6, Step:    22700, Batch Loss:     1.689640, Batch Acc: 0.536361, Tokens per Sec:     3291, Lr: 0.000300
2023-05-28 03:20:50,925 - INFO - joeynmt.training - Epoch   6, Step:    22800, Batch Loss:     1.633421, Batch Acc: 0.541471, Tokens per Sec:     3133, Lr: 0.000300
2023-05-28 03:21:13,046 - INFO - joeynmt.training - Epoch   6, Step:    22900, Batch Loss:     1.631043, Batch Acc: 0.538447, Tokens per Sec:     3219, Lr: 0.000300
2023-05-28 03:21:33,162 - INFO - joeynmt.training - Epoch   6, Step:    23000, Batch Loss:     1.520041, Batch Acc: 0.535362, Tokens per Sec:     3475, Lr: 0.000300
2023-05-28 03:21:33,164 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:21:33,164 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:22:35,507 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.57, acc:   0.51, generation: 62.2494[sec], evaluation: 0.0000[sec]
2023-05-28 03:22:35,510 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:22:35,610 - INFO - joeynmt.helpers - delete models/transformer_b/20500.ckpt
2023-05-28 03:22:35,619 - INFO - joeynmt.training - Example #0
2023-05-28 03:22:35,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:22:35,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:22:35,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', ',', 'heb', 'ik', 'deze', 'twee', 'f@@', 'ou@@', 't', 'om', 'te', 'ver@@', 'tro@@', 'uw@@', 'en', 'te', 'ver@@', 'tro@@', 'kken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'ac@@', 'ti@@', 'sche', 'e@@', 'c@@', 'ap@@', 'ac@@', 't', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'anderen', '.', '</s>']
2023-05-28 03:22:35,619 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:22:35,620 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:22:35,620 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden, heb ik deze twee fout om te vertrouwen te vertrokken dat de artische ecapactische ecapact, om 40 procent te veranderen.
2023-05-28 03:22:35,620 - INFO - joeynmt.training - Example #1
2023-05-28 03:22:35,620 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:22:35,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:22:35,620 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'in@@', 'st@@', 'ie@@', 'k', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 03:22:35,620 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:22:35,620 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:22:35,620 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste eerste instiek, want het is niet de dik van het ijs.
2023-05-28 03:22:35,620 - INFO - joeynmt.training - Example #2
2023-05-28 03:22:35,620 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:22:35,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:22:35,620 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'la@@', 'gende', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:22:35,620 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:22:35,620 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:22:35,620 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het lagende hart van ons wereldsysteem.
2023-05-28 03:22:35,620 - INFO - joeynmt.training - Example #3
2023-05-28 03:22:35,620 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:22:35,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:22:35,620 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:22:35,621 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:22:35,621 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:22:35,621 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schroepen in de zomer.
2023-05-28 03:22:35,621 - INFO - joeynmt.training - Example #4
2023-05-28 03:22:35,621 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:22:35,621 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:22:35,621 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'te@@', 'ff@@', 'er@@', 'ie', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 03:22:35,621 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:22:35,621 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:22:35,621 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tefferie van de laatste 25 jaar.
2023-05-28 03:22:56,038 - INFO - joeynmt.training - Epoch   6, Step:    23100, Batch Loss:     1.506815, Batch Acc: 0.537309, Tokens per Sec:     3528, Lr: 0.000300
2023-05-28 03:23:17,443 - INFO - joeynmt.training - Epoch   6, Step:    23200, Batch Loss:     1.489740, Batch Acc: 0.531034, Tokens per Sec:     3237, Lr: 0.000300
2023-05-28 03:23:39,086 - INFO - joeynmt.training - Epoch   6, Step:    23300, Batch Loss:     1.347668, Batch Acc: 0.540348, Tokens per Sec:     3172, Lr: 0.000300
2023-05-28 03:24:01,305 - INFO - joeynmt.training - Epoch   6, Step:    23400, Batch Loss:     1.497939, Batch Acc: 0.538531, Tokens per Sec:     3187, Lr: 0.000300
2023-05-28 03:24:21,924 - INFO - joeynmt.training - Epoch   6, Step:    23500, Batch Loss:     1.471790, Batch Acc: 0.537095, Tokens per Sec:     3445, Lr: 0.000300
2023-05-28 03:24:21,925 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:24:21,925 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:25:25,644 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.54, acc:   0.51, generation: 63.6281[sec], evaluation: 0.0000[sec]
2023-05-28 03:25:25,646 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:25:25,740 - INFO - joeynmt.helpers - delete models/transformer_b/21000.ckpt
2023-05-28 03:25:25,754 - INFO - joeynmt.training - Example #0
2023-05-28 03:25:25,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:25:25,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:25:25,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 're@@', 'c@@', 'te@@', 'ur', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'to@@', 'on@@', 'de', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'voor', 'de', 'hu@@', 'id@@', 'ige', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', ',', 'die', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 03:25:25,754 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:25:25,754 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:25:25,754 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee directeur getoond om te vertoonde dat de artische ijskappen voor de huidige ijskappen, die 40 procent.
2023-05-28 03:25:25,754 - INFO - joeynmt.training - Example #1
2023-05-28 03:25:25,755 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:25:25,755 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:25:25,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'is', 'dat', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'men', 'uit', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 03:25:25,755 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:25:25,755 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:25:25,755 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste eerste is dat dit speciale probleem niet de dikke problemen uit, want het is niet de dikke van het ijs.
2023-05-28 03:25:25,755 - INFO - joeynmt.training - Example #2
2023-05-28 03:25:25,755 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:25:25,755 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:25:25,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', '.', '</s>']
2023-05-28 03:25:25,755 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:25:25,755 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:25:25,755 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapparctische ijskappen.
2023-05-28 03:25:25,755 - INFO - joeynmt.training - Example #3
2023-05-28 03:25:25,755 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:25:25,755 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:25:25,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'k@@', 'ken@@', 'de', '.', '</s>']
2023-05-28 03:25:25,755 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:25:25,755 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:25:25,755 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schokkende.
2023-05-28 03:25:25,755 - INFO - joeynmt.training - Example #4
2023-05-28 03:25:25,756 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:25:25,756 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:25:25,756 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ap', 'van', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 03:25:25,756 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:25:25,756 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:25:25,756 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie tonen is een tijdschap van de afgelopen 25 jaar.
2023-05-28 03:25:47,131 - INFO - joeynmt.training - Epoch   6, Step:    23600, Batch Loss:     1.694977, Batch Acc: 0.537758, Tokens per Sec:     3335, Lr: 0.000300
2023-05-28 03:26:07,717 - INFO - joeynmt.training - Epoch   6, Step:    23700, Batch Loss:     1.574309, Batch Acc: 0.537138, Tokens per Sec:     3421, Lr: 0.000300
2023-05-28 03:26:30,693 - INFO - joeynmt.training - Epoch   6, Step:    23800, Batch Loss:     1.436309, Batch Acc: 0.542670, Tokens per Sec:     3119, Lr: 0.000300
2023-05-28 03:26:51,701 - INFO - joeynmt.training - Epoch   6, Step:    23900, Batch Loss:     1.656527, Batch Acc: 0.539633, Tokens per Sec:     3329, Lr: 0.000300
2023-05-28 03:27:13,600 - INFO - joeynmt.training - Epoch   6, Step:    24000, Batch Loss:     1.578821, Batch Acc: 0.541437, Tokens per Sec:     3157, Lr: 0.000300
2023-05-28 03:27:13,602 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:27:13,602 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:28:20,106 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.53, acc:   0.51, generation: 66.4110[sec], evaluation: 0.0000[sec]
2023-05-28 03:28:20,108 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:28:20,200 - INFO - joeynmt.helpers - delete models/transformer_b/21500.ckpt
2023-05-28 03:28:20,211 - INFO - joeynmt.training - Example #0
2023-05-28 03:28:20,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:28:20,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:28:20,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'ol@@', 'gens', 'mij', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'zien', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'de', 'onder@@', 'aan', 'van', '4@@', '8', 'proc@@', 'ent', '.', '</s>']
2023-05-28 03:28:20,212 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:28:20,212 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:28:20,212 - INFO - joeynmt.training - 	Hypothesis: Volgens mij heb ik deze twee dia gezien om te verwijderen dat de artische ijskappen die voor de artische ijskappen van de onderaan van 48 procent.
2023-05-28 03:28:20,212 - INFO - joeynmt.training - Example #1
2023-05-28 03:28:20,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:28:20,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:28:20,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'dat', 'is', 'dat', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'is', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 03:28:20,212 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:28:20,212 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:28:20,212 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste eerste dat is dat speciale probleem is, want het is niet de dikke van het ijs.
2023-05-28 03:28:20,212 - INFO - joeynmt.training - Example #2
2023-05-28 03:28:20,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:28:20,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:28:20,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:28:20,213 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:28:20,213 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:28:20,213 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het hart van ons wereldwijde klimaatsysteem.
2023-05-28 03:28:20,213 - INFO - joeynmt.training - Example #3
2023-05-28 03:28:20,213 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:28:20,213 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:28:20,213 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:28:20,213 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:28:20,213 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:28:20,213 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schromp in de zomer.
2023-05-28 03:28:20,213 - INFO - joeynmt.training - Example #4
2023-05-28 03:28:20,213 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:28:20,213 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:28:20,213 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'ende', '2@@', '5', 'jaar', 'gebeur@@', 'd', '.', '</s>']
2023-05-28 03:28:20,213 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:28:20,213 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:28:20,213 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie laten zien is een tijdtrafferende 25 jaar gebeurd.
2023-05-28 03:28:42,909 - INFO - joeynmt.training - Epoch   6, Step:    24100, Batch Loss:     1.693895, Batch Acc: 0.535664, Tokens per Sec:     3033, Lr: 0.000300
2023-05-28 03:29:04,384 - INFO - joeynmt.training - Epoch   6, Step:    24200, Batch Loss:     1.371478, Batch Acc: 0.533885, Tokens per Sec:     3242, Lr: 0.000300
2023-05-28 03:29:24,839 - INFO - joeynmt.training - Epoch   6, Step:    24300, Batch Loss:     1.455056, Batch Acc: 0.543701, Tokens per Sec:     3418, Lr: 0.000300
2023-05-28 03:29:46,508 - INFO - joeynmt.training - Epoch   6, Step:    24400, Batch Loss:     1.599299, Batch Acc: 0.540196, Tokens per Sec:     3253, Lr: 0.000300
2023-05-28 03:30:08,174 - INFO - joeynmt.training - Epoch   6, Step:    24500, Batch Loss:     1.662967, Batch Acc: 0.539439, Tokens per Sec:     3221, Lr: 0.000300
2023-05-28 03:30:08,175 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:30:08,175 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:31:15,887 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.53, acc:   0.51, generation: 67.6183[sec], evaluation: 0.0000[sec]
2023-05-28 03:31:15,985 - INFO - joeynmt.helpers - delete models/transformer_b/22000.ckpt
2023-05-28 03:31:15,995 - INFO - joeynmt.training - Example #0
2023-05-28 03:31:15,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:31:15,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:31:15,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'te', 'zien', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'gele@@', 'den', 'had', 'ge@@', 'maakt', 'om', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 03:31:15,996 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:31:15,996 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:31:15,996 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia getoond te zien om te verwijderen dat de artische ijskappen die voor de artische ijskappen die drie miljoen jaar geleden had gemaakt om 40 procent.
2023-05-28 03:31:15,996 - INFO - joeynmt.training - Example #1
2023-05-28 03:31:15,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:31:15,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:31:15,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'in@@', 'st@@', 'h@@', 'af@@', 'del@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 03:31:15,996 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:31:15,996 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:31:15,996 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste eerste insthafdeling van dit speciale probleem, want het is niet de dikke dikke van het ijs.
2023-05-28 03:31:15,996 - INFO - joeynmt.training - Example #2
2023-05-28 03:31:15,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:31:15,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:31:15,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'uit@@', 'ein@@', 'delijk', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:31:15,996 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:31:15,996 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:31:15,996 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het uiteindelijk van onze wereldwijde klimaatsysteem.
2023-05-28 03:31:15,996 - INFO - joeynmt.training - Example #3
2023-05-28 03:31:15,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:31:15,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:31:15,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'pt', 'in', 'het', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:31:15,997 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:31:15,997 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:31:15,997 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schroept in het zomer.
2023-05-28 03:31:15,997 - INFO - joeynmt.training - Example #4
2023-05-28 03:31:15,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:31:15,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:31:15,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'zien', 'is', 'een', 'te@@', 'mp@@', 'o', '&@@', 'ap@@', 'o@@', 's@@', ';', 'n', 't@@', 'op@@', 'op@@', 'nam@@', 'e', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'die', 'ik', 'je', 'ge@@', 'maakt', 'is', '.', '</s>']
2023-05-28 03:31:15,997 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:31:15,997 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:31:15,997 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie zien is een tempo 'n topopname' s die ik je gemaakt is.
2023-05-28 03:31:38,315 - INFO - joeynmt.training - Epoch   6, Step:    24600, Batch Loss:     1.501351, Batch Acc: 0.532569, Tokens per Sec:     3212, Lr: 0.000300
2023-05-28 03:32:00,155 - INFO - joeynmt.training - Epoch   6, Step:    24700, Batch Loss:     1.592504, Batch Acc: 0.541386, Tokens per Sec:     3179, Lr: 0.000300
2023-05-28 03:32:22,022 - INFO - joeynmt.training - Epoch   6, Step:    24800, Batch Loss:     1.632123, Batch Acc: 0.537959, Tokens per Sec:     3150, Lr: 0.000300
2023-05-28 03:32:42,922 - INFO - joeynmt.training - Epoch   6, Step:    24900, Batch Loss:     1.674886, Batch Acc: 0.545753, Tokens per Sec:     3415, Lr: 0.000300
2023-05-28 03:33:04,792 - INFO - joeynmt.training - Epoch   6, Step:    25000, Batch Loss:     1.587216, Batch Acc: 0.540930, Tokens per Sec:     3319, Lr: 0.000300
2023-05-28 03:33:04,793 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:33:04,793 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:34:13,706 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.46, acc:   0.51, generation: 68.8207[sec], evaluation: 0.0000[sec]
2023-05-28 03:34:13,708 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:34:13,792 - INFO - joeynmt.helpers - delete models/transformer_b/22500.ckpt
2023-05-28 03:34:13,802 - INFO - joeynmt.training - Example #0
2023-05-28 03:34:13,802 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:34:13,802 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:34:13,802 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 're@@', 'c@@', 'te@@', 'ur', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'to@@', 'ond', 'te', 'ver@@', 'lie@@', 't', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'tot', 'drie', 'miljo@@', 'en', 'jaar', ',', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'tot', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 03:34:13,802 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:34:13,802 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:34:13,802 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee directeur getoond om te vertoond te verliet dat de artische ijskappen die van de onderste 48 tot drie miljoen jaar, de grootte van de onderste 48 tot 40 procent.
2023-05-28 03:34:13,802 - INFO - joeynmt.training - Example #1
2023-05-28 03:34:13,802 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:34:13,802 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:34:13,802 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'oor@@', 'z@@', 'aa@@', 'm@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', '.', '</s>']
2023-05-28 03:34:13,803 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:34:13,803 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:34:13,803 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de oorzaamheid van dit specifieke probleem van dit specifieke probleem.
2023-05-28 03:34:13,803 - INFO - joeynmt.training - Example #2
2023-05-28 03:34:13,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:34:13,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:34:13,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'la@@', 'gen', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:34:13,803 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:34:13,803 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:34:13,803 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het lagen van onze wereldwijde klimaatsysteem.
2023-05-28 03:34:13,803 - INFO - joeynmt.training - Example #3
2023-05-28 03:34:13,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:34:13,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:34:13,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:34:13,803 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:34:13,803 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:34:13,803 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en scheppen in de zomer.
2023-05-28 03:34:13,803 - INFO - joeynmt.training - Example #4
2023-05-28 03:34:13,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:34:13,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:34:13,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'ende', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 03:34:13,804 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:34:13,804 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:34:13,804 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie jullie tonen is een tijdtrafferende 25 jaar.
2023-05-28 03:34:36,034 - INFO - joeynmt.training - Epoch   6, Step:    25100, Batch Loss:     1.494404, Batch Acc: 0.539635, Tokens per Sec:     3148, Lr: 0.000300
2023-05-28 03:34:58,728 - INFO - joeynmt.training - Epoch   6, Step:    25200, Batch Loss:     1.600891, Batch Acc: 0.542700, Tokens per Sec:     3055, Lr: 0.000300
2023-05-28 03:35:20,739 - INFO - joeynmt.training - Epoch   6, Step:    25300, Batch Loss:     1.552237, Batch Acc: 0.540208, Tokens per Sec:     3187, Lr: 0.000300
2023-05-28 03:35:42,678 - INFO - joeynmt.training - Epoch   6, Step:    25400, Batch Loss:     1.500836, Batch Acc: 0.536120, Tokens per Sec:     3312, Lr: 0.000300
2023-05-28 03:36:04,498 - INFO - joeynmt.training - Epoch   6, Step:    25500, Batch Loss:     1.726325, Batch Acc: 0.541365, Tokens per Sec:     3162, Lr: 0.000300
2023-05-28 03:36:04,499 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:36:04,499 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:37:09,690 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.47, acc:   0.51, generation: 65.0980[sec], evaluation: 0.0000[sec]
2023-05-28 03:37:09,778 - INFO - joeynmt.helpers - delete models/transformer_b/23000.ckpt
2023-05-28 03:37:09,791 - INFO - joeynmt.training - Example #0
2023-05-28 03:37:09,791 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:37:09,791 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:37:09,791 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'oor@@', 'dat', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'lie@@', 'f@@', 'de', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'h@@', 'and', 'van', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'die', 'gro@@', 'ter', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 03:37:09,791 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:37:09,791 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:37:09,791 - INFO - joeynmt.training - 	Hypothesis: Voordat jaar heb ik deze twee dia getoond om te verliefde dat de artische ijskappen die voor de hand van de drie miljoen jaar die groter van de onderste 40 procent.
2023-05-28 03:37:09,791 - INFO - joeynmt.training - Example #1
2023-05-28 03:37:09,791 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:37:09,791 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:37:09,791 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'de', 'in@@', 'v@@', 'l@@', 'oe@@', 'd', 'de', 'eerste', 'n@@', 'i@@', 've@@', 'au', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 03:37:09,792 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:37:09,792 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:37:09,792 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet de invloed de eerste niveau van dit speciale probleem, want het is het niet de dikke van het ijs.
2023-05-28 03:37:09,792 - INFO - joeynmt.training - Example #2
2023-05-28 03:37:09,792 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:37:09,792 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:37:09,792 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'dat', 'het', 'uit@@', 'ein@@', 'delijk', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:37:09,792 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:37:09,792 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:37:09,792 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart dat het uiteindelijk van onze wereldwijd klimaatsysteem.
2023-05-28 03:37:09,792 - INFO - joeynmt.training - Example #3
2023-05-28 03:37:09,792 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:37:09,792 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:37:09,792 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'pen', '.', '</s>']
2023-05-28 03:37:09,792 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:37:09,792 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:37:09,792 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schrompen.
2023-05-28 03:37:09,793 - INFO - joeynmt.training - Example #4
2023-05-28 03:37:09,793 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:37:09,793 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:37:09,793 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'ende', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 03:37:09,793 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:37:09,794 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:37:09,794 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie tonen is een tijdtrafferende 25 jaar.
2023-05-28 03:37:31,479 - INFO - joeynmt.training - Epoch   6, Step:    25600, Batch Loss:     1.629319, Batch Acc: 0.538619, Tokens per Sec:     3145, Lr: 0.000300
2023-05-28 03:37:54,230 - INFO - joeynmt.training - Epoch   6, Step:    25700, Batch Loss:     1.467200, Batch Acc: 0.537556, Tokens per Sec:     3031, Lr: 0.000300
2023-05-28 03:38:16,016 - INFO - joeynmt.training - Epoch   6, Step:    25800, Batch Loss:     1.644245, Batch Acc: 0.539353, Tokens per Sec:     3261, Lr: 0.000300
2023-05-28 03:38:37,747 - INFO - joeynmt.training - Epoch   6, Step:    25900, Batch Loss:     1.587478, Batch Acc: 0.542302, Tokens per Sec:     3242, Lr: 0.000300
2023-05-28 03:38:59,853 - INFO - joeynmt.training - Epoch   6, Step:    26000, Batch Loss:     1.578062, Batch Acc: 0.533386, Tokens per Sec:     3152, Lr: 0.000300
2023-05-28 03:38:59,853 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:38:59,854 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:40:07,030 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.43, acc:   0.51, generation: 67.0816[sec], evaluation: 0.0000[sec]
2023-05-28 03:40:07,033 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:40:07,114 - INFO - joeynmt.helpers - delete models/transformer_b/23500.ckpt
2023-05-28 03:40:07,124 - INFO - joeynmt.training - Example #0
2023-05-28 03:40:07,124 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:40:07,124 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:40:07,124 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'en', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'anderen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'k@@', 'app@@', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'k@@', 'app@@', 'ar@@', 'ti@@', 'sche', 'e@@', 'ce@@', 's@@', 'vo@@', 'l', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 03:40:07,124 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:40:07,124 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:40:07,124 - INFO - joeynmt.training - 	Hypothesis: Ten jaar heb ik deze twee getoond getoond om te veranderen dat de artische eiskappartische eiskappartische ecesvol van de onderste 40 procent.
2023-05-28 03:40:07,124 - INFO - joeynmt.training - Example #1
2023-05-28 03:40:07,124 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:40:07,124 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:40:07,124 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'veel', 'genoe@@', 'g', 'de', 'aar@@', 'de', 'is', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'in@@', 'z@@', 'icht', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.', '</s>']
2023-05-28 03:40:07,125 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:40:07,125 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:40:07,125 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet veel genoeg de aarde is van dit speciale probleem, omdat het niet de inzicht van het ijs laat zien.
2023-05-28 03:40:07,125 - INFO - joeynmt.training - Example #2
2023-05-28 03:40:07,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:40:07,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:40:07,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'la@@', 'gen', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:40:07,125 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:40:07,125 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:40:07,125 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het lagen van ons wereldwijde klimaatsysteem.
2023-05-28 03:40:07,125 - INFO - joeynmt.training - Example #3
2023-05-28 03:40:07,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:40:07,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:40:07,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:40:07,125 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:40:07,125 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:40:07,125 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schrompt in de zomer.
2023-05-28 03:40:07,125 - INFO - joeynmt.training - Example #4
2023-05-28 03:40:07,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:40:07,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:40:07,126 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'is', 'dat', 'ik', 'jullie', 't@@', 'on@@', 'en', ',', 'is', 'een', 't@@', 'ra@@', 'ff@@', 'er@@', 'op@@', 'nam@@', 'e', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 03:40:07,126 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:40:07,126 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:40:07,126 - INFO - joeynmt.training - 	Hypothesis: De volgende dia is dat ik jullie tonen, is een trafferopname wat er in de afgelopen 25 jaar gebeurt.
2023-05-28 03:40:29,202 - INFO - joeynmt.training - Epoch   6, Step:    26100, Batch Loss:     1.571217, Batch Acc: 0.538445, Tokens per Sec:     3180, Lr: 0.000300
2023-05-28 03:40:51,062 - INFO - joeynmt.training - Epoch   6, Step:    26200, Batch Loss:     1.600545, Batch Acc: 0.540533, Tokens per Sec:     3139, Lr: 0.000300
2023-05-28 03:41:13,368 - INFO - joeynmt.training - Epoch   6, Step:    26300, Batch Loss:     1.533232, Batch Acc: 0.542718, Tokens per Sec:     3140, Lr: 0.000300
2023-05-28 03:41:35,080 - INFO - joeynmt.training - Epoch   6, Step:    26400, Batch Loss:     1.562370, Batch Acc: 0.536351, Tokens per Sec:     3274, Lr: 0.000300
2023-05-28 03:41:57,286 - INFO - joeynmt.training - Epoch   6, Step:    26500, Batch Loss:     1.476076, Batch Acc: 0.539746, Tokens per Sec:     3165, Lr: 0.000300
2023-05-28 03:41:57,287 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:41:57,287 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:43:00,929 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.40, acc:   0.52, generation: 63.5470[sec], evaluation: 0.0000[sec]
2023-05-28 03:43:00,930 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:43:01,027 - INFO - joeynmt.helpers - delete models/transformer_b/24500.ckpt
2023-05-28 03:43:01,038 - INFO - joeynmt.training - Example #0
2023-05-28 03:43:01,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:43:01,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:43:01,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'oor@@', 'dat', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'te', 'ver@@', 'to@@', 'on@@', 'den', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', '-@@', 'ij@@', 's@@', '-@@', 'ij@@', 's@@', '-@@', 'ij@@', 's@@', '-@@', '-@@', 'en@@', '-@@', 'en@@', '-@@', 'Amerik@@', 'aan@@', 'se', 'op@@', 'lo@@', 'ss@@', 'ing', '.', '</s>']
2023-05-28 03:43:01,039 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:43:01,039 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:43:01,039 - INFO - joeynmt.training - 	Hypothesis: Voordat ik deze twee dia getoond te vertoonden om te verwijderen dat de artische ijs-ijs-ijs-ijs--en-en-Amerikaanse oplossing.
2023-05-28 03:43:01,039 - INFO - joeynmt.training - Example #1
2023-05-28 03:43:01,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:43:01,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:43:01,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'n@@', 'aa@@', 'st', 'de', 'eerste', 'sta@@', 'p', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', '.', '</s>']
2023-05-28 03:43:01,039 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:43:01,039 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:43:01,039 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste naast de eerste stap van dit specifieke probleem.
2023-05-28 03:43:01,039 - INFO - joeynmt.training - Example #2
2023-05-28 03:43:01,040 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:43:01,040 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:43:01,040 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'ot', ',', 'het', 'is', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:43:01,040 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:43:01,040 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:43:01,040 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapot, het is ons wereldwijde klimaatsysteem.
2023-05-28 03:43:01,040 - INFO - joeynmt.training - Example #3
2023-05-28 03:43:01,040 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:43:01,040 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:43:01,040 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:43:01,040 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:43:01,040 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:43:01,040 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schrompt in de zomer.
2023-05-28 03:43:01,040 - INFO - joeynmt.training - Example #4
2023-05-28 03:43:01,040 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:43:01,040 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:43:01,040 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'je', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd', '.', '</s>']
2023-05-28 03:43:01,040 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:43:01,040 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:43:01,040 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdje wat er in de laatste 25 jaar gebeurd.
2023-05-28 03:43:23,830 - INFO - joeynmt.training - Epoch   6, Step:    26600, Batch Loss:     1.534817, Batch Acc: 0.537032, Tokens per Sec:     3055, Lr: 0.000300
2023-05-28 03:43:30,192 - INFO - joeynmt.training - Epoch   6: total training loss 7116.90
2023-05-28 03:43:30,192 - INFO - joeynmt.training - EPOCH 7
2023-05-28 03:43:30,222 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=6
2023-05-28 03:43:45,609 - INFO - joeynmt.training - Epoch   7, Step:    26700, Batch Loss:     1.770001, Batch Acc: 0.550719, Tokens per Sec:     3270, Lr: 0.000300
2023-05-28 03:44:07,064 - INFO - joeynmt.training - Epoch   7, Step:    26800, Batch Loss:     1.513717, Batch Acc: 0.550605, Tokens per Sec:     3203, Lr: 0.000300
2023-05-28 03:44:29,380 - INFO - joeynmt.training - Epoch   7, Step:    26900, Batch Loss:     1.493719, Batch Acc: 0.543321, Tokens per Sec:     3159, Lr: 0.000300
2023-05-28 03:44:52,714 - INFO - joeynmt.training - Epoch   7, Step:    27000, Batch Loss:     1.891861, Batch Acc: 0.550947, Tokens per Sec:     2949, Lr: 0.000300
2023-05-28 03:44:52,714 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:44:52,714 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:45:41,801 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.40, acc:   0.52, generation: 48.9896[sec], evaluation: 0.0000[sec]
2023-05-28 03:45:41,803 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:45:41,906 - INFO - joeynmt.helpers - delete models/transformer_b/24000.ckpt
2023-05-28 03:45:41,918 - INFO - joeynmt.training - Example #0
2023-05-28 03:45:41,918 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:45:41,918 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:45:41,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'ol@@', 'i@@', 'ë', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'onder@@', 'aan', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 03:45:41,919 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:45:41,919 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:45:41,919 - INFO - joeynmt.training - 	Hypothesis: Volië heb ik deze twee dia getoond om te verbekijken dat de artische ijskappen die voor de artische eskappen die onderaan 40 procent.
2023-05-28 03:45:41,919 - INFO - joeynmt.training - Example #1
2023-05-28 03:45:41,919 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:45:41,919 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:45:41,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'ver@@', 'n@@', 'u@@', 'l', 'van', 'het', 'e@@', 'ven@@', 'eens', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't', '.', '</s>']
2023-05-28 03:45:41,919 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:45:41,919 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:45:41,919 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste vernul van het eveneens, want het is het niet de dikke van het ijs toont.
2023-05-28 03:45:41,919 - INFO - joeynmt.training - Example #2
2023-05-28 03:45:41,919 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:45:41,919 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:45:41,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:45:41,920 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:45:41,920 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:45:41,920 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het hart van onze wereldwijde klimaatsysteem.
2023-05-28 03:45:41,920 - INFO - joeynmt.training - Example #3
2023-05-28 03:45:41,920 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:45:41,920 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:45:41,920 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:45:41,920 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:45:41,920 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:45:41,920 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schroeppen in de zomer.
2023-05-28 03:45:41,920 - INFO - joeynmt.training - Example #4
2023-05-28 03:45:41,920 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:45:41,920 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:45:41,920 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'to@@', 'on@@', 't', 'zien', 'is', 'een', 'tij@@', 'd@@', 'op@@', 'er@@', 'ie', 'van', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 03:45:41,920 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:45:41,920 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:45:41,920 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie toont zien is een tijdoperie van 25 jaar.
2023-05-28 03:46:05,324 - INFO - joeynmt.training - Epoch   7, Step:    27100, Batch Loss:     1.342062, Batch Acc: 0.549061, Tokens per Sec:     3036, Lr: 0.000300
2023-05-28 03:46:26,838 - INFO - joeynmt.training - Epoch   7, Step:    27200, Batch Loss:     1.556501, Batch Acc: 0.548284, Tokens per Sec:     3278, Lr: 0.000300
2023-05-28 03:46:47,851 - INFO - joeynmt.training - Epoch   7, Step:    27300, Batch Loss:     1.452173, Batch Acc: 0.548162, Tokens per Sec:     3380, Lr: 0.000300
2023-05-28 03:47:09,392 - INFO - joeynmt.training - Epoch   7, Step:    27400, Batch Loss:     1.607339, Batch Acc: 0.544163, Tokens per Sec:     3257, Lr: 0.000300
2023-05-28 03:47:30,784 - INFO - joeynmt.training - Epoch   7, Step:    27500, Batch Loss:     1.641490, Batch Acc: 0.550463, Tokens per Sec:     3289, Lr: 0.000300
2023-05-28 03:47:30,786 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:47:30,786 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:48:38,197 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.37, acc:   0.52, generation: 67.3154[sec], evaluation: 0.0000[sec]
2023-05-28 03:48:38,198 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:48:38,296 - INFO - joeynmt.helpers - delete models/transformer_b/25500.ckpt
2023-05-28 03:48:38,306 - INFO - joeynmt.training - Example #0
2023-05-28 03:48:38,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:48:38,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:48:38,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'to@@', 'ond', 'te', 'ver@@', 'to@@', 'ond', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'hu@@', 'id@@', 'ige', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'van', 'de', 'drie', 'miljo@@', 'en', 'jaar', ',', 'de', 'gro@@', 'ot', 'van', 'de', 'gro@@', 'ot', 'is', '.', '</s>']
2023-05-28 03:48:38,307 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:48:38,307 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:48:38,307 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee getoond deze twee getoond om te vertoond te vertoond dat de artische ijskappen die voor de huidige ijskappen die van de drie miljoen jaar, de groot van de groot is.
2023-05-28 03:48:38,307 - INFO - joeynmt.training - Example #1
2023-05-28 03:48:38,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:48:38,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:48:38,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'aar@@', 'de', ',', 'omdat', 'het', 'ge@@', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'het', 'ij@@', 's@@', 'heid', 'van', 'het', 'ij@@', 's@@', 'm@@', 'ati@@', 'g', '.', '</s>']
2023-05-28 03:48:38,307 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:48:38,307 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:48:38,307 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aarde, omdat het gespeciale probleem van het ijsheid van het ijsmatig.
2023-05-28 03:48:38,307 - INFO - joeynmt.training - Example #2
2023-05-28 03:48:38,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:48:38,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:48:38,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'g', 'het', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'het', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:48:38,307 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:48:38,307 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:48:38,307 - INFO - joeynmt.training - 	Hypothesis: In zeg het artische ijskappen van het wereldwijde klimaatsysteem.
2023-05-28 03:48:38,307 - INFO - joeynmt.training - Example #3
2023-05-28 03:48:38,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:48:38,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:48:38,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'er@@', 'p@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:48:38,308 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:48:38,308 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:48:38,308 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en scherppen in de zomer.
2023-05-28 03:48:38,308 - INFO - joeynmt.training - Example #4
2023-05-28 03:48:38,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:48:38,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:48:38,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', ',', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 03:48:38,308 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:48:38,308 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:48:38,308 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie laat zien is een tijdje, is een tijdje van de afgelopen 25 jaar.
2023-05-28 03:49:00,461 - INFO - joeynmt.training - Epoch   7, Step:    27600, Batch Loss:     1.523253, Batch Acc: 0.540169, Tokens per Sec:     3107, Lr: 0.000300
2023-05-28 03:49:21,293 - INFO - joeynmt.training - Epoch   7, Step:    27700, Batch Loss:     1.509940, Batch Acc: 0.546316, Tokens per Sec:     3379, Lr: 0.000300
2023-05-28 03:49:42,994 - INFO - joeynmt.training - Epoch   7, Step:    27800, Batch Loss:     1.440825, Batch Acc: 0.543814, Tokens per Sec:     3159, Lr: 0.000300
2023-05-28 03:50:03,934 - INFO - joeynmt.training - Epoch   7, Step:    27900, Batch Loss:     1.650679, Batch Acc: 0.543162, Tokens per Sec:     3427, Lr: 0.000300
2023-05-28 03:50:24,816 - INFO - joeynmt.training - Epoch   7, Step:    28000, Batch Loss:     1.421236, Batch Acc: 0.546655, Tokens per Sec:     3235, Lr: 0.000300
2023-05-28 03:50:24,816 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:50:24,816 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:51:27,165 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.40, acc:   0.52, generation: 62.2558[sec], evaluation: 0.0000[sec]
2023-05-28 03:51:27,256 - INFO - joeynmt.helpers - delete models/transformer_b/25000.ckpt
2023-05-28 03:51:27,265 - INFO - joeynmt.training - Example #0
2023-05-28 03:51:27,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:51:27,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:51:27,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'ol@@', 'ie@@', 'der', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'A@@', 'f@@', 'en@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'de', 'sta@@', 'd', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'lie@@', 'ten', '.', '</s>']
2023-05-28 03:51:27,266 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:51:27,266 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:51:27,266 - INFO - joeynmt.training - 	Hypothesis: Volieder jaar heb ik deze twee dia om te verwijderen te zien dat de artische ijskappen die voor de Afentische ijskappen van de stad, om 40 procent te verlieten.
2023-05-28 03:51:27,266 - INFO - joeynmt.training - Example #1
2023-05-28 03:51:27,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:51:27,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:51:27,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'in@@', 'st@@', 'ort@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'w@@', 'aa@@', 'd', '.', '</s>']
2023-05-28 03:51:27,266 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:51:27,266 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:51:27,266 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste instorting van dit speciale probleem, want het is niet de dikke van het ijskwaad.
2023-05-28 03:51:27,266 - INFO - joeynmt.training - Example #2
2023-05-28 03:51:27,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:51:27,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:51:27,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:51:27,267 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:51:27,267 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:51:27,267 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het hart van ons wereldwijde klimaatsysteem.
2023-05-28 03:51:27,267 - INFO - joeynmt.training - Example #3
2023-05-28 03:51:27,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:51:27,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:51:27,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:51:27,267 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:51:27,267 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:51:27,267 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomer in de zomer.
2023-05-28 03:51:27,267 - INFO - joeynmt.training - Example #4
2023-05-28 03:51:27,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:51:27,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:51:27,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'op@@', 'nam@@', 'e', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 03:51:27,267 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:51:27,267 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:51:27,267 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie tonen is een tijdtrafferopname van de laatste 25 jaar.
2023-05-28 03:51:50,246 - INFO - joeynmt.training - Epoch   7, Step:    28100, Batch Loss:     1.576655, Batch Acc: 0.543957, Tokens per Sec:     3054, Lr: 0.000300
2023-05-28 03:52:12,378 - INFO - joeynmt.training - Epoch   7, Step:    28200, Batch Loss:     1.661563, Batch Acc: 0.546328, Tokens per Sec:     3193, Lr: 0.000300
2023-05-28 03:52:35,390 - INFO - joeynmt.training - Epoch   7, Step:    28300, Batch Loss:     1.591059, Batch Acc: 0.552328, Tokens per Sec:     3119, Lr: 0.000300
2023-05-28 03:52:57,543 - INFO - joeynmt.training - Epoch   7, Step:    28400, Batch Loss:     1.433138, Batch Acc: 0.554433, Tokens per Sec:     3267, Lr: 0.000300
2023-05-28 03:53:21,149 - INFO - joeynmt.training - Epoch   7, Step:    28500, Batch Loss:     1.534198, Batch Acc: 0.544777, Tokens per Sec:     3026, Lr: 0.000300
2023-05-28 03:53:21,149 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:53:21,150 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:54:39,028 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.35, acc:   0.52, generation: 77.7811[sec], evaluation: 0.0000[sec]
2023-05-28 03:54:39,030 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:54:39,124 - INFO - joeynmt.helpers - delete models/transformer_b/26000.ckpt
2023-05-28 03:54:39,133 - INFO - joeynmt.training - Example #0
2023-05-28 03:54:39,133 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:54:39,133 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:54:39,133 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aat@@', 'je', ',', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'to@@', 'on@@', 't', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'te@@', 'ment', 'van', 'drie', 'miljo@@', 'en', 'jaar', ',', 'de', 'gr@@', 'ens', 'van', 'de', 'gro@@', 'ter', 'van', '4@@', '0', '%', '.', '</s>']
2023-05-28 03:54:39,134 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:54:39,134 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:54:39,134 - INFO - joeynmt.training - 	Hypothesis: Laatje, jaar heb ik deze twee getoond om te vertoont te verwijderen dat de artische ijskappartement van drie miljoen jaar, de grens van de groter van 40%.
2023-05-28 03:54:39,134 - INFO - joeynmt.training - Example #1
2023-05-28 03:54:39,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:54:39,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:54:39,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'dat', 'het', 'ge@@', 'eft', ',', 'is', 'dat', 'de', 'eerste', 'be@@', 'ste', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'w@@', 'aa@@', 'd', '.', '</s>']
2023-05-28 03:54:39,134 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:54:39,134 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:54:39,134 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet dat het geeft, is dat de eerste beste van dit speciale probleem, want het is niet de dikke van het ijskwaad.
2023-05-28 03:54:39,134 - INFO - joeynmt.training - Example #2
2023-05-28 03:54:39,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:54:39,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:54:39,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 't', ',', 'het', 'is', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:54:39,135 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:54:39,135 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:54:39,135 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapt, het is het hart van ons wereldwijde klimaatsysteem.
2023-05-28 03:54:39,135 - INFO - joeynmt.training - Example #3
2023-05-28 03:54:39,135 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:54:39,135 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:54:39,135 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'sch@@', 'ru@@', 'st@@', 'm@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:54:39,135 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:54:39,135 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:54:39,135 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer en schrustmt in de zomer.
2023-05-28 03:54:39,135 - INFO - joeynmt.training - Example #4
2023-05-28 03:54:39,135 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:54:39,135 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:54:39,135 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 03:54:39,135 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:54:39,135 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:54:39,135 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdperk van 25 jaar gebeurt.
2023-05-28 03:55:02,464 - INFO - joeynmt.training - Epoch   7, Step:    28600, Batch Loss:     1.537559, Batch Acc: 0.548883, Tokens per Sec:     3001, Lr: 0.000300
2023-05-28 03:55:25,859 - INFO - joeynmt.training - Epoch   7, Step:    28700, Batch Loss:     1.598244, Batch Acc: 0.551809, Tokens per Sec:     2998, Lr: 0.000300
2023-05-28 03:55:47,952 - INFO - joeynmt.training - Epoch   7, Step:    28800, Batch Loss:     1.536423, Batch Acc: 0.547190, Tokens per Sec:     3173, Lr: 0.000300
2023-05-28 03:56:11,836 - INFO - joeynmt.training - Epoch   7, Step:    28900, Batch Loss:     1.597859, Batch Acc: 0.549017, Tokens per Sec:     2879, Lr: 0.000300
2023-05-28 03:56:35,702 - INFO - joeynmt.training - Epoch   7, Step:    29000, Batch Loss:     1.597490, Batch Acc: 0.548276, Tokens per Sec:     3044, Lr: 0.000300
2023-05-28 03:56:35,703 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:56:35,703 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 03:57:51,535 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.32, acc:   0.52, generation: 75.7359[sec], evaluation: 0.0000[sec]
2023-05-28 03:57:51,538 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 03:57:51,620 - INFO - joeynmt.helpers - delete models/transformer_b/26500.ckpt
2023-05-28 03:57:51,632 - INFO - joeynmt.training - Example #0
2023-05-28 03:57:51,632 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 03:57:51,632 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 03:57:51,632 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'deze', 'twee', 'di@@', 'a', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'gele@@', 'den', 'die', 'onder@@', 'wij@@', 's', 'van', 'de', 'jaren', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'onder@@', 'wij@@', 's', ',', 'om', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 03:57:51,633 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 03:57:51,633 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 03:57:51,633 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia getoond deze twee dia om te bekijken dat de artische ijskappen die voor de drie miljoen jaar geleden die onderwijs van de jaren 's onderwijs, om 40 procent.
2023-05-28 03:57:51,633 - INFO - joeynmt.training - Example #1
2023-05-28 03:57:51,633 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 03:57:51,633 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 03:57:51,633 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'n@@', 'st@@', 'ro@@', 'm@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't', '.', '</s>']
2023-05-28 03:57:51,633 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 03:57:51,633 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 03:57:51,633 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de eerste eerste nstroming van dit speciale probleem, omdat het niet de dikke van het ijs toont.
2023-05-28 03:57:51,633 - INFO - joeynmt.training - Example #2
2023-05-28 03:57:51,633 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 03:57:51,633 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 03:57:51,633 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'mo@@', 'gelijk', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 03:57:51,634 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 03:57:51,634 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 03:57:51,634 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het mogelijk van onze wereldwijde klimaatsysteem.
2023-05-28 03:57:51,634 - INFO - joeynmt.training - Example #3
2023-05-28 03:57:51,634 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 03:57:51,634 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 03:57:51,634 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'k@@', 'ken@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 03:57:51,634 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 03:57:51,634 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 03:57:51,634 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schokkent in de zomer.
2023-05-28 03:57:51,634 - INFO - joeynmt.training - Example #4
2023-05-28 03:57:51,634 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 03:57:51,634 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 03:57:51,634 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de', '.', '</s>']
2023-05-28 03:57:51,634 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 03:57:51,634 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 03:57:51,634 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie tonen is een tijdperk van de laatste 25 jaar gebeurde.
2023-05-28 03:58:14,913 - INFO - joeynmt.training - Epoch   7, Step:    29100, Batch Loss:     1.632900, Batch Acc: 0.547943, Tokens per Sec:     2993, Lr: 0.000300
2023-05-28 03:58:38,657 - INFO - joeynmt.training - Epoch   7, Step:    29200, Batch Loss:     1.357074, Batch Acc: 0.545734, Tokens per Sec:     2958, Lr: 0.000300
2023-05-28 03:59:02,412 - INFO - joeynmt.training - Epoch   7, Step:    29300, Batch Loss:     1.436032, Batch Acc: 0.549409, Tokens per Sec:     2925, Lr: 0.000300
2023-05-28 03:59:25,201 - INFO - joeynmt.training - Epoch   7, Step:    29400, Batch Loss:     1.604466, Batch Acc: 0.546245, Tokens per Sec:     3094, Lr: 0.000300
2023-05-28 03:59:50,282 - INFO - joeynmt.training - Epoch   7, Step:    29500, Batch Loss:     1.610650, Batch Acc: 0.543883, Tokens per Sec:     2786, Lr: 0.000300
2023-05-28 03:59:50,283 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 03:59:50,283 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:01:00,897 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.32, acc:   0.52, generation: 70.5179[sec], evaluation: 0.0000[sec]
2023-05-28 04:01:00,899 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 04:01:00,994 - INFO - joeynmt.helpers - delete models/transformer_b/28000.ckpt
2023-05-28 04:01:01,006 - INFO - joeynmt.training - Example #0
2023-05-28 04:01:01,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:01:01,006 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:01:01,006 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'oor', 'het', 'jaar', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'af@@', 'kom@@', 'st@@', 'ig', 'van', 'de', 'onder@@', 'e', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:01:01,006 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:01:01,006 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:01:01,006 - INFO - joeynmt.training - 	Hypothesis: Voor het jaar jaar heb ik deze twee dia getoond om te verwijderen dat de artische ijskappen die voor de afkomstig van de ondere 40 procent.
2023-05-28 04:01:01,006 - INFO - joeynmt.training - Example #1
2023-05-28 04:01:01,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:01:01,007 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:01:01,007 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'oor@@', 'st@@', 'rij@@', 'd', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', '.', '</s>']
2023-05-28 04:01:01,007 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:01:01,007 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:01:01,007 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de oorstrijd van dit speciale probleem, want het is niet de dikke probleem, want het is niet de dikke van het ijs laat.
2023-05-28 04:01:01,007 - INFO - joeynmt.training - Example #2
2023-05-28 04:01:01,007 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:01:01,007 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:01:01,007 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 'z@@', 'er', 'is', 'het', 'on@@', 's@@', 'zelf', 'van', 'onze', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:01:01,007 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:01:01,007 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:01:01,007 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijzer is het onszelf van onze globale klimaatsysteem.
2023-05-28 04:01:01,007 - INFO - joeynmt.training - Example #3
2023-05-28 04:01:01,007 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:01:01,007 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:01:01,007 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'rij@@', 'ver', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:01:01,007 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:01:01,007 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:01:01,007 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schrijver in de zomer.
2023-05-28 04:01:01,007 - INFO - joeynmt.training - Example #4
2023-05-28 04:01:01,008 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:01:01,008 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:01:01,008 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'ende', 'op@@', 'z@@', 'ich@@', 'te', 'van', '2@@', '5', 'jaar', 'gebeur@@', 'de', '.', '</s>']
2023-05-28 04:01:01,008 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:01:01,008 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:01:01,008 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdtrafferende opzichte van 25 jaar gebeurde.
2023-05-28 04:01:22,575 - INFO - joeynmt.training - Epoch   7, Step:    29600, Batch Loss:     1.578678, Batch Acc: 0.543325, Tokens per Sec:     3105, Lr: 0.000300
2023-05-28 04:01:42,688 - INFO - joeynmt.training - Epoch   7, Step:    29700, Batch Loss:     1.299791, Batch Acc: 0.547483, Tokens per Sec:     3527, Lr: 0.000300
2023-05-28 04:02:03,536 - INFO - joeynmt.training - Epoch   7, Step:    29800, Batch Loss:     1.517756, Batch Acc: 0.542701, Tokens per Sec:     3440, Lr: 0.000300
2023-05-28 04:02:24,513 - INFO - joeynmt.training - Epoch   7, Step:    29900, Batch Loss:     1.473283, Batch Acc: 0.549658, Tokens per Sec:     3419, Lr: 0.000300
2023-05-28 04:02:46,717 - INFO - joeynmt.training - Epoch   7, Step:    30000, Batch Loss:     1.525886, Batch Acc: 0.545048, Tokens per Sec:     3200, Lr: 0.000300
2023-05-28 04:02:46,719 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:02:46,719 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:04:08,388 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.30, acc:   0.52, generation: 81.5738[sec], evaluation: 0.0000[sec]
2023-05-28 04:04:08,392 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 04:04:08,504 - INFO - joeynmt.helpers - delete models/transformer_b/27000.ckpt
2023-05-28 04:04:08,514 - INFO - joeynmt.training - Example #0
2023-05-28 04:04:08,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:04:08,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:04:08,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'vol@@', 'gens', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'ce@@', 's@@', 'vo@@', 'l', 'van', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ter', 'van', 'de', 'onder@@', 'e', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:04:08,515 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:04:08,515 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:04:08,515 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia getoond om te vervolgens te verwijderen dat de artische ecesvol van drie miljoen jaar de groter van de ondere 40 procent.
2023-05-28 04:04:08,515 - INFO - joeynmt.training - Example #1
2023-05-28 04:04:08,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:04:08,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:04:08,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'n@@', 'i@@', 've@@', 'au', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's@@', 'e', '.', '</s>']
2023-05-28 04:04:08,515 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:04:08,515 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:04:08,515 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste niveau van dit specifieke probleem, want het is niet de dik van het ijse.
2023-05-28 04:04:08,515 - INFO - joeynmt.training - Example #2
2023-05-28 04:04:08,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:04:08,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:04:08,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:04:08,516 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:04:08,516 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:04:08,516 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape van onze wereldwijde klimaatsysteem.
2023-05-28 04:04:08,516 - INFO - joeynmt.training - Example #3
2023-05-28 04:04:08,516 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:04:08,516 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:04:08,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 're@@', 'e@@', 'p@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:04:08,516 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:04:08,516 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:04:08,516 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schreeppen in de zomer.
2023-05-28 04:04:08,516 - INFO - joeynmt.training - Example #4
2023-05-28 04:04:08,516 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:04:08,516 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:04:08,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 04:04:08,516 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:04:08,516 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:04:08,516 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdje van de afgelopen 25 jaar gebeurde in de afgelopen 25 jaar.
2023-05-28 04:04:31,054 - INFO - joeynmt.training - Epoch   7, Step:    30100, Batch Loss:     1.617305, Batch Acc: 0.548918, Tokens per Sec:     3108, Lr: 0.000300
2023-05-28 04:04:53,936 - INFO - joeynmt.training - Epoch   7, Step:    30200, Batch Loss:     1.467525, Batch Acc: 0.552017, Tokens per Sec:     3149, Lr: 0.000300
2023-05-28 04:05:16,129 - INFO - joeynmt.training - Epoch   7, Step:    30300, Batch Loss:     1.727184, Batch Acc: 0.546523, Tokens per Sec:     3172, Lr: 0.000300
2023-05-28 04:05:37,809 - INFO - joeynmt.training - Epoch   7, Step:    30400, Batch Loss:     1.651543, Batch Acc: 0.549640, Tokens per Sec:     3139, Lr: 0.000300
2023-05-28 04:05:59,616 - INFO - joeynmt.training - Epoch   7, Step:    30500, Batch Loss:     1.743140, Batch Acc: 0.552979, Tokens per Sec:     3249, Lr: 0.000300
2023-05-28 04:05:59,617 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:05:59,617 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:07:07,014 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.27, acc:   0.52, generation: 67.3047[sec], evaluation: 0.0000[sec]
2023-05-28 04:07:07,015 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 04:07:07,117 - INFO - joeynmt.helpers - delete models/transformer_b/27500.ckpt
2023-05-28 04:07:07,128 - INFO - joeynmt.training - Example #0
2023-05-28 04:07:07,128 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:07:07,128 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:07:07,128 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'ie@@', 't', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'anderen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'eerste', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'er', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:07:07,129 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:07:07,129 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:07:07,129 - INFO - joeynmt.training - 	Hypothesis: Niet jaar heb ik deze twee dia getoond om te veranderen dat de artische ijskappen die voor de eerste ijskappen die er 40 procent.
2023-05-28 04:07:07,129 - INFO - joeynmt.training - Example #1
2023-05-28 04:07:07,129 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:07:07,129 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:07:07,129 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'n@@', 'st@@', 'ij@@', 'l', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 04:07:07,129 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:07:07,129 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:07:07,129 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste nstijl van dit specifieke probleem, want het is niet de dikke van het ijs.
2023-05-28 04:07:07,129 - INFO - joeynmt.training - Example #2
2023-05-28 04:07:07,129 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:07:07,129 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:07:07,129 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'la@@', 'st@@', 'ig', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:07:07,129 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:07:07,129 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:07:07,129 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het lastig hart van ons wereldwijde klimaatsysteem.
2023-05-28 04:07:07,129 - INFO - joeynmt.training - Example #3
2023-05-28 04:07:07,130 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:07:07,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:07:07,130 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:07:07,130 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:07:07,130 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:07:07,130 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomer.
2023-05-28 04:07:07,130 - INFO - joeynmt.training - Example #4
2023-05-28 04:07:07,130 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:07:07,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:07:07,130 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'zien', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'ende', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 04:07:07,130 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:07:07,130 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:07:07,130 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie zien is een tijdtrafferende 25 jaar.
2023-05-28 04:07:30,092 - INFO - joeynmt.training - Epoch   7, Step:    30600, Batch Loss:     1.513229, Batch Acc: 0.547077, Tokens per Sec:     3055, Lr: 0.000300
2023-05-28 04:07:51,568 - INFO - joeynmt.training - Epoch   7, Step:    30700, Batch Loss:     1.831753, Batch Acc: 0.547950, Tokens per Sec:     3325, Lr: 0.000300
2023-05-28 04:08:13,721 - INFO - joeynmt.training - Epoch   7, Step:    30800, Batch Loss:     1.474679, Batch Acc: 0.551077, Tokens per Sec:     3153, Lr: 0.000300
2023-05-28 04:08:35,117 - INFO - joeynmt.training - Epoch   7, Step:    30900, Batch Loss:     1.673626, Batch Acc: 0.550974, Tokens per Sec:     3247, Lr: 0.000300
2023-05-28 04:08:56,889 - INFO - joeynmt.training - Epoch   7, Step:    31000, Batch Loss:     1.597595, Batch Acc: 0.548051, Tokens per Sec:     3209, Lr: 0.000300
2023-05-28 04:08:56,889 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:08:56,889 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:10:12,587 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.27, acc:   0.52, generation: 75.6038[sec], evaluation: 0.0000[sec]
2023-05-28 04:10:12,678 - INFO - joeynmt.helpers - delete models/transformer_b/28500.ckpt
2023-05-28 04:10:12,691 - INFO - joeynmt.training - Example #0
2023-05-28 04:10:12,691 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:10:12,691 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:10:12,691 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'we', 'deze', 'twee', 'di@@', 'a', 'to@@', 'on@@', 'de', 'di@@', 'a', 'om', 'te', 'ver@@', 'anderen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:10:12,691 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:10:12,691 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:10:12,691 - INFO - joeynmt.training - 	Hypothesis: Laten we deze twee dia toonde dia om te veranderen dat de artische ijskappen die voor de artische ijskappen die voor de onderste 40 procent.
2023-05-28 04:10:12,691 - INFO - joeynmt.training - Example #1
2023-05-28 04:10:12,691 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:10:12,691 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:10:12,691 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'n@@', 'u@@', 'g', 'de', 'eerste', 'e@@', 'chte', 'proble@@', 'em', 'dat', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'is', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'heid', 'to@@', 'on@@', 't', '.', '</s>']
2023-05-28 04:10:12,691 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:10:12,692 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:10:12,692 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste nug de eerste echte probleem dat speciale probleem is, omdat het niet de dikke dikke van het ijsheid toont.
2023-05-28 04:10:12,692 - INFO - joeynmt.training - Example #2
2023-05-28 04:10:12,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:10:12,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:10:12,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:10:12,692 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:10:12,692 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:10:12,692 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape ijskape van ons wereldwijde klimaatsysteem.
2023-05-28 04:10:12,692 - INFO - joeynmt.training - Example #3
2023-05-28 04:10:12,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:10:12,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:10:12,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'on@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:10:12,692 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:10:12,692 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:10:12,692 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schoont in de zomer.
2023-05-28 04:10:12,692 - INFO - joeynmt.training - Example #4
2023-05-28 04:10:12,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:10:12,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:10:12,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er', 'wat', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 04:10:12,693 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:10:12,693 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:10:12,693 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdtraffer wat in de laatste 25 jaar gebeurt.
2023-05-28 04:10:33,251 - INFO - joeynmt.training - Epoch   7: total training loss 6981.10
2023-05-28 04:10:33,252 - INFO - joeynmt.training - EPOCH 8
2023-05-28 04:10:33,284 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=7
2023-05-28 04:10:34,834 - INFO - joeynmt.training - Epoch   8, Step:    31100, Batch Loss:     1.366047, Batch Acc: 0.555122, Tokens per Sec:     3568, Lr: 0.000300
2023-05-28 04:10:57,697 - INFO - joeynmt.training - Epoch   8, Step:    31200, Batch Loss:     1.417411, Batch Acc: 0.554034, Tokens per Sec:     2961, Lr: 0.000300
2023-05-28 04:11:20,043 - INFO - joeynmt.training - Epoch   8, Step:    31300, Batch Loss:     1.350365, Batch Acc: 0.559536, Tokens per Sec:     3233, Lr: 0.000300
2023-05-28 04:11:41,812 - INFO - joeynmt.training - Epoch   8, Step:    31400, Batch Loss:     1.687055, Batch Acc: 0.556743, Tokens per Sec:     3181, Lr: 0.000300
2023-05-28 04:12:04,939 - INFO - joeynmt.training - Epoch   8, Step:    31500, Batch Loss:     1.499497, Batch Acc: 0.559073, Tokens per Sec:     3050, Lr: 0.000300
2023-05-28 04:12:04,940 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:12:04,940 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:13:13,197 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.52, generation: 68.1622[sec], evaluation: 0.0000[sec]
2023-05-28 04:13:13,199 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 04:13:13,286 - INFO - joeynmt.helpers - delete models/transformer_b/29000.ckpt
2023-05-28 04:13:13,297 - INFO - joeynmt.training - Example #0
2023-05-28 04:13:13,297 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:13:13,297 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:13:13,297 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'ge@@', 'eft', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', ',', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:13:13,297 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:13:13,297 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:13:13,297 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia 's geeft om te verwijderen, dat de artische ijskappen die voor de artische ijskappe van de onderste 40 procent.
2023-05-28 04:13:13,297 - INFO - joeynmt.training - Example #1
2023-05-28 04:13:13,297 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:13:13,297 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:13:13,297 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'du@@', 'i@@', 'delijk', 'is', 'het', 'vol@@', 'gende', 'hoo@@', 'f@@', 'd@@', 'stu@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.', '</s>']
2023-05-28 04:13:13,298 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:13:13,298 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:13:13,298 - INFO - joeynmt.training - 	Hypothesis: Maar dit duidelijk is het volgende hoofdstuk van dit specifieke probleem, omdat het niet de dikke van het ijs laat zien.
2023-05-28 04:13:13,298 - INFO - joeynmt.training - Example #2
2023-05-28 04:13:13,298 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:13:13,298 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:13:13,298 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', '.', '</s>']
2023-05-28 04:13:13,298 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:13:13,298 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:13:13,298 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape van onze wereldwijd.
2023-05-28 04:13:13,298 - INFO - joeynmt.training - Example #3
2023-05-28 04:13:13,298 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:13:13,298 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:13:13,298 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Je', 'gro@@', 'eit', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'sch@@', 'rij@@', 'ver', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:13:13,298 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:13:13,298 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:13:13,298 - INFO - joeynmt.training - 	Hypothesis: Je groeit in de zomer en schrijver in de zomer.
2023-05-28 04:13:13,298 - INFO - joeynmt.training - Example #4
2023-05-28 04:13:13,298 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:13:13,298 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:13:13,298 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', ',', 'is', 'een', 'teken@@', 'ing', 'van', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de', '.', '</s>']
2023-05-28 04:13:13,299 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:13:13,299 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:13:13,299 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie laten zien, is een tekening van wat er in de laatste 25 jaar gebeurde.
2023-05-28 04:13:35,630 - INFO - joeynmt.training - Epoch   8, Step:    31600, Batch Loss:     1.451741, Batch Acc: 0.557896, Tokens per Sec:     3179, Lr: 0.000300
2023-05-28 04:13:57,420 - INFO - joeynmt.training - Epoch   8, Step:    31700, Batch Loss:     1.562442, Batch Acc: 0.558791, Tokens per Sec:     3211, Lr: 0.000300
2023-05-28 04:14:19,748 - INFO - joeynmt.training - Epoch   8, Step:    31800, Batch Loss:     1.641657, Batch Acc: 0.557971, Tokens per Sec:     3179, Lr: 0.000300
2023-05-28 04:14:41,273 - INFO - joeynmt.training - Epoch   8, Step:    31900, Batch Loss:     1.597046, Batch Acc: 0.554048, Tokens per Sec:     3308, Lr: 0.000300
2023-05-28 04:15:01,981 - INFO - joeynmt.training - Epoch   8, Step:    32000, Batch Loss:     1.773237, Batch Acc: 0.552228, Tokens per Sec:     3435, Lr: 0.000300
2023-05-28 04:15:01,983 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:15:01,983 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:16:20,855 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.52, generation: 78.7753[sec], evaluation: 0.0000[sec]
2023-05-28 04:16:20,858 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 04:16:20,939 - INFO - joeynmt.helpers - delete models/transformer_b/29500.ckpt
2023-05-28 04:16:20,949 - INFO - joeynmt.training - Example #0
2023-05-28 04:16:20,949 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:16:20,949 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:16:20,949 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'at@@', 'te', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'p', 'die', 'voor', 'de', 'drie', 'miljo@@', 'en', 'jaar', ',', 'de', 'groot@@', 'te', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'e', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:16:20,950 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:16:20,950 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:16:20,950 - INFO - joeynmt.training - 	Hypothesis: Latte jaar heb ik deze twee dia getoond te verwijderen dat de arctische ijskp die voor de drie miljoen jaar, de grootte van de grootte van de onderste 40 procent van de grootte van de ondere 40 procent.
2023-05-28 04:16:20,950 - INFO - joeynmt.training - Example #1
2023-05-28 04:16:20,950 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:16:20,950 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:16:20,950 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'n@@', 'st@@', 'and@@', 'pun@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', '.', '</s>']
2023-05-28 04:16:20,950 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:16:20,950 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:16:20,950 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste nstandpunt van dit specifieke probleem, want het is niet de dik van het ijs laat.
2023-05-28 04:16:20,950 - INFO - joeynmt.training - Example #2
2023-05-28 04:16:20,950 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:16:20,950 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:16:20,950 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:16:20,951 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:16:20,951 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:16:20,951 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape hart van onze wereldwijde klimaatsysteem.
2023-05-28 04:16:20,951 - INFO - joeynmt.training - Example #3
2023-05-28 04:16:20,951 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:16:20,951 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:16:20,951 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'on@@', 'maa@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:16:20,951 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:16:20,951 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:16:20,951 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schoonmaat in de zomer.
2023-05-28 04:16:20,951 - INFO - joeynmt.training - Example #4
2023-05-28 04:16:20,951 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:16:20,951 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:16:20,951 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 'zal', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'ing', 'van', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 04:16:20,951 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:16:20,951 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:16:20,951 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie zal laten zien is een tijdtraffering van wat er in de afgelopen 25 jaar.
2023-05-28 04:16:42,285 - INFO - joeynmt.training - Epoch   8, Step:    32100, Batch Loss:     1.395654, Batch Acc: 0.554310, Tokens per Sec:     3228, Lr: 0.000300
2023-05-28 04:17:02,836 - INFO - joeynmt.training - Epoch   8, Step:    32200, Batch Loss:     1.452399, Batch Acc: 0.562316, Tokens per Sec:     3472, Lr: 0.000300
2023-05-28 04:17:23,311 - INFO - joeynmt.training - Epoch   8, Step:    32300, Batch Loss:     1.477243, Batch Acc: 0.555552, Tokens per Sec:     3385, Lr: 0.000300
2023-05-28 04:17:44,155 - INFO - joeynmt.training - Epoch   8, Step:    32400, Batch Loss:     1.413472, Batch Acc: 0.562852, Tokens per Sec:     3355, Lr: 0.000300
2023-05-28 04:18:04,802 - INFO - joeynmt.training - Epoch   8, Step:    32500, Batch Loss:     1.768670, Batch Acc: 0.548921, Tokens per Sec:     3440, Lr: 0.000300
2023-05-28 04:18:04,803 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:18:04,803 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:19:10,612 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.28, acc:   0.52, generation: 65.7134[sec], evaluation: 0.0000[sec]
2023-05-28 04:19:10,731 - INFO - joeynmt.helpers - delete models/transformer_b/30000.ckpt
2023-05-28 04:19:10,742 - INFO - joeynmt.training - Example #0
2023-05-28 04:19:10,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:19:10,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:19:10,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'to@@', 'on@@', 'den', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'onder@@', 'aan', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:19:10,742 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:19:10,742 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:19:10,742 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia getoond om te vertoonden dat de artische ijskappen voor de artische ijskappen die onderaan 40 procent.
2023-05-28 04:19:10,742 - INFO - joeynmt.training - Example #1
2023-05-28 04:19:10,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:19:10,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:19:10,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'genoe@@', 'g', 'de', 'eerste', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 04:19:10,743 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:19:10,743 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:19:10,743 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste genoeg de eerste kwestie van dit speciale probleem, want het is niet de dikke van het ijs.
2023-05-28 04:19:10,743 - INFO - joeynmt.training - Example #2
2023-05-28 04:19:10,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:19:10,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:19:10,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', ',', 'het', 'p@@', 'la@@', 'st@@', 'ig', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:19:10,743 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:19:10,743 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:19:10,743 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen, het plastig hart van onze wereldklimaatsysteem.
2023-05-28 04:19:10,743 - INFO - joeynmt.training - Example #3
2023-05-28 04:19:10,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:19:10,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:19:10,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'sch@@', 'ro@@', 'm@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:19:10,743 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:19:10,743 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:19:10,743 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer en schromt in de zomer.
2023-05-28 04:19:10,743 - INFO - joeynmt.training - Example #4
2023-05-28 04:19:10,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:19:10,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:19:10,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'op@@', 'er@@', 'at@@', 'ies', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 04:19:10,744 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:19:10,744 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:19:10,744 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie laten zien is een tijdtraoperaties wat er gebeurt in de laatste 25 jaar.
2023-05-28 04:19:33,123 - INFO - joeynmt.training - Epoch   8, Step:    32600, Batch Loss:     1.602371, Batch Acc: 0.553937, Tokens per Sec:     3106, Lr: 0.000300
2023-05-28 04:19:54,266 - INFO - joeynmt.training - Epoch   8, Step:    32700, Batch Loss:     1.520889, Batch Acc: 0.554529, Tokens per Sec:     3236, Lr: 0.000300
2023-05-28 04:20:14,779 - INFO - joeynmt.training - Epoch   8, Step:    32800, Batch Loss:     1.546654, Batch Acc: 0.553881, Tokens per Sec:     3409, Lr: 0.000300
2023-05-28 04:20:36,876 - INFO - joeynmt.training - Epoch   8, Step:    32900, Batch Loss:     1.568165, Batch Acc: 0.551894, Tokens per Sec:     3169, Lr: 0.000300
2023-05-28 04:20:58,979 - INFO - joeynmt.training - Epoch   8, Step:    33000, Batch Loss:     1.412603, Batch Acc: 0.551897, Tokens per Sec:     3115, Lr: 0.000300
2023-05-28 04:20:58,981 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:20:58,981 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:22:08,830 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.52, generation: 69.7534[sec], evaluation: 0.0000[sec]
2023-05-28 04:22:08,930 - INFO - joeynmt.helpers - delete models/transformer_b/32500.ckpt
2023-05-28 04:22:08,940 - INFO - joeynmt.helpers - delete /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_b/32500.ckpt
2023-05-28 04:22:08,940 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_b/32500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_b/32500.ckpt')
2023-05-28 04:22:08,941 - INFO - joeynmt.training - Example #0
2023-05-28 04:22:08,941 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:22:08,941 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:22:08,941 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'ij@@', 's@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'anderen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'dro@@', 'om', 'van', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'dro@@', 'om', 'van', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'z@@', 'am@@', 'elen', '.', '</s>']
2023-05-28 04:22:08,941 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:22:08,941 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:22:08,941 - INFO - joeynmt.training - 	Hypothesis: Tijsig jaar heb ik deze twee dia getoond om te veranderen dat de artische ijskappen die voor droom van de artische ijskappen die voor droom van 40 procent te verzamelen.
2023-05-28 04:22:08,941 - INFO - joeynmt.training - Example #1
2023-05-28 04:22:08,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:22:08,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:22:08,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'k@@', 'n@@', 'u@@', 'g', 'de', 'eerste', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', '.', '</s>']
2023-05-28 04:22:08,942 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:22:08,942 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:22:08,942 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste knug de eerste kwestie van dit specifiek.
2023-05-28 04:22:08,942 - INFO - joeynmt.training - Example #2
2023-05-28 04:22:08,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:22:08,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:22:08,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 'z@@', 'er', 'is', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:22:08,942 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:22:08,942 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:22:08,942 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijzer is het hart van ons wereldwijde klimaatsysteem.
2023-05-28 04:22:08,942 - INFO - joeynmt.training - Example #3
2023-05-28 04:22:08,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:22:08,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:22:08,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 're@@', 'e@@', 'p', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:22:08,942 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:22:08,942 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:22:08,942 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schreep in de zomer.
2023-05-28 04:22:08,942 - INFO - joeynmt.training - Example #4
2023-05-28 04:22:08,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:22:08,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:22:08,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', '-@@', 'tra@@', 'ff@@', 'er@@', 'ende', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 04:22:08,943 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:22:08,943 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:22:08,943 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik jullie tonen is een tijd-trafferende 25 jaar gebeurt.
2023-05-28 04:22:29,370 - INFO - joeynmt.training - Epoch   8, Step:    33100, Batch Loss:     1.615435, Batch Acc: 0.556029, Tokens per Sec:     3451, Lr: 0.000300
2023-05-28 04:22:50,679 - INFO - joeynmt.training - Epoch   8, Step:    33200, Batch Loss:     1.559065, Batch Acc: 0.554883, Tokens per Sec:     3301, Lr: 0.000300
2023-05-28 04:23:12,779 - INFO - joeynmt.training - Epoch   8, Step:    33300, Batch Loss:     1.234480, Batch Acc: 0.557660, Tokens per Sec:     3258, Lr: 0.000300
2023-05-28 04:23:34,085 - INFO - joeynmt.training - Epoch   8, Step:    33400, Batch Loss:     1.589192, Batch Acc: 0.548005, Tokens per Sec:     3340, Lr: 0.000300
2023-05-28 04:23:54,695 - INFO - joeynmt.training - Epoch   8, Step:    33500, Batch Loss:     1.567920, Batch Acc: 0.557336, Tokens per Sec:     3379, Lr: 0.000300
2023-05-28 04:23:54,695 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:23:54,695 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:25:12,669 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.24, acc:   0.52, generation: 77.8789[sec], evaluation: 0.0000[sec]
2023-05-28 04:25:12,670 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 04:25:12,753 - INFO - joeynmt.helpers - delete models/transformer_b/31000.ckpt
2023-05-28 04:25:12,764 - INFO - joeynmt.training - Example #0
2023-05-28 04:25:12,764 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:25:12,764 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:25:12,764 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aat@@', 'te', 'ik', 'deze', 'twee', 'di@@', 'a', 'l@@', 'aat', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', ',', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'te', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:25:12,765 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:25:12,765 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:25:12,765 - INFO - joeynmt.training - 	Hypothesis: Laatte ik deze twee dia laat zien dat de artische ijskappen, die voor de artische ijskappen die drie miljoen jaar de grote van de grootte van de onderste 40 procent.
2023-05-28 04:25:12,765 - INFO - joeynmt.training - Example #1
2023-05-28 04:25:12,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:25:12,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:25:12,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'ver@@', 'tel@@', 't', '.', '</s>']
2023-05-28 04:25:12,765 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:25:12,765 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:25:12,765 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste is dat speciale probleem van dit speciale probleem, want het is niet de dikke van het ijsvertelt.
2023-05-28 04:25:12,765 - INFO - joeynmt.training - Example #2
2023-05-28 04:25:12,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:25:12,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:25:12,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:25:12,765 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:25:12,765 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:25:12,765 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape van onze wereldwijde klimaatsysteem.
2023-05-28 04:25:12,765 - INFO - joeynmt.training - Example #3
2023-05-28 04:25:12,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:25:12,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:25:12,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'sch@@', 'ro@@', 'e@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:25:12,766 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:25:12,766 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:25:12,766 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer en schroepen in de zomer.
2023-05-28 04:25:12,766 - INFO - joeynmt.training - Example #4
2023-05-28 04:25:12,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:25:12,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:25:12,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', '-@@', 'op@@', 'nam@@', 'e', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 04:25:12,766 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:25:12,766 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:25:12,766 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijd-opname van de laatste 25 jaar.
2023-05-28 04:25:34,915 - INFO - joeynmt.training - Epoch   8, Step:    33600, Batch Loss:     1.443069, Batch Acc: 0.554387, Tokens per Sec:     3209, Lr: 0.000300
2023-05-28 04:25:56,735 - INFO - joeynmt.training - Epoch   8, Step:    33700, Batch Loss:     1.552829, Batch Acc: 0.557462, Tokens per Sec:     3190, Lr: 0.000300
2023-05-28 04:26:18,923 - INFO - joeynmt.training - Epoch   8, Step:    33800, Batch Loss:     1.441341, Batch Acc: 0.551658, Tokens per Sec:     3263, Lr: 0.000300
2023-05-28 04:26:39,187 - INFO - joeynmt.training - Epoch   8, Step:    33900, Batch Loss:     1.397193, Batch Acc: 0.557594, Tokens per Sec:     3527, Lr: 0.000300
2023-05-28 04:26:58,198 - INFO - joeynmt.training - Epoch   8, Step:    34000, Batch Loss:     1.806743, Batch Acc: 0.549809, Tokens per Sec:     3645, Lr: 0.000300
2023-05-28 04:26:58,199 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:26:58,200 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:28:09,454 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.19, acc:   0.52, generation: 71.1593[sec], evaluation: 0.0000[sec]
2023-05-28 04:28:09,455 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 04:28:09,536 - INFO - joeynmt.helpers - delete models/transformer_b/30500.ckpt
2023-05-28 04:28:09,546 - INFO - joeynmt.training - Example #0
2023-05-28 04:28:09,546 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:28:09,546 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:28:09,546 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'en', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'enen', 'ge@@', 'zien', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', ',', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ot', 'van', 'de', 'gro@@', 'ot', 'van', 'de', 'groot@@', 'te', 'van', 'de', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:28:09,547 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:28:09,547 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:28:09,547 - INFO - joeynmt.training - 	Hypothesis: Ten jaar heb ik deze twee dienen gezien om te verwijderen dat de artische ijskapen, die drie miljoen jaar de groot van de groot van de grootte van de 48 staten om 40 procent.
2023-05-28 04:28:09,547 - INFO - joeynmt.training - Example #1
2023-05-28 04:28:09,547 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:28:09,547 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:28:09,547 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'plaats', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 04:28:09,547 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:28:09,547 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:28:09,547 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste plaats van dit specifieke probleem, want het is niet de dikke van het ijs.
2023-05-28 04:28:09,547 - INFO - joeynmt.training - Example #2
2023-05-28 04:28:09,547 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:28:09,547 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:28:09,547 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', ',', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat', '.', '</s>']
2023-05-28 04:28:09,547 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:28:09,547 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:28:09,547 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen, het hart van onze wereldwijde klimaat.
2023-05-28 04:28:09,547 - INFO - joeynmt.training - Example #3
2023-05-28 04:28:09,547 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:28:09,547 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:28:09,547 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'ver@@', 'st@@', 'ro@@', 'men', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:28:09,548 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:28:09,548 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:28:09,548 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer en verstromen in de zomer.
2023-05-28 04:28:09,548 - INFO - joeynmt.training - Example #4
2023-05-28 04:28:09,548 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:28:09,548 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:28:09,548 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ap', ',', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ap', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 04:28:09,548 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:28:09,548 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:28:09,548 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie zien is een tijdschap, is een tijdschap wat er in de laatste 25 jaar.
2023-05-28 04:28:29,752 - INFO - joeynmt.training - Epoch   8, Step:    34100, Batch Loss:     1.710492, Batch Acc: 0.557675, Tokens per Sec:     3463, Lr: 0.000300
2023-05-28 04:28:50,255 - INFO - joeynmt.training - Epoch   8, Step:    34200, Batch Loss:     1.447553, Batch Acc: 0.562925, Tokens per Sec:     3433, Lr: 0.000300
2023-05-28 04:29:10,899 - INFO - joeynmt.training - Epoch   8, Step:    34300, Batch Loss:     1.742251, Batch Acc: 0.563401, Tokens per Sec:     3386, Lr: 0.000300
2023-05-28 04:29:31,487 - INFO - joeynmt.training - Epoch   8, Step:    34400, Batch Loss:     1.379223, Batch Acc: 0.551217, Tokens per Sec:     3367, Lr: 0.000300
2023-05-28 04:29:52,375 - INFO - joeynmt.training - Epoch   8, Step:    34500, Batch Loss:     1.722521, Batch Acc: 0.554885, Tokens per Sec:     3410, Lr: 0.000300
2023-05-28 04:29:52,376 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:29:52,376 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:30:55,865 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.18, acc:   0.53, generation: 63.3974[sec], evaluation: 0.0000[sec]
2023-05-28 04:30:55,867 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 04:30:55,947 - INFO - joeynmt.helpers - delete models/transformer_b/31500.ckpt
2023-05-28 04:30:55,957 - INFO - joeynmt.training - Example #0
2023-05-28 04:30:55,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:30:55,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:30:55,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'ij@@', 'den@@', 's', 'de', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 'l@@', 'aat', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'ij@@', 'z@@', 'er', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'ot', 'van', 'de', 'onder@@', 'ste', '4@@', '0', '%', '.', '</s>']
2023-05-28 04:30:55,958 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:30:55,958 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:30:55,958 - INFO - joeynmt.training - 	Hypothesis: Tijdens de twee dia 'laat zien dat de artische ijskappe ijzer die voor de artische ijskapot van de onderste 40%.
2023-05-28 04:30:55,958 - INFO - joeynmt.training - Example #1
2023-05-28 04:30:55,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:30:55,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:30:55,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'n@@', 'i@@', 've@@', 'au', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 04:30:55,958 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:30:55,958 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:30:55,958 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de eerste niveau van dit speciale probleem, want het is niet de dikke van het ijs.
2023-05-28 04:30:55,958 - INFO - joeynmt.training - Example #2
2023-05-28 04:30:55,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:30:55,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:30:55,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'sl@@', 'aa@@', 'g@@', 'de', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:30:55,959 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:30:55,959 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:30:55,959 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het slaagde hart van onze wereldklimaatsysteem.
2023-05-28 04:30:55,959 - INFO - joeynmt.training - Example #3
2023-05-28 04:30:55,959 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:30:55,959 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:30:55,959 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'sch@@', 'er@@', 'p@@', 'ft', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:30:55,959 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:30:55,959 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:30:55,959 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer en scherpft in de zomer.
2023-05-28 04:30:55,959 - INFO - joeynmt.training - Example #4
2023-05-28 04:30:55,959 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:30:55,959 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:30:55,959 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'ie', 'die', 'ik', 'je', 't@@', 'on@@', 'g', 't@@', 'on@@', 'en', ',', 'is', 'een', 'tij@@', 'd@@', '-@@', 'op@@', 'er@@', 'atie', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 04:30:55,959 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:30:55,959 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:30:55,959 - INFO - joeynmt.training - 	Hypothesis: De volgende diie die ik je tong tonen, is een tijd-operatie wat er in de laatste 25 jaar.
2023-05-28 04:31:17,839 - INFO - joeynmt.training - Epoch   8, Step:    34600, Batch Loss:     1.572617, Batch Acc: 0.554579, Tokens per Sec:     3235, Lr: 0.000300
2023-05-28 04:31:38,091 - INFO - joeynmt.training - Epoch   8, Step:    34700, Batch Loss:     1.437895, Batch Acc: 0.552343, Tokens per Sec:     3510, Lr: 0.000300
2023-05-28 04:31:59,854 - INFO - joeynmt.training - Epoch   8, Step:    34800, Batch Loss:     1.397469, Batch Acc: 0.555377, Tokens per Sec:     3341, Lr: 0.000300
2023-05-28 04:32:20,335 - INFO - joeynmt.training - Epoch   8, Step:    34900, Batch Loss:     1.298386, Batch Acc: 0.561921, Tokens per Sec:     3476, Lr: 0.000300
2023-05-28 04:32:40,910 - INFO - joeynmt.training - Epoch   8, Step:    35000, Batch Loss:     1.600524, Batch Acc: 0.550875, Tokens per Sec:     3365, Lr: 0.000300
2023-05-28 04:32:40,911 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:32:40,911 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:33:41,588 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.17, acc:   0.53, generation: 60.5856[sec], evaluation: 0.0000[sec]
2023-05-28 04:33:41,590 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 04:33:41,676 - INFO - joeynmt.helpers - delete models/transformer_b/33000.ckpt
2023-05-28 04:33:41,677 - INFO - joeynmt.training - Example #0
2023-05-28 04:33:41,677 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:33:41,677 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:33:41,677 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'onder@@', 'wij@@', 's', 'was', 'voor', 'de', 'h@@', 'and', 'van', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:33:41,677 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:33:41,677 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:33:41,677 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verwijderen dat de artische ijskappen die onderwijs was voor de hand van de drie miljoen jaar de grootte van de grootte van de onderste 40 procent.
2023-05-28 04:33:41,677 - INFO - joeynmt.training - Example #1
2023-05-28 04:33:41,677 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:33:41,677 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:33:41,677 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 04:33:41,678 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:33:41,678 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:33:41,678 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste is dat speciale problemen van dit speciale problemen, want het is niet de dikke van het ijs.
2023-05-28 04:33:41,678 - INFO - joeynmt.training - Example #2
2023-05-28 04:33:41,678 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:33:41,678 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:33:41,678 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'p@@', 'la@@', 'st@@', 'ig', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:33:41,678 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:33:41,678 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:33:41,678 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het plastig van onze wereldwijde klimaatsysteem.
2023-05-28 04:33:41,678 - INFO - joeynmt.training - Example #3
2023-05-28 04:33:41,678 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:33:41,678 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:33:41,678 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'er@@', 'p@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:33:41,678 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:33:41,678 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:33:41,678 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scherppen in de zomer.
2023-05-28 04:33:41,678 - INFO - joeynmt.training - Example #4
2023-05-28 04:33:41,678 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:33:41,678 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:33:41,678 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'ende', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 04:33:41,679 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:33:41,679 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:33:41,679 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdtrafferende 25 jaar.
2023-05-28 04:34:02,825 - INFO - joeynmt.training - Epoch   8, Step:    35100, Batch Loss:     1.764567, Batch Acc: 0.557668, Tokens per Sec:     3235, Lr: 0.000300
2023-05-28 04:34:23,375 - INFO - joeynmt.training - Epoch   8, Step:    35200, Batch Loss:     1.662247, Batch Acc: 0.555494, Tokens per Sec:     3492, Lr: 0.000300
2023-05-28 04:34:43,312 - INFO - joeynmt.training - Epoch   8, Step:    35300, Batch Loss:     1.643697, Batch Acc: 0.556558, Tokens per Sec:     3513, Lr: 0.000300
2023-05-28 04:35:03,974 - INFO - joeynmt.training - Epoch   8, Step:    35400, Batch Loss:     1.519299, Batch Acc: 0.554396, Tokens per Sec:     3358, Lr: 0.000300
2023-05-28 04:35:25,151 - INFO - joeynmt.training - Epoch   8, Step:    35500, Batch Loss:     1.349878, Batch Acc: 0.557537, Tokens per Sec:     3366, Lr: 0.000300
2023-05-28 04:35:25,152 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:35:25,152 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:36:21,646 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.15, acc:   0.53, generation: 56.4009[sec], evaluation: 0.0000[sec]
2023-05-28 04:36:21,648 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 04:36:21,739 - INFO - joeynmt.helpers - delete models/transformer_b/32000.ckpt
2023-05-28 04:36:21,749 - INFO - joeynmt.training - Example #0
2023-05-28 04:36:21,749 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:36:21,749 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:36:21,749 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', ',', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'van', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ot', 'was', 'van', 'de', 'gro@@', 'ot', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'tot', 'tot', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:36:21,750 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:36:21,750 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:36:21,750 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia getoond, om te verwijderen dat de artische ijskapen van drie miljoen jaar de groot was van de groot van de grootte van de onderste 40 tot tot 40 procent.
2023-05-28 04:36:21,750 - INFO - joeynmt.training - Example #1
2023-05-28 04:36:21,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:36:21,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:36:21,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'be@@', 'v@@', 'rij@@', 'd', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 04:36:21,750 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:36:21,750 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:36:21,750 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste eerste bevrijd van dit speciale probleem, want het is het niet de dikke van het ijs.
2023-05-28 04:36:21,750 - INFO - joeynmt.training - Example #2
2023-05-28 04:36:21,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:36:21,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:36:21,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'sl@@', 'aa@@', 'g@@', 'de', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:36:21,750 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:36:21,750 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:36:21,750 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het slaagde hart van ons wereldwijde klimaatsysteem.
2023-05-28 04:36:21,751 - INFO - joeynmt.training - Example #3
2023-05-28 04:36:21,751 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:36:21,751 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:36:21,751 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:36:21,751 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:36:21,751 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:36:21,751 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompen in de zomer.
2023-05-28 04:36:21,751 - INFO - joeynmt.training - Example #4
2023-05-28 04:36:21,751 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:36:21,751 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:36:21,751 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 04:36:21,751 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:36:21,751 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:36:21,751 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie jullie laten zien is een tijdperk van de laatste 25 jaar.
2023-05-28 04:36:29,085 - INFO - joeynmt.training - Epoch   8: total training loss 6817.98
2023-05-28 04:36:29,086 - INFO - joeynmt.training - EPOCH 9
2023-05-28 04:36:29,120 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=8
2023-05-28 04:36:41,229 - INFO - joeynmt.training - Epoch   9, Step:    35600, Batch Loss:     1.404188, Batch Acc: 0.558952, Tokens per Sec:     3653, Lr: 0.000300
2023-05-28 04:37:01,733 - INFO - joeynmt.training - Epoch   9, Step:    35700, Batch Loss:     1.405344, Batch Acc: 0.565441, Tokens per Sec:     3516, Lr: 0.000300
2023-05-28 04:37:22,792 - INFO - joeynmt.training - Epoch   9, Step:    35800, Batch Loss:     1.538657, Batch Acc: 0.563831, Tokens per Sec:     3275, Lr: 0.000300
2023-05-28 04:37:44,997 - INFO - joeynmt.training - Epoch   9, Step:    35900, Batch Loss:     1.572114, Batch Acc: 0.570411, Tokens per Sec:     3173, Lr: 0.000300
2023-05-28 04:38:07,271 - INFO - joeynmt.training - Epoch   9, Step:    36000, Batch Loss:     1.553676, Batch Acc: 0.560897, Tokens per Sec:     3161, Lr: 0.000300
2023-05-28 04:38:07,272 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:38:07,272 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:39:22,454 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.20, acc:   0.53, generation: 75.0870[sec], evaluation: 0.0000[sec]
2023-05-28 04:39:22,561 - INFO - joeynmt.helpers - delete models/transformer_b/33500.ckpt
2023-05-28 04:39:22,566 - INFO - joeynmt.training - Example #0
2023-05-28 04:39:22,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:39:22,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:39:22,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'het', 'eer@@', 'der', 'van', 'de', 'onder@@', 'kan@@', 't', ',', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'een', 'gro@@', 'ot', 'gro@@', 'ter', 'ter', 'ter', '4@@', '8', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:39:22,567 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:39:22,567 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:39:22,567 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verwijderen dat de artische ijskappen die voor het eerder van de onderkant, die drie miljoen jaar een groot groter ter ter 48 procent.
2023-05-28 04:39:22,567 - INFO - joeynmt.training - Example #1
2023-05-28 04:39:22,567 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:39:22,567 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:39:22,567 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'plaats', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 04:39:22,567 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:39:22,567 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:39:22,567 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste plaats van dit speciale probleem, want het is het niet de dikke van het ijs.
2023-05-28 04:39:22,567 - INFO - joeynmt.training - Example #2
2023-05-28 04:39:22,567 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:39:22,567 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:39:22,567 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'uit@@', 'ein@@', 'delijk', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:39:22,567 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:39:22,567 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:39:22,567 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het uiteindelijk hart van onze wereldklimaatsysteem.
2023-05-28 04:39:22,567 - INFO - joeynmt.training - Example #3
2023-05-28 04:39:22,567 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:39:22,567 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:39:22,568 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:39:22,568 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:39:22,568 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:39:22,568 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schromp in de zomer.
2023-05-28 04:39:22,568 - INFO - joeynmt.training - Example #4
2023-05-28 04:39:22,568 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:39:22,568 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:39:22,568 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'je', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', '-@@', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 04:39:22,568 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:39:22,568 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:39:22,568 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je tonen is een tijdtraffer-afgelopen 25 jaar.
2023-05-28 04:39:44,854 - INFO - joeynmt.training - Epoch   9, Step:    36100, Batch Loss:     1.327180, Batch Acc: 0.558259, Tokens per Sec:     3173, Lr: 0.000300
2023-05-28 04:40:07,252 - INFO - joeynmt.training - Epoch   9, Step:    36200, Batch Loss:     1.718955, Batch Acc: 0.559651, Tokens per Sec:     3139, Lr: 0.000300
2023-05-28 04:40:28,984 - INFO - joeynmt.training - Epoch   9, Step:    36300, Batch Loss:     1.382651, Batch Acc: 0.565381, Tokens per Sec:     3220, Lr: 0.000300
2023-05-28 04:40:51,665 - INFO - joeynmt.training - Epoch   9, Step:    36400, Batch Loss:     1.359929, Batch Acc: 0.563127, Tokens per Sec:     3128, Lr: 0.000300
2023-05-28 04:41:14,161 - INFO - joeynmt.training - Epoch   9, Step:    36500, Batch Loss:     1.620532, Batch Acc: 0.559221, Tokens per Sec:     3129, Lr: 0.000300
2023-05-28 04:41:14,162 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:41:14,162 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:42:21,696 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.16, acc:   0.53, generation: 67.4383[sec], evaluation: 0.0000[sec]
2023-05-28 04:42:21,786 - INFO - joeynmt.helpers - delete models/transformer_b/36000.ckpt
2023-05-28 04:42:21,791 - INFO - joeynmt.helpers - delete /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_b/36000.ckpt
2023-05-28 04:42:21,791 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_b/36000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_b/36000.ckpt')
2023-05-28 04:42:21,792 - INFO - joeynmt.training - Example #0
2023-05-28 04:42:21,792 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:42:21,792 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:42:21,792 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'to@@', 'on@@', 'de', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'an@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', ',', 'die', 'onder@@', 'en', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'zien', ',', 'om', '4@@', '8', 'proc@@', 'ent', 'te', 'gebeur@@', 'en', '.', '</s>']
2023-05-28 04:42:21,792 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:42:21,792 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:42:21,792 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te vertoonde dat de artische ijskappen die voor antische ijskappen, die onderen 48 staten had gezien, om 48 procent te gebeuren.
2023-05-28 04:42:21,792 - INFO - joeynmt.training - Example #1
2023-05-28 04:42:21,792 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:42:21,792 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:42:21,792 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'sta@@', 'f', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 04:42:21,793 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:42:21,793 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:42:21,793 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste staf van dit specifieke probleem, want het is niet de dikke van het ijs.
2023-05-28 04:42:21,793 - INFO - joeynmt.training - Example #2
2023-05-28 04:42:21,793 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:42:21,793 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:42:21,793 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:42:21,793 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:42:21,793 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:42:21,793 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het hart van ons wereldwijde klimaatsysteem.
2023-05-28 04:42:21,793 - INFO - joeynmt.training - Example #3
2023-05-28 04:42:21,793 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:42:21,793 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:42:21,793 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:42:21,793 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:42:21,793 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:42:21,793 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroeppen in de zomer.
2023-05-28 04:42:21,793 - INFO - joeynmt.training - Example #4
2023-05-28 04:42:21,793 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:42:21,794 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:42:21,794 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'jullie', 'laten', 'zien', 'is', 'een', 'te@@', 'tra@@', 'ff@@', 'er@@', 'op@@', 'nam@@', 'e', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de', '.', '</s>']
2023-05-28 04:42:21,794 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:42:21,794 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:42:21,794 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie jullie laten zien is een tetrafferopname wat er in de laatste 25 jaar gebeurde.
2023-05-28 04:42:45,762 - INFO - joeynmt.training - Epoch   9, Step:    36600, Batch Loss:     1.399914, Batch Acc: 0.558707, Tokens per Sec:     2883, Lr: 0.000300
2023-05-28 04:43:08,888 - INFO - joeynmt.training - Epoch   9, Step:    36700, Batch Loss:     1.495842, Batch Acc: 0.556075, Tokens per Sec:     3044, Lr: 0.000300
2023-05-28 04:43:32,347 - INFO - joeynmt.training - Epoch   9, Step:    36800, Batch Loss:     1.428009, Batch Acc: 0.565674, Tokens per Sec:     3031, Lr: 0.000300
2023-05-28 04:43:56,844 - INFO - joeynmt.training - Epoch   9, Step:    36900, Batch Loss:     1.600260, Batch Acc: 0.558649, Tokens per Sec:     2916, Lr: 0.000300
2023-05-28 04:44:19,593 - INFO - joeynmt.training - Epoch   9, Step:    37000, Batch Loss:     1.549703, Batch Acc: 0.562974, Tokens per Sec:     3231, Lr: 0.000300
2023-05-28 04:44:19,595 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:44:19,595 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:45:34,668 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.13, acc:   0.53, generation: 74.9752[sec], evaluation: 0.0000[sec]
2023-05-28 04:45:34,669 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 04:45:34,759 - INFO - joeynmt.helpers - delete models/transformer_b/34000.ckpt
2023-05-28 04:45:34,765 - INFO - joeynmt.training - Example #0
2023-05-28 04:45:34,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:45:34,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:45:34,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'die', 'voor', 'een', 'goe@@', 'de', 'ij@@', 'st@@', 'aten', 'die', 'er', 'ongeveer', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ter', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'groot@@', 'te', 'van', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:45:34,765 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:45:34,765 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:45:34,765 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia getoond om te verwijderen dat de artische ijskape die voor een goede ijstaten die er ongeveer drie miljoen jaar de groter van de grootte van de grootte van 40 procent.
2023-05-28 04:45:34,765 - INFO - joeynmt.training - Example #1
2023-05-28 04:45:34,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:45:34,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:45:34,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'aar@@', 'de', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 04:45:34,765 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:45:34,765 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:45:34,766 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aarde de van dit speciale probleem, omdat het niet de dikke dikke van het ijs.
2023-05-28 04:45:34,766 - INFO - joeynmt.training - Example #2
2023-05-28 04:45:34,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:45:34,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:45:34,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:45:34,766 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:45:34,766 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:45:34,766 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape van onze wereldwijde klimaatsysteem.
2023-05-28 04:45:34,766 - INFO - joeynmt.training - Example #3
2023-05-28 04:45:34,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:45:34,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:45:34,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 're@@', 'ef', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:45:34,766 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:45:34,766 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:45:34,766 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schreef in de zomer.
2023-05-28 04:45:34,766 - INFO - joeynmt.training - Example #4
2023-05-28 04:45:34,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:45:34,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:45:34,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'jullie', 'laten', 'zien', 'is', 'een', 'te@@', 'tra@@', 'ff@@', 'er@@', 'op@@', 'nam@@', 'e', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 04:45:34,767 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:45:34,767 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:45:34,767 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie jullie laten zien is een tetrafferopname van de laatste 25 jaar gebeurt.
2023-05-28 04:45:58,504 - INFO - joeynmt.training - Epoch   9, Step:    37100, Batch Loss:     1.369564, Batch Acc: 0.562050, Tokens per Sec:     2967, Lr: 0.000300
2023-05-28 04:46:19,812 - INFO - joeynmt.training - Epoch   9, Step:    37200, Batch Loss:     1.652470, Batch Acc: 0.564486, Tokens per Sec:     3357, Lr: 0.000300
2023-05-28 04:46:41,195 - INFO - joeynmt.training - Epoch   9, Step:    37300, Batch Loss:     1.413970, Batch Acc: 0.563786, Tokens per Sec:     3291, Lr: 0.000300
2023-05-28 04:47:02,815 - INFO - joeynmt.training - Epoch   9, Step:    37400, Batch Loss:     1.247555, Batch Acc: 0.566537, Tokens per Sec:     3169, Lr: 0.000300
2023-05-28 04:47:25,114 - INFO - joeynmt.training - Epoch   9, Step:    37500, Batch Loss:     1.559899, Batch Acc: 0.566866, Tokens per Sec:     3155, Lr: 0.000300
2023-05-28 04:47:25,115 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:47:25,115 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:48:32,213 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.14, acc:   0.53, generation: 67.0055[sec], evaluation: 0.0000[sec]
2023-05-28 04:48:32,322 - INFO - joeynmt.helpers - delete models/transformer_b/34500.ckpt
2023-05-28 04:48:32,329 - INFO - joeynmt.training - Example #0
2023-05-28 04:48:32,330 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:48:32,330 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:48:32,330 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'A@@', 'an@@', 'ge@@', '-@@', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'onder@@', 'aan', '4@@', '8', 'st@@', 'aten', 'had', 'om', '4@@', '8', 'proc@@', 'ent', 'te', 'ver@@', 'st@@', 'ap@@', 'ten', '.', '</s>']
2023-05-28 04:48:32,330 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:48:32,330 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:48:32,330 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verwijderen dat de artische ijskappen die voor de Aange-ijskappen die onderaan 48 staten had om 48 procent te verstapten.
2023-05-28 04:48:32,330 - INFO - joeynmt.training - Example #1
2023-05-28 04:48:32,330 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:48:32,330 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:48:32,330 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 04:48:32,330 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:48:32,330 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:48:32,330 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste is dat het speciale probleem van dit speciale probleem, want het is niet de dikke van het ijs.
2023-05-28 04:48:32,330 - INFO - joeynmt.training - Example #2
2023-05-28 04:48:32,330 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:48:32,330 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:48:32,331 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:48:32,331 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:48:32,331 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:48:32,331 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen van ons wereldwijde klimaatsysteem.
2023-05-28 04:48:32,331 - INFO - joeynmt.training - Example #3
2023-05-28 04:48:32,331 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:48:32,331 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:48:32,331 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'gro@@', 'eit', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'sch@@', 'ro@@', 'm@@', 'pen', '.', '</s>']
2023-05-28 04:48:32,331 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:48:32,331 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:48:32,331 - INFO - joeynmt.training - 	Hypothesis: Het groeit in de zomer en schrompen.
2023-05-28 04:48:32,331 - INFO - joeynmt.training - Example #4
2023-05-28 04:48:32,331 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:48:32,331 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:48:32,331 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'op@@', 'er@@', 'atie', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 04:48:32,331 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:48:32,331 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:48:32,331 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdtraoperatie wat er gebeurt in de afgelopen 25 jaar.
2023-05-28 04:48:54,080 - INFO - joeynmt.training - Epoch   9, Step:    37600, Batch Loss:     1.372689, Batch Acc: 0.559362, Tokens per Sec:     3234, Lr: 0.000300
2023-05-28 04:49:16,332 - INFO - joeynmt.training - Epoch   9, Step:    37700, Batch Loss:     1.645138, Batch Acc: 0.559301, Tokens per Sec:     3236, Lr: 0.000300
2023-05-28 04:49:37,984 - INFO - joeynmt.training - Epoch   9, Step:    37800, Batch Loss:     1.489270, Batch Acc: 0.556389, Tokens per Sec:     3176, Lr: 0.000300
2023-05-28 04:49:59,301 - INFO - joeynmt.training - Epoch   9, Step:    37900, Batch Loss:     1.409955, Batch Acc: 0.565970, Tokens per Sec:     3363, Lr: 0.000300
2023-05-28 04:50:19,941 - INFO - joeynmt.training - Epoch   9, Step:    38000, Batch Loss:     1.340167, Batch Acc: 0.560906, Tokens per Sec:     3381, Lr: 0.000300
2023-05-28 04:50:19,942 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:50:19,942 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:51:34,175 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.13, acc:   0.53, generation: 74.1383[sec], evaluation: 0.0000[sec]
2023-05-28 04:51:34,262 - INFO - joeynmt.helpers - delete models/transformer_b/35000.ckpt
2023-05-28 04:51:34,270 - INFO - joeynmt.training - Example #0
2023-05-28 04:51:34,270 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:51:34,270 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:51:34,270 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'to@@', 'on@@', 't', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'een', 'an@@', 'an@@', 'an@@', 'g@@', 'st@@', 'aan@@', 'de', 'van', '4@@', '0', '%', '.', '</s>']
2023-05-28 04:51:34,271 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:51:34,271 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:51:34,271 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te vertoont dat de artische ijskappen die voor een ananangstaande van 40%.
2023-05-28 04:51:34,271 - INFO - joeynmt.training - Example #1
2023-05-28 04:51:34,271 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:51:34,271 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:51:34,271 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', ',', 'genoe@@', 'g', 'de', 'eerste', ',', 'dat', 'is', 'het', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'uit', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 04:51:34,271 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:51:34,271 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:51:34,271 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste, genoeg de eerste, dat is het speciale probleem uit het ijs.
2023-05-28 04:51:34,271 - INFO - joeynmt.training - Example #2
2023-05-28 04:51:34,271 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:51:34,271 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:51:34,271 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:51:34,271 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:51:34,271 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:51:34,271 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het hart van onze wereldwijde klimaatsysteem.
2023-05-28 04:51:34,271 - INFO - joeynmt.training - Example #3
2023-05-28 04:51:34,271 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:51:34,271 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:51:34,271 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:51:34,272 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:51:34,272 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:51:34,272 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompen in de zomer.
2023-05-28 04:51:34,272 - INFO - joeynmt.training - Example #4
2023-05-28 04:51:34,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:51:34,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:51:34,272 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'zien', 'is', 'een', 'teken@@', 'ing', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de', 'is', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 04:51:34,272 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:51:34,272 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:51:34,272 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie zien is een tekening van de laatste 25 jaar gebeurde is in de laatste 25 jaar.
2023-05-28 04:51:57,189 - INFO - joeynmt.training - Epoch   9, Step:    38100, Batch Loss:     1.576788, Batch Acc: 0.560094, Tokens per Sec:     3094, Lr: 0.000300
2023-05-28 04:52:19,284 - INFO - joeynmt.training - Epoch   9, Step:    38200, Batch Loss:     1.456858, Batch Acc: 0.558789, Tokens per Sec:     3243, Lr: 0.000300
2023-05-28 04:52:42,076 - INFO - joeynmt.training - Epoch   9, Step:    38300, Batch Loss:     1.637567, Batch Acc: 0.561917, Tokens per Sec:     3115, Lr: 0.000300
2023-05-28 04:53:04,530 - INFO - joeynmt.training - Epoch   9, Step:    38400, Batch Loss:     1.421975, Batch Acc: 0.565588, Tokens per Sec:     3198, Lr: 0.000300
2023-05-28 04:53:27,403 - INFO - joeynmt.training - Epoch   9, Step:    38500, Batch Loss:     1.498898, Batch Acc: 0.561607, Tokens per Sec:     3097, Lr: 0.000300
2023-05-28 04:53:27,404 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:53:27,404 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:54:36,745 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.11, acc:   0.53, generation: 69.2478[sec], evaluation: 0.0000[sec]
2023-05-28 04:54:36,747 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 04:54:36,839 - INFO - joeynmt.helpers - delete models/transformer_b/36500.ckpt
2023-05-28 04:54:36,844 - INFO - joeynmt.training - Example #0
2023-05-28 04:54:36,844 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:54:36,844 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:54:36,844 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'h@@', 'and', 'he@@', 'et', 'van', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'e', '4@@', '0', 'tot', 'tot', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:54:36,844 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:54:36,844 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:54:36,844 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verwijderen dat de artische ijskappen die voor de hand heet van de drie miljoen jaar de grootte van de ondere 40 tot tot 40 procent.
2023-05-28 04:54:36,845 - INFO - joeynmt.training - Example #1
2023-05-28 04:54:36,845 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:54:36,845 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:54:36,845 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'veel', 'genoe@@', 'g', 'de', 'eerste', 'v@@', 'eil@@', 'ig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't', '.', '</s>']
2023-05-28 04:54:36,845 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:54:36,845 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:54:36,845 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet veel genoeg de eerste veiligheid van dit speciale probleem, omdat het niet de dik van het ijs toont.
2023-05-28 04:54:36,845 - INFO - joeynmt.training - Example #2
2023-05-28 04:54:36,845 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:54:36,845 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:54:36,845 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'p@@', 'la@@', 'st@@', 'ig', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:54:36,845 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:54:36,845 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:54:36,845 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het plastig hart van onze wereldwijde klimaatsysteem.
2023-05-28 04:54:36,845 - INFO - joeynmt.training - Example #3
2023-05-28 04:54:36,845 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:54:36,845 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:54:36,845 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'v@@', 'ast@@', 'st@@', 'ro@@', 'm@@', 'p', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 04:54:36,845 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:54:36,846 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:54:36,846 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en vaststromp in de zomer.
2023-05-28 04:54:36,846 - INFO - joeynmt.training - Example #4
2023-05-28 04:54:36,846 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:54:36,846 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:54:36,846 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', ',', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ap', ',', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de', '.', '</s>']
2023-05-28 04:54:36,846 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:54:36,846 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:54:36,846 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen, is een tijdschap, wat er in de laatste 25 jaar gebeurde.
2023-05-28 04:55:00,529 - INFO - joeynmt.training - Epoch   9, Step:    38600, Batch Loss:     1.239186, Batch Acc: 0.559434, Tokens per Sec:     2994, Lr: 0.000300
2023-05-28 04:55:22,677 - INFO - joeynmt.training - Epoch   9, Step:    38700, Batch Loss:     1.479915, Batch Acc: 0.558381, Tokens per Sec:     3196, Lr: 0.000300
2023-05-28 04:55:45,004 - INFO - joeynmt.training - Epoch   9, Step:    38800, Batch Loss:     1.404638, Batch Acc: 0.558600, Tokens per Sec:     3134, Lr: 0.000300
2023-05-28 04:56:06,953 - INFO - joeynmt.training - Epoch   9, Step:    38900, Batch Loss:     1.376525, Batch Acc: 0.570944, Tokens per Sec:     3237, Lr: 0.000300
2023-05-28 04:56:27,405 - INFO - joeynmt.training - Epoch   9, Step:    39000, Batch Loss:     1.626019, Batch Acc: 0.563205, Tokens per Sec:     3410, Lr: 0.000300
2023-05-28 04:56:27,406 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:56:27,406 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 04:57:31,905 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.11, acc:   0.53, generation: 64.4057[sec], evaluation: 0.0000[sec]
2023-05-28 04:57:31,907 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 04:57:31,991 - INFO - joeynmt.helpers - delete models/transformer_b/35500.ckpt
2023-05-28 04:57:31,997 - INFO - joeynmt.training - Example #0
2023-05-28 04:57:31,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 04:57:31,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 04:57:31,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'zien', 'om', 'te', 'ver@@', 'to@@', 'on@@', 'den', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', ',', 'die', 'voor', 'de', 'h@@', 'and', 'he@@', 'den', 'die', 'drie', 'miljo@@', 'en', 'jaar', ',', 'de', 'groot@@', 'te', 'van', 'de', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 04:57:31,997 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 04:57:31,997 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 04:57:31,997 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia gezien om te vertoonden dat de artische ijskapen, die voor de hand heden die drie miljoen jaar, de grootte van de 40 procent.
2023-05-28 04:57:31,997 - INFO - joeynmt.training - Example #1
2023-05-28 04:57:31,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 04:57:31,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 04:57:31,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'h@@', 'aa@@', 'st', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'uit', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 04:57:31,998 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 04:57:31,998 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 04:57:31,998 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste haast dit speciale probleem uit, want het is niet de dik van het ijs.
2023-05-28 04:57:31,998 - INFO - joeynmt.training - Example #2
2023-05-28 04:57:31,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 04:57:31,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 04:57:31,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'bl@@', 'ijk@@', 't', 'dat', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 04:57:31,998 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 04:57:31,998 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 04:57:31,998 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het blijkt dat ons wereldwijde klimaatsysteem.
2023-05-28 04:57:31,998 - INFO - joeynmt.training - Example #3
2023-05-28 04:57:31,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 04:57:31,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 04:57:31,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 're@@', 'e@@', 'p@@', 'te', '.', '</s>']
2023-05-28 04:57:31,998 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 04:57:31,998 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 04:57:31,998 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schreepte.
2023-05-28 04:57:31,998 - INFO - joeynmt.training - Example #4
2023-05-28 04:57:31,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 04:57:31,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 04:57:31,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'jullie', 'zien', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'ff@@', 'er@@', 'ende', '2@@', '5', 'jaar', 'gebeur@@', 'de', '.', '</s>']
2023-05-28 04:57:31,999 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 04:57:31,999 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 04:57:31,999 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie jullie zien is een tijdtrafferende 25 jaar gebeurde.
2023-05-28 04:57:54,082 - INFO - joeynmt.training - Epoch   9, Step:    39100, Batch Loss:     1.531499, Batch Acc: 0.561040, Tokens per Sec:     3119, Lr: 0.000300
2023-05-28 04:58:15,363 - INFO - joeynmt.training - Epoch   9, Step:    39200, Batch Loss:     1.265171, Batch Acc: 0.559022, Tokens per Sec:     3259, Lr: 0.000300
2023-05-28 04:58:36,991 - INFO - joeynmt.training - Epoch   9, Step:    39300, Batch Loss:     1.473647, Batch Acc: 0.562137, Tokens per Sec:     3319, Lr: 0.000300
2023-05-28 04:58:59,092 - INFO - joeynmt.training - Epoch   9, Step:    39400, Batch Loss:     1.354247, Batch Acc: 0.563000, Tokens per Sec:     3236, Lr: 0.000300
2023-05-28 04:59:21,426 - INFO - joeynmt.training - Epoch   9, Step:    39500, Batch Loss:     1.550919, Batch Acc: 0.563045, Tokens per Sec:     3189, Lr: 0.000300
2023-05-28 04:59:21,427 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 04:59:21,427 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:00:39,675 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.10, acc:   0.53, generation: 78.1533[sec], evaluation: 0.0000[sec]
2023-05-28 05:00:39,677 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 05:00:39,763 - INFO - joeynmt.helpers - delete models/transformer_b/37500.ckpt
2023-05-28 05:00:39,769 - INFO - joeynmt.training - Example #0
2023-05-28 05:00:39,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:00:39,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:00:39,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'den', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'noe@@', 'm@@', 't', ',', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ter', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'tot', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 05:00:39,769 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:00:39,769 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:00:39,769 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoonden om te verwijderen dat de artische ijskappen die voor noemt, die drie miljoen jaar de groter van de onderste 40 tot 40 procent.
2023-05-28 05:00:39,769 - INFO - joeynmt.training - Example #1
2023-05-28 05:00:39,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 05:00:39,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 05:00:39,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'ver@@', 'sla@@', 'v@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ë@@', 'le', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'is', '.', '</s>']
2023-05-28 05:00:39,770 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:00:39,770 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:00:39,770 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste verslaving van dit speciële probleem, omdat het niet de dikke probleem is.
2023-05-28 05:00:39,770 - INFO - joeynmt.training - Example #2
2023-05-28 05:00:39,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 05:00:39,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 05:00:39,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 05:00:39,770 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:00:39,770 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:00:39,770 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het hart van onze wereldwijde klimaatsysteem.
2023-05-28 05:00:39,770 - INFO - joeynmt.training - Example #3
2023-05-28 05:00:39,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 05:00:39,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 05:00:39,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'pen', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 05:00:39,770 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:00:39,770 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:00:39,770 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppen in de zomer.
2023-05-28 05:00:39,770 - INFO - joeynmt.training - Example #4
2023-05-28 05:00:39,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 05:00:39,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 05:00:39,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'zien', 'is', 'een', 'te@@', 'tra@@', 'ff@@', 'er@@', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 05:00:39,771 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:00:39,771 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:00:39,771 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie zien is een tetrafferopname wat er gebeurt in de laatste 25 jaar.
2023-05-28 05:01:02,970 - INFO - joeynmt.training - Epoch   9, Step:    39600, Batch Loss:     1.392307, Batch Acc: 0.560557, Tokens per Sec:     2998, Lr: 0.000300
2023-05-28 05:01:25,396 - INFO - joeynmt.training - Epoch   9, Step:    39700, Batch Loss:     1.721618, Batch Acc: 0.560540, Tokens per Sec:     3133, Lr: 0.000300
2023-05-28 05:01:47,365 - INFO - joeynmt.training - Epoch   9, Step:    39800, Batch Loss:     1.470108, Batch Acc: 0.559930, Tokens per Sec:     3207, Lr: 0.000300
2023-05-28 05:02:09,494 - INFO - joeynmt.training - Epoch   9, Step:    39900, Batch Loss:     1.631573, Batch Acc: 0.561095, Tokens per Sec:     3138, Lr: 0.000300
2023-05-28 05:02:25,637 - INFO - joeynmt.training - Epoch   9: total training loss 6701.84
2023-05-28 05:02:25,639 - INFO - joeynmt.training - EPOCH 10
2023-05-28 05:02:25,672 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=9
2023-05-28 05:02:31,063 - INFO - joeynmt.training - Epoch  10, Step:    40000, Batch Loss:     1.536488, Batch Acc: 0.565277, Tokens per Sec:     3241, Lr: 0.000300
2023-05-28 05:02:31,063 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:02:31,063 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:04:03,432 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.07, acc:   0.53, generation: 92.2728[sec], evaluation: 0.0000[sec]
2023-05-28 05:04:03,435 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 05:04:03,520 - INFO - joeynmt.helpers - delete models/transformer_b/38000.ckpt
2023-05-28 05:04:03,525 - INFO - joeynmt.training - Example #0
2023-05-28 05:04:03,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:04:03,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:04:03,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'anderen', '.', '</s>']
2023-05-28 05:04:03,525 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:04:03,525 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:04:03,525 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verwijderen dat de artische ijskapen van de grootte van de onderste 48 staten, om 40 procent te veranderen.
2023-05-28 05:04:03,525 - INFO - joeynmt.training - Example #1
2023-05-28 05:04:03,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 05:04:03,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 05:04:03,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'de', 'eerste', 'is', 'het', 'vol@@', 'gende', 'dat', 'het', 'ge@@', 'spe@@', 'ci@@', 'ë@@', 'le', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 05:04:03,526 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:04:03,526 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:04:03,526 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet de eerste is het volgende dat het gespeciële problemen van dit speciale probleem, want het is niet de dik van het ijs.
2023-05-28 05:04:03,526 - INFO - joeynmt.training - Example #2
2023-05-28 05:04:03,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 05:04:03,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 05:04:03,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'p@@', 'la@@', 'st@@', 'ige', 'ij@@', 'ds', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 05:04:03,526 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:04:03,526 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:04:03,526 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het plastige ijds van onze wereldwijde klimaatsysteem.
2023-05-28 05:04:03,526 - INFO - joeynmt.training - Example #3
2023-05-28 05:04:03,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 05:04:03,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 05:04:03,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'on@@', 'heid', '.', '</s>']
2023-05-28 05:04:03,526 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:04:03,526 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:04:03,526 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schoonheid.
2023-05-28 05:04:03,526 - INFO - joeynmt.training - Example #4
2023-05-28 05:04:03,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 05:04:03,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 05:04:03,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'te@@', 'mp@@', 'o', 'van', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 05:04:03,527 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:04:03,527 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:04:03,527 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tempo van wat er gebeurde in de laatste 25 jaar.
2023-05-28 05:04:25,782 - INFO - joeynmt.training - Epoch  10, Step:    40100, Batch Loss:     1.562988, Batch Acc: 0.568721, Tokens per Sec:     3251, Lr: 0.000300
2023-05-28 05:04:46,360 - INFO - joeynmt.training - Epoch  10, Step:    40200, Batch Loss:     1.337805, Batch Acc: 0.571439, Tokens per Sec:     3432, Lr: 0.000300
2023-05-28 05:05:07,059 - INFO - joeynmt.training - Epoch  10, Step:    40300, Batch Loss:     1.432710, Batch Acc: 0.571514, Tokens per Sec:     3457, Lr: 0.000300
2023-05-28 05:05:28,120 - INFO - joeynmt.training - Epoch  10, Step:    40400, Batch Loss:     1.387548, Batch Acc: 0.568801, Tokens per Sec:     3407, Lr: 0.000300
2023-05-28 05:05:47,941 - INFO - joeynmt.training - Epoch  10, Step:    40500, Batch Loss:     1.480224, Batch Acc: 0.568757, Tokens per Sec:     3550, Lr: 0.000300
2023-05-28 05:05:47,941 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:05:47,941 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:06:43,742 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.09, acc:   0.53, generation: 55.7087[sec], evaluation: 0.0000[sec]
2023-05-28 05:06:43,837 - INFO - joeynmt.helpers - delete models/transformer_b/37000.ckpt
2023-05-28 05:06:43,844 - INFO - joeynmt.training - Example #0
2023-05-28 05:06:43,844 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:06:43,844 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:06:43,844 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'ot', 'ij@@', 's', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ter', 'van', 'de', 'gro@@', 'ter', 'van', 'de', 'gro@@', 'ter', '4@@', '8', 'proc@@', 'ent', '.', '</s>']
2023-05-28 05:06:43,844 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:06:43,845 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:06:43,845 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verwijderen dat de artische ijskapot ijs die drie miljoen jaar de groter van de groter van de groter 48 procent.
2023-05-28 05:06:43,845 - INFO - joeynmt.training - Example #1
2023-05-28 05:06:43,845 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 05:06:43,845 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 05:06:43,845 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'h@@', 'aa@@', 'm@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k', '.', '</s>']
2023-05-28 05:06:43,845 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:06:43,845 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:06:43,845 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste haamheid van dit speciale probleem, want het is niet de dik.
2023-05-28 05:06:43,845 - INFO - joeynmt.training - Example #2
2023-05-28 05:06:43,845 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 05:06:43,845 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 05:06:43,845 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 05:06:43,845 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:06:43,845 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:06:43,845 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape ijskapen het hart van onze wereldwijde klimaatsysteem.
2023-05-28 05:06:43,845 - INFO - joeynmt.training - Example #3
2023-05-28 05:06:43,845 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 05:06:43,845 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 05:06:43,845 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'st@@', 'ro@@', 'm@@', 'ing', '.', '</s>']
2023-05-28 05:06:43,846 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:06:43,846 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:06:43,846 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en stroming.
2023-05-28 05:06:43,846 - INFO - joeynmt.training - Example #4
2023-05-28 05:06:43,846 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 05:06:43,846 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 05:06:43,846 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'zien', 'is', 'een', 'te@@', 'tra@@', 'p@@', 'er@@', '-@@', 'op@@', 'nam@@', 'e', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 05:06:43,846 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:06:43,846 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:06:43,846 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie zien is een tetraper-opname van wat er gebeurt in de laatste 25 jaar.
2023-05-28 05:07:05,261 - INFO - joeynmt.training - Epoch  10, Step:    40600, Batch Loss:     1.337062, Batch Acc: 0.569361, Tokens per Sec:     3323, Lr: 0.000300
2023-05-28 05:07:27,357 - INFO - joeynmt.training - Epoch  10, Step:    40700, Batch Loss:     1.578619, Batch Acc: 0.565862, Tokens per Sec:     3050, Lr: 0.000300
2023-05-28 05:07:48,330 - INFO - joeynmt.training - Epoch  10, Step:    40800, Batch Loss:     1.533791, Batch Acc: 0.565368, Tokens per Sec:     3365, Lr: 0.000300
2023-05-28 05:08:09,628 - INFO - joeynmt.training - Epoch  10, Step:    40900, Batch Loss:     1.542059, Batch Acc: 0.569077, Tokens per Sec:     3252, Lr: 0.000300
2023-05-28 05:08:31,696 - INFO - joeynmt.training - Epoch  10, Step:    41000, Batch Loss:     1.505041, Batch Acc: 0.559060, Tokens per Sec:     3159, Lr: 0.000300
2023-05-28 05:08:31,697 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:08:31,697 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:09:34,206 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.10, acc:   0.53, generation: 62.4123[sec], evaluation: 0.0000[sec]
2023-05-28 05:09:34,306 - INFO - joeynmt.helpers - delete models/transformer_b/38500.ckpt
2023-05-28 05:09:34,314 - INFO - joeynmt.training - Example #0
2023-05-28 05:09:34,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:09:34,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:09:34,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 't@@', 'te', 'van', 'de', 'gro@@', 'ter', 'van', 'de', '4@@', '0', 'uur', '.', '</s>']
2023-05-28 05:09:34,314 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:09:34,314 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:09:34,314 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia getoond om te bekijken dat de artische ijskape ijskape van drie miljoen jaar de grotte van de groter van de 40 uur.
2023-05-28 05:09:34,314 - INFO - joeynmt.training - Example #1
2023-05-28 05:09:34,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 05:09:34,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 05:09:34,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'de', 'n@@', 'u@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 05:09:34,314 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:09:34,314 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:09:34,314 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste is de nut van dit speciale problemen, want het is niet de dik van het ijs.
2023-05-28 05:09:34,314 - INFO - joeynmt.training - Example #2
2023-05-28 05:09:34,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 05:09:34,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 05:09:34,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 05:09:34,315 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:09:34,315 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:09:34,315 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het hart van onze wereldwijde klimaatsysteem.
2023-05-28 05:09:34,315 - INFO - joeynmt.training - Example #3
2023-05-28 05:09:34,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 05:09:34,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 05:09:34,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'st@@', 'ro@@', 'm@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 05:09:34,315 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:09:34,315 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:09:34,315 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en strompt in de zomer.
2023-05-28 05:09:34,315 - INFO - joeynmt.training - Example #4
2023-05-28 05:09:34,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 05:09:34,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 05:09:34,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ap', 'van', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 05:09:34,315 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:09:34,315 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:09:34,315 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschap van de afgelopen 25 jaar.
2023-05-28 05:09:56,017 - INFO - joeynmt.training - Epoch  10, Step:    41100, Batch Loss:     1.371025, Batch Acc: 0.568004, Tokens per Sec:     3288, Lr: 0.000300
2023-05-28 05:10:17,654 - INFO - joeynmt.training - Epoch  10, Step:    41200, Batch Loss:     1.531493, Batch Acc: 0.568582, Tokens per Sec:     3373, Lr: 0.000300
2023-05-28 05:10:39,374 - INFO - joeynmt.training - Epoch  10, Step:    41300, Batch Loss:     1.337437, Batch Acc: 0.569240, Tokens per Sec:     3288, Lr: 0.000300
2023-05-28 05:11:01,518 - INFO - joeynmt.training - Epoch  10, Step:    41400, Batch Loss:     1.470483, Batch Acc: 0.569058, Tokens per Sec:     3236, Lr: 0.000300
2023-05-28 05:11:23,496 - INFO - joeynmt.training - Epoch  10, Step:    41500, Batch Loss:     1.563910, Batch Acc: 0.564010, Tokens per Sec:     3191, Lr: 0.000300
2023-05-28 05:11:23,497 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:11:23,497 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:12:31,402 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.53, generation: 67.8102[sec], evaluation: 0.0000[sec]
2023-05-28 05:12:31,403 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 05:12:31,487 - INFO - joeynmt.helpers - delete models/transformer_b/39000.ckpt
2023-05-28 05:12:31,493 - INFO - joeynmt.training - Example #0
2023-05-28 05:12:31,493 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:12:31,493 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:12:31,493 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 't@@', 'ten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'zien', ',', 'om', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 05:12:31,493 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:12:31,493 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:12:31,493 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verwijderen dat de artische ijskapen die drie miljoen jaar de grotten van de onderste 48 staten had gezien, om 40 procent.
2023-05-28 05:12:31,493 - INFO - joeynmt.training - Example #1
2023-05-28 05:12:31,494 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 05:12:31,494 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 05:12:31,494 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'genoe@@', 'g', 'de', 'eerste', 'is', 'de', 'eerste', 'e@@', 'chte', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 05:12:31,494 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:12:31,494 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:12:31,494 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de eerste is de eerste echte van dit speciale problemen, want het is niet de dik van het ijs.
2023-05-28 05:12:31,494 - INFO - joeynmt.training - Example #2
2023-05-28 05:12:31,494 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 05:12:31,494 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 05:12:31,494 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 'z@@', 'er', 'dat', 'we', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 05:12:31,494 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:12:31,494 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:12:31,494 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijzer dat we het hart van onze wereldwijd klimaatsysteem.
2023-05-28 05:12:31,494 - INFO - joeynmt.training - Example #3
2023-05-28 05:12:31,494 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 05:12:31,494 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 05:12:31,494 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'st@@', 'op@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 05:12:31,494 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:12:31,494 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:12:31,494 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en stopt in de zomer.
2023-05-28 05:12:31,495 - INFO - joeynmt.training - Example #4
2023-05-28 05:12:31,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 05:12:31,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 05:12:31,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'teken@@', 'tra@@', 'ff@@', 'er@@', 'ende', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 05:12:31,495 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:12:31,495 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:12:31,495 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tekentrafferende 25 jaar gebeurt.
2023-05-28 05:12:52,694 - INFO - joeynmt.training - Epoch  10, Step:    41600, Batch Loss:     1.581847, Batch Acc: 0.567006, Tokens per Sec:     3288, Lr: 0.000300
2023-05-28 05:13:15,482 - INFO - joeynmt.training - Epoch  10, Step:    41700, Batch Loss:     1.506559, Batch Acc: 0.565524, Tokens per Sec:     3023, Lr: 0.000300
2023-05-28 05:13:37,521 - INFO - joeynmt.training - Epoch  10, Step:    41800, Batch Loss:     1.482077, Batch Acc: 0.571025, Tokens per Sec:     3084, Lr: 0.000300
2023-05-28 05:13:59,903 - INFO - joeynmt.training - Epoch  10, Step:    41900, Batch Loss:     1.689351, Batch Acc: 0.562506, Tokens per Sec:     3151, Lr: 0.000300
2023-05-28 05:14:22,552 - INFO - joeynmt.training - Epoch  10, Step:    42000, Batch Loss:     1.721444, Batch Acc: 0.567837, Tokens per Sec:     3162, Lr: 0.000300
2023-05-28 05:14:22,553 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:14:22,553 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:15:36,213 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.53, generation: 73.5632[sec], evaluation: 0.0000[sec]
2023-05-28 05:15:36,215 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 05:15:36,304 - INFO - joeynmt.helpers - delete models/transformer_b/41000.ckpt
2023-05-28 05:15:36,307 - INFO - joeynmt.training - Example #0
2023-05-28 05:15:36,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:15:36,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:15:36,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'de', 're@@', 'den', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ot', 'van', 'de', 'gro@@', 'ot', 'van', 'de', 'onder@@', 'ste', '4@@', '0', '%', '.', '</s>']
2023-05-28 05:15:36,307 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:15:36,307 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:15:36,307 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verbeteren dat de artische ijskape ijskape van de reden die drie miljoen jaar de groot van de groot van de onderste 40%.
2023-05-28 05:15:36,307 - INFO - joeynmt.training - Example #1
2023-05-28 05:15:36,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 05:15:36,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 05:15:36,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'plaats', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.', '</s>']
2023-05-28 05:15:36,308 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:15:36,308 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:15:36,308 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste plaats van dit specifieke probleem, omdat het niet de dikke van het ijs laat zien.
2023-05-28 05:15:36,308 - INFO - joeynmt.training - Example #2
2023-05-28 05:15:36,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 05:15:36,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 05:15:36,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 05:15:36,308 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:15:36,308 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:15:36,308 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape van onze wereldwijde klimaatsysteem.
2023-05-28 05:15:36,308 - INFO - joeynmt.training - Example #3
2023-05-28 05:15:36,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 05:15:36,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 05:15:36,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'st@@', 'ro@@', 'mp@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 05:15:36,308 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:15:36,308 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:15:36,308 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en stromppt in de zomer.
2023-05-28 05:15:36,308 - INFO - joeynmt.training - Example #4
2023-05-28 05:15:36,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 05:15:36,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 05:15:36,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ap', 'van', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', '.', '</s>']
2023-05-28 05:15:36,309 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:15:36,309 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:15:36,309 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdschap van wat er in de laatste 25 jaar gebeurt.
2023-05-28 05:15:59,033 - INFO - joeynmt.training - Epoch  10, Step:    42100, Batch Loss:     1.466445, Batch Acc: 0.564641, Tokens per Sec:     3094, Lr: 0.000300
2023-05-28 05:16:20,382 - INFO - joeynmt.training - Epoch  10, Step:    42200, Batch Loss:     1.588682, Batch Acc: 0.564572, Tokens per Sec:     3258, Lr: 0.000300
2023-05-28 05:16:39,679 - INFO - joeynmt.training - Epoch  10, Step:    42300, Batch Loss:     1.462047, Batch Acc: 0.562210, Tokens per Sec:     3658, Lr: 0.000300
2023-05-28 05:16:59,943 - INFO - joeynmt.training - Epoch  10, Step:    42400, Batch Loss:     1.446546, Batch Acc: 0.567538, Tokens per Sec:     3472, Lr: 0.000300
2023-05-28 05:17:20,438 - INFO - joeynmt.training - Epoch  10, Step:    42500, Batch Loss:     1.466574, Batch Acc: 0.567769, Tokens per Sec:     3527, Lr: 0.000300
2023-05-28 05:17:20,439 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:17:20,439 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:18:28,820 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.01, acc:   0.53, generation: 68.2890[sec], evaluation: 0.0000[sec]
2023-05-28 05:18:28,822 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 05:18:28,906 - INFO - joeynmt.helpers - delete models/transformer_b/39500.ckpt
2023-05-28 05:18:28,912 - INFO - joeynmt.training - Example #0
2023-05-28 05:18:28,912 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:18:28,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:18:28,912 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ct@@', 'ie@@', 'c@@', 'ap@@', 'ac@@', 't', 'te', 'ver@@', 'anderen', ',', 'dat', 'de', 'ar@@', 'ct@@', 'ie@@', 'k@@', 'app@@', 'ar@@', 'te@@', 'ment', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 05:18:28,912 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:18:28,912 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:18:28,912 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verbekijken dat de arctiecapact te veranderen, dat de arctiekappartement van de grootte van de onderste 40 procent.
2023-05-28 05:18:28,912 - INFO - joeynmt.training - Example #1
2023-05-28 05:18:28,912 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 05:18:28,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 05:18:28,912 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', ',', 'genoe@@', 'g', 'de', 'eerste', 'dat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'is', '.', '</s>']
2023-05-28 05:18:28,912 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:18:28,912 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:18:28,912 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste, genoeg de eerste dat het niet de dik van dit speciale probleem is.
2023-05-28 05:18:28,913 - INFO - joeynmt.training - Example #2
2023-05-28 05:18:28,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 05:18:28,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 05:18:28,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 05:18:28,913 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:18:28,913 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:18:28,913 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het hart van onze wereldsysteem.
2023-05-28 05:18:28,913 - INFO - joeynmt.training - Example #3
2023-05-28 05:18:28,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 05:18:28,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 05:18:28,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 05:18:28,913 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:18:28,913 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:18:28,913 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomer.
2023-05-28 05:18:28,913 - INFO - joeynmt.training - Example #4
2023-05-28 05:18:28,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 05:18:28,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 05:18:28,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', ',', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ap', 'van', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 05:18:28,913 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:18:28,913 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:18:28,913 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschap van de afgelopen 25 jaar.
2023-05-28 05:18:48,971 - INFO - joeynmt.training - Epoch  10, Step:    42600, Batch Loss:     1.515188, Batch Acc: 0.561554, Tokens per Sec:     3425, Lr: 0.000300
2023-05-28 05:19:09,951 - INFO - joeynmt.training - Epoch  10, Step:    42700, Batch Loss:     1.407897, Batch Acc: 0.563977, Tokens per Sec:     3367, Lr: 0.000300
2023-05-28 05:19:31,376 - INFO - joeynmt.training - Epoch  10, Step:    42800, Batch Loss:     1.461096, Batch Acc: 0.562776, Tokens per Sec:     3363, Lr: 0.000300
2023-05-28 05:19:52,581 - INFO - joeynmt.training - Epoch  10, Step:    42900, Batch Loss:     1.320910, Batch Acc: 0.567179, Tokens per Sec:     3384, Lr: 0.000300
2023-05-28 05:20:12,919 - INFO - joeynmt.training - Epoch  10, Step:    43000, Batch Loss:     1.345322, Batch Acc: 0.556178, Tokens per Sec:     3476, Lr: 0.000300
2023-05-28 05:20:12,921 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:20:12,921 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:21:21,575 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.02, acc:   0.53, generation: 68.5604[sec], evaluation: 0.0000[sec]
2023-05-28 05:21:21,659 - INFO - joeynmt.helpers - delete models/transformer_b/40500.ckpt
2023-05-28 05:21:21,665 - INFO - joeynmt.training - Example #0
2023-05-28 05:21:21,665 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:21:21,665 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:21:21,665 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', ',', 'om', 'te', 'ver@@', 'tro@@', 'uw@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'en@@', 'ten', 'van', 'de', 'gro@@', 'ter@@', 'e', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 05:21:21,665 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:21:21,665 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:21:21,665 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond, om te vertrouwen dat de artische ijskappen die drie miljoen jaar de groenten van de grotere 40 procent.
2023-05-28 05:21:21,665 - INFO - joeynmt.training - Example #1
2023-05-28 05:21:21,666 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 05:21:21,666 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 05:21:21,666 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'e@@', 'chte', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't', '.', '</s>']
2023-05-28 05:21:21,666 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:21:21,666 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:21:21,666 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste echte van dit specifieke probleem, omdat het niet de dikke van het ijs toont.
2023-05-28 05:21:21,666 - INFO - joeynmt.training - Example #2
2023-05-28 05:21:21,666 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 05:21:21,666 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 05:21:21,666 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 05:21:21,666 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:21:21,666 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:21:21,666 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het hart van ons wereldwijde klimaatsysteem.
2023-05-28 05:21:21,666 - INFO - joeynmt.training - Example #3
2023-05-28 05:21:21,666 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 05:21:21,666 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 05:21:21,666 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'v@@', 'ast@@', 'hou@@', 'den', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 05:21:21,666 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:21:21,666 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:21:21,666 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en vasthouden in de zomer.
2023-05-28 05:21:21,666 - INFO - joeynmt.training - Example #4
2023-05-28 05:21:21,667 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 05:21:21,667 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 05:21:21,667 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ap', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de', '.', '</s>']
2023-05-28 05:21:21,667 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:21:21,667 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:21:21,667 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen is een tijdschap van de laatste 25 jaar gebeurde.
2023-05-28 05:21:43,066 - INFO - joeynmt.training - Epoch  10, Step:    43100, Batch Loss:     1.292849, Batch Acc: 0.564852, Tokens per Sec:     3285, Lr: 0.000300
2023-05-28 05:22:04,164 - INFO - joeynmt.training - Epoch  10, Step:    43200, Batch Loss:     1.401859, Batch Acc: 0.560160, Tokens per Sec:     3433, Lr: 0.000300
2023-05-28 05:22:25,757 - INFO - joeynmt.training - Epoch  10, Step:    43300, Batch Loss:     1.512387, Batch Acc: 0.565564, Tokens per Sec:     3209, Lr: 0.000300
2023-05-28 05:22:46,210 - INFO - joeynmt.training - Epoch  10, Step:    43400, Batch Loss:     1.765406, Batch Acc: 0.562499, Tokens per Sec:     3411, Lr: 0.000300
2023-05-28 05:23:06,645 - INFO - joeynmt.training - Epoch  10, Step:    43500, Batch Loss:     1.425090, Batch Acc: 0.561001, Tokens per Sec:     3528, Lr: 0.000300
2023-05-28 05:23:06,646 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:23:06,646 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:24:07,803 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.03, acc:   0.53, generation: 61.0649[sec], evaluation: 0.0000[sec]
2023-05-28 05:24:07,892 - INFO - joeynmt.helpers - delete models/transformer_b/40000.ckpt
2023-05-28 05:24:07,901 - INFO - joeynmt.training - Example #0
2023-05-28 05:24:07,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:24:07,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:24:07,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'die', 'voor', 'een', 'da@@', 't@@', 'a', 'van', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ot', 'is', '.', '</s>']
2023-05-28 05:24:07,902 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:24:07,902 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:24:07,902 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verwijderen dat de artische ijskape ijskape die voor een data van drie miljoen jaar de groot is.
2023-05-28 05:24:07,902 - INFO - joeynmt.training - Example #1
2023-05-28 05:24:07,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 05:24:07,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 05:24:07,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'ster@@', 'k', 'genoe@@', 'g', ',', 'genoe@@', 'g', 'de', 'eerste', 'vraag', 'van', 'dit', 'proble@@', 'em', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', '.', '</s>']
2023-05-28 05:24:07,902 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:24:07,902 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:24:07,902 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg, genoeg de eerste vraag van dit probleem, want het is niet de dikke van het ijs.
2023-05-28 05:24:07,902 - INFO - joeynmt.training - Example #2
2023-05-28 05:24:07,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 05:24:07,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 05:24:07,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 05:24:07,902 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:24:07,902 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:24:07,902 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape van ons globale klimaatsysteem.
2023-05-28 05:24:07,902 - INFO - joeynmt.training - Example #3
2023-05-28 05:24:07,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 05:24:07,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 05:24:07,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'st@@', 'ro@@', 'o@@', 'f@@', 'te', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 05:24:07,903 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:24:07,903 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:24:07,903 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en stroofte in de zomer.
2023-05-28 05:24:07,903 - INFO - joeynmt.training - Example #4
2023-05-28 05:24:07,903 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 05:24:07,903 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 05:24:07,903 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ap', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 05:24:07,903 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:24:07,903 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:24:07,903 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdschap in de laatste 25 jaar.
2023-05-28 05:24:30,103 - INFO - joeynmt.training - Epoch  10, Step:    43600, Batch Loss:     1.314363, Batch Acc: 0.563510, Tokens per Sec:     3120, Lr: 0.000300
2023-05-28 05:24:52,748 - INFO - joeynmt.training - Epoch  10, Step:    43700, Batch Loss:     1.446180, Batch Acc: 0.566392, Tokens per Sec:     3091, Lr: 0.000300
2023-05-28 05:25:14,211 - INFO - joeynmt.training - Epoch  10, Step:    43800, Batch Loss:     1.484766, Batch Acc: 0.566832, Tokens per Sec:     3232, Lr: 0.000300
2023-05-28 05:25:36,591 - INFO - joeynmt.training - Epoch  10, Step:    43900, Batch Loss:     1.607889, Batch Acc: 0.564557, Tokens per Sec:     3279, Lr: 0.000300
2023-05-28 05:25:58,641 - INFO - joeynmt.training - Epoch  10, Step:    44000, Batch Loss:     1.483257, Batch Acc: 0.568179, Tokens per Sec:     3314, Lr: 0.000300
2023-05-28 05:25:58,641 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:25:58,641 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:26:51,534 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.01, acc:   0.54, generation: 52.7971[sec], evaluation: 0.0000[sec]
2023-05-28 05:26:51,535 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 05:26:51,642 - INFO - joeynmt.helpers - delete models/transformer_b/41500.ckpt
2023-05-28 05:26:51,649 - INFO - joeynmt.training - Example #0
2023-05-28 05:26:51,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt', ',', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lichen', ',', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', ',', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hatte', ',', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist', '.']
2023-05-28 05:26:51,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a', '&@@', 'ap@@', 'o@@', 's@@', ';', 's', 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S', ',', 'met', '4@@', '0', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was', '.']
2023-05-28 05:26:51,649 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', ',', 'die', 'voor', 'de', 'A@@', 'zi@@', 'ë', ',', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ot', 'gro@@', 'ot', 'zijn', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', '.', '</s>']
2023-05-28 05:26:51,649 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2023-05-28 05:26:51,649 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia 's zien om aan te tonen dat de poolijskap, die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS, met 40% gekrompen was.
2023-05-28 05:26:51,649 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te bekijken dat de artische ijskapen, die voor de Azië, drie miljoen jaar de groot groot zijn van de onderste 40 procent.
2023-05-28 05:26:51,649 - INFO - joeynmt.training - Example #1
2023-05-28 05:26:51,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'gt', '.']
2023-05-28 05:26:51,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', '.']
2023-05-28 05:26:51,649 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dru@@', 'kt', 'niet', 'veel', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'de', 'eerste', 'e@@', 'chte', 'proble@@', 'em', 'uit', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't', '.', '</s>']
2023-05-28 05:26:51,649 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2023-05-28 05:26:51,649 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien.
2023-05-28 05:26:51,650 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet veel genoeg de eerste is dat de eerste echte probleem uit, omdat het niet de dikke dikke van het ijs toont.
2023-05-28 05:26:51,650 - INFO - joeynmt.training - Example #2
2023-05-28 05:26:51,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's', '.']
2023-05-28 05:26:51,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.']
2023-05-28 05:26:51,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', '.', '</s>']
2023-05-28 05:26:51,650 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2023-05-28 05:26:51,650 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem.
2023-05-28 05:26:51,650 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape van ons wereldwijde klimaatsysteem.
2023-05-28 05:26:51,650 - INFO - joeynmt.training - Example #3
2023-05-28 05:26:51,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'omm@@', 'er', '.']
2023-05-28 05:26:51,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.']
2023-05-28 05:26:51,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'st@@', 'ro@@', 'm@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er', '.', '</s>']
2023-05-28 05:26:51,650 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2023-05-28 05:26:51,650 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2023-05-28 05:26:51,650 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en strompt in de zomer.
2023-05-28 05:26:51,650 - INFO - joeynmt.training - Example #4
2023-05-28 05:26:51,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie', ',', 'die', 'ich', 'Ihnen', 'zei@@', 'ge', ',', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist', '.']
2023-05-28 05:26:51,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', '.']
2023-05-28 05:26:51,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', ',', 'is', 'een', 'tij@@', 'd@@', 'je', ',', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', '.', '</s>']
2023-05-28 05:26:51,651 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2023-05-28 05:26:51,651 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2023-05-28 05:26:51,651 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen, is een tijdje, wat er in de laatste 25 jaar.
2023-05-28 05:27:14,705 - INFO - joeynmt.training - Epoch  10, Step:    44100, Batch Loss:     1.564417, Batch Acc: 0.568716, Tokens per Sec:     2971, Lr: 0.000300
2023-05-28 05:27:36,532 - INFO - joeynmt.training - Epoch  10, Step:    44200, Batch Loss:     1.471251, Batch Acc: 0.566899, Tokens per Sec:     3225, Lr: 0.000300
2023-05-28 05:27:58,665 - INFO - joeynmt.training - Epoch  10, Step:    44300, Batch Loss:     1.499933, Batch Acc: 0.565149, Tokens per Sec:     3162, Lr: 0.000300
2023-05-28 05:28:21,664 - INFO - joeynmt.training - Epoch  10, Step:    44400, Batch Loss:     1.588453, Batch Acc: 0.569321, Tokens per Sec:     2944, Lr: 0.000300
2023-05-28 05:28:21,968 - INFO - joeynmt.training - Epoch  10: total training loss 6609.60
2023-05-28 05:28:21,968 - INFO - joeynmt.training - Training ended after  10 epochs.
2023-05-28 05:28:21,968 - INFO - joeynmt.training - Best validation result (greedy) at step    44000:   5.01 ppl.
2023-05-28 05:28:21,980 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-28 05:28:22,012 - INFO - joeynmt.model - Enc-dec model built.
2023-05-28 05:28:22,042 - INFO - joeynmt.helpers - Load model from /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_b/44000.ckpt.
2023-05-28 05:28:22,045 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2002),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2002),
	loss_function=None)
2023-05-28 05:28:22,047 - INFO - joeynmt.prediction - Decoding on dev set...
2023-05-28 05:28:22,047 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:28:22,047 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:29:26,651 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 64.5123[sec], evaluation: 0.0000[sec]
2023-05-28 05:29:26,655 - INFO - joeynmt.prediction - Translations saved to: /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_b/00044000.hyps.dev.
2023-05-28 05:29:26,655 - INFO - joeynmt.prediction - Decoding on test set...
2023-05-28 05:29:26,655 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 05:29:26,655 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 05:30:56,766 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 89.9619[sec], evaluation: 0.0000[sec]
2023-05-28 05:30:56,768 - INFO - joeynmt.prediction - Translations saved to: /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_b/00044000.hyps.test.
