2023-05-27 22:54:05,623 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2023-05-27 22:54:05,623 - INFO - joeynmt.helpers -                           cfg.name : transformer_a
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -                     cfg.data.train : ../mt-2023-ex05/data/train.de-nl
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -                       cfg.data.dev : ../mt-2023-ex05/data/dev.de-nl
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -                      cfg.data.test : ../mt-2023-ex05/data/test.de-nl
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -       cfg.data.sample_train_subset : 100000
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -                 cfg.data.src.level : word
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -             cfg.data.src.normalize : False
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -             cfg.data.src.voc_limit : 2000
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : sentencepiece
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenizer : moses
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.model_file : ?
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.model_type : unigram
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.alpha : 0.1
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.character_coverage : 1.0
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.nbest_size : 10
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : nl
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -                 cfg.data.trg.level : word
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -             cfg.data.trg.normalize : False
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -             cfg.data.trg.voc_limit : 2000
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : sentencepiece
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenizer : moses
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.model_type : unigram
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.alpha : 0.1
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.character_coverage : 1.0
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.nbest_size : 10
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2023-05-27 22:54:05,624 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/transformer_a
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -             cfg.training.overwrite : True
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : False
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2023-05-27 22:54:05,625 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2023-05-27 22:54:05,627 - INFO - joeynmt.data - Building tokenizer...
2023-05-27 22:54:05,733 - INFO - joeynmt.tokenizers - de tokenizer: BasicTokenizer(level=word, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses)
2023-05-27 22:54:05,734 - INFO - joeynmt.tokenizers - nl tokenizer: BasicTokenizer(level=word, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses)
2023-05-27 22:54:05,734 - INFO - joeynmt.data - Loading train set...
2023-05-27 22:54:28,474 - INFO - joeynmt.data - Building vocabulary...
2023-05-27 22:54:30,364 - INFO - joeynmt.data - Loading dev set...
2023-05-27 22:54:30,470 - INFO - joeynmt.data - Loading test set...
2023-05-27 22:54:30,641 - INFO - joeynmt.data - Data loaded.
2023-05-27 22:54:30,642 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=216893, src_lang=de, trg_lang=nl, has_trg=True, random_subset=100000)
2023-05-27 22:54:30,642 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1001, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2023-05-27 22:54:30,642 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1779, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2023-05-27 22:54:30,642 - INFO - joeynmt.data - First training example:
	[SRC] Al Gore : Die Abwendung der Klimakatastrophe
	[TRG] Al Gore over het afwenden van de klimaatcrisis
2023-05-27 22:54:30,642 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) die (7) und (8) der (9) ist
2023-05-27 22:54:30,642 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) de (7) een (8) het (9) van
2023-05-27 22:54:30,642 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2004
2023-05-27 22:54:30,642 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2004
2023-05-27 22:54:30,643 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-27 22:54:30,682 - INFO - joeynmt.model - Enc-dec model built.
2023-05-27 22:54:30,683 - INFO - joeynmt.model - Total params: 3925248
2023-05-27 22:54:30,684 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2023-05-27 22:54:30,684 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2023-05-27 22:54:30,684 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2023-05-27 22:54:30,684 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2023-05-27 22:54:30,684 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2023-05-27 22:54:30,684 - INFO - joeynmt.training - EPOCH 1
2023-05-27 22:54:30,713 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=0
2023-05-27 22:54:51,892 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     2.906503, Batch Acc: 0.196080, Tokens per Sec:     3176, Lr: 0.000300
2023-05-27 22:55:13,770 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     2.857312, Batch Acc: 0.236329, Tokens per Sec:     3057, Lr: 0.000300
2023-05-27 22:55:36,487 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     2.828763, Batch Acc: 0.252151, Tokens per Sec:     2922, Lr: 0.000300
2023-05-27 22:55:58,657 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     2.742246, Batch Acc: 0.267793, Tokens per Sec:     2949, Lr: 0.000300
2023-05-27 22:56:19,977 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     2.685183, Batch Acc: 0.279550, Tokens per Sec:     3064, Lr: 0.000300
2023-05-27 22:56:19,978 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 22:56:19,978 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 22:56:54,901 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.64, ppl:  13.98, acc:   0.29, generation: 34.8778[sec], evaluation: 0.0000[sec]
2023-05-27 22:56:54,903 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 22:56:55,043 - INFO - joeynmt.training - Example #0
2023-05-27 22:56:55,043 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 22:56:55,043 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 22:56:55,043 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 22:56:55,043 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 22:56:55,043 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 22:56:55,043 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> <unk> <unk>, <unk> <unk>, <unk> <unk>, <unk>, <unk>, <unk>, <unk>, <unk> <unk> <unk> <unk> <unk>.
2023-05-27 22:56:55,043 - INFO - joeynmt.training - Example #1
2023-05-27 22:56:55,043 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 22:56:55,044 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 22:56:55,044 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'niet', 'niet', 'niet', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 22:56:55,044 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 22:56:55,044 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 22:56:55,044 - INFO - joeynmt.training - 	Hypothesis: Maar niet niet niet de <unk> <unk> <unk> <unk>, <unk>, <unk> <unk> <unk> <unk> <unk>.
2023-05-27 22:56:55,044 - INFO - joeynmt.training - Example #2
2023-05-27 22:56:55,044 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 22:56:55,044 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 22:56:55,044 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 22:56:55,044 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 22:56:55,044 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 22:56:55,044 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>.
2023-05-27 22:56:55,044 - INFO - joeynmt.training - Example #3
2023-05-27 22:56:55,044 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 22:56:55,044 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 22:56:55,044 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', '<unk>', 'en', '<unk>', 'en', '<unk>', '.', '</s>']
2023-05-27 22:56:55,044 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 22:56:55,044 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 22:56:55,044 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> <unk> en <unk> en <unk>.
2023-05-27 22:56:55,044 - INFO - joeynmt.training - Example #4
2023-05-27 22:56:55,044 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 22:56:55,044 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 22:56:55,044 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', '<unk>', '<unk>', '<unk>', ',', 'is', 'is', 'is', 'een', '<unk>', ',', 'is', 'is', 'is', 'een', '<unk>', '.', '</s>']
2023-05-27 22:56:55,045 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 22:56:55,045 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 22:56:55,045 - INFO - joeynmt.training - 	Hypothesis: De <unk> <unk> <unk>, is is is een <unk>, is is is een <unk>.
2023-05-27 22:57:16,056 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     2.565970, Batch Acc: 0.304124, Tokens per Sec:     3149, Lr: 0.000300
2023-05-27 22:57:36,898 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     2.575306, Batch Acc: 0.314151, Tokens per Sec:     3274, Lr: 0.000300
2023-05-27 22:57:58,500 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     2.524127, Batch Acc: 0.321205, Tokens per Sec:     2976, Lr: 0.000300
2023-05-27 22:58:20,942 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     2.408654, Batch Acc: 0.333264, Tokens per Sec:     2996, Lr: 0.000300
2023-05-27 22:58:42,458 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     2.413021, Batch Acc: 0.343652, Tokens per Sec:     3090, Lr: 0.000300
2023-05-27 22:58:42,458 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 22:58:42,458 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 22:59:09,805 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.39, ppl:  10.92, acc:   0.34, generation: 27.3042[sec], evaluation: 0.0000[sec]
2023-05-27 22:59:09,807 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 22:59:09,948 - INFO - joeynmt.training - Example #0
2023-05-27 22:59:09,948 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 22:59:09,948 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 22:59:09,948 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'ik', 'deze', '<unk>', '<unk>', 'om', 'te', '<unk>', 'om', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', 'voor', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 22:59:09,948 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 22:59:09,948 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 22:59:09,948 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar ik deze <unk> <unk> om te <unk> om de <unk> <unk> <unk> <unk>, <unk>, <unk> voor de <unk> <unk> <unk>, <unk> <unk>, <unk> <unk>, <unk> <unk> <unk>.
2023-05-27 22:59:09,948 - INFO - joeynmt.training - Example #1
2023-05-27 22:59:09,948 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 22:59:09,948 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 22:59:09,948 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'niet', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', 'niet', '<unk>', '.', '</s>']
2023-05-27 22:59:09,949 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 22:59:09,949 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 22:59:09,949 - INFO - joeynmt.training - 	Hypothesis: Maar het niet <unk> van deze <unk> <unk>, <unk>, <unk> niet <unk>.
2023-05-27 22:59:09,949 - INFO - joeynmt.training - Example #2
2023-05-27 22:59:09,949 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 22:59:09,949 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 22:59:09,949 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2023-05-27 22:59:09,949 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 22:59:09,949 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 22:59:09,949 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> <unk> <unk> van de <unk> <unk>.
2023-05-27 22:59:09,949 - INFO - joeynmt.training - Example #3
2023-05-27 22:59:09,949 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 22:59:09,949 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 22:59:09,949 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', '<unk>', 'en', '<unk>', 'in', 'het', '<unk>', '.', '</s>']
2023-05-27 22:59:09,949 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 22:59:09,949 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 22:59:09,949 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> <unk> en <unk> in het <unk>.
2023-05-27 22:59:09,949 - INFO - joeynmt.training - Example #4
2023-05-27 22:59:09,949 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 22:59:09,949 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 22:59:09,949 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', '<unk>', '<unk>', ',', 'ik', 'jullie', 'jullie', 'jullie', 'een', '<unk>', '<unk>', 'in', 'de', '<unk>', 'jaar', 'jaar', '.', '</s>']
2023-05-27 22:59:09,949 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 22:59:09,949 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 22:59:09,949 - INFO - joeynmt.training - 	Hypothesis: De <unk> <unk>, ik jullie jullie jullie een <unk> <unk> in de <unk> jaar jaar.
2023-05-27 22:59:32,070 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     2.249196, Batch Acc: 0.345128, Tokens per Sec:     2923, Lr: 0.000300
2023-05-27 22:59:54,647 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     2.243616, Batch Acc: 0.355927, Tokens per Sec:     3002, Lr: 0.000300
2023-05-27 23:00:16,288 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     2.242637, Batch Acc: 0.366192, Tokens per Sec:     3008, Lr: 0.000300
2023-05-27 23:00:37,665 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     2.212692, Batch Acc: 0.370709, Tokens per Sec:     3100, Lr: 0.000300
2023-05-27 23:00:58,531 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     2.191115, Batch Acc: 0.373712, Tokens per Sec:     3167, Lr: 0.000300
2023-05-27 23:00:58,532 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:00:58,532 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:01:29,312 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.24, ppl:   9.42, acc:   0.36, generation: 30.7339[sec], evaluation: 0.0000[sec]
2023-05-27 23:01:29,314 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:01:29,414 - INFO - joeynmt.training - Example #0
2023-05-27 23:01:29,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:01:29,414 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:01:29,414 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', 'ik', 'deze', 'twee', 'jaar', 'om', '<unk>', 'te', '<unk>', 'om', '<unk>', 'te', '<unk>', 'dat', 'de', '<unk>', 'voor', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'van', 'de', '<unk>', ',', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:01:29,414 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:01:29,415 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:01:29,415 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> ik deze twee jaar om <unk> te <unk> om <unk> te <unk> dat de <unk> voor de <unk> van de <unk> <unk> van de <unk>, <unk> <unk>.
2023-05-27 23:01:29,415 - INFO - joeynmt.training - Example #1
2023-05-27 23:01:29,415 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:01:29,415 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:01:29,415 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', '<unk>', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-27 23:01:29,415 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:01:29,415 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:01:29,415 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> de <unk> van deze <unk> <unk>, <unk> het niet de <unk> van de <unk>.
2023-05-27 23:01:29,415 - INFO - joeynmt.training - Example #2
2023-05-27 23:01:29,415 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:01:29,415 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:01:29,415 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:01:29,415 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:01:29,415 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:01:29,415 - INFO - joeynmt.training - 	Hypothesis: In <unk> is de <unk> <unk> <unk> <unk> <unk> <unk>.
2023-05-27 23:01:29,415 - INFO - joeynmt.training - Example #3
2023-05-27 23:01:29,415 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:01:29,415 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:01:29,415 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', '<unk>', '.', '</s>']
2023-05-27 23:01:29,415 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:01:29,415 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:01:29,415 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in het <unk> en <unk> in de <unk>.
2023-05-27 23:01:29,415 - INFO - joeynmt.training - Example #4
2023-05-27 23:01:29,415 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:01:29,415 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:01:29,415 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', '<unk>', 'die', 'ik', 'jullie', '<unk>', ',', '<unk>', ',', 'is', 'een', '<unk>', 'in', 'de', 'afgelopen', 'jaar', '.', '</s>']
2023-05-27 23:01:29,416 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:01:29,416 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:01:29,416 - INFO - joeynmt.training - 	Hypothesis: De <unk> die ik jullie <unk>, <unk>, is een <unk> in de afgelopen jaar.
2023-05-27 23:01:49,955 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     2.272731, Batch Acc: 0.386949, Tokens per Sec:     3181, Lr: 0.000300
2023-05-27 23:02:10,766 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     2.177468, Batch Acc: 0.391379, Tokens per Sec:     3167, Lr: 0.000300
2023-05-27 23:02:32,016 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.087221, Batch Acc: 0.394729, Tokens per Sec:     3134, Lr: 0.000300
2023-05-27 23:02:51,945 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     1.994912, Batch Acc: 0.400031, Tokens per Sec:     3232, Lr: 0.000300
2023-05-27 23:03:12,136 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.182802, Batch Acc: 0.404642, Tokens per Sec:     3192, Lr: 0.000300
2023-05-27 23:03:12,137 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:03:12,137 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:03:39,429 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.13, ppl:   8.42, acc:   0.39, generation: 27.2473[sec], evaluation: 0.0000[sec]
2023-05-27 23:03:39,430 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:03:39,555 - INFO - joeynmt.training - Example #0
2023-05-27 23:03:39,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:03:39,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:03:39,555 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', ',', 'om', '<unk>', 'te', '<unk>', ',', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:03:39,555 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:03:39,555 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:03:39,555 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk>, om <unk> te <unk>, dat de <unk> <unk> <unk>, <unk> <unk> <unk>.
2023-05-27 23:03:39,555 - INFO - joeynmt.training - Example #1
2023-05-27 23:03:39,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:03:39,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:03:39,555 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'genoeg', '<unk>', 'die', '<unk>', '<unk>', 'uit', ',', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-27 23:03:39,555 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:03:39,555 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:03:39,556 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg genoeg <unk> die <unk> <unk> uit, het niet de <unk> van het <unk> van het <unk>.
2023-05-27 23:03:39,556 - INFO - joeynmt.training - Example #2
2023-05-27 23:03:39,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:03:39,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:03:39,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:03:39,556 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:03:39,556 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:03:39,556 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> <unk> <unk> <unk>.
2023-05-27 23:03:39,556 - INFO - joeynmt.training - Example #3
2023-05-27 23:03:39,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:03:39,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:03:39,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', '<unk>', 'en', '<unk>', 'in', 'de', '<unk>', '.', '</s>']
2023-05-27 23:03:39,556 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:03:39,556 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:03:39,556 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in <unk> en <unk> in de <unk>.
2023-05-27 23:03:39,556 - INFO - joeynmt.training - Example #4
2023-05-27 23:03:39,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:03:39,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:03:39,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', ',', 'is', 'een', '<unk>', 'van', 'de', 'laatste', 'laatste', 'laatste', 'jaar', 'is', 'is', '.', '</s>']
2023-05-27 23:03:39,556 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:03:39,556 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:03:39,556 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie, is een <unk> van de laatste laatste laatste jaar is is.
2023-05-27 23:03:59,951 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.077709, Batch Acc: 0.410004, Tokens per Sec:     3274, Lr: 0.000300
2023-05-27 23:04:19,745 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.026309, Batch Acc: 0.415856, Tokens per Sec:     3290, Lr: 0.000300
2023-05-27 23:04:41,271 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.009048, Batch Acc: 0.425248, Tokens per Sec:     3074, Lr: 0.000300
2023-05-27 23:05:03,670 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     1.892026, Batch Acc: 0.418815, Tokens per Sec:     3005, Lr: 0.000300
2023-05-27 23:05:25,416 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     1.938823, Batch Acc: 0.427062, Tokens per Sec:     2950, Lr: 0.000300
2023-05-27 23:05:25,417 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:05:25,417 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:05:58,708 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.05, ppl:   7.76, acc:   0.41, generation: 33.2409[sec], evaluation: 0.0000[sec]
2023-05-27 23:05:58,711 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:05:58,876 - INFO - joeynmt.training - Example #0
2023-05-27 23:05:58,876 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:05:58,876 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:05:58,876 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', ',', 'om', '<unk>', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'van', 'de', 'drie', 'miljoen', 'jaar', 'geleden', '<unk>', '<unk>', 'miljoen', 'jaar', 'geleden', 'geleden', '.', '</s>']
2023-05-27 23:05:58,876 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:05:58,876 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:05:58,876 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk>, om <unk> te <unk> dat de <unk> <unk> van de drie miljoen jaar geleden <unk> <unk> miljoen jaar geleden geleden.
2023-05-27 23:05:58,876 - INFO - joeynmt.training - Example #1
2023-05-27 23:05:58,876 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:05:58,876 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:05:58,876 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', 'van', '<unk>', ',', 'en', 'het', '<unk>', 'van', 'het', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-27 23:05:58,876 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:05:58,876 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:05:58,876 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg genoeg de <unk> van dit <unk> van <unk>, en het <unk> van het <unk> van het <unk>.
2023-05-27 23:05:58,876 - INFO - joeynmt.training - Example #2
2023-05-27 23:05:58,876 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:05:58,876 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:05:58,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'van', 'ons', '<unk>', '<unk>', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:05:58,877 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:05:58,877 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:05:58,877 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> van ons <unk> <unk> van ons <unk>.
2023-05-27 23:05:58,877 - INFO - joeynmt.training - Example #3
2023-05-27 23:05:58,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:05:58,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:05:58,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', '<unk>', 'en', '<unk>', 'in', 'de', '<unk>', '.', '</s>']
2023-05-27 23:05:58,877 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:05:58,877 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:05:58,877 - INFO - joeynmt.training - 	Hypothesis: Het is <unk> en <unk> in de <unk>.
2023-05-27 23:05:58,877 - INFO - joeynmt.training - Example #4
2023-05-27 23:05:58,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:05:58,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:05:58,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', ',', 'de', 'volgende', '<unk>', ',', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '<unk>', 'jaar', 'is', '.', '</s>']
2023-05-27 23:05:58,877 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:05:58,877 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:05:58,877 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk>, de volgende <unk>, is een <unk> van de laatste <unk> jaar is.
2023-05-27 23:06:20,190 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     1.955176, Batch Acc: 0.425084, Tokens per Sec:     3052, Lr: 0.000300
2023-05-27 23:06:41,339 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.084781, Batch Acc: 0.433979, Tokens per Sec:     3204, Lr: 0.000300
2023-05-27 23:06:48,428 - INFO - joeynmt.training - Epoch   1: total training loss 6345.81
2023-05-27 23:06:48,429 - INFO - joeynmt.training - EPOCH 2
2023-05-27 23:06:48,462 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=1
2023-05-27 23:07:02,439 - INFO - joeynmt.training - Epoch   2, Step:     2800, Batch Loss:     1.923357, Batch Acc: 0.435638, Tokens per Sec:     3029, Lr: 0.000300
2023-05-27 23:07:24,789 - INFO - joeynmt.training - Epoch   2, Step:     2900, Batch Loss:     1.853836, Batch Acc: 0.446600, Tokens per Sec:     3056, Lr: 0.000300
2023-05-27 23:07:45,714 - INFO - joeynmt.training - Epoch   2, Step:     3000, Batch Loss:     1.839638, Batch Acc: 0.445279, Tokens per Sec:     3149, Lr: 0.000300
2023-05-27 23:07:45,714 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:07:45,715 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:08:07,314 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.27, acc:   0.42, generation: 21.5543[sec], evaluation: 0.0000[sec]
2023-05-27 23:08:07,316 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:08:07,448 - INFO - joeynmt.helpers - delete models/transformer_a/500.ckpt
2023-05-27 23:08:07,463 - INFO - joeynmt.training - Example #0
2023-05-27 23:08:07,463 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:08:07,463 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:08:07,463 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', 'voor', '<unk>', ',', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:08:07,463 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:08:07,463 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:08:07,463 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> dat de <unk> <unk> <unk> <unk>, die <unk> <unk> <unk> voor <unk>, de <unk> van de <unk> <unk> <unk> van de <unk> <unk> <unk>.
2023-05-27 23:08:07,463 - INFO - joeynmt.training - Example #1
2023-05-27 23:08:07,463 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:08:07,463 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:08:07,463 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-27 23:08:07,463 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:08:07,463 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:08:07,463 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg de <unk> van de <unk> <unk>, want het is niet de <unk> van het <unk>.
2023-05-27 23:08:07,463 - INFO - joeynmt.training - Example #2
2023-05-27 23:08:07,463 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:08:07,463 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:08:07,464 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:08:07,464 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:08:07,464 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:08:07,464 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> <unk> <unk>.
2023-05-27 23:08:07,464 - INFO - joeynmt.training - Example #3
2023-05-27 23:08:07,464 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:08:07,464 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:08:07,464 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:08:07,464 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:08:07,464 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:08:07,464 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in het <unk> en <unk> in de zomer.
2023-05-27 23:08:07,464 - INFO - joeynmt.training - Example #4
2023-05-27 23:08:07,464 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:08:07,464 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:08:07,464 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:08:07,464 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:08:07,464 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:08:07,464 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie zien, is een <unk> wat in de laatste 25 jaar is.
2023-05-27 23:08:27,637 - INFO - joeynmt.training - Epoch   2, Step:     3100, Batch Loss:     1.987747, Batch Acc: 0.448916, Tokens per Sec:     3257, Lr: 0.000300
2023-05-27 23:08:47,917 - INFO - joeynmt.training - Epoch   2, Step:     3200, Batch Loss:     1.952995, Batch Acc: 0.454743, Tokens per Sec:     3248, Lr: 0.000300
2023-05-27 23:09:09,534 - INFO - joeynmt.training - Epoch   2, Step:     3300, Batch Loss:     1.880391, Batch Acc: 0.447916, Tokens per Sec:     3010, Lr: 0.000300
2023-05-27 23:09:35,081 - INFO - joeynmt.training - Epoch   2, Step:     3400, Batch Loss:     1.883570, Batch Acc: 0.453084, Tokens per Sec:     2596, Lr: 0.000300
2023-05-27 23:10:12,910 - INFO - joeynmt.training - Epoch   2, Step:     3500, Batch Loss:     1.691344, Batch Acc: 0.459790, Tokens per Sec:     1723, Lr: 0.000300
2023-05-27 23:10:12,910 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:10:12,911 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:11:05,844 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.05, acc:   0.43, generation: 52.8831[sec], evaluation: 0.0000[sec]
2023-05-27 23:11:05,846 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:11:06,049 - INFO - joeynmt.helpers - delete models/transformer_a/1000.ckpt
2023-05-27 23:11:06,064 - INFO - joeynmt.training - Example #0
2023-05-27 23:11:06,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:11:06,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:11:06,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'voor', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:11:06,065 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:11:06,065 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:11:06,065 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> om te <unk> dat de <unk> <unk> voor <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> van de <unk> <unk> <unk>.
2023-05-27 23:11:06,065 - INFO - joeynmt.training - Example #1
2023-05-27 23:11:06,065 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:11:06,065 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:11:06,065 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-27 23:11:06,065 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:11:06,065 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:11:06,065 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg genoeg de <unk> van dit <unk> <unk>, het niet de <unk> van de <unk>.
2023-05-27 23:11:06,065 - INFO - joeynmt.training - Example #2
2023-05-27 23:11:06,065 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:11:06,065 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:11:06,065 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'van', 'het', 'hart', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-27 23:11:06,066 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:11:06,066 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:11:06,066 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> van het hart van de <unk> van de <unk>.
2023-05-27 23:11:06,066 - INFO - joeynmt.training - Example #3
2023-05-27 23:11:06,066 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:11:06,066 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:11:06,066 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', 'zomer', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:11:06,066 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:11:06,066 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:11:06,066 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de zomer en <unk> in de zomer.
2023-05-27 23:11:06,066 - INFO - joeynmt.training - Example #4
2023-05-27 23:11:06,066 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:11:06,066 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:11:06,066 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-27 23:11:06,066 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:11:06,066 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:11:06,066 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie zien, is een <unk> wat in de laatste 25 jaar.
2023-05-27 23:11:42,325 - INFO - joeynmt.training - Epoch   2, Step:     3600, Batch Loss:     1.786509, Batch Acc: 0.460905, Tokens per Sec:     1710, Lr: 0.000300
2023-05-27 23:12:19,194 - INFO - joeynmt.training - Epoch   2, Step:     3700, Batch Loss:     1.912759, Batch Acc: 0.464096, Tokens per Sec:     1836, Lr: 0.000300
2023-05-27 23:12:41,560 - INFO - joeynmt.training - Epoch   2, Step:     3800, Batch Loss:     1.969069, Batch Acc: 0.464195, Tokens per Sec:     2960, Lr: 0.000300
2023-05-27 23:13:05,922 - INFO - joeynmt.training - Epoch   2, Step:     3900, Batch Loss:     1.725823, Batch Acc: 0.467043, Tokens per Sec:     2735, Lr: 0.000300
2023-05-27 23:13:28,850 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     1.864661, Batch Acc: 0.467023, Tokens per Sec:     2892, Lr: 0.000300
2023-05-27 23:13:28,850 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:13:28,850 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:14:00,476 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.81, acc:   0.44, generation: 31.5819[sec], evaluation: 0.0000[sec]
2023-05-27 23:14:00,477 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:14:00,607 - INFO - joeynmt.helpers - delete models/transformer_a/1500.ckpt
2023-05-27 23:14:00,614 - INFO - joeynmt.training - Example #0
2023-05-27 23:14:00,614 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:14:00,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:14:00,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'om', 'te', '<unk>', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:14:00,615 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:14:00,615 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:14:00,615 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> om te <unk> te <unk> dat de <unk> <unk> <unk>, voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk>.
2023-05-27 23:14:00,615 - INFO - joeynmt.training - Example #1
2023-05-27 23:14:00,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:14:00,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:14:00,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'genoeg', 'de', '<unk>', '<unk>', 'uit', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-27 23:14:00,615 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:14:00,615 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:14:00,615 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg genoeg de <unk> <unk> uit, want het is niet de <unk> van het <unk>.
2023-05-27 23:14:00,615 - INFO - joeynmt.training - Example #2
2023-05-27 23:14:00,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:14:00,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:14:00,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:14:00,615 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:14:00,615 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:14:00,615 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> van ons <unk>.
2023-05-27 23:14:00,615 - INFO - joeynmt.training - Example #3
2023-05-27 23:14:00,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:14:00,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:14:00,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:14:00,616 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:14:00,616 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:14:00,616 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de <unk> en <unk> in de zomer.
2023-05-27 23:14:00,616 - INFO - joeynmt.training - Example #4
2023-05-27 23:14:00,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:14:00,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:14:00,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', '<unk>', ',', 'is', 'een', '<unk>', 'wat', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-27 23:14:00,616 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:14:00,616 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:14:00,616 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie <unk>, is een <unk> wat in de afgelopen 25 jaar.
2023-05-27 23:14:22,394 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     1.776145, Batch Acc: 0.463948, Tokens per Sec:     3029, Lr: 0.000300
2023-05-27 23:14:43,477 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     1.844422, Batch Acc: 0.465964, Tokens per Sec:     3149, Lr: 0.000300
2023-05-27 23:15:05,554 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     1.792549, Batch Acc: 0.469826, Tokens per Sec:     3084, Lr: 0.000300
2023-05-27 23:15:27,547 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     1.774227, Batch Acc: 0.470146, Tokens per Sec:     3093, Lr: 0.000300
2023-05-27 23:15:49,698 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     1.859634, Batch Acc: 0.473156, Tokens per Sec:     3047, Lr: 0.000300
2023-05-27 23:15:49,699 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:15:49,699 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:16:31,578 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.56, acc:   0.45, generation: 41.8327[sec], evaluation: 0.0000[sec]
2023-05-27 23:16:31,579 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:16:31,690 - INFO - joeynmt.helpers - delete models/transformer_a/2000.ckpt
2023-05-27 23:16:31,701 - INFO - joeynmt.training - Example #0
2023-05-27 23:16:31,701 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:16:31,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:16:31,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', '<unk>', 'ik', 'deze', 'twee', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', '<unk>', '<unk>', 'voor', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', 'ik', 'deze']
2023-05-27 23:16:31,701 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:16:31,701 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:16:31,701 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar <unk> ik deze twee <unk> om te <unk> dat de <unk> <unk> die <unk> <unk> voor <unk>, die <unk> <unk> <unk> <unk>, <unk> <unk> <unk>, <unk> <unk>, <unk>, <unk> <unk>, <unk>, <unk>, <unk>, <unk> <unk>, <unk> <unk>, <unk>, <unk>, <unk> <unk>, <unk>, <unk>, <unk> ik deze
2023-05-27 23:16:31,701 - INFO - joeynmt.training - Example #1
2023-05-27 23:16:31,701 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:16:31,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:16:31,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', 'uit', ',', 'want', 'het', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-27 23:16:31,701 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:16:31,701 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:16:31,701 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet genoeg de <unk> van dit <unk> <unk> uit, want het <unk> van het <unk>.
2023-05-27 23:16:31,701 - INFO - joeynmt.training - Example #2
2023-05-27 23:16:31,701 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:16:31,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:16:31,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', 'van', 'ons', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:16:31,701 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:16:31,702 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:16:31,702 - INFO - joeynmt.training - 	Hypothesis: In <unk> is de <unk> <unk> <unk> van ons hart van ons <unk>.
2023-05-27 23:16:31,702 - INFO - joeynmt.training - Example #3
2023-05-27 23:16:31,702 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:16:31,702 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:16:31,702 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', '<unk>', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:16:31,702 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:16:31,702 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:16:31,702 - INFO - joeynmt.training - 	Hypothesis: Het is <unk> in het <unk> en <unk> in de zomer.
2023-05-27 23:16:31,702 - INFO - joeynmt.training - Example #4
2023-05-27 23:16:31,702 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:16:31,702 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:16:31,702 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'gebeurt', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-27 23:16:31,702 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:16:31,702 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:16:31,702 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien, is een <unk> wat er gebeurt in de laatste 25 jaar.
2023-05-27 23:16:54,158 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     1.663007, Batch Acc: 0.469403, Tokens per Sec:     2901, Lr: 0.000300
2023-05-27 23:17:16,258 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     2.047477, Batch Acc: 0.477592, Tokens per Sec:     3013, Lr: 0.000300
2023-05-27 23:17:37,977 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     1.809565, Batch Acc: 0.468675, Tokens per Sec:     3047, Lr: 0.000300
2023-05-27 23:18:00,832 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     1.699287, Batch Acc: 0.473162, Tokens per Sec:     2919, Lr: 0.000300
2023-05-27 23:18:23,351 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     1.750803, Batch Acc: 0.479856, Tokens per Sec:     2934, Lr: 0.000300
2023-05-27 23:18:23,352 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:18:23,352 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:18:56,131 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.45, acc:   0.45, generation: 32.7342[sec], evaluation: 0.0000[sec]
2023-05-27 23:18:56,132 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:18:56,236 - INFO - joeynmt.helpers - delete models/transformer_a/2500.ckpt
2023-05-27 23:18:56,251 - INFO - joeynmt.training - Example #0
2023-05-27 23:18:56,251 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:18:56,251 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:18:56,251 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', 'drie', 'miljoen', 'jaar', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'had', 'de', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:18:56,251 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:18:56,251 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:18:56,251 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die voor drie miljoen jaar de <unk> <unk> <unk> <unk>, had de <unk> <unk> <unk>.
2023-05-27 23:18:56,251 - INFO - joeynmt.training - Example #1
2023-05-27 23:18:56,251 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:18:56,251 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:18:56,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-27 23:18:56,252 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:18:56,252 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:18:56,252 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van het <unk>.
2023-05-27 23:18:56,252 - INFO - joeynmt.training - Example #2
2023-05-27 23:18:56,252 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:18:56,252 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:18:56,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', 'van', 'ons', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:18:56,252 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:18:56,252 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:18:56,252 - INFO - joeynmt.training - 	Hypothesis: In <unk> is de <unk> <unk> <unk> van ons <unk> hart van ons <unk>.
2023-05-27 23:18:56,252 - INFO - joeynmt.training - Example #3
2023-05-27 23:18:56,252 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:18:56,252 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:18:56,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:18:56,252 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:18:56,252 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:18:56,252 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de <unk> en <unk> in de zomer.
2023-05-27 23:18:56,252 - INFO - joeynmt.training - Example #4
2023-05-27 23:18:56,252 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:18:56,252 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:18:56,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'gebeurt', '.', '</s>']
2023-05-27 23:18:56,252 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:18:56,252 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:18:56,253 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> wat er in de laatste 25 jaar gebeurt.
2023-05-27 23:19:18,499 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     1.775992, Batch Acc: 0.477220, Tokens per Sec:     2906, Lr: 0.000300
2023-05-27 23:19:40,688 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     1.729257, Batch Acc: 0.471377, Tokens per Sec:     3023, Lr: 0.000300
2023-05-27 23:20:02,500 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     1.753543, Batch Acc: 0.477070, Tokens per Sec:     3034, Lr: 0.000300
2023-05-27 23:20:25,612 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     1.879190, Batch Acc: 0.477365, Tokens per Sec:     2952, Lr: 0.000300
2023-05-27 23:20:39,264 - INFO - joeynmt.training - Epoch   2: total training loss 4999.82
2023-05-27 23:20:39,264 - INFO - joeynmt.training - EPOCH 3
2023-05-27 23:20:39,296 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=2
2023-05-27 23:20:47,327 - INFO - joeynmt.training - Epoch   3, Step:     5500, Batch Loss:     1.818693, Batch Acc: 0.487129, Tokens per Sec:     2934, Lr: 0.000300
2023-05-27 23:20:47,327 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:20:47,327 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:21:23,349 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.39, acc:   0.46, generation: 35.9716[sec], evaluation: 0.0000[sec]
2023-05-27 23:21:23,350 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:21:23,466 - INFO - joeynmt.helpers - delete models/transformer_a/3000.ckpt
2023-05-27 23:21:23,476 - INFO - joeynmt.training - Example #0
2023-05-27 23:21:23,476 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:21:23,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:21:23,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'om', 'te', 'zien', 'dat', 'de', '<unk>', '<unk>', 'die', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:21:23,476 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:21:23,476 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:21:23,476 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> om te zien dat de <unk> <unk> die de <unk> <unk> die voor <unk> drie miljoen jaar <unk> <unk> <unk> <unk>.
2023-05-27 23:21:23,477 - INFO - joeynmt.training - Example #1
2023-05-27 23:21:23,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:21:23,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:21:23,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'want', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-27 23:21:23,477 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:21:23,477 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:21:23,477 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg de <unk> van dit <unk> <unk>, want het niet de <unk> van de <unk>.
2023-05-27 23:21:23,477 - INFO - joeynmt.training - Example #2
2023-05-27 23:21:23,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:21:23,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:21:23,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:21:23,477 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:21:23,477 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:21:23,477 - INFO - joeynmt.training - 	Hypothesis: In <unk> is de <unk> <unk> het <unk> van ons <unk> <unk>.
2023-05-27 23:21:23,477 - INFO - joeynmt.training - Example #3
2023-05-27 23:21:23,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:21:23,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:21:23,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:21:23,477 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:21:23,477 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:21:23,477 - INFO - joeynmt.training - 	Hypothesis: Het is <unk> en <unk> in de zomer.
2023-05-27 23:21:23,477 - INFO - joeynmt.training - Example #4
2023-05-27 23:21:23,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:21:23,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:21:23,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:21:23,478 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:21:23,478 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:21:23,478 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> wat er in de laatste 25 jaar is.
2023-05-27 23:21:44,943 - INFO - joeynmt.training - Epoch   3, Step:     5600, Batch Loss:     1.778337, Batch Acc: 0.488328, Tokens per Sec:     3087, Lr: 0.000300
2023-05-27 23:22:07,216 - INFO - joeynmt.training - Epoch   3, Step:     5700, Batch Loss:     1.745209, Batch Acc: 0.488538, Tokens per Sec:     3059, Lr: 0.000300
2023-05-27 23:22:29,194 - INFO - joeynmt.training - Epoch   3, Step:     5800, Batch Loss:     1.964349, Batch Acc: 0.489646, Tokens per Sec:     2951, Lr: 0.000300
2023-05-27 23:22:51,296 - INFO - joeynmt.training - Epoch   3, Step:     5900, Batch Loss:     1.721778, Batch Acc: 0.484525, Tokens per Sec:     3117, Lr: 0.000300
2023-05-27 23:23:13,672 - INFO - joeynmt.training - Epoch   3, Step:     6000, Batch Loss:     1.896431, Batch Acc: 0.490316, Tokens per Sec:     2974, Lr: 0.000300
2023-05-27 23:23:13,673 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:23:13,673 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:23:50,092 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.26, acc:   0.46, generation: 36.3754[sec], evaluation: 0.0000[sec]
2023-05-27 23:23:50,093 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:23:50,181 - INFO - joeynmt.helpers - delete models/transformer_a/3500.ckpt
2023-05-27 23:23:50,195 - INFO - joeynmt.training - Example #0
2023-05-27 23:23:50,196 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:23:50,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:23:50,196 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:23:50,196 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:23:50,196 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:23:50,196 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk> die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk>.
2023-05-27 23:23:50,196 - INFO - joeynmt.training - Example #1
2023-05-27 23:23:50,196 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:23:50,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:23:50,196 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-27 23:23:50,196 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:23:50,196 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:23:50,196 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2023-05-27 23:23:50,196 - INFO - joeynmt.training - Example #2
2023-05-27 23:23:50,196 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:23:50,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:23:50,196 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', 'het', 'hart', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:23:50,196 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:23:50,196 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:23:50,196 - INFO - joeynmt.training - 	Hypothesis: In <unk> is de <unk> <unk> <unk> het hart hart van ons <unk>.
2023-05-27 23:23:50,196 - INFO - joeynmt.training - Example #3
2023-05-27 23:23:50,196 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:23:50,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:23:50,196 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:23:50,197 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:23:50,197 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:23:50,197 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de <unk> en <unk> in de zomer.
2023-05-27 23:23:50,197 - INFO - joeynmt.training - Example #4
2023-05-27 23:23:50,197 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:23:50,197 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:23:50,197 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:23:50,197 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:23:50,197 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:23:50,197 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> wat er in de laatste 25 jaar is.
2023-05-27 23:24:12,755 - INFO - joeynmt.training - Epoch   3, Step:     6100, Batch Loss:     1.521233, Batch Acc: 0.485550, Tokens per Sec:     2945, Lr: 0.000300
2023-05-27 23:24:34,930 - INFO - joeynmt.training - Epoch   3, Step:     6200, Batch Loss:     1.553667, Batch Acc: 0.488877, Tokens per Sec:     2986, Lr: 0.000300
2023-05-27 23:24:57,165 - INFO - joeynmt.training - Epoch   3, Step:     6300, Batch Loss:     1.607619, Batch Acc: 0.487880, Tokens per Sec:     3045, Lr: 0.000300
2023-05-27 23:25:19,127 - INFO - joeynmt.training - Epoch   3, Step:     6400, Batch Loss:     1.859260, Batch Acc: 0.483981, Tokens per Sec:     2902, Lr: 0.000300
2023-05-27 23:25:41,351 - INFO - joeynmt.training - Epoch   3, Step:     6500, Batch Loss:     1.632695, Batch Acc: 0.489506, Tokens per Sec:     2965, Lr: 0.000300
2023-05-27 23:25:41,352 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:25:41,352 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:26:15,977 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.20, acc:   0.46, generation: 34.5816[sec], evaluation: 0.0000[sec]
2023-05-27 23:26:15,977 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:26:16,101 - INFO - joeynmt.helpers - delete models/transformer_a/4000.ckpt
2023-05-27 23:26:16,120 - INFO - joeynmt.training - Example #0
2023-05-27 23:26:16,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:26:16,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:26:16,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', 'zien', 'dat', 'de', '<unk>', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', 'had', '<unk>', 'om', '40', 'procent', 'te', 'hebben', '.', '</s>']
2023-05-27 23:26:16,120 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:26:16,120 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:26:16,120 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te zien dat de <unk> <unk> <unk> die voor <unk> drie miljoen jaar de <unk> van de <unk> staten had <unk> om 40 procent te hebben.
2023-05-27 23:26:16,120 - INFO - joeynmt.training - Example #1
2023-05-27 23:26:16,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:26:16,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:26:16,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'om', 'de', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-27 23:26:16,120 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:26:16,120 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:26:16,120 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg om de <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2023-05-27 23:26:16,120 - INFO - joeynmt.training - Example #2
2023-05-27 23:26:16,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:26:16,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:26:16,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', ',', 'is', 'de', '<unk>', '<unk>', 'het', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:26:16,121 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:26:16,121 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:26:16,121 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk>, is de <unk> <unk> het hart van ons <unk>.
2023-05-27 23:26:16,121 - INFO - joeynmt.training - Example #3
2023-05-27 23:26:16,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:26:16,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:26:16,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:26:16,121 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:26:16,121 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:26:16,121 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de <unk> en <unk> in de zomer.
2023-05-27 23:26:16,121 - INFO - joeynmt.training - Example #4
2023-05-27 23:26:16,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:26:16,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:26:16,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:26:16,121 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:26:16,121 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:26:16,121 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> wat er in de laatste 25 jaar is.
2023-05-27 23:26:37,615 - INFO - joeynmt.training - Epoch   3, Step:     6600, Batch Loss:     1.786002, Batch Acc: 0.490677, Tokens per Sec:     3155, Lr: 0.000300
2023-05-27 23:26:59,290 - INFO - joeynmt.training - Epoch   3, Step:     6700, Batch Loss:     1.711031, Batch Acc: 0.492759, Tokens per Sec:     3062, Lr: 0.000300
2023-05-27 23:27:19,671 - INFO - joeynmt.training - Epoch   3, Step:     6800, Batch Loss:     1.625473, Batch Acc: 0.490765, Tokens per Sec:     3339, Lr: 0.000300
2023-05-27 23:27:40,680 - INFO - joeynmt.training - Epoch   3, Step:     6900, Batch Loss:     1.745064, Batch Acc: 0.488958, Tokens per Sec:     3242, Lr: 0.000300
2023-05-27 23:28:01,008 - INFO - joeynmt.training - Epoch   3, Step:     7000, Batch Loss:     1.749910, Batch Acc: 0.490470, Tokens per Sec:     3293, Lr: 0.000300
2023-05-27 23:28:01,009 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:28:01,009 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:28:35,605 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.07, acc:   0.47, generation: 34.5518[sec], evaluation: 0.0000[sec]
2023-05-27 23:28:35,606 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:28:35,706 - INFO - joeynmt.helpers - delete models/transformer_a/4500.ckpt
2023-05-27 23:28:35,716 - INFO - joeynmt.training - Example #0
2023-05-27 23:28:35,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:28:35,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:28:35,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', 'is', '.', '</s>']
2023-05-27 23:28:35,717 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:28:35,717 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:28:35,717 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> <unk> om te <unk> dat de <unk> <unk> die voor <unk> drie miljoen <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>, <unk> is.
2023-05-27 23:28:35,717 - INFO - joeynmt.training - Example #1
2023-05-27 23:28:35,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:28:35,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:28:35,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-27 23:28:35,717 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:28:35,717 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:28:35,717 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2023-05-27 23:28:35,717 - INFO - joeynmt.training - Example #2
2023-05-27 23:28:35,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:28:35,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:28:35,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', ',', 'is', 'de', '<unk>', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:28:35,717 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:28:35,717 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:28:35,717 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk>, is de <unk> <unk> hart van ons <unk>.
2023-05-27 23:28:35,717 - INFO - joeynmt.training - Example #3
2023-05-27 23:28:35,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:28:35,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:28:35,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:28:35,718 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:28:35,718 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:28:35,718 - INFO - joeynmt.training - 	Hypothesis: Het is in de <unk> en <unk> in de zomer.
2023-05-27 23:28:35,718 - INFO - joeynmt.training - Example #4
2023-05-27 23:28:35,718 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:28:35,718 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:28:35,718 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:28:35,718 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:28:35,718 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:28:35,718 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> wat er in de laatste 25 jaar is.
2023-05-27 23:28:56,779 - INFO - joeynmt.training - Epoch   3, Step:     7100, Batch Loss:     1.745282, Batch Acc: 0.489073, Tokens per Sec:     3049, Lr: 0.000300
2023-05-27 23:29:16,160 - INFO - joeynmt.training - Epoch   3, Step:     7200, Batch Loss:     1.693042, Batch Acc: 0.494066, Tokens per Sec:     3369, Lr: 0.000300
2023-05-27 23:29:36,052 - INFO - joeynmt.training - Epoch   3, Step:     7300, Batch Loss:     1.578460, Batch Acc: 0.490639, Tokens per Sec:     3437, Lr: 0.000300
2023-05-27 23:29:56,250 - INFO - joeynmt.training - Epoch   3, Step:     7400, Batch Loss:     1.597463, Batch Acc: 0.491706, Tokens per Sec:     3173, Lr: 0.000300
2023-05-27 23:30:17,019 - INFO - joeynmt.training - Epoch   3, Step:     7500, Batch Loss:     1.575230, Batch Acc: 0.492684, Tokens per Sec:     3205, Lr: 0.000300
2023-05-27 23:30:17,020 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:30:17,020 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:30:50,236 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   6.02, acc:   0.47, generation: 33.1710[sec], evaluation: 0.0000[sec]
2023-05-27 23:30:50,237 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:30:50,336 - INFO - joeynmt.helpers - delete models/transformer_a/5000.ckpt
2023-05-27 23:30:50,351 - INFO - joeynmt.training - Example #0
2023-05-27 23:30:50,351 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:30:50,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:30:50,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', ',', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', 'is', '.', '</s>']
2023-05-27 23:30:50,351 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:30:50,351 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:30:50,351 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk>, om te <unk> dat de <unk> <unk> <unk> die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk> <unk> <unk>, om 40 procent <unk> te <unk> is.
2023-05-27 23:30:50,351 - INFO - joeynmt.training - Example #1
2023-05-27 23:30:50,351 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:30:50,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:30:50,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-27 23:30:50,352 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:30:50,352 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:30:50,352 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg de <unk> van dit <unk> <unk>, want het is niet de <unk> van de <unk>.
2023-05-27 23:30:50,352 - INFO - joeynmt.training - Example #2
2023-05-27 23:30:50,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:30:50,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:30:50,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'van', 'ons', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:30:50,352 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:30:50,352 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:30:50,352 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> van ons <unk> hart van ons <unk>.
2023-05-27 23:30:50,352 - INFO - joeynmt.training - Example #3
2023-05-27 23:30:50,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:30:50,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:30:50,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:30:50,352 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:30:50,352 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:30:50,352 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-27 23:30:50,352 - INFO - joeynmt.training - Example #4
2023-05-27 23:30:50,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:30:50,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:30:50,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:30:50,352 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:30:50,352 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:30:50,352 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> wat er in de afgelopen 25 jaar is.
2023-05-27 23:31:11,377 - INFO - joeynmt.training - Epoch   3, Step:     7600, Batch Loss:     1.676003, Batch Acc: 0.496570, Tokens per Sec:     3262, Lr: 0.000300
2023-05-27 23:31:31,490 - INFO - joeynmt.training - Epoch   3, Step:     7700, Batch Loss:     1.733350, Batch Acc: 0.500392, Tokens per Sec:     3232, Lr: 0.000300
2023-05-27 23:31:51,462 - INFO - joeynmt.training - Epoch   3, Step:     7800, Batch Loss:     1.751081, Batch Acc: 0.489063, Tokens per Sec:     3237, Lr: 0.000300
2023-05-27 23:32:12,204 - INFO - joeynmt.training - Epoch   3, Step:     7900, Batch Loss:     1.553754, Batch Acc: 0.493871, Tokens per Sec:     3135, Lr: 0.000300
2023-05-27 23:32:33,119 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:     1.516084, Batch Acc: 0.495043, Tokens per Sec:     3149, Lr: 0.000300
2023-05-27 23:32:33,120 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:32:33,120 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:33:10,918 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   5.99, acc:   0.46, generation: 37.7529[sec], evaluation: 0.0000[sec]
2023-05-27 23:33:10,919 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:33:11,014 - INFO - joeynmt.helpers - delete models/transformer_a/5500.ckpt
2023-05-27 23:33:11,023 - INFO - joeynmt.training - Example #0
2023-05-27 23:33:11,023 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:33:11,023 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:33:11,023 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', 'had', '<unk>', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2023-05-27 23:33:11,023 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:33:11,023 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:33:11,023 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> staten had <unk> om 40 procent te <unk>.
2023-05-27 23:33:11,023 - INFO - joeynmt.training - Example #1
2023-05-27 23:33:11,023 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:33:11,023 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:33:11,023 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', '<unk>', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-27 23:33:11,023 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:33:11,023 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:33:11,023 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg de <unk> van dit <unk> <unk>, <unk> het niet de <unk> van het <unk>.
2023-05-27 23:33:11,023 - INFO - joeynmt.training - Example #2
2023-05-27 23:33:11,023 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:33:11,023 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:33:11,023 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'van', 'het', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:33:11,023 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:33:11,023 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:33:11,023 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> van het hart van ons <unk>.
2023-05-27 23:33:11,023 - INFO - joeynmt.training - Example #3
2023-05-27 23:33:11,023 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:33:11,023 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:33:11,023 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:33:11,024 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:33:11,024 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:33:11,024 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-27 23:33:11,024 - INFO - joeynmt.training - Example #4
2023-05-27 23:33:11,024 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:33:11,024 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:33:11,024 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:33:11,024 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:33:11,024 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:33:11,024 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> wat er in de laatste 25 jaar is.
2023-05-27 23:33:32,313 - INFO - joeynmt.training - Epoch   3, Step:     8100, Batch Loss:     1.802883, Batch Acc: 0.493822, Tokens per Sec:     3030, Lr: 0.000300
2023-05-27 23:33:51,676 - INFO - joeynmt.training - Epoch   3: total training loss 4673.55
2023-05-27 23:33:51,676 - INFO - joeynmt.training - EPOCH 4
2023-05-27 23:33:51,704 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=3
2023-05-27 23:33:53,326 - INFO - joeynmt.training - Epoch   4, Step:     8200, Batch Loss:     1.589734, Batch Acc: 0.497235, Tokens per Sec:     3070, Lr: 0.000300
2023-05-27 23:34:15,305 - INFO - joeynmt.training - Epoch   4, Step:     8300, Batch Loss:     1.764145, Batch Acc: 0.504193, Tokens per Sec:     3017, Lr: 0.000300
2023-05-27 23:34:37,508 - INFO - joeynmt.training - Epoch   4, Step:     8400, Batch Loss:     1.583707, Batch Acc: 0.502342, Tokens per Sec:     3029, Lr: 0.000300
2023-05-27 23:34:59,519 - INFO - joeynmt.training - Epoch   4, Step:     8500, Batch Loss:     1.523892, Batch Acc: 0.504210, Tokens per Sec:     2957, Lr: 0.000300
2023-05-27 23:34:59,520 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:34:59,520 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:35:24,406 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.92, acc:   0.47, generation: 24.8423[sec], evaluation: 0.0000[sec]
2023-05-27 23:35:24,407 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:35:24,511 - INFO - joeynmt.helpers - delete models/transformer_a/6000.ckpt
2023-05-27 23:35:24,523 - INFO - joeynmt.training - Example #0
2023-05-27 23:35:24,523 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:35:24,523 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:35:24,523 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:35:24,523 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:35:24,523 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:35:24,523 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk> <unk> <unk>.
2023-05-27 23:35:24,523 - INFO - joeynmt.training - Example #1
2023-05-27 23:35:24,523 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:35:24,523 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:35:24,523 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:35:24,523 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:35:24,523 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:35:24,523 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg de <unk> van deze <unk> <unk>, omdat het niet de <unk> van de <unk> <unk>.
2023-05-27 23:35:24,523 - INFO - joeynmt.training - Example #2
2023-05-27 23:35:24,523 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:35:24,523 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:35:24,523 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:35:24,524 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:35:24,524 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:35:24,524 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het hart van ons <unk>.
2023-05-27 23:35:24,524 - INFO - joeynmt.training - Example #3
2023-05-27 23:35:24,524 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:35:24,524 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:35:24,524 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:35:24,524 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:35:24,524 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:35:24,524 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-27 23:35:24,524 - INFO - joeynmt.training - Example #4
2023-05-27 23:35:24,524 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:35:24,524 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:35:24,524 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:35:24,524 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:35:24,524 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:35:24,524 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> wat er in de laatste 25 jaar is.
2023-05-27 23:35:45,696 - INFO - joeynmt.training - Epoch   4, Step:     8600, Batch Loss:     1.604765, Batch Acc: 0.505976, Tokens per Sec:     3191, Lr: 0.000300
2023-05-27 23:36:06,046 - INFO - joeynmt.training - Epoch   4, Step:     8700, Batch Loss:     1.773301, Batch Acc: 0.505224, Tokens per Sec:     3255, Lr: 0.000300
2023-05-27 23:36:27,462 - INFO - joeynmt.training - Epoch   4, Step:     8800, Batch Loss:     1.686384, Batch Acc: 0.501946, Tokens per Sec:     3120, Lr: 0.000300
2023-05-27 23:36:48,798 - INFO - joeynmt.training - Epoch   4, Step:     8900, Batch Loss:     1.559838, Batch Acc: 0.499494, Tokens per Sec:     3055, Lr: 0.000300
2023-05-27 23:37:09,821 - INFO - joeynmt.training - Epoch   4, Step:     9000, Batch Loss:     1.550187, Batch Acc: 0.508604, Tokens per Sec:     3063, Lr: 0.000300
2023-05-27 23:37:09,821 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:37:09,821 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:37:43,713 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.89, acc:   0.47, generation: 33.8443[sec], evaluation: 0.0000[sec]
2023-05-27 23:37:43,714 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:37:43,806 - INFO - joeynmt.helpers - delete models/transformer_a/6500.ckpt
2023-05-27 23:37:43,822 - INFO - joeynmt.training - Example #0
2023-05-27 23:37:43,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:37:43,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:37:43,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:37:43,822 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:37:43,823 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:37:43,823 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die <unk> <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk> van de <unk> <unk> van de <unk> <unk> <unk>.
2023-05-27 23:37:43,823 - INFO - joeynmt.training - Example #1
2023-05-27 23:37:43,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:37:43,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:37:43,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', 'toont', '.', '</s>']
2023-05-27 23:37:43,823 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:37:43,823 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:37:43,823 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van het <unk> toont.
2023-05-27 23:37:43,823 - INFO - joeynmt.training - Example #2
2023-05-27 23:37:43,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:37:43,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:37:43,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:37:43,823 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:37:43,823 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:37:43,823 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-27 23:37:43,823 - INFO - joeynmt.training - Example #3
2023-05-27 23:37:43,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:37:43,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:37:43,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:37:43,823 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:37:43,823 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:37:43,823 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in <unk> en <unk> in de zomer.
2023-05-27 23:37:43,823 - INFO - joeynmt.training - Example #4
2023-05-27 23:37:43,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:37:43,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:37:43,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:37:43,824 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:37:43,824 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:37:43,824 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> wat er in de afgelopen 25 jaar is.
2023-05-27 23:38:04,728 - INFO - joeynmt.training - Epoch   4, Step:     9100, Batch Loss:     1.610532, Batch Acc: 0.501129, Tokens per Sec:     3120, Lr: 0.000300
2023-05-27 23:38:25,992 - INFO - joeynmt.training - Epoch   4, Step:     9200, Batch Loss:     1.478688, Batch Acc: 0.504531, Tokens per Sec:     3134, Lr: 0.000300
2023-05-27 23:38:47,016 - INFO - joeynmt.training - Epoch   4, Step:     9300, Batch Loss:     1.617189, Batch Acc: 0.507061, Tokens per Sec:     3133, Lr: 0.000300
2023-05-27 23:39:08,641 - INFO - joeynmt.training - Epoch   4, Step:     9400, Batch Loss:     1.655497, Batch Acc: 0.498118, Tokens per Sec:     2973, Lr: 0.000300
2023-05-27 23:39:29,669 - INFO - joeynmt.training - Epoch   4, Step:     9500, Batch Loss:     1.495124, Batch Acc: 0.506728, Tokens per Sec:     3153, Lr: 0.000300
2023-05-27 23:39:29,669 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:39:29,669 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:40:01,049 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.87, acc:   0.47, generation: 31.3333[sec], evaluation: 0.0000[sec]
2023-05-27 23:40:01,050 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:40:01,168 - INFO - joeynmt.helpers - delete models/transformer_a/7000.ckpt
2023-05-27 23:40:01,181 - INFO - joeynmt.training - Example #0
2023-05-27 23:40:01,181 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:40:01,181 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:40:01,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:40:01,181 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:40:01,181 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:40:01,181 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk> <unk>.
2023-05-27 23:40:01,181 - INFO - joeynmt.training - Example #1
2023-05-27 23:40:01,181 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:40:01,181 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:40:01,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-27 23:40:01,181 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:40:01,181 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:40:01,181 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg de <unk> van dit <unk> <unk>, want het is niet de <unk> van het <unk>.
2023-05-27 23:40:01,181 - INFO - joeynmt.training - Example #2
2023-05-27 23:40:01,181 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:40:01,181 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:40:01,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'van', 'het', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:40:01,182 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:40:01,182 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:40:01,182 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> van het hart van ons <unk>.
2023-05-27 23:40:01,182 - INFO - joeynmt.training - Example #3
2023-05-27 23:40:01,182 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:40:01,182 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:40:01,182 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:40:01,182 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:40:01,182 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:40:01,182 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-27 23:40:01,182 - INFO - joeynmt.training - Example #4
2023-05-27 23:40:01,182 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:40:01,182 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:40:01,182 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:40:01,182 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:40:01,182 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:40:01,182 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> wat er in de laatste 25 jaar is.
2023-05-27 23:40:21,813 - INFO - joeynmt.training - Epoch   4, Step:     9600, Batch Loss:     1.712203, Batch Acc: 0.498809, Tokens per Sec:     3195, Lr: 0.000300
2023-05-27 23:40:43,043 - INFO - joeynmt.training - Epoch   4, Step:     9700, Batch Loss:     1.549722, Batch Acc: 0.502649, Tokens per Sec:     3103, Lr: 0.000300
2023-05-27 23:41:04,134 - INFO - joeynmt.training - Epoch   4, Step:     9800, Batch Loss:     1.639170, Batch Acc: 0.502360, Tokens per Sec:     3034, Lr: 0.000300
2023-05-27 23:41:23,761 - INFO - joeynmt.training - Epoch   4, Step:     9900, Batch Loss:     1.497379, Batch Acc: 0.500672, Tokens per Sec:     3336, Lr: 0.000300
2023-05-27 23:41:42,709 - INFO - joeynmt.training - Epoch   4, Step:    10000, Batch Loss:     1.602894, Batch Acc: 0.503213, Tokens per Sec:     3507, Lr: 0.000300
2023-05-27 23:41:42,710 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:41:42,710 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:42:13,060 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.83, acc:   0.47, generation: 30.3052[sec], evaluation: 0.0000[sec]
2023-05-27 23:42:13,061 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:42:13,156 - INFO - joeynmt.helpers - delete models/transformer_a/7500.ckpt
2023-05-27 23:42:13,167 - INFO - joeynmt.training - Example #0
2023-05-27 23:42:13,167 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:42:13,167 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:42:13,167 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', '<unk>', 'staten', 'had', ',', '<unk>', '<unk>', '<unk>', 'staten', ',', '<unk>', '<unk>', ',', '<unk>', 'is', '40', 'procent', '.', '</s>']
2023-05-27 23:42:13,167 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:42:13,167 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:42:13,168 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, de <unk> <unk> <unk> <unk> staten had, <unk> <unk> <unk> staten, <unk> <unk>, <unk> is 40 procent.
2023-05-27 23:42:13,168 - INFO - joeynmt.training - Example #1
2023-05-27 23:42:13,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:42:13,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:42:13,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'veel', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-27 23:42:13,168 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:42:13,168 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:42:13,168 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet veel genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van het <unk>.
2023-05-27 23:42:13,168 - INFO - joeynmt.training - Example #2
2023-05-27 23:42:13,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:42:13,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:42:13,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:42:13,168 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:42:13,168 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:42:13,168 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-27 23:42:13,168 - INFO - joeynmt.training - Example #3
2023-05-27 23:42:13,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:42:13,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:42:13,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:42:13,168 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:42:13,168 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:42:13,168 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2023-05-27 23:42:13,168 - INFO - joeynmt.training - Example #4
2023-05-27 23:42:13,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:42:13,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:42:13,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'is', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-27 23:42:13,169 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:42:13,169 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:42:13,169 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> wat er is in de laatste 25 jaar.
2023-05-27 23:42:31,886 - INFO - joeynmt.training - Epoch   4, Step:    10100, Batch Loss:     1.610126, Batch Acc: 0.512469, Tokens per Sec:     3666, Lr: 0.000300
2023-05-27 23:42:50,664 - INFO - joeynmt.training - Epoch   4, Step:    10200, Batch Loss:     1.671729, Batch Acc: 0.509937, Tokens per Sec:     3454, Lr: 0.000300
2023-05-27 23:43:10,518 - INFO - joeynmt.training - Epoch   4, Step:    10300, Batch Loss:     1.701152, Batch Acc: 0.504712, Tokens per Sec:     3309, Lr: 0.000300
2023-05-27 23:43:29,913 - INFO - joeynmt.training - Epoch   4, Step:    10400, Batch Loss:     1.619990, Batch Acc: 0.505739, Tokens per Sec:     3374, Lr: 0.000300
2023-05-27 23:43:49,812 - INFO - joeynmt.training - Epoch   4, Step:    10500, Batch Loss:     1.570175, Batch Acc: 0.503675, Tokens per Sec:     3303, Lr: 0.000300
2023-05-27 23:43:49,813 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:43:49,813 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:44:26,203 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.81, acc:   0.48, generation: 36.3435[sec], evaluation: 0.0000[sec]
2023-05-27 23:44:26,207 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:44:26,294 - INFO - joeynmt.helpers - delete models/transformer_a/8000.ckpt
2023-05-27 23:44:26,306 - INFO - joeynmt.training - Example #0
2023-05-27 23:44:26,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:44:26,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:44:26,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', 'had', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2023-05-27 23:44:26,307 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:44:26,307 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:44:26,307 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk> <unk> had om 40 procent te <unk>.
2023-05-27 23:44:26,307 - INFO - joeynmt.training - Example #1
2023-05-27 23:44:26,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:44:26,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:44:26,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'zo', 'genoeg', ',', 'de', '<unk>', 'van', 'de', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-27 23:44:26,307 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:44:26,307 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:44:26,307 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet zo genoeg, de <unk> van de <unk>, want het is niet de <unk> van de <unk>.
2023-05-27 23:44:26,307 - INFO - joeynmt.training - Example #2
2023-05-27 23:44:26,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:44:26,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:44:26,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:44:26,307 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:44:26,307 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:44:26,307 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> hart van ons <unk>.
2023-05-27 23:44:26,307 - INFO - joeynmt.training - Example #3
2023-05-27 23:44:26,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:44:26,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:44:26,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:44:26,308 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:44:26,308 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:44:26,308 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-27 23:44:26,308 - INFO - joeynmt.training - Example #4
2023-05-27 23:44:26,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:44:26,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:44:26,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:44:26,308 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:44:26,308 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:44:26,308 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> wat er in de laatste 25 jaar is.
2023-05-27 23:44:46,002 - INFO - joeynmt.training - Epoch   4, Step:    10600, Batch Loss:     1.691031, Batch Acc: 0.509904, Tokens per Sec:     3374, Lr: 0.000300
2023-05-27 23:45:06,278 - INFO - joeynmt.training - Epoch   4, Step:    10700, Batch Loss:     1.546138, Batch Acc: 0.506643, Tokens per Sec:     3323, Lr: 0.000300
2023-05-27 23:45:26,653 - INFO - joeynmt.training - Epoch   4, Step:    10800, Batch Loss:     1.777941, Batch Acc: 0.499345, Tokens per Sec:     3296, Lr: 0.000300
2023-05-27 23:45:47,042 - INFO - joeynmt.training - Epoch   4, Step:    10900, Batch Loss:     1.629758, Batch Acc: 0.506838, Tokens per Sec:     3138, Lr: 0.000300
2023-05-27 23:45:54,036 - INFO - joeynmt.training - Epoch   4: total training loss 4531.18
2023-05-27 23:45:54,037 - INFO - joeynmt.training - EPOCH 5
2023-05-27 23:45:54,069 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=4
2023-05-27 23:46:07,278 - INFO - joeynmt.training - Epoch   5, Step:    11000, Batch Loss:     1.479478, Batch Acc: 0.520943, Tokens per Sec:     3051, Lr: 0.000300
2023-05-27 23:46:07,279 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:46:07,279 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:46:43,216 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.73, acc:   0.48, generation: 35.8903[sec], evaluation: 0.0000[sec]
2023-05-27 23:46:43,218 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:46:43,354 - INFO - joeynmt.helpers - delete models/transformer_a/8500.ckpt
2023-05-27 23:46:43,368 - INFO - joeynmt.training - Example #0
2023-05-27 23:46:43,368 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:46:43,368 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:46:43,368 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', '<unk>', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', 'had', 'om', '40', 'procent', '<unk>', 'te', 'zijn', '.', '</s>']
2023-05-27 23:46:43,368 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:46:43,368 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:46:43,368 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar <unk> ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, de <unk> <unk>, de <unk> <unk> van de <unk> <unk> <unk> <unk> had om 40 procent <unk> te zijn.
2023-05-27 23:46:43,368 - INFO - joeynmt.training - Example #1
2023-05-27 23:46:43,369 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:46:43,369 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:46:43,369 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-27 23:46:43,369 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:46:43,369 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:46:43,369 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg de <unk> van dit <unk>, want het is niet de <unk> van de <unk>.
2023-05-27 23:46:43,369 - INFO - joeynmt.training - Example #2
2023-05-27 23:46:43,369 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:46:43,369 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:46:43,369 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:46:43,369 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:46:43,369 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:46:43,369 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-27 23:46:43,369 - INFO - joeynmt.training - Example #3
2023-05-27 23:46:43,369 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:46:43,369 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:46:43,369 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:46:43,369 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:46:43,369 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:46:43,369 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-27 23:46:43,369 - INFO - joeynmt.training - Example #4
2023-05-27 23:46:43,369 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:46:43,369 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:46:43,369 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:46:43,369 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:46:43,369 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:46:43,370 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> wat er in de laatste 25 jaar is.
2023-05-27 23:47:04,884 - INFO - joeynmt.training - Epoch   5, Step:    11100, Batch Loss:     1.592108, Batch Acc: 0.514521, Tokens per Sec:     3018, Lr: 0.000300
2023-05-27 23:47:26,075 - INFO - joeynmt.training - Epoch   5, Step:    11200, Batch Loss:     1.694741, Batch Acc: 0.512484, Tokens per Sec:     3143, Lr: 0.000300
2023-05-27 23:47:48,287 - INFO - joeynmt.training - Epoch   5, Step:    11300, Batch Loss:     1.683877, Batch Acc: 0.517057, Tokens per Sec:     3059, Lr: 0.000300
2023-05-27 23:48:10,204 - INFO - joeynmt.training - Epoch   5, Step:    11400, Batch Loss:     1.711524, Batch Acc: 0.516625, Tokens per Sec:     3031, Lr: 0.000300
2023-05-27 23:48:32,384 - INFO - joeynmt.training - Epoch   5, Step:    11500, Batch Loss:     1.560839, Batch Acc: 0.515542, Tokens per Sec:     2931, Lr: 0.000300
2023-05-27 23:48:32,385 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:48:32,385 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:49:11,005 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.71, acc:   0.48, generation: 38.5722[sec], evaluation: 0.0000[sec]
2023-05-27 23:49:11,007 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:49:11,122 - INFO - joeynmt.helpers - delete models/transformer_a/9000.ckpt
2023-05-27 23:49:11,135 - INFO - joeynmt.training - Example #0
2023-05-27 23:49:11,135 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:49:11,135 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:49:11,135 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', 'had', '<unk>', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2023-05-27 23:49:11,135 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:49:11,135 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:49:11,135 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk> die voor <unk> drie miljoen jaar de <unk> van de <unk> staten had <unk> om 40 procent <unk> te <unk>.
2023-05-27 23:49:11,135 - INFO - joeynmt.training - Example #1
2023-05-27 23:49:11,135 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:49:11,135 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:49:11,135 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'veel', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-27 23:49:11,135 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:49:11,135 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:49:11,135 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet veel genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> van de <unk>.
2023-05-27 23:49:11,135 - INFO - joeynmt.training - Example #2
2023-05-27 23:49:11,135 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:49:11,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:49:11,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:49:11,136 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:49:11,136 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:49:11,136 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-27 23:49:11,136 - INFO - joeynmt.training - Example #3
2023-05-27 23:49:11,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:49:11,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:49:11,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:49:11,136 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:49:11,136 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:49:11,136 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-27 23:49:11,136 - INFO - joeynmt.training - Example #4
2023-05-27 23:49:11,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:49:11,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:49:11,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:49:11,136 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:49:11,136 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:49:11,136 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> wat er in de laatste 25 jaar is.
2023-05-27 23:49:32,042 - INFO - joeynmt.training - Epoch   5, Step:    11600, Batch Loss:     1.487605, Batch Acc: 0.516351, Tokens per Sec:     3128, Lr: 0.000300
2023-05-27 23:49:53,187 - INFO - joeynmt.training - Epoch   5, Step:    11700, Batch Loss:     1.708929, Batch Acc: 0.511756, Tokens per Sec:     3184, Lr: 0.000300
2023-05-27 23:50:14,258 - INFO - joeynmt.training - Epoch   5, Step:    11800, Batch Loss:     1.661763, Batch Acc: 0.512792, Tokens per Sec:     3237, Lr: 0.000300
2023-05-27 23:50:36,209 - INFO - joeynmt.training - Epoch   5, Step:    11900, Batch Loss:     1.724350, Batch Acc: 0.512887, Tokens per Sec:     2987, Lr: 0.000300
2023-05-27 23:50:57,516 - INFO - joeynmt.training - Epoch   5, Step:    12000, Batch Loss:     1.508896, Batch Acc: 0.506929, Tokens per Sec:     3129, Lr: 0.000300
2023-05-27 23:50:57,516 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:50:57,516 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:51:24,638 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.70, acc:   0.48, generation: 27.0768[sec], evaluation: 0.0000[sec]
2023-05-27 23:51:24,639 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:51:24,735 - INFO - joeynmt.helpers - delete models/transformer_a/9500.ckpt
2023-05-27 23:51:24,749 - INFO - joeynmt.training - Example #0
2023-05-27 23:51:24,749 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:51:24,749 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:51:24,749 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', 'had', '<unk>', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2023-05-27 23:51:24,749 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:51:24,749 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:51:24,750 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk> die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> staten had <unk> om 40 procent <unk> te <unk>.
2023-05-27 23:51:24,750 - INFO - joeynmt.training - Example #1
2023-05-27 23:51:24,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:51:24,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:51:24,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-27 23:51:24,750 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:51:24,750 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:51:24,750 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2023-05-27 23:51:24,750 - INFO - joeynmt.training - Example #2
2023-05-27 23:51:24,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:51:24,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:51:24,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:51:24,750 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:51:24,750 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:51:24,750 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> <unk> het <unk> hart van ons <unk>.
2023-05-27 23:51:24,750 - INFO - joeynmt.training - Example #3
2023-05-27 23:51:24,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:51:24,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:51:24,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:51:24,750 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:51:24,750 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:51:24,750 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de <unk> en <unk> in de zomer.
2023-05-27 23:51:24,750 - INFO - joeynmt.training - Example #4
2023-05-27 23:51:24,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:51:24,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:51:24,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:51:24,751 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:51:24,751 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:51:24,751 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> wat er in de afgelopen 25 jaar is.
2023-05-27 23:51:46,685 - INFO - joeynmt.training - Epoch   5, Step:    12100, Batch Loss:     1.472870, Batch Acc: 0.514787, Tokens per Sec:     3130, Lr: 0.000300
2023-05-27 23:52:08,735 - INFO - joeynmt.training - Epoch   5, Step:    12200, Batch Loss:     1.640724, Batch Acc: 0.510518, Tokens per Sec:     2997, Lr: 0.000300
2023-05-27 23:52:30,381 - INFO - joeynmt.training - Epoch   5, Step:    12300, Batch Loss:     1.584422, Batch Acc: 0.513818, Tokens per Sec:     3104, Lr: 0.000300
2023-05-27 23:52:53,308 - INFO - joeynmt.training - Epoch   5, Step:    12400, Batch Loss:     1.513201, Batch Acc: 0.516205, Tokens per Sec:     2894, Lr: 0.000300
2023-05-27 23:53:14,962 - INFO - joeynmt.training - Epoch   5, Step:    12500, Batch Loss:     1.674727, Batch Acc: 0.512807, Tokens per Sec:     3058, Lr: 0.000300
2023-05-27 23:53:14,963 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:53:14,963 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:53:46,294 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.69, acc:   0.48, generation: 31.2832[sec], evaluation: 0.0000[sec]
2023-05-27 23:53:46,295 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:53:46,408 - INFO - joeynmt.helpers - delete models/transformer_a/10000.ckpt
2023-05-27 23:53:46,421 - INFO - joeynmt.training - Example #0
2023-05-27 23:53:46,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:53:46,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:53:46,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', 'had', 'ik', 'deze', 'twee', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:53:46,422 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:53:46,422 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:53:46,422 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die voor drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk>, had ik deze twee <unk> <unk>.
2023-05-27 23:53:46,422 - INFO - joeynmt.training - Example #1
2023-05-27 23:53:46,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:53:46,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:53:46,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'veel', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-27 23:53:46,422 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:53:46,422 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:53:46,422 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet veel genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2023-05-27 23:53:46,422 - INFO - joeynmt.training - Example #2
2023-05-27 23:53:46,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:53:46,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:53:46,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:53:46,422 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:53:46,422 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:53:46,422 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-27 23:53:46,422 - INFO - joeynmt.training - Example #3
2023-05-27 23:53:46,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:53:46,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:53:46,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:53:46,423 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:53:46,423 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:53:46,423 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-27 23:53:46,423 - INFO - joeynmt.training - Example #4
2023-05-27 23:53:46,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:53:46,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:53:46,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-27 23:53:46,423 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:53:46,423 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:53:46,423 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> wat er in de afgelopen 25 jaar is.
2023-05-27 23:54:07,269 - INFO - joeynmt.training - Epoch   5, Step:    12600, Batch Loss:     1.600809, Batch Acc: 0.511164, Tokens per Sec:     3211, Lr: 0.000300
2023-05-27 23:54:28,716 - INFO - joeynmt.training - Epoch   5, Step:    12700, Batch Loss:     1.597685, Batch Acc: 0.515488, Tokens per Sec:     3158, Lr: 0.000300
2023-05-27 23:54:50,976 - INFO - joeynmt.training - Epoch   5, Step:    12800, Batch Loss:     1.531154, Batch Acc: 0.514772, Tokens per Sec:     2982, Lr: 0.000300
2023-05-27 23:55:12,889 - INFO - joeynmt.training - Epoch   5, Step:    12900, Batch Loss:     1.563379, Batch Acc: 0.514449, Tokens per Sec:     3048, Lr: 0.000300
2023-05-27 23:55:35,186 - INFO - joeynmt.training - Epoch   5, Step:    13000, Batch Loss:     1.526413, Batch Acc: 0.511264, Tokens per Sec:     2950, Lr: 0.000300
2023-05-27 23:55:35,187 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:55:35,187 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:56:10,909 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.63, acc:   0.48, generation: 35.6768[sec], evaluation: 0.0000[sec]
2023-05-27 23:56:10,910 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:56:11,017 - INFO - joeynmt.helpers - delete models/transformer_a/10500.ckpt
2023-05-27 23:56:11,030 - INFO - joeynmt.training - Example #0
2023-05-27 23:56:11,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:56:11,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:56:11,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', '<unk>', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', '<unk>', '<unk>', '.', '</s>']
2023-05-27 23:56:11,030 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:56:11,030 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:56:11,030 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die <unk> <unk> <unk>, die <unk> <unk> drie miljoen jaar de <unk> van de <unk> staten <unk> <unk>.
2023-05-27 23:56:11,030 - INFO - joeynmt.training - Example #1
2023-05-27 23:56:11,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:56:11,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:56:11,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', 'laat', 'zien', '.', '</s>']
2023-05-27 23:56:11,031 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:56:11,031 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:56:11,031 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van het <unk> laat zien.
2023-05-27 23:56:11,031 - INFO - joeynmt.training - Example #2
2023-05-27 23:56:11,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:56:11,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:56:11,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:56:11,031 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:56:11,031 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:56:11,031 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> van ons <unk>.
2023-05-27 23:56:11,031 - INFO - joeynmt.training - Example #3
2023-05-27 23:56:11,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:56:11,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:56:11,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:56:11,031 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:56:11,031 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:56:11,031 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-27 23:56:11,031 - INFO - joeynmt.training - Example #4
2023-05-27 23:56:11,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:56:11,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:56:11,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-27 23:56:11,031 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:56:11,031 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:56:11,031 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> van de laatste 25 jaar.
2023-05-27 23:56:31,543 - INFO - joeynmt.training - Epoch   5, Step:    13100, Batch Loss:     1.676468, Batch Acc: 0.514537, Tokens per Sec:     3197, Lr: 0.000300
2023-05-27 23:56:52,951 - INFO - joeynmt.training - Epoch   5, Step:    13200, Batch Loss:     1.703864, Batch Acc: 0.512920, Tokens per Sec:     3158, Lr: 0.000300
2023-05-27 23:57:13,983 - INFO - joeynmt.training - Epoch   5, Step:    13300, Batch Loss:     1.681706, Batch Acc: 0.508160, Tokens per Sec:     3196, Lr: 0.000300
2023-05-27 23:57:33,830 - INFO - joeynmt.training - Epoch   5, Step:    13400, Batch Loss:     1.617622, Batch Acc: 0.515493, Tokens per Sec:     3339, Lr: 0.000300
2023-05-27 23:57:55,199 - INFO - joeynmt.training - Epoch   5, Step:    13500, Batch Loss:     1.715163, Batch Acc: 0.515186, Tokens per Sec:     3123, Lr: 0.000300
2023-05-27 23:57:55,201 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-27 23:57:55,201 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-27 23:58:26,103 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.61, acc:   0.48, generation: 30.8565[sec], evaluation: 0.0000[sec]
2023-05-27 23:58:26,104 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-27 23:58:26,234 - INFO - joeynmt.helpers - delete models/transformer_a/11000.ckpt
2023-05-27 23:58:26,252 - INFO - joeynmt.training - Example #0
2023-05-27 23:58:26,252 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-27 23:58:26,252 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-27 23:58:26,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'ongeveer', '40', 'procent', '<unk>', 'is', '.', '</s>']
2023-05-27 23:58:26,252 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-27 23:58:26,252 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-27 23:58:26,253 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die <unk> <unk> <unk> <unk>, de <unk> <unk> van de <unk> <unk> staten, ongeveer 40 procent <unk> is.
2023-05-27 23:58:26,253 - INFO - joeynmt.training - Example #1
2023-05-27 23:58:26,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-27 23:58:26,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-27 23:58:26,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-27 23:58:26,253 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-27 23:58:26,253 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-27 23:58:26,253 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van het <unk>.
2023-05-27 23:58:26,253 - INFO - joeynmt.training - Example #2
2023-05-27 23:58:26,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-27 23:58:26,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-27 23:58:26,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-27 23:58:26,253 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-27 23:58:26,253 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-27 23:58:26,253 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-27 23:58:26,253 - INFO - joeynmt.training - Example #3
2023-05-27 23:58:26,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-27 23:58:26,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-27 23:58:26,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-27 23:58:26,253 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-27 23:58:26,253 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-27 23:58:26,253 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-27 23:58:26,253 - INFO - joeynmt.training - Example #4
2023-05-27 23:58:26,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-27 23:58:26,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-27 23:58:26,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2023-05-27 23:58:26,254 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-27 23:58:26,254 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-27 23:58:26,254 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> wat er in de afgelopen 25 jaar is gebeurd.
2023-05-27 23:58:47,236 - INFO - joeynmt.training - Epoch   5, Step:    13600, Batch Loss:     1.569169, Batch Acc: 0.513384, Tokens per Sec:     3127, Lr: 0.000300
2023-05-27 23:58:59,566 - INFO - joeynmt.training - Epoch   5: total training loss 4376.22
2023-05-27 23:58:59,566 - INFO - joeynmt.training - EPOCH 6
2023-05-27 23:58:59,598 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=5
2023-05-27 23:59:08,291 - INFO - joeynmt.training - Epoch   6, Step:    13700, Batch Loss:     1.615939, Batch Acc: 0.533426, Tokens per Sec:     3316, Lr: 0.000300
2023-05-27 23:59:30,016 - INFO - joeynmt.training - Epoch   6, Step:    13800, Batch Loss:     1.498278, Batch Acc: 0.528334, Tokens per Sec:     3045, Lr: 0.000300
2023-05-27 23:59:51,001 - INFO - joeynmt.training - Epoch   6, Step:    13900, Batch Loss:     1.575687, Batch Acc: 0.518493, Tokens per Sec:     3195, Lr: 0.000300
2023-05-28 00:00:12,470 - INFO - joeynmt.training - Epoch   6, Step:    14000, Batch Loss:     1.485253, Batch Acc: 0.522717, Tokens per Sec:     3093, Lr: 0.000300
2023-05-28 00:00:12,471 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:00:12,471 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:00:39,841 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.60, acc:   0.48, generation: 27.3262[sec], evaluation: 0.0000[sec]
2023-05-28 00:00:39,843 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:00:39,938 - INFO - joeynmt.helpers - delete models/transformer_a/11500.ckpt
2023-05-28 00:00:39,950 - INFO - joeynmt.training - Example #0
2023-05-28 00:00:39,951 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:00:39,951 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:00:39,951 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', '<unk>', 'staten', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2023-05-28 00:00:39,951 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:00:39,951 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:00:39,951 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, de <unk> <unk> <unk>, de <unk> <unk> <unk> <unk> staten, om 40 procent <unk> te <unk>.
2023-05-28 00:00:39,951 - INFO - joeynmt.training - Example #1
2023-05-28 00:00:39,951 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:00:39,951 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:00:39,951 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-28 00:00:39,951 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:00:39,951 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:00:39,951 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg de <unk> van deze <unk> <unk>, omdat het niet de <unk> van de <unk>.
2023-05-28 00:00:39,951 - INFO - joeynmt.training - Example #2
2023-05-28 00:00:39,951 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:00:39,951 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:00:39,951 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:00:39,951 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:00:39,951 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:00:39,951 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-28 00:00:39,951 - INFO - joeynmt.training - Example #3
2023-05-28 00:00:39,951 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:00:39,951 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:00:39,951 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:00:39,952 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:00:39,952 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:00:39,952 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2023-05-28 00:00:39,952 - INFO - joeynmt.training - Example #4
2023-05-28 00:00:39,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:00:39,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:00:39,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'zal', 'laten', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'is', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 00:00:39,952 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:00:39,952 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:00:39,952 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie zal laten zien, is een <unk> wat er is in de afgelopen 25 jaar.
2023-05-28 00:01:01,767 - INFO - joeynmt.training - Epoch   6, Step:    14100, Batch Loss:     1.543787, Batch Acc: 0.520651, Tokens per Sec:     3073, Lr: 0.000300
2023-05-28 00:01:23,207 - INFO - joeynmt.training - Epoch   6, Step:    14200, Batch Loss:     1.693986, Batch Acc: 0.519280, Tokens per Sec:     3075, Lr: 0.000300
2023-05-28 00:01:43,997 - INFO - joeynmt.training - Epoch   6, Step:    14300, Batch Loss:     1.590770, Batch Acc: 0.515920, Tokens per Sec:     3192, Lr: 0.000300
2023-05-28 00:02:03,875 - INFO - joeynmt.training - Epoch   6, Step:    14400, Batch Loss:     1.621316, Batch Acc: 0.518082, Tokens per Sec:     3163, Lr: 0.000300
2023-05-28 00:02:23,226 - INFO - joeynmt.training - Epoch   6, Step:    14500, Batch Loss:     1.797810, Batch Acc: 0.525805, Tokens per Sec:     3365, Lr: 0.000300
2023-05-28 00:02:23,227 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:02:23,227 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:02:54,757 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.63, acc:   0.48, generation: 31.4845[sec], evaluation: 0.0000[sec]
2023-05-28 00:02:54,859 - INFO - joeynmt.helpers - delete models/transformer_a/12000.ckpt
2023-05-28 00:02:54,870 - INFO - joeynmt.training - Example #0
2023-05-28 00:02:54,870 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:02:54,870 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:02:54,870 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2023-05-28 00:02:54,871 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:02:54,871 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:02:54,871 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk> die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk>, om 40 procent <unk> te <unk>.
2023-05-28 00:02:54,871 - INFO - joeynmt.training - Example #1
2023-05-28 00:02:54,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:02:54,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:02:54,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2023-05-28 00:02:54,871 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:02:54,871 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:02:54,871 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg de <unk> van deze <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2023-05-28 00:02:54,871 - INFO - joeynmt.training - Example #2
2023-05-28 00:02:54,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:02:54,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:02:54,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'onze', '<unk>', '.', '</s>']
2023-05-28 00:02:54,871 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:02:54,871 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:02:54,871 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van onze <unk>.
2023-05-28 00:02:54,871 - INFO - joeynmt.training - Example #3
2023-05-28 00:02:54,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:02:54,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:02:54,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:02:54,871 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:02:54,871 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:02:54,871 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:02:54,871 - INFO - joeynmt.training - Example #4
2023-05-28 00:02:54,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:02:54,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:02:54,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 00:02:54,872 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:02:54,872 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:02:54,872 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien, is een <unk> van de laatste 25 jaar.
2023-05-28 00:03:15,365 - INFO - joeynmt.training - Epoch   6, Step:    14600, Batch Loss:     1.423621, Batch Acc: 0.516077, Tokens per Sec:     3234, Lr: 0.000300
2023-05-28 00:03:35,610 - INFO - joeynmt.training - Epoch   6, Step:    14700, Batch Loss:     1.568990, Batch Acc: 0.523765, Tokens per Sec:     3301, Lr: 0.000300
2023-05-28 00:03:55,456 - INFO - joeynmt.training - Epoch   6, Step:    14800, Batch Loss:     1.367432, Batch Acc: 0.520253, Tokens per Sec:     3328, Lr: 0.000300
2023-05-28 00:04:15,031 - INFO - joeynmt.training - Epoch   6, Step:    14900, Batch Loss:     1.528883, Batch Acc: 0.515695, Tokens per Sec:     3359, Lr: 0.000300
2023-05-28 00:04:34,233 - INFO - joeynmt.training - Epoch   6, Step:    15000, Batch Loss:     1.654939, Batch Acc: 0.523797, Tokens per Sec:     3445, Lr: 0.000300
2023-05-28 00:04:34,234 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:04:34,234 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:05:04,463 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.54, acc:   0.48, generation: 30.1845[sec], evaluation: 0.0000[sec]
2023-05-28 00:05:04,464 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:05:04,563 - INFO - joeynmt.helpers - delete models/transformer_a/12500.ckpt
2023-05-28 00:05:04,576 - INFO - joeynmt.training - Example #0
2023-05-28 00:05:04,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:05:04,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:05:04,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', ',', 'met', '40', 'procent', '<unk>', 'is', '.', '</s>']
2023-05-28 00:05:04,577 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:05:04,577 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:05:04,577 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> <unk> om te <unk> dat de <unk> <unk> <unk> <unk>, de <unk> <unk> <unk> <unk>, de <unk> <unk> <unk> <unk>, <unk>, met 40 procent <unk> is.
2023-05-28 00:05:04,577 - INFO - joeynmt.training - Example #1
2023-05-28 00:05:04,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:05:04,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:05:04,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'veel', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-28 00:05:04,577 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:05:04,577 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:05:04,577 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet veel genoeg de <unk> van dit <unk> <unk>, want het is niet de <unk> van de <unk>.
2023-05-28 00:05:04,577 - INFO - joeynmt.training - Example #2
2023-05-28 00:05:04,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:05:04,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:05:04,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:05:04,577 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:05:04,577 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:05:04,577 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-28 00:05:04,577 - INFO - joeynmt.training - Example #3
2023-05-28 00:05:04,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:05:04,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:05:04,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:05:04,578 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:05:04,578 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:05:04,578 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer.
2023-05-28 00:05:04,578 - INFO - joeynmt.training - Example #4
2023-05-28 00:05:04,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:05:04,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:05:04,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 00:05:04,578 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:05:04,578 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:05:04,578 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien, is een <unk> wat er in de afgelopen 25 jaar is.
2023-05-28 00:05:25,662 - INFO - joeynmt.training - Epoch   6, Step:    15100, Batch Loss:     1.586746, Batch Acc: 0.520578, Tokens per Sec:     3122, Lr: 0.000300
2023-05-28 00:05:46,324 - INFO - joeynmt.training - Epoch   6, Step:    15200, Batch Loss:     1.388002, Batch Acc: 0.516426, Tokens per Sec:     3168, Lr: 0.000300
2023-05-28 00:06:06,901 - INFO - joeynmt.training - Epoch   6, Step:    15300, Batch Loss:     1.633749, Batch Acc: 0.521719, Tokens per Sec:     3200, Lr: 0.000300
2023-05-28 00:06:27,810 - INFO - joeynmt.training - Epoch   6, Step:    15400, Batch Loss:     1.707986, Batch Acc: 0.521843, Tokens per Sec:     3185, Lr: 0.000300
2023-05-28 00:06:48,801 - INFO - joeynmt.training - Epoch   6, Step:    15500, Batch Loss:     1.714073, Batch Acc: 0.521839, Tokens per Sec:     3145, Lr: 0.000300
2023-05-28 00:06:48,802 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:06:48,802 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:07:18,458 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.52, acc:   0.48, generation: 29.6105[sec], evaluation: 0.0000[sec]
2023-05-28 00:07:18,459 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:07:18,559 - INFO - joeynmt.helpers - delete models/transformer_a/13000.ckpt
2023-05-28 00:07:18,572 - INFO - joeynmt.training - Example #0
2023-05-28 00:07:18,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:07:18,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:07:18,572 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'liet', 'ik', 'deze', 'twee', '<unk>', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', 'die', '<unk>', '<unk>', '<unk>', '<unk>', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', 'had', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2023-05-28 00:07:18,572 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:07:18,572 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:07:18,573 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar liet ik deze twee <unk> zien om te <unk> dat de <unk> die <unk> <unk> <unk> <unk> voor <unk> drie miljoen jaar de <unk> van de <unk> staten had om 40 procent te <unk>.
2023-05-28 00:07:18,573 - INFO - joeynmt.training - Example #1
2023-05-28 00:07:18,573 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:07:18,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:07:18,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'sterk', 'genoeg', 'is', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-28 00:07:18,573 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:07:18,573 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:07:18,573 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet sterk genoeg is de <unk> van dit <unk> <unk>, want het is niet de <unk> van het <unk>.
2023-05-28 00:07:18,573 - INFO - joeynmt.training - Example #2
2023-05-28 00:07:18,573 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:07:18,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:07:18,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:07:18,573 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:07:18,573 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:07:18,573 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-28 00:07:18,573 - INFO - joeynmt.training - Example #3
2023-05-28 00:07:18,573 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:07:18,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:07:18,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:07:18,573 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:07:18,573 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:07:18,573 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:07:18,573 - INFO - joeynmt.training - Example #4
2023-05-28 00:07:18,573 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:07:18,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:07:18,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 00:07:18,574 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:07:18,574 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:07:18,574 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> van de laatste 25 jaar.
2023-05-28 00:07:39,600 - INFO - joeynmt.training - Epoch   6, Step:    15600, Batch Loss:     1.513494, Batch Acc: 0.513689, Tokens per Sec:     3060, Lr: 0.000300
2023-05-28 00:08:01,036 - INFO - joeynmt.training - Epoch   6, Step:    15700, Batch Loss:     1.521324, Batch Acc: 0.520357, Tokens per Sec:     3082, Lr: 0.000300
2023-05-28 00:08:22,276 - INFO - joeynmt.training - Epoch   6, Step:    15800, Batch Loss:     1.511232, Batch Acc: 0.514887, Tokens per Sec:     3080, Lr: 0.000300
2023-05-28 00:08:43,453 - INFO - joeynmt.training - Epoch   6, Step:    15900, Batch Loss:     1.635543, Batch Acc: 0.519838, Tokens per Sec:     3075, Lr: 0.000300
2023-05-28 00:09:04,830 - INFO - joeynmt.training - Epoch   6, Step:    16000, Batch Loss:     1.569858, Batch Acc: 0.515860, Tokens per Sec:     3169, Lr: 0.000300
2023-05-28 00:09:04,830 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:09:04,830 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:09:36,902 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.51, acc:   0.48, generation: 32.0261[sec], evaluation: 0.0000[sec]
2023-05-28 00:09:36,903 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:09:36,995 - INFO - joeynmt.helpers - delete models/transformer_a/14500.ckpt
2023-05-28 00:09:37,001 - INFO - joeynmt.training - Example #0
2023-05-28 00:09:37,001 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:09:37,001 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:09:37,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'de', '40', 'procent', '<unk>', 'is', '.', '</s>']
2023-05-28 00:09:37,001 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:09:37,001 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:09:37,001 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die <unk> <unk> <unk> <unk>, de <unk> <unk> <unk> <unk> <unk> <unk>, de 40 procent <unk> is.
2023-05-28 00:09:37,001 - INFO - joeynmt.training - Example #1
2023-05-28 00:09:37,001 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:09:37,001 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:09:37,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'sterk', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-28 00:09:37,001 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:09:37,001 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:09:37,001 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet sterk genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2023-05-28 00:09:37,001 - INFO - joeynmt.training - Example #2
2023-05-28 00:09:37,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:09:37,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:09:37,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:09:37,002 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:09:37,002 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:09:37,002 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-28 00:09:37,002 - INFO - joeynmt.training - Example #3
2023-05-28 00:09:37,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:09:37,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:09:37,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:09:37,002 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:09:37,002 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:09:37,002 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:09:37,002 - INFO - joeynmt.training - Example #4
2023-05-28 00:09:37,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:09:37,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:09:37,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'gebeurt', '.', '</s>']
2023-05-28 00:09:37,002 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:09:37,002 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:09:37,002 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> wat er in de laatste 25 jaar gebeurt.
2023-05-28 00:09:59,196 - INFO - joeynmt.training - Epoch   6, Step:    16100, Batch Loss:     1.600826, Batch Acc: 0.517813, Tokens per Sec:     2968, Lr: 0.000300
2023-05-28 00:10:22,353 - INFO - joeynmt.training - Epoch   6, Step:    16200, Batch Loss:     1.797877, Batch Acc: 0.517282, Tokens per Sec:     2899, Lr: 0.000300
2023-05-28 00:10:45,194 - INFO - joeynmt.training - Epoch   6, Step:    16300, Batch Loss:     1.598658, Batch Acc: 0.518219, Tokens per Sec:     2898, Lr: 0.000300
2023-05-28 00:11:06,202 - INFO - joeynmt.training - Epoch   6: total training loss 4332.57
2023-05-28 00:11:06,202 - INFO - joeynmt.training - EPOCH 7
2023-05-28 00:11:06,230 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=6
2023-05-28 00:11:06,409 - INFO - joeynmt.training - Epoch   7, Step:    16400, Batch Loss:     1.437827, Batch Acc: 0.550336, Tokens per Sec:     2896, Lr: 0.000300
2023-05-28 00:11:24,675 - INFO - joeynmt.training - Epoch   7, Step:    16500, Batch Loss:     1.365543, Batch Acc: 0.532053, Tokens per Sec:     3579, Lr: 0.000300
2023-05-28 00:11:24,676 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:11:24,676 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:11:55,057 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.50, acc:   0.48, generation: 30.3324[sec], evaluation: 0.0000[sec]
2023-05-28 00:11:55,058 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:11:55,154 - INFO - joeynmt.helpers - delete models/transformer_a/13500.ckpt
2023-05-28 00:11:55,168 - INFO - joeynmt.training - Example #0
2023-05-28 00:11:55,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:11:55,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:11:55,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'om', '40', '%', '<unk>', 'te', '<unk>', '.', '</s>']
2023-05-28 00:11:55,168 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:11:55,168 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:11:55,168 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk> die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> staten, om 40% <unk> te <unk>.
2023-05-28 00:11:55,168 - INFO - joeynmt.training - Example #1
2023-05-28 00:11:55,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:11:55,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:11:55,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2023-05-28 00:11:55,168 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:11:55,168 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:11:55,168 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk> <unk>.
2023-05-28 00:11:55,168 - INFO - joeynmt.training - Example #2
2023-05-28 00:11:55,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:11:55,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:11:55,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:11:55,169 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:11:55,169 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:11:55,169 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-28 00:11:55,169 - INFO - joeynmt.training - Example #3
2023-05-28 00:11:55,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:11:55,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:11:55,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:11:55,169 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:11:55,169 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:11:55,169 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:11:55,169 - INFO - joeynmt.training - Example #4
2023-05-28 00:11:55,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:11:55,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:11:55,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2023-05-28 00:11:55,169 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:11:55,169 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:11:55,169 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> wat er in de afgelopen 25 jaar is gebeurd.
2023-05-28 00:12:13,614 - INFO - joeynmt.training - Epoch   7, Step:    16600, Batch Loss:     1.666060, Batch Acc: 0.528498, Tokens per Sec:     3575, Lr: 0.000300
2023-05-28 00:12:32,855 - INFO - joeynmt.training - Epoch   7, Step:    16700, Batch Loss:     1.527687, Batch Acc: 0.528387, Tokens per Sec:     3422, Lr: 0.000300
2023-05-28 00:12:53,356 - INFO - joeynmt.training - Epoch   7, Step:    16800, Batch Loss:     1.478680, Batch Acc: 0.526144, Tokens per Sec:     3248, Lr: 0.000300
2023-05-28 00:13:13,579 - INFO - joeynmt.training - Epoch   7, Step:    16900, Batch Loss:     1.384837, Batch Acc: 0.522564, Tokens per Sec:     3291, Lr: 0.000300
2023-05-28 00:13:33,855 - INFO - joeynmt.training - Epoch   7, Step:    17000, Batch Loss:     1.536413, Batch Acc: 0.524102, Tokens per Sec:     3191, Lr: 0.000300
2023-05-28 00:13:33,856 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:13:33,856 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:14:01,608 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.51, acc:   0.48, generation: 27.7082[sec], evaluation: 0.0000[sec]
2023-05-28 00:14:01,707 - INFO - joeynmt.helpers - delete models/transformer_a/14000.ckpt
2023-05-28 00:14:01,726 - INFO - joeynmt.training - Example #0
2023-05-28 00:14:01,727 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:14:01,727 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:14:01,727 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', '<unk>', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', ',', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-28 00:14:01,727 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:14:01,727 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:14:01,727 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar <unk> ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> staten, <unk> <unk> <unk>.
2023-05-28 00:14:01,727 - INFO - joeynmt.training - Example #1
2023-05-28 00:14:01,727 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:14:01,727 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:14:01,727 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'erg', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2023-05-28 00:14:01,727 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:14:01,727 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:14:01,727 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet erg genoeg om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk> <unk>.
2023-05-28 00:14:01,727 - INFO - joeynmt.training - Example #2
2023-05-28 00:14:01,727 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:14:01,727 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:14:01,727 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2023-05-28 00:14:01,727 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:14:01,727 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:14:01,727 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2023-05-28 00:14:01,727 - INFO - joeynmt.training - Example #3
2023-05-28 00:14:01,727 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:14:01,727 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:14:01,727 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:14:01,728 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:14:01,728 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:14:01,728 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:14:01,728 - INFO - joeynmt.training - Example #4
2023-05-28 00:14:01,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:14:01,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:14:01,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 00:14:01,728 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:14:01,728 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:14:01,728 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> wat er in de afgelopen 25 jaar is.
2023-05-28 00:14:22,029 - INFO - joeynmt.training - Epoch   7, Step:    17100, Batch Loss:     1.783558, Batch Acc: 0.525772, Tokens per Sec:     3177, Lr: 0.000300
2023-05-28 00:14:43,281 - INFO - joeynmt.training - Epoch   7, Step:    17200, Batch Loss:     1.559365, Batch Acc: 0.523885, Tokens per Sec:     3172, Lr: 0.000300
2023-05-28 00:15:03,471 - INFO - joeynmt.training - Epoch   7, Step:    17300, Batch Loss:     1.565713, Batch Acc: 0.526638, Tokens per Sec:     3182, Lr: 0.000300
2023-05-28 00:15:23,146 - INFO - joeynmt.training - Epoch   7, Step:    17400, Batch Loss:     1.360481, Batch Acc: 0.524061, Tokens per Sec:     3346, Lr: 0.000300
2023-05-28 00:15:43,548 - INFO - joeynmt.training - Epoch   7, Step:    17500, Batch Loss:     1.513712, Batch Acc: 0.527554, Tokens per Sec:     3364, Lr: 0.000300
2023-05-28 00:15:43,552 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:15:43,553 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:16:11,111 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.49, acc:   0.48, generation: 27.5122[sec], evaluation: 0.0000[sec]
2023-05-28 00:16:11,112 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:16:11,204 - INFO - joeynmt.helpers - delete models/transformer_a/15000.ckpt
2023-05-28 00:16:11,222 - INFO - joeynmt.training - Example #0
2023-05-28 00:16:11,222 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:16:11,222 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:16:11,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'om', '40', 'procent', 'te', '<unk>', 'is', '.', '</s>']
2023-05-28 00:16:11,223 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:16:11,223 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:16:11,223 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die <unk> drie miljoen jaar <unk> van de <unk> <unk> staten, om 40 procent te <unk> is.
2023-05-28 00:16:11,223 - INFO - joeynmt.training - Example #1
2023-05-28 00:16:11,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:16:11,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:16:11,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'sterk', 'genoeg', 'is', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-28 00:16:11,223 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:16:11,223 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:16:11,223 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet sterk genoeg is de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2023-05-28 00:16:11,223 - INFO - joeynmt.training - Example #2
2023-05-28 00:16:11,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:16:11,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:16:11,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:16:11,223 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:16:11,223 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:16:11,223 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-28 00:16:11,223 - INFO - joeynmt.training - Example #3
2023-05-28 00:16:11,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:16:11,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:16:11,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:16:11,223 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:16:11,224 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:16:11,224 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2023-05-28 00:16:11,224 - INFO - joeynmt.training - Example #4
2023-05-28 00:16:11,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:16:11,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:16:11,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 00:16:11,224 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:16:11,224 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:16:11,224 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> wat er in de laatste 25 jaar is.
2023-05-28 00:16:32,117 - INFO - joeynmt.training - Epoch   7, Step:    17600, Batch Loss:     1.619540, Batch Acc: 0.524024, Tokens per Sec:     3185, Lr: 0.000300
2023-05-28 00:16:52,855 - INFO - joeynmt.training - Epoch   7, Step:    17700, Batch Loss:     1.586027, Batch Acc: 0.532732, Tokens per Sec:     3151, Lr: 0.000300
2023-05-28 00:17:14,030 - INFO - joeynmt.training - Epoch   7, Step:    17800, Batch Loss:     1.609171, Batch Acc: 0.524489, Tokens per Sec:     3173, Lr: 0.000300
2023-05-28 00:17:34,617 - INFO - joeynmt.training - Epoch   7, Step:    17900, Batch Loss:     1.532968, Batch Acc: 0.523684, Tokens per Sec:     3273, Lr: 0.000300
2023-05-28 00:17:55,269 - INFO - joeynmt.training - Epoch   7, Step:    18000, Batch Loss:     1.567429, Batch Acc: 0.523585, Tokens per Sec:     3159, Lr: 0.000300
2023-05-28 00:17:55,270 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:17:55,270 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:18:24,224 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.49, acc:   0.49, generation: 28.9093[sec], evaluation: 0.0000[sec]
2023-05-28 00:18:24,354 - INFO - joeynmt.helpers - delete models/transformer_a/15500.ckpt
2023-05-28 00:18:24,373 - INFO - joeynmt.training - Example #0
2023-05-28 00:18:24,373 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:18:24,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:18:24,373 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', 'staten', ',', '40', 'procent', '<unk>', 'is', '.', '</s>']
2023-05-28 00:18:24,373 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:18:24,373 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:18:24,374 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> om te <unk> dat de <unk> <unk> <unk>, die <unk> <unk> <unk>, die <unk> <unk> <unk> <unk>, de <unk> <unk> staten, 40 procent <unk> is.
2023-05-28 00:18:24,374 - INFO - joeynmt.training - Example #1
2023-05-28 00:18:24,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:18:24,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:18:24,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-28 00:18:24,374 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:18:24,374 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:18:24,374 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2023-05-28 00:18:24,374 - INFO - joeynmt.training - Example #2
2023-05-28 00:18:24,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:18:24,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:18:24,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'de', 'wereldwijde', '<unk>', '.', '</s>']
2023-05-28 00:18:24,374 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:18:24,374 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:18:24,374 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van de wereldwijde <unk>.
2023-05-28 00:18:24,374 - INFO - joeynmt.training - Example #3
2023-05-28 00:18:24,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:18:24,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:18:24,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:18:24,374 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:18:24,374 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:18:24,374 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:18:24,374 - INFO - joeynmt.training - Example #4
2023-05-28 00:18:24,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:18:24,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:18:24,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'toon', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2023-05-28 00:18:24,375 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:18:24,375 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:18:24,375 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie toon, is een <unk> wat er in de laatste 25 jaar is gebeurd.
2023-05-28 00:18:46,349 - INFO - joeynmt.training - Epoch   7, Step:    18100, Batch Loss:     1.502990, Batch Acc: 0.526709, Tokens per Sec:     2995, Lr: 0.000300
2023-05-28 00:19:07,437 - INFO - joeynmt.training - Epoch   7, Step:    18200, Batch Loss:     1.703139, Batch Acc: 0.519241, Tokens per Sec:     2996, Lr: 0.000300
2023-05-28 00:19:27,097 - INFO - joeynmt.training - Epoch   7, Step:    18300, Batch Loss:     1.614183, Batch Acc: 0.520711, Tokens per Sec:     3309, Lr: 0.000300
2023-05-28 00:19:47,519 - INFO - joeynmt.training - Epoch   7, Step:    18400, Batch Loss:     1.606666, Batch Acc: 0.523876, Tokens per Sec:     3303, Lr: 0.000300
2023-05-28 00:20:07,941 - INFO - joeynmt.training - Epoch   7, Step:    18500, Batch Loss:     1.476752, Batch Acc: 0.524005, Tokens per Sec:     3239, Lr: 0.000300
2023-05-28 00:20:07,943 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:20:07,943 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:20:38,776 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.47, acc:   0.49, generation: 30.7877[sec], evaluation: 0.0000[sec]
2023-05-28 00:20:38,778 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:20:38,892 - INFO - joeynmt.helpers - delete models/transformer_a/17000.ckpt
2023-05-28 00:20:38,905 - INFO - joeynmt.training - Example #0
2023-05-28 00:20:38,905 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:20:38,905 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:20:38,905 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', ',', 'ongeveer', '40', 'procent', '<unk>', 'is', '.', '</s>']
2023-05-28 00:20:38,905 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:20:38,905 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:20:38,905 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> staten, ongeveer 40 procent <unk> is.
2023-05-28 00:20:38,905 - INFO - joeynmt.training - Example #1
2023-05-28 00:20:38,905 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:20:38,905 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:20:38,905 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'het', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-28 00:20:38,906 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:20:38,906 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:20:38,906 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg de <unk> van het <unk> <unk>, omdat het niet de <unk> van het <unk>.
2023-05-28 00:20:38,906 - INFO - joeynmt.training - Example #2
2023-05-28 00:20:38,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:20:38,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:20:38,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'onze', '<unk>', '.', '</s>']
2023-05-28 00:20:38,906 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:20:38,906 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:20:38,906 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van onze <unk>.
2023-05-28 00:20:38,906 - INFO - joeynmt.training - Example #3
2023-05-28 00:20:38,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:20:38,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:20:38,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:20:38,906 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:20:38,906 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:20:38,906 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:20:38,906 - INFO - joeynmt.training - Example #4
2023-05-28 00:20:38,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:20:38,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:20:38,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 00:20:38,906 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:20:38,906 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:20:38,906 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> wat er in de afgelopen 25 jaar is.
2023-05-28 00:20:59,760 - INFO - joeynmt.training - Epoch   7, Step:    18600, Batch Loss:     1.427268, Batch Acc: 0.524947, Tokens per Sec:     3175, Lr: 0.000300
2023-05-28 00:21:20,146 - INFO - joeynmt.training - Epoch   7, Step:    18700, Batch Loss:     1.396906, Batch Acc: 0.523605, Tokens per Sec:     3189, Lr: 0.000300
2023-05-28 00:21:40,513 - INFO - joeynmt.training - Epoch   7, Step:    18800, Batch Loss:     1.294187, Batch Acc: 0.525859, Tokens per Sec:     3264, Lr: 0.000300
2023-05-28 00:22:01,141 - INFO - joeynmt.training - Epoch   7, Step:    18900, Batch Loss:     1.469304, Batch Acc: 0.521226, Tokens per Sec:     3136, Lr: 0.000300
2023-05-28 00:22:21,185 - INFO - joeynmt.training - Epoch   7, Step:    19000, Batch Loss:     1.664700, Batch Acc: 0.522440, Tokens per Sec:     3331, Lr: 0.000300
2023-05-28 00:22:21,187 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:22:21,187 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:22:51,128 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.46, acc:   0.49, generation: 29.8973[sec], evaluation: 0.0000[sec]
2023-05-28 00:22:51,132 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:22:51,228 - INFO - joeynmt.helpers - delete models/transformer_a/16000.ckpt
2023-05-28 00:22:51,248 - INFO - joeynmt.training - Example #0
2023-05-28 00:22:51,248 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:22:51,248 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:22:51,248 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2023-05-28 00:22:51,248 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:22:51,248 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:22:51,248 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> om te <unk> dat de <unk> <unk>, die <unk> <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> staten, om 40 procent <unk> te <unk>.
2023-05-28 00:22:51,248 - INFO - joeynmt.training - Example #1
2023-05-28 00:22:51,248 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:22:51,248 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:22:51,248 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-28 00:22:51,248 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:22:51,248 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:22:51,248 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> <unk> <unk>.
2023-05-28 00:22:51,248 - INFO - joeynmt.training - Example #2
2023-05-28 00:22:51,248 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:22:51,248 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:22:51,248 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2023-05-28 00:22:51,248 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:22:51,248 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:22:51,248 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> <unk> het <unk> hart van ons <unk> <unk>.
2023-05-28 00:22:51,248 - INFO - joeynmt.training - Example #3
2023-05-28 00:22:51,249 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:22:51,249 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:22:51,249 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:22:51,249 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:22:51,249 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:22:51,249 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:22:51,249 - INFO - joeynmt.training - Example #4
2023-05-28 00:22:51,249 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:22:51,249 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:22:51,249 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 00:22:51,249 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:22:51,249 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:22:51,249 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> van wat er in de laatste 25 jaar.
2023-05-28 00:23:12,260 - INFO - joeynmt.training - Epoch   7, Step:    19100, Batch Loss:     1.486645, Batch Acc: 0.529288, Tokens per Sec:     3116, Lr: 0.000300
2023-05-28 00:23:22,213 - INFO - joeynmt.training - Epoch   7: total training loss 4276.72
2023-05-28 00:23:22,213 - INFO - joeynmt.training - EPOCH 8
2023-05-28 00:23:22,244 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=7
2023-05-28 00:23:31,598 - INFO - joeynmt.training - Epoch   8, Step:    19200, Batch Loss:     1.488472, Batch Acc: 0.526090, Tokens per Sec:     3478, Lr: 0.000300
2023-05-28 00:23:50,730 - INFO - joeynmt.training - Epoch   8, Step:    19300, Batch Loss:     1.545618, Batch Acc: 0.535844, Tokens per Sec:     3490, Lr: 0.000300
2023-05-28 00:24:10,673 - INFO - joeynmt.training - Epoch   8, Step:    19400, Batch Loss:     1.485856, Batch Acc: 0.536045, Tokens per Sec:     3286, Lr: 0.000300
2023-05-28 00:24:30,441 - INFO - joeynmt.training - Epoch   8, Step:    19500, Batch Loss:     1.506976, Batch Acc: 0.536581, Tokens per Sec:     3448, Lr: 0.000300
2023-05-28 00:24:30,442 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:24:30,442 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:24:56,716 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.43, acc:   0.49, generation: 26.2273[sec], evaluation: 0.0000[sec]
2023-05-28 00:24:56,717 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:24:56,841 - INFO - joeynmt.helpers - delete models/transformer_a/16500.ckpt
2023-05-28 00:24:56,860 - INFO - joeynmt.training - Example #0
2023-05-28 00:24:56,860 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:24:56,860 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:24:56,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'ongeveer', '40', 'procent', '<unk>', 'is', '.', '</s>']
2023-05-28 00:24:56,860 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:24:56,860 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:24:56,860 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die voor <unk> drie miljoen jaar <unk> <unk> van de <unk> <unk> staten, ongeveer 40 procent <unk> is.
2023-05-28 00:24:56,860 - INFO - joeynmt.training - Example #1
2023-05-28 00:24:56,860 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:24:56,860 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:24:56,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'sterk', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-28 00:24:56,861 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:24:56,861 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:24:56,861 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet sterk genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van het <unk>.
2023-05-28 00:24:56,861 - INFO - joeynmt.training - Example #2
2023-05-28 00:24:56,861 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:24:56,861 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:24:56,861 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:24:56,861 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:24:56,861 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:24:56,861 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-28 00:24:56,861 - INFO - joeynmt.training - Example #3
2023-05-28 00:24:56,861 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:24:56,861 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:24:56,861 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:24:56,861 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:24:56,861 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:24:56,861 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2023-05-28 00:24:56,861 - INFO - joeynmt.training - Example #4
2023-05-28 00:24:56,861 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:24:56,861 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:24:56,861 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'gebeurt', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 00:24:56,861 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:24:56,861 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:24:56,861 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> wat er gebeurt in de laatste 25 jaar.
2023-05-28 00:25:15,018 - INFO - joeynmt.training - Epoch   8, Step:    19600, Batch Loss:     1.601520, Batch Acc: 0.534206, Tokens per Sec:     3585, Lr: 0.000300
2023-05-28 00:25:33,532 - INFO - joeynmt.training - Epoch   8, Step:    19700, Batch Loss:     1.587833, Batch Acc: 0.532782, Tokens per Sec:     3613, Lr: 0.000300
2023-05-28 00:25:52,908 - INFO - joeynmt.training - Epoch   8, Step:    19800, Batch Loss:     1.431430, Batch Acc: 0.533690, Tokens per Sec:     3401, Lr: 0.000300
2023-05-28 00:26:13,230 - INFO - joeynmt.training - Epoch   8, Step:    19900, Batch Loss:     1.445082, Batch Acc: 0.530860, Tokens per Sec:     3211, Lr: 0.000300
2023-05-28 00:26:33,079 - INFO - joeynmt.training - Epoch   8, Step:    20000, Batch Loss:     1.776924, Batch Acc: 0.530420, Tokens per Sec:     3320, Lr: 0.000300
2023-05-28 00:26:33,080 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:26:33,080 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:27:00,403 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.41, acc:   0.49, generation: 27.2795[sec], evaluation: 0.0000[sec]
2023-05-28 00:27:00,404 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:27:00,515 - INFO - joeynmt.helpers - delete models/transformer_a/18000.ckpt
2023-05-28 00:27:00,532 - INFO - joeynmt.training - Example #0
2023-05-28 00:27:00,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:27:00,532 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:27:00,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '.', '</s>']
2023-05-28 00:27:00,532 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:27:00,532 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:27:00,532 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> om te <unk> dat de <unk> <unk> <unk> die voor <unk> drie miljoen jaar <unk> <unk>.
2023-05-28 00:27:00,532 - INFO - joeynmt.training - Example #1
2023-05-28 00:27:00,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:27:00,532 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:27:00,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'om', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-28 00:27:00,532 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:27:00,532 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:27:00,532 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg om de <unk> van dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2023-05-28 00:27:00,532 - INFO - joeynmt.training - Example #2
2023-05-28 00:27:00,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:27:00,532 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:27:00,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:27:00,532 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:27:00,532 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:27:00,532 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> van ons <unk>.
2023-05-28 00:27:00,532 - INFO - joeynmt.training - Example #3
2023-05-28 00:27:00,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:27:00,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:27:00,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:27:00,533 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:27:00,533 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:27:00,533 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2023-05-28 00:27:00,533 - INFO - joeynmt.training - Example #4
2023-05-28 00:27:00,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:27:00,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:27:00,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'gebeurt', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 00:27:00,533 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:27:00,533 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:27:00,533 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> wat er gebeurt in de laatste 25 jaar.
2023-05-28 00:27:21,079 - INFO - joeynmt.training - Epoch   8, Step:    20100, Batch Loss:     1.345320, Batch Acc: 0.528783, Tokens per Sec:     3200, Lr: 0.000300
2023-05-28 00:27:40,484 - INFO - joeynmt.training - Epoch   8, Step:    20200, Batch Loss:     1.488973, Batch Acc: 0.531647, Tokens per Sec:     3340, Lr: 0.000300
2023-05-28 00:27:59,956 - INFO - joeynmt.training - Epoch   8, Step:    20300, Batch Loss:     1.743817, Batch Acc: 0.529037, Tokens per Sec:     3379, Lr: 0.000300
2023-05-28 00:28:20,414 - INFO - joeynmt.training - Epoch   8, Step:    20400, Batch Loss:     1.513610, Batch Acc: 0.528959, Tokens per Sec:     3243, Lr: 0.000300
2023-05-28 00:28:42,563 - INFO - joeynmt.training - Epoch   8, Step:    20500, Batch Loss:     1.699494, Batch Acc: 0.532664, Tokens per Sec:     2992, Lr: 0.000300
2023-05-28 00:28:42,564 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:28:42,564 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:29:09,419 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.44, acc:   0.49, generation: 26.8110[sec], evaluation: 0.0000[sec]
2023-05-28 00:29:09,526 - INFO - joeynmt.helpers - delete models/transformer_a/17500.ckpt
2023-05-28 00:29:09,541 - INFO - joeynmt.training - Example #0
2023-05-28 00:29:09,541 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:29:09,541 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:29:09,541 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', '<unk>', '<unk>', '<unk>', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '.', '</s>']
2023-05-28 00:29:09,541 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:29:09,541 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:29:09,541 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> om te <unk> dat de <unk> <unk> die <unk> <unk> <unk> voor <unk> drie miljoen jaar <unk>.
2023-05-28 00:29:09,541 - INFO - joeynmt.training - Example #1
2023-05-28 00:29:09,541 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:29:09,541 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:29:09,541 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'sterk', 'genoeg', 'om', 'de', '<unk>', 'van', 'dit', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-28 00:29:09,542 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:29:09,542 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:29:09,542 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg om de <unk> van dit <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2023-05-28 00:29:09,542 - INFO - joeynmt.training - Example #2
2023-05-28 00:29:09,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:29:09,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:29:09,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'van', 'onze', 'wereldwijde', '<unk>', '.', '</s>']
2023-05-28 00:29:09,542 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:29:09,542 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:29:09,542 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> van onze wereldwijde <unk>.
2023-05-28 00:29:09,542 - INFO - joeynmt.training - Example #3
2023-05-28 00:29:09,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:29:09,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:29:09,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:29:09,542 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:29:09,542 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:29:09,542 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:29:09,542 - INFO - joeynmt.training - Example #4
2023-05-28 00:29:09,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:29:09,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:29:09,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'is', 'gebeurd', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 00:29:09,542 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:29:09,542 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:29:09,542 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> wat er is gebeurd in de laatste 25 jaar.
2023-05-28 00:29:31,813 - INFO - joeynmt.training - Epoch   8, Step:    20600, Batch Loss:     1.504806, Batch Acc: 0.527189, Tokens per Sec:     3071, Lr: 0.000300
2023-05-28 00:29:53,759 - INFO - joeynmt.training - Epoch   8, Step:    20700, Batch Loss:     1.381531, Batch Acc: 0.529360, Tokens per Sec:     2978, Lr: 0.000300
2023-05-28 00:30:15,140 - INFO - joeynmt.training - Epoch   8, Step:    20800, Batch Loss:     1.524872, Batch Acc: 0.530247, Tokens per Sec:     3111, Lr: 0.000300
2023-05-28 00:30:35,697 - INFO - joeynmt.training - Epoch   8, Step:    20900, Batch Loss:     1.507894, Batch Acc: 0.533781, Tokens per Sec:     3265, Lr: 0.000300
2023-05-28 00:30:56,206 - INFO - joeynmt.training - Epoch   8, Step:    21000, Batch Loss:     1.502513, Batch Acc: 0.527473, Tokens per Sec:     3185, Lr: 0.000300
2023-05-28 00:30:56,207 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:30:56,207 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:31:25,588 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.44, acc:   0.49, generation: 29.3359[sec], evaluation: 0.0000[sec]
2023-05-28 00:31:25,757 - INFO - joeynmt.helpers - delete models/transformer_a/18500.ckpt
2023-05-28 00:31:25,780 - INFO - joeynmt.training - Example #0
2023-05-28 00:31:25,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:31:25,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:31:25,780 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', ',', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2023-05-28 00:31:25,780 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:31:25,780 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:31:25,780 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk> die voor <unk> drie miljoen jaar de <unk> van de <unk> staten, om 40 procent te <unk>.
2023-05-28 00:31:25,780 - INFO - joeynmt.training - Example #1
2023-05-28 00:31:25,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:31:25,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:31:25,780 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'sterk', 'genoeg', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-28 00:31:25,780 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:31:25,780 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:31:25,780 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de <unk> van deze <unk> <unk>, omdat het niet de <unk> van de <unk>.
2023-05-28 00:31:25,780 - INFO - joeynmt.training - Example #2
2023-05-28 00:31:25,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:31:25,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:31:25,780 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2023-05-28 00:31:25,780 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:31:25,780 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:31:25,781 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> het <unk> hart van ons <unk> <unk>.
2023-05-28 00:31:25,781 - INFO - joeynmt.training - Example #3
2023-05-28 00:31:25,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:31:25,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:31:25,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:31:25,781 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:31:25,781 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:31:25,781 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:31:25,781 - INFO - joeynmt.training - Example #4
2023-05-28 00:31:25,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:31:25,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:31:25,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 00:31:25,781 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:31:25,781 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:31:25,781 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> van de laatste 25 jaar.
2023-05-28 00:31:46,637 - INFO - joeynmt.training - Epoch   8, Step:    21100, Batch Loss:     1.520007, Batch Acc: 0.532451, Tokens per Sec:     3143, Lr: 0.000300
2023-05-28 00:32:08,513 - INFO - joeynmt.training - Epoch   8, Step:    21200, Batch Loss:     1.628468, Batch Acc: 0.524597, Tokens per Sec:     2978, Lr: 0.000300
2023-05-28 00:32:30,812 - INFO - joeynmt.training - Epoch   8, Step:    21300, Batch Loss:     1.517486, Batch Acc: 0.527362, Tokens per Sec:     3004, Lr: 0.000300
2023-05-28 00:32:51,882 - INFO - joeynmt.training - Epoch   8, Step:    21400, Batch Loss:     1.437978, Batch Acc: 0.528130, Tokens per Sec:     3210, Lr: 0.000300
2023-05-28 00:33:11,727 - INFO - joeynmt.training - Epoch   8, Step:    21500, Batch Loss:     1.444356, Batch Acc: 0.534103, Tokens per Sec:     3355, Lr: 0.000300
2023-05-28 00:33:11,728 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:33:11,728 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:33:39,432 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.39, acc:   0.49, generation: 27.6572[sec], evaluation: 0.0000[sec]
2023-05-28 00:33:39,433 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:33:39,555 - INFO - joeynmt.helpers - delete models/transformer_a/19000.ckpt
2023-05-28 00:33:39,570 - INFO - joeynmt.training - Example #0
2023-05-28 00:33:39,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:33:39,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:33:39,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', 'staten', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', 'is', '.', '</s>']
2023-05-28 00:33:39,570 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:33:39,570 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:33:39,570 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> <unk>, de <unk> <unk> <unk> <unk>, de <unk> <unk> <unk> staten, om 40 procent <unk> te <unk> is.
2023-05-28 00:33:39,570 - INFO - joeynmt.training - Example #1
2023-05-28 00:33:39,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:33:39,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:33:39,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', 'toont', '.', '</s>']
2023-05-28 00:33:39,570 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:33:39,570 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:33:39,570 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van het <unk> toont.
2023-05-28 00:33:39,570 - INFO - joeynmt.training - Example #2
2023-05-28 00:33:39,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:33:39,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:33:39,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:33:39,571 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:33:39,571 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:33:39,571 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-28 00:33:39,571 - INFO - joeynmt.training - Example #3
2023-05-28 00:33:39,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:33:39,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:33:39,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:33:39,571 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:33:39,571 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:33:39,571 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2023-05-28 00:33:39,571 - INFO - joeynmt.training - Example #4
2023-05-28 00:33:39,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:33:39,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:33:39,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2023-05-28 00:33:39,571 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:33:39,571 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:33:39,571 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> wat er in de afgelopen 25 jaar is gebeurd.
2023-05-28 00:34:00,978 - INFO - joeynmt.training - Epoch   8, Step:    21600, Batch Loss:     1.735304, Batch Acc: 0.523956, Tokens per Sec:     3003, Lr: 0.000300
2023-05-28 00:34:22,348 - INFO - joeynmt.training - Epoch   8, Step:    21700, Batch Loss:     1.490160, Batch Acc: 0.535101, Tokens per Sec:     3109, Lr: 0.000300
2023-05-28 00:34:44,604 - INFO - joeynmt.training - Epoch   8, Step:    21800, Batch Loss:     1.448571, Batch Acc: 0.527257, Tokens per Sec:     3015, Lr: 0.000300
2023-05-28 00:35:02,729 - INFO - joeynmt.training - Epoch   8: total training loss 4191.55
2023-05-28 00:35:02,731 - INFO - joeynmt.training - EPOCH 9
2023-05-28 00:35:02,771 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=8
2023-05-28 00:35:06,244 - INFO - joeynmt.training - Epoch   9, Step:    21900, Batch Loss:     1.563768, Batch Acc: 0.530776, Tokens per Sec:     2983, Lr: 0.000300
2023-05-28 00:35:27,864 - INFO - joeynmt.training - Epoch   9, Step:    22000, Batch Loss:     1.481655, Batch Acc: 0.536767, Tokens per Sec:     3088, Lr: 0.000300
2023-05-28 00:35:27,865 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:35:27,865 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:35:57,447 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.39, acc:   0.49, generation: 29.5350[sec], evaluation: 0.0000[sec]
2023-05-28 00:35:57,542 - INFO - joeynmt.helpers - delete models/transformer_a/20500.ckpt
2023-05-28 00:35:57,564 - INFO - joeynmt.training - Example #0
2023-05-28 00:35:57,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:35:57,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:35:57,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', '<unk>', '<unk>', 'staten', 'had', '<unk>', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2023-05-28 00:35:57,565 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:35:57,565 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:35:57,565 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, de <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> <unk> <unk> staten had <unk> om 40 procent <unk> te <unk>.
2023-05-28 00:35:57,565 - INFO - joeynmt.training - Example #1
2023-05-28 00:35:57,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:35:57,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:35:57,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', ',', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2023-05-28 00:35:57,565 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:35:57,565 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:35:57,565 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg, de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> <unk>.
2023-05-28 00:35:57,565 - INFO - joeynmt.training - Example #2
2023-05-28 00:35:57,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:35:57,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:35:57,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'van', 'het', '<unk>', 'hart', '.', '</s>']
2023-05-28 00:35:57,565 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:35:57,565 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:35:57,565 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> van het <unk> hart.
2023-05-28 00:35:57,565 - INFO - joeynmt.training - Example #3
2023-05-28 00:35:57,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:35:57,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:35:57,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:35:57,566 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:35:57,566 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:35:57,566 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:35:57,566 - INFO - joeynmt.training - Example #4
2023-05-28 00:35:57,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:35:57,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:35:57,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'zal', 'laten', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'gebeurt', '.', '</s>']
2023-05-28 00:35:57,566 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:35:57,566 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:35:57,566 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik zal laten zien is een <unk> wat er in de afgelopen 25 jaar gebeurt.
2023-05-28 00:36:17,308 - INFO - joeynmt.training - Epoch   9, Step:    22100, Batch Loss:     1.392820, Batch Acc: 0.540503, Tokens per Sec:     3377, Lr: 0.000300
2023-05-28 00:36:36,550 - INFO - joeynmt.training - Epoch   9, Step:    22200, Batch Loss:     1.583572, Batch Acc: 0.536073, Tokens per Sec:     3479, Lr: 0.000300
2023-05-28 00:36:55,809 - INFO - joeynmt.training - Epoch   9, Step:    22300, Batch Loss:     1.526003, Batch Acc: 0.535575, Tokens per Sec:     3496, Lr: 0.000300
2023-05-28 00:37:15,685 - INFO - joeynmt.training - Epoch   9, Step:    22400, Batch Loss:     1.608568, Batch Acc: 0.539396, Tokens per Sec:     3276, Lr: 0.000300
2023-05-28 00:37:34,539 - INFO - joeynmt.training - Epoch   9, Step:    22500, Batch Loss:     1.493639, Batch Acc: 0.533724, Tokens per Sec:     3560, Lr: 0.000300
2023-05-28 00:37:34,540 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:37:34,541 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:38:04,763 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.39, acc:   0.49, generation: 30.1778[sec], evaluation: 0.0000[sec]
2023-05-28 00:38:04,869 - INFO - joeynmt.helpers - delete models/transformer_a/21000.ckpt
2023-05-28 00:38:04,889 - INFO - joeynmt.training - Example #0
2023-05-28 00:38:04,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:38:04,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:38:04,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'staten', 'had', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2023-05-28 00:38:04,890 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:38:04,890 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:38:04,890 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die <unk> <unk> <unk> <unk> <unk> <unk> <unk> staten had om 40 procent <unk> te <unk>.
2023-05-28 00:38:04,890 - INFO - joeynmt.training - Example #1
2023-05-28 00:38:04,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:38:04,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:38:04,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-28 00:38:04,890 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:38:04,890 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:38:04,890 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2023-05-28 00:38:04,890 - INFO - joeynmt.training - Example #2
2023-05-28 00:38:04,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:38:04,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:38:04,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:38:04,890 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:38:04,890 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:38:04,890 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> het <unk> hart van ons <unk>.
2023-05-28 00:38:04,890 - INFO - joeynmt.training - Example #3
2023-05-28 00:38:04,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:38:04,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:38:04,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:38:04,890 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:38:04,890 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:38:04,890 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2023-05-28 00:38:04,890 - INFO - joeynmt.training - Example #4
2023-05-28 00:38:04,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:38:04,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:38:04,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'is', 'gebeurd', '.', '</s>']
2023-05-28 00:38:04,891 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:38:04,891 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:38:04,891 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> wat er is gebeurd.
2023-05-28 00:38:24,981 - INFO - joeynmt.training - Epoch   9, Step:    22600, Batch Loss:     1.591268, Batch Acc: 0.535428, Tokens per Sec:     3304, Lr: 0.000300
2023-05-28 00:38:44,542 - INFO - joeynmt.training - Epoch   9, Step:    22700, Batch Loss:     1.536926, Batch Acc: 0.533768, Tokens per Sec:     3397, Lr: 0.000300
2023-05-28 00:39:04,462 - INFO - joeynmt.training - Epoch   9, Step:    22800, Batch Loss:     1.531805, Batch Acc: 0.536619, Tokens per Sec:     3368, Lr: 0.000300
2023-05-28 00:39:25,168 - INFO - joeynmt.training - Epoch   9, Step:    22900, Batch Loss:     1.456447, Batch Acc: 0.534771, Tokens per Sec:     3241, Lr: 0.000300
2023-05-28 00:39:45,098 - INFO - joeynmt.training - Epoch   9, Step:    23000, Batch Loss:     1.482019, Batch Acc: 0.533297, Tokens per Sec:     3343, Lr: 0.000300
2023-05-28 00:39:45,099 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:39:45,099 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:40:14,272 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.36, acc:   0.49, generation: 29.1297[sec], evaluation: 0.0000[sec]
2023-05-28 00:40:14,274 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:40:14,367 - INFO - joeynmt.helpers - delete models/transformer_a/19500.ckpt
2023-05-28 00:40:14,387 - INFO - joeynmt.training - Example #0
2023-05-28 00:40:14,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:40:14,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:40:14,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'met', '40', 'procent', '<unk>', '.', '</s>']
2023-05-28 00:40:14,387 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:40:14,387 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:40:14,387 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die <unk> <unk> <unk> <unk>, die <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>, met 40 procent <unk>.
2023-05-28 00:40:14,387 - INFO - joeynmt.training - Example #1
2023-05-28 00:40:14,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:40:14,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:40:14,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'om', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-28 00:40:14,387 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:40:14,387 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:40:14,387 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg om de <unk> van dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2023-05-28 00:40:14,387 - INFO - joeynmt.training - Example #2
2023-05-28 00:40:14,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:40:14,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:40:14,388 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:40:14,388 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:40:14,388 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:40:14,388 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-28 00:40:14,388 - INFO - joeynmt.training - Example #3
2023-05-28 00:40:14,388 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:40:14,388 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:40:14,388 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:40:14,388 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:40:14,388 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:40:14,388 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2023-05-28 00:40:14,388 - INFO - joeynmt.training - Example #4
2023-05-28 00:40:14,388 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:40:14,388 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:40:14,388 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 00:40:14,388 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:40:14,388 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:40:14,388 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> wat er in de afgelopen 25 jaar is.
2023-05-28 00:40:35,966 - INFO - joeynmt.training - Epoch   9, Step:    23100, Batch Loss:     1.457719, Batch Acc: 0.536519, Tokens per Sec:     3007, Lr: 0.000300
2023-05-28 00:40:56,998 - INFO - joeynmt.training - Epoch   9, Step:    23200, Batch Loss:     1.314379, Batch Acc: 0.530688, Tokens per Sec:     3153, Lr: 0.000300
2023-05-28 00:41:17,558 - INFO - joeynmt.training - Epoch   9, Step:    23300, Batch Loss:     1.507244, Batch Acc: 0.531344, Tokens per Sec:     3202, Lr: 0.000300
2023-05-28 00:41:37,876 - INFO - joeynmt.training - Epoch   9, Step:    23400, Batch Loss:     1.422436, Batch Acc: 0.535327, Tokens per Sec:     3284, Lr: 0.000300
2023-05-28 00:41:58,203 - INFO - joeynmt.training - Epoch   9, Step:    23500, Batch Loss:     1.532727, Batch Acc: 0.535333, Tokens per Sec:     3182, Lr: 0.000300
2023-05-28 00:41:58,204 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:41:58,204 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:42:30,428 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.34, acc:   0.49, generation: 32.1784[sec], evaluation: 0.0000[sec]
2023-05-28 00:42:30,429 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:42:30,600 - INFO - joeynmt.helpers - delete models/transformer_a/20000.ckpt
2023-05-28 00:42:30,623 - INFO - joeynmt.training - Example #0
2023-05-28 00:42:30,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:42:30,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:42:30,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', '<unk>', 'van', 'de', '<unk>', 'staten', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2023-05-28 00:42:30,623 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:42:30,623 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:42:30,623 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> <unk>, die <unk> drie miljoen jaar de <unk> <unk> van de <unk> staten, om 40 procent <unk> te <unk>.
2023-05-28 00:42:30,623 - INFO - joeynmt.training - Example #1
2023-05-28 00:42:30,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:42:30,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:42:30,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'erg', 'genoeg', 'is', 'om', 'deze', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-28 00:42:30,623 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:42:30,624 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:42:30,624 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet erg genoeg is om deze <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2023-05-28 00:42:30,624 - INFO - joeynmt.training - Example #2
2023-05-28 00:42:30,624 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:42:30,624 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:42:30,624 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:42:30,624 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:42:30,624 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:42:30,624 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-28 00:42:30,624 - INFO - joeynmt.training - Example #3
2023-05-28 00:42:30,624 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:42:30,624 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:42:30,624 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:42:30,624 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:42:30,624 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:42:30,624 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:42:30,624 - INFO - joeynmt.training - Example #4
2023-05-28 00:42:30,624 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:42:30,624 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:42:30,624 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 00:42:30,624 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:42:30,624 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:42:30,624 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> van de laatste 25 jaar.
2023-05-28 00:42:52,349 - INFO - joeynmt.training - Epoch   9, Step:    23600, Batch Loss:     1.551243, Batch Acc: 0.532649, Tokens per Sec:     2961, Lr: 0.000300
2023-05-28 00:43:13,578 - INFO - joeynmt.training - Epoch   9, Step:    23700, Batch Loss:     1.643533, Batch Acc: 0.533164, Tokens per Sec:     3080, Lr: 0.000300
2023-05-28 00:43:34,889 - INFO - joeynmt.training - Epoch   9, Step:    23800, Batch Loss:     1.486840, Batch Acc: 0.537577, Tokens per Sec:     3086, Lr: 0.000300
2023-05-28 00:43:56,491 - INFO - joeynmt.training - Epoch   9, Step:    23900, Batch Loss:     1.643718, Batch Acc: 0.529566, Tokens per Sec:     2999, Lr: 0.000300
2023-05-28 00:44:18,289 - INFO - joeynmt.training - Epoch   9, Step:    24000, Batch Loss:     1.467758, Batch Acc: 0.537117, Tokens per Sec:     3062, Lr: 0.000300
2023-05-28 00:44:18,290 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:44:18,290 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:44:49,921 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.34, acc:   0.49, generation: 31.5871[sec], evaluation: 0.0000[sec]
2023-05-28 00:44:49,924 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:44:50,034 - INFO - joeynmt.helpers - delete models/transformer_a/22000.ckpt
2023-05-28 00:44:50,054 - INFO - joeynmt.training - Example #0
2023-05-28 00:44:50,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:44:50,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:44:50,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'liet', 'ik', 'deze', 'twee', '<unk>', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', ',', 'had', '<unk>', ',', 'met', '40', 'procent', '<unk>', '.', '</s>']
2023-05-28 00:44:50,054 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:44:50,054 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:44:50,054 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar liet ik deze twee <unk> zien om te <unk> dat de <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> staten, had <unk>, met 40 procent <unk>.
2023-05-28 00:44:50,054 - INFO - joeynmt.training - Example #1
2023-05-28 00:44:50,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:44:50,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:44:50,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'sterk', 'genoeg', 'is', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-28 00:44:50,055 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:44:50,055 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:44:50,055 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet sterk genoeg is de <unk> van dit <unk> <unk>, omdat het niet de <unk> van het <unk>.
2023-05-28 00:44:50,055 - INFO - joeynmt.training - Example #2
2023-05-28 00:44:50,055 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:44:50,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:44:50,055 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', 'het', '<unk>', 'van', 'het', '<unk>', 'hart', 'van', 'onze', 'wereldwijde', '<unk>', '.', '</s>']
2023-05-28 00:44:50,055 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:44:50,055 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:44:50,055 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> het <unk> van het <unk> hart van onze wereldwijde <unk>.
2023-05-28 00:44:50,055 - INFO - joeynmt.training - Example #3
2023-05-28 00:44:50,055 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:44:50,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:44:50,055 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:44:50,055 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:44:50,055 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:44:50,055 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:44:50,055 - INFO - joeynmt.training - Example #4
2023-05-28 00:44:50,055 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:44:50,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:44:50,055 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 00:44:50,056 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:44:50,056 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:44:50,056 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> wat er in de afgelopen 25 jaar is.
2023-05-28 00:45:12,235 - INFO - joeynmt.training - Epoch   9, Step:    24100, Batch Loss:     1.439122, Batch Acc: 0.533689, Tokens per Sec:     2981, Lr: 0.000300
2023-05-28 00:45:33,562 - INFO - joeynmt.training - Epoch   9, Step:    24200, Batch Loss:     1.311882, Batch Acc: 0.532702, Tokens per Sec:     3158, Lr: 0.000300
2023-05-28 00:45:55,177 - INFO - joeynmt.training - Epoch   9, Step:    24300, Batch Loss:     1.487062, Batch Acc: 0.533196, Tokens per Sec:     3093, Lr: 0.000300
2023-05-28 00:46:16,771 - INFO - joeynmt.training - Epoch   9, Step:    24400, Batch Loss:     1.602231, Batch Acc: 0.531135, Tokens per Sec:     3022, Lr: 0.000300
2023-05-28 00:46:38,905 - INFO - joeynmt.training - Epoch   9, Step:    24500, Batch Loss:     1.523489, Batch Acc: 0.531900, Tokens per Sec:     2949, Lr: 0.000300
2023-05-28 00:46:38,906 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:46:38,906 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:47:09,480 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.34, acc:   0.49, generation: 30.5287[sec], evaluation: 0.0000[sec]
2023-05-28 00:47:09,482 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:47:09,607 - INFO - joeynmt.helpers - delete models/transformer_a/22500.ckpt
2023-05-28 00:47:09,622 - INFO - joeynmt.training - Example #0
2023-05-28 00:47:09,622 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:47:09,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:47:09,622 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', 'staten', 'had', '<unk>', 'met', '40', 'procent', '<unk>', '.', '</s>']
2023-05-28 00:47:09,622 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:47:09,622 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:47:09,622 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> om te <unk> dat de <unk> <unk> <unk>, die drie miljoen jaar de <unk> <unk> <unk> <unk>, <unk> <unk> <unk> staten had <unk> met 40 procent <unk>.
2023-05-28 00:47:09,622 - INFO - joeynmt.training - Example #1
2023-05-28 00:47:09,622 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:47:09,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:47:09,622 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-28 00:47:09,622 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:47:09,622 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:47:09,622 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg om dit <unk> <unk> te <unk>, omdat het niet de <unk> van het <unk>.
2023-05-28 00:47:09,622 - INFO - joeynmt.training - Example #2
2023-05-28 00:47:09,622 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:47:09,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:47:09,622 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', '<unk>', 'de', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:47:09,622 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:47:09,622 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:47:09,622 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> <unk> de <unk> het <unk> hart van ons <unk>.
2023-05-28 00:47:09,622 - INFO - joeynmt.training - Example #3
2023-05-28 00:47:09,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:47:09,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:47:09,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:47:09,623 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:47:09,623 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:47:09,623 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2023-05-28 00:47:09,623 - INFO - joeynmt.training - Example #4
2023-05-28 00:47:09,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:47:09,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:47:09,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2023-05-28 00:47:09,623 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:47:09,623 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:47:09,623 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> wat er in de afgelopen 25 jaar is gebeurd.
2023-05-28 00:47:31,452 - INFO - joeynmt.training - Epoch   9, Step:    24600, Batch Loss:     1.466625, Batch Acc: 0.531595, Tokens per Sec:     2841, Lr: 0.000300
2023-05-28 00:47:37,324 - INFO - joeynmt.training - Epoch   9: total training loss 4158.53
2023-05-28 00:47:37,325 - INFO - joeynmt.training - EPOCH 10
2023-05-28 00:47:37,357 - INFO - joeynmt.training - Sample random subset from dev set: n=100000, seed=9
2023-05-28 00:47:53,284 - INFO - joeynmt.training - Epoch  10, Step:    24700, Batch Loss:     1.467105, Batch Acc: 0.543402, Tokens per Sec:     3074, Lr: 0.000300
2023-05-28 00:48:14,622 - INFO - joeynmt.training - Epoch  10, Step:    24800, Batch Loss:     1.580892, Batch Acc: 0.540479, Tokens per Sec:     3182, Lr: 0.000300
2023-05-28 00:48:35,506 - INFO - joeynmt.training - Epoch  10, Step:    24900, Batch Loss:     1.545182, Batch Acc: 0.545499, Tokens per Sec:     3153, Lr: 0.000300
2023-05-28 00:48:56,322 - INFO - joeynmt.training - Epoch  10, Step:    25000, Batch Loss:     1.271357, Batch Acc: 0.544325, Tokens per Sec:     3247, Lr: 0.000300
2023-05-28 00:48:56,324 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:48:56,325 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:49:21,634 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.37, acc:   0.49, generation: 25.2629[sec], evaluation: 0.0000[sec]
2023-05-28 00:49:21,744 - INFO - joeynmt.helpers - delete models/transformer_a/21500.ckpt
2023-05-28 00:49:21,760 - INFO - joeynmt.training - Example #0
2023-05-28 00:49:21,760 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:49:21,760 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:49:21,760 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', '<unk>', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '.', '</s>']
2023-05-28 00:49:21,760 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:49:21,760 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:49:21,760 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> <unk> <unk> voor <unk> drie miljoen jaar <unk> <unk>.
2023-05-28 00:49:21,760 - INFO - joeynmt.training - Example #1
2023-05-28 00:49:21,760 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:49:21,760 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:49:21,760 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'erg', 'genoeg', 'is', 'om', 'dit', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-28 00:49:21,761 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:49:21,761 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:49:21,761 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet erg genoeg is om dit <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2023-05-28 00:49:21,761 - INFO - joeynmt.training - Example #2
2023-05-28 00:49:21,761 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:49:21,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:49:21,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', 'het', '<unk>', 'hart', 'van', 'onze', 'mondiale', '<unk>', '.', '</s>']
2023-05-28 00:49:21,761 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:49:21,761 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:49:21,761 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> het <unk> hart van onze mondiale <unk>.
2023-05-28 00:49:21,761 - INFO - joeynmt.training - Example #3
2023-05-28 00:49:21,761 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:49:21,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:49:21,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:49:21,761 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:49:21,761 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:49:21,761 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:49:21,761 - INFO - joeynmt.training - Example #4
2023-05-28 00:49:21,761 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:49:21,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:49:21,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 00:49:21,761 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:49:21,761 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:49:21,761 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> wat er in de laatste 25 jaar is.
2023-05-28 00:49:42,239 - INFO - joeynmt.training - Epoch  10, Step:    25100, Batch Loss:     1.730636, Batch Acc: 0.541856, Tokens per Sec:     3076, Lr: 0.000300
2023-05-28 00:50:03,016 - INFO - joeynmt.training - Epoch  10, Step:    25200, Batch Loss:     1.771658, Batch Acc: 0.539559, Tokens per Sec:     3118, Lr: 0.000300
2023-05-28 00:50:23,955 - INFO - joeynmt.training - Epoch  10, Step:    25300, Batch Loss:     1.544481, Batch Acc: 0.535040, Tokens per Sec:     3151, Lr: 0.000300
2023-05-28 00:50:45,558 - INFO - joeynmt.training - Epoch  10, Step:    25400, Batch Loss:     1.304745, Batch Acc: 0.542510, Tokens per Sec:     3153, Lr: 0.000300
2023-05-28 00:51:06,627 - INFO - joeynmt.training - Epoch  10, Step:    25500, Batch Loss:     1.448377, Batch Acc: 0.540313, Tokens per Sec:     3152, Lr: 0.000300
2023-05-28 00:51:06,629 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:51:06,629 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:51:32,749 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.34, acc:   0.49, generation: 26.0753[sec], evaluation: 0.0000[sec]
2023-05-28 00:51:32,752 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:51:32,869 - INFO - joeynmt.helpers - delete models/transformer_a/25000.ckpt
2023-05-28 00:51:32,874 - INFO - joeynmt.training - Example #0
2023-05-28 00:51:32,874 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:51:32,874 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:51:32,874 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', 'met', '40', 'procent', '<unk>', '.', '</s>']
2023-05-28 00:51:32,874 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:51:32,874 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:51:32,874 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> <unk> die voor <unk> drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk>, met 40 procent <unk>.
2023-05-28 00:51:32,874 - INFO - joeynmt.training - Example #1
2023-05-28 00:51:32,874 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:51:32,874 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:51:32,874 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'om', 'het', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2023-05-28 00:51:32,874 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:51:32,874 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:51:32,874 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg om het <unk> van deze <unk> <unk>, omdat het niet de <unk> van het <unk>.
2023-05-28 00:51:32,874 - INFO - joeynmt.training - Example #2
2023-05-28 00:51:32,874 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:51:32,874 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:51:32,874 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2023-05-28 00:51:32,875 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:51:32,875 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:51:32,875 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2023-05-28 00:51:32,875 - INFO - joeynmt.training - Example #3
2023-05-28 00:51:32,875 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:51:32,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:51:32,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:51:32,875 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:51:32,875 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:51:32,875 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:51:32,875 - INFO - joeynmt.training - Example #4
2023-05-28 00:51:32,875 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:51:32,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:51:32,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'gebeurt', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2023-05-28 00:51:32,875 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:51:32,875 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:51:32,875 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> wat er gebeurt in de afgelopen 25 jaar is.
2023-05-28 00:51:53,423 - INFO - joeynmt.training - Epoch  10, Step:    25600, Batch Loss:     1.435826, Batch Acc: 0.536367, Tokens per Sec:     3197, Lr: 0.000300
2023-05-28 00:52:14,520 - INFO - joeynmt.training - Epoch  10, Step:    25700, Batch Loss:     1.450927, Batch Acc: 0.539011, Tokens per Sec:     3102, Lr: 0.000300
2023-05-28 00:52:35,976 - INFO - joeynmt.training - Epoch  10, Step:    25800, Batch Loss:     1.543551, Batch Acc: 0.537241, Tokens per Sec:     3070, Lr: 0.000300
2023-05-28 00:52:56,232 - INFO - joeynmt.training - Epoch  10, Step:    25900, Batch Loss:     1.515692, Batch Acc: 0.539224, Tokens per Sec:     3351, Lr: 0.000300
2023-05-28 00:53:15,774 - INFO - joeynmt.training - Epoch  10, Step:    26000, Batch Loss:     1.345099, Batch Acc: 0.537189, Tokens per Sec:     3365, Lr: 0.000300
2023-05-28 00:53:15,775 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:53:15,775 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:53:42,575 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.30, acc:   0.49, generation: 26.7563[sec], evaluation: 0.0000[sec]
2023-05-28 00:53:42,575 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2023-05-28 00:53:42,703 - INFO - joeynmt.helpers - delete models/transformer_a/23000.ckpt
2023-05-28 00:53:42,719 - INFO - joeynmt.training - Example #0
2023-05-28 00:53:42,719 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:53:42,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:53:42,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', '<unk>', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', ',', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', '.', '</s>']
2023-05-28 00:53:42,719 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:53:42,719 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:53:42,719 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar <unk> ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> voor <unk> drie miljoen jaar, de <unk> van de <unk> staten.
2023-05-28 00:53:42,719 - INFO - joeynmt.training - Example #1
2023-05-28 00:53:42,719 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:53:42,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:53:42,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'genoeg', 'om', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2023-05-28 00:53:42,719 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:53:42,719 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:53:42,719 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo genoeg om de <unk> van deze <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2023-05-28 00:53:42,719 - INFO - joeynmt.training - Example #2
2023-05-28 00:53:42,719 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:53:42,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:53:42,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2023-05-28 00:53:42,720 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:53:42,720 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:53:42,720 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk> <unk>.
2023-05-28 00:53:42,720 - INFO - joeynmt.training - Example #3
2023-05-28 00:53:42,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:53:42,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:53:42,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:53:42,720 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:53:42,720 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:53:42,720 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:53:42,720 - INFO - joeynmt.training - Example #4
2023-05-28 00:53:42,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:53:42,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:53:42,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2023-05-28 00:53:42,720 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:53:42,720 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:53:42,720 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> van de laatste 25 jaar.
2023-05-28 00:54:02,446 - INFO - joeynmt.training - Epoch  10, Step:    26100, Batch Loss:     1.437665, Batch Acc: 0.534378, Tokens per Sec:     3284, Lr: 0.000300
2023-05-28 00:54:23,461 - INFO - joeynmt.training - Epoch  10, Step:    26200, Batch Loss:     1.432616, Batch Acc: 0.533199, Tokens per Sec:     3193, Lr: 0.000300
2023-05-28 00:54:43,797 - INFO - joeynmt.training - Epoch  10, Step:    26300, Batch Loss:     1.570558, Batch Acc: 0.534810, Tokens per Sec:     3133, Lr: 0.000300
2023-05-28 00:55:05,094 - INFO - joeynmt.training - Epoch  10, Step:    26400, Batch Loss:     1.292444, Batch Acc: 0.535718, Tokens per Sec:     3087, Lr: 0.000300
2023-05-28 00:55:25,859 - INFO - joeynmt.training - Epoch  10, Step:    26500, Batch Loss:     1.565786, Batch Acc: 0.530211, Tokens per Sec:     3220, Lr: 0.000300
2023-05-28 00:55:25,860 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:55:25,860 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:55:55,768 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.34, acc:   0.49, generation: 29.8635[sec], evaluation: 0.0000[sec]
2023-05-28 00:55:55,885 - INFO - joeynmt.helpers - delete models/transformer_a/23500.ckpt
2023-05-28 00:55:55,899 - INFO - joeynmt.training - Example #0
2023-05-28 00:55:55,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:55:55,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:55:55,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', '<unk>', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', '.', '</s>']
2023-05-28 00:55:55,900 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:55:55,900 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:55:55,900 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik <unk> <unk> <unk> om te <unk> dat de <unk> <unk>, die <unk> <unk> <unk> <unk> <unk>, die <unk> <unk> <unk> <unk> <unk>, <unk> <unk> <unk>.
2023-05-28 00:55:55,900 - INFO - joeynmt.training - Example #1
2023-05-28 00:55:55,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:55:55,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:55:55,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', 'laat', 'zien', '.', '</s>']
2023-05-28 00:55:55,900 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:55:55,900 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:55:55,900 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg van de <unk> van de <unk> <unk>, omdat het niet de <unk> van het <unk> laat zien.
2023-05-28 00:55:55,900 - INFO - joeynmt.training - Example #2
2023-05-28 00:55:55,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:55:55,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:55:55,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2023-05-28 00:55:55,900 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:55:55,900 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:55:55,900 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> van ons <unk> <unk>.
2023-05-28 00:55:55,900 - INFO - joeynmt.training - Example #3
2023-05-28 00:55:55,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:55:55,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:55:55,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:55:55,901 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:55:55,901 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:55:55,901 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:55:55,901 - INFO - joeynmt.training - Example #4
2023-05-28 00:55:55,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:55:55,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:55:55,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2023-05-28 00:55:55,901 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:55:55,901 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:55:55,901 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> wat er in de afgelopen 25 jaar is gebeurd.
2023-05-28 00:56:15,147 - INFO - joeynmt.training - Epoch  10, Step:    26600, Batch Loss:     1.618176, Batch Acc: 0.535353, Tokens per Sec:     3364, Lr: 0.000300
2023-05-28 00:56:34,552 - INFO - joeynmt.training - Epoch  10, Step:    26700, Batch Loss:     1.397807, Batch Acc: 0.535028, Tokens per Sec:     3413, Lr: 0.000300
2023-05-28 00:56:54,664 - INFO - joeynmt.training - Epoch  10, Step:    26800, Batch Loss:     1.391773, Batch Acc: 0.537606, Tokens per Sec:     3385, Lr: 0.000300
2023-05-28 00:57:14,657 - INFO - joeynmt.training - Epoch  10, Step:    26900, Batch Loss:     1.737048, Batch Acc: 0.534611, Tokens per Sec:     3250, Lr: 0.000300
2023-05-28 00:57:35,891 - INFO - joeynmt.training - Epoch  10, Step:    27000, Batch Loss:     1.412643, Batch Acc: 0.533903, Tokens per Sec:     3107, Lr: 0.000300
2023-05-28 00:57:35,892 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:57:35,892 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:58:03,918 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.31, acc:   0.49, generation: 27.9816[sec], evaluation: 0.0000[sec]
2023-05-28 00:58:04,018 - INFO - joeynmt.helpers - delete models/transformer_a/24000.ckpt
2023-05-28 00:58:04,037 - INFO - joeynmt.training - Example #0
2023-05-28 00:58:04,037 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2023-05-28 00:58:04,037 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2023-05-28 00:58:04,037 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', 'met', '40', 'procent', 'is', '<unk>', '.', '</s>']
2023-05-28 00:58:04,037 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2023-05-28 00:58:04,037 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2023-05-28 00:58:04,038 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die <unk> <unk>, die <unk> <unk> <unk> met 40 procent is <unk>.
2023-05-28 00:58:04,038 - INFO - joeynmt.training - Example #1
2023-05-28 00:58:04,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2023-05-28 00:58:04,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2023-05-28 00:58:04,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'veel', 'genoeg', 'van', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2023-05-28 00:58:04,038 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2023-05-28 00:58:04,038 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2023-05-28 00:58:04,038 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet veel genoeg van de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2023-05-28 00:58:04,038 - INFO - joeynmt.training - Example #2
2023-05-28 00:58:04,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2023-05-28 00:58:04,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2023-05-28 00:58:04,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2023-05-28 00:58:04,038 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2023-05-28 00:58:04,038 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2023-05-28 00:58:04,038 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2023-05-28 00:58:04,038 - INFO - joeynmt.training - Example #3
2023-05-28 00:58:04,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2023-05-28 00:58:04,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2023-05-28 00:58:04,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2023-05-28 00:58:04,038 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2023-05-28 00:58:04,038 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2023-05-28 00:58:04,038 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2023-05-28 00:58:04,038 - INFO - joeynmt.training - Example #4
2023-05-28 00:58:04,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2023-05-28 00:58:04,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2023-05-28 00:58:04,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2023-05-28 00:58:04,038 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2023-05-28 00:58:04,039 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2023-05-28 00:58:04,039 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> van de afgelopen 25 jaar.
2023-05-28 00:58:23,735 - INFO - joeynmt.training - Epoch  10, Step:    27100, Batch Loss:     1.469060, Batch Acc: 0.538224, Tokens per Sec:     3347, Lr: 0.000300
2023-05-28 00:58:43,844 - INFO - joeynmt.training - Epoch  10, Step:    27200, Batch Loss:     1.358099, Batch Acc: 0.536662, Tokens per Sec:     3280, Lr: 0.000300
2023-05-28 00:59:05,022 - INFO - joeynmt.training - Epoch  10, Step:    27300, Batch Loss:     1.631641, Batch Acc: 0.529822, Tokens per Sec:     3119, Lr: 0.000300
2023-05-28 00:59:17,044 - INFO - joeynmt.training - Epoch  10: total training loss 4113.77
2023-05-28 00:59:17,045 - INFO - joeynmt.training - Training ended after  10 epochs.
2023-05-28 00:59:17,045 - INFO - joeynmt.training - Best validation result (greedy) at step    26000:   5.30 ppl.
2023-05-28 00:59:17,055 - INFO - joeynmt.model - Building an encoder-decoder model...
2023-05-28 00:59:17,095 - INFO - joeynmt.model - Enc-dec model built.
2023-05-28 00:59:17,138 - INFO - joeynmt.helpers - Load model from /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_a/26000.ckpt.
2023-05-28 00:59:17,141 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=None)
2023-05-28 00:59:17,141 - INFO - joeynmt.prediction - Decoding on dev set...
2023-05-28 00:59:17,141 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:59:17,141 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 00:59:46,746 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 29.5602[sec], evaluation: 0.0000[sec]
2023-05-28 00:59:46,747 - INFO - joeynmt.prediction - Translations saved to: /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_a/00026000.hyps.dev.
2023-05-28 00:59:46,747 - INFO - joeynmt.prediction - Decoding on test set...
2023-05-28 00:59:46,747 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2023-05-28 00:59:46,747 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2023-05-28 01:00:31,486 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 44.6685[sec], evaluation: 0.0000[sec]
2023-05-28 01:00:31,487 - INFO - joeynmt.prediction - Translations saved to: /Users/alisonykim/Documents/master_uzh/_23fs_mt/ex/mt-2023-ex05/models/transformer_a/00026000.hyps.test.
